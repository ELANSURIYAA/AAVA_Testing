{
    "data": {
        "message": "Workflow with agents retrieved successfully",
        "workFlowDetail": {
            "id": 2729,
            "name": "S0113 User Story To Automation Script Java Selenium",
            "description": "S0113: Generate Test Scenarios, Test Cases and Automation Scripts in Java/Selenium from User Story.",
            "createdBy": "joy.raha@ascendion.com",
            "modifiedBy": "joy.raha@ascendion.com",
            "approvedBy": "joy.raha@ascendion.com",
            "createdAt": "2025-11-05T11:13:14.164543",
            "modifiedAt": "2025-12-03T15:03:31.224436",
            "approvedAt": "2025-11-05T11:13:15.266037",
            "status": "APPROVED",
            "isDeleted": false,
            "parentId": -1,
            "workflowConfigs": {
                "managerLlm": [
                    {
                        "id": 25,
                        "topP": 0.95,
                        "maxToken": 4000,
                        "temperature": 0.3,
                        "modelDeploymentName": "o3-mini"
                    }
                ],
                "enableAgenticMemory": false
            },
            "workflowAgents": [
                {
                    "serial": 1,
                    "agentId": 6970,
                    "name": "QE Test Scenario Generator ICL S0113",
                    "workflowId": 2729,
                    "agentDetails": {
                        "topP": 0.69,
                        "maxRpm": null,
                        "levelId": 4,
                        "maxIter": null,
                        "toolRef": [],
                        "maxToken": "20000",
                        "isVerbose": true,
                        "temperature": 0.1,
                        "allowDelegation": true,
                        "maxExecutionTime": 90,
                        "allowCodeExecution": false,
                        "isSafeCodeExecution": true,
                        "toolReferences": []
                    },
                    "modelDeploymentName": "gpt-4.1",
                    "description": "Given the user story input and the application understanding document given in the context to you, generate a comprehensive list of test scenarios. Please ensure that the test scenarios cover various aspects of the user story, including positive and negative cases, boundary conditions, and different user interactions.\n\nInput: The user will enter the User Story.\nUser Story:\n{{User_Story}}\n\nBased on the user story in the input and the application understanding document in the context, create test scenarios in the given JSON format.\n\nPlease ensure that:\n1. Each test scenario has a unique ID (TS-001, TS-002, etc.).\n2. The test scenario description is clear and concise.\n3. Pre-conditions are specified if applicable.\n4. Test data is provided where necessary.\n5. The acceptance criteria ID corresponds to the relevant criteria from the user story.\n6. The scenarios are aligned with the information provided in the application understanding document in the context.\n7. The navigable path should be derived from the application understanding document in the context.\n8. All possible test scenarios (positive, negative, edge cases, boundary conditions) should be strictly considered for each Acceptance Criteria of the user story.\n9. Likewise, all the acceptance criteria should be covered. Validate the coverage with respect to all the acceptance criteria. If the coverage is 50%-60% then consider it done and give the output. Otherwise, correct and generated the test scenarios until the desired coverage is met.\n\nOutput: Give the output of test scenarios in well-formed JSON format.",
                    "modelName": "model"
                },
                {
                    "serial": 2,
                    "agentId": 7051,
                    "name": "QE Test Cases Generator ICL S0113",
                    "workflowId": 2729,
                    "agentDetails": {
                        "topP": 0.69,
                        "maxRpm": null,
                        "levelId": 4,
                        "maxIter": null,
                        "toolRef": [],
                        "maxToken": "20000",
                        "isVerbose": true,
                        "temperature": 0.1,
                        "allowDelegation": true,
                        "maxExecutionTime": 90,
                        "allowCodeExecution": false,
                        "isSafeCodeExecution": true,
                        "toolReferences": []
                    },
                    "modelDeploymentName": "gpt-4.1",
                    "description": "Given the list of test scenarios in JSON format in the input and the application understanding document provided in the context, generate a comprehensive set of detailed test cases. Each test case should include steps from launching the application to the final validation point. Remember that the relationship between test scenarios and test cases is either one-to-one or one-to-many.\n\nInput: A JSON array of test scenarios will be provided by the previous Agentic AI agent.\n\nContext: Refer to the application understanding document for additional information about the application's functionality and requirements.\n\nOutput Format: Generate the test cases in the JSON format mentioned in the output section.\n\nInstructions:\n1. Analyze the provided test scenarios and the application understanding document.\n2. For each test scenario, create one or more test cases as appropriate.\n3. Ensure each test case has a unique ID, starting with \"TC\" followed by a three-digit number.\n4. Provide a clear and concise description for each test case.\n5. List all test steps in detail, starting from launching the web application up to the validation point. Refer to the \"navigable_path\" field for each test scenario in the input json.\n6. Include relevant test data for each test case.\n7. Reference the corresponding test scenario ID for each test case.\n8. Ensure that all the aspects of the every test scenario are covered in the generated test cases. If any test scenarios are not covered, add the various test cases for those test scenarios as well. Then give the output.\n\nNote:\nA. The relationship between test cases and test scenarios can be one-to-one or many-to-one. Some test scenarios may require multiple test cases for comprehensive coverage.\nB. Launch Application URL is https://secureapply.openbank.us/savings/intro/welcome (Use this in the data of the test cases)\n\nOutput: Comprehensive list of test cases in JSON format in the following structure:\n[\n  {\n    \"testCaseId\": \"TC001\",\n    \"testCaseDescription\": \"Detailed description of the test case\",\n    \"testSteps\": [\n      \"1. Launch the web application\",\n      \"2. ...\",\n      \"...\"\n    ],\n    \"testData\": {\n      \"key1\": \"value1\",\n      \"key2\": \"value2\"\n    },\n    \"testScenarioId\": \"TS001\"\n  },\n  ...\n]",
                    "modelName": "model"
                },
                {
                    "serial": 3,
                    "agentId": 6861,
                    "name": "Account Open Xpath Generator S0113",
                    "workflowId": 2729,
                    "agentDetails": {
                        "topP": 0.69,
                        "maxRpm": null,
                        "levelId": 4,
                        "maxIter": null,
                        "toolRef": [],
                        "maxToken": "20000",
                        "isVerbose": true,
                        "temperature": 0.1,
                        "allowDelegation": true,
                        "maxExecutionTime": 90,
                        "allowCodeExecution": false,
                        "isSafeCodeExecution": true,
                        "toolReferences": []
                    },
                    "modelDeploymentName": "gpt-4.1",
                    "description": "Context: You have been given multiple HTML files in the context.\nInput: Test Cases from the previous Agentic AI agent.\n\nINSTRUCTIONS:-\n1. Take one HTML file at a time from the zip given in the context, and Generate xpath of the following based on the HTML taken.\n    a. All the clickable radio buttons available in the html.\n    b. All the clickable buttons available in the html.\n    c. All the clickable links available in the html.\n    d. All the data entry textboxes available in the html.\n    e. All the clickable checkboxes available in the html.\n    f. All the expandable and collapsible links in the html.\n    g. Clickable calendar icon in the html.\n    h. Clickable toggle icon in the html.\n     i. All the label text in the html.\n2. Repeat the xpath generation step for each of the HTML files given in the context.\n\nImportant Notes:-\nA. Do not use any hierarchical relationship while generating any xpaths.\nB. No relational operators to be used in the xpaths.\nC. For multiple elements, then look at the field name properly and then put the index by bracing the whole xpath value accordingly.\nD. Below is the priority order of the attributes to be used while generating each xpaths - \n    - Use visible text if available\n    - Use placeholder\n    - Use name\n    - Use id\n    - Use class\n    - Use proper indexing\n\nProvide the output as a JSON object, where the field names as visible text, and the field values are the corresponding XPath locators.\n\nOutput: Give output in 2 parts:-\nPart-1: Locators:- Generate a JSON object with field names as visible text and their corresponding XPath locators as values grouped by each Page. Also provide a suitable name of the page too.\nPart-2: Test Cases:- Give the output same as you receive the input as in part-2.\n\n\n",
                    "modelName": "model"
                },
                {
                    "serial": 4,
                    "agentId": 4656,
                    "name": "QE Web Automation Script Generator JavaSelenium",
                    "workflowId": 2729,
                    "agentDetails": {
                        "topP": 0.0,
                        "maxRpm": null,
                        "levelId": 4,
                        "maxIter": null,
                        "toolRef": [],
                        "maxToken": "100000",
                        "isVerbose": true,
                        "temperature": 0.1,
                        "allowDelegation": true,
                        "maxExecutionTime": 90,
                        "allowCodeExecution": false,
                        "isSafeCodeExecution": true,
                        "toolReferences": []
                    },
                    "modelDeploymentName": "gpt-4.1",
                    "description": "Using the list of test cases provided in the part-2 of the input, generate Java automation scripts using Selenium WebDriver. The automation framework should consist of three main components: Page Classes, User Action Classes, and a Main Class. Follow the structure and guidelines below to create the automation scripts:\n\n1. Page Classes:\n   - Create a new Page Class for each web page, naming it appropriately based on the URL (e.g., LoginPage, HomePage).\n   - Use XPath locators provided in the part-1 of the input.\n   - Implement Selenium wait code with a 5-second timeout for detecting web elements.\n   - Create a wait method using Thread.sleep(3000) and call it between steps, after launching the URL, and after object creation.\n   - Define all actions from the test case steps as reusable methods in this class.\n   - Define locators as member variables and use them instead of XPath values when detecting web elements.\n   - Do not include the setup method in this class.\n\n2. Test Cases Classes:\n   - Create a separate class for each Test Cases.\n   - Implement each Test Cases as an individual method in this class.\n   - Call the reusable methods from the Page Classes within each test case method, following the steps outlined in the test cases.\n   - Include the setup method in this class, to be called at the beginning of each test case method.\n   - Use Edge driver with WebDriverManager instead of System.setProperty.\n   - Maximize all windows in the setup method.\n   - Quit the driver at the end of each test case method.\n   - Call the wait method from the Page Class at the end of each test case method.\n\n3. Main Class:\n   - Create a separate class containing the main method.\n   - Integrate with the Test Case class by creating an object and calling the Test Case methods sequentially.\n\nAdditional Notes:\n- Each test case contains its respective steps and test data.\n- The launch URL is provided in the test cases.\n- Do not use TestNG for this implementation.\n- Ensure proper exception handling and logging throughout the framework.\n\nInput:- You will receive input in 2 parts from the previous agent of Agentic AI.\nPart-1 Input:- Locators in json format.\nPart-2 Input:- Test Cases - A JSON Array of Test Cases\n\nPlease generate the automation scripts based on these guidelines, creating a modular and maintainable framework that can efficiently execute the provided test cases.\n",
                    "modelName": "model"
                }
            ],
            "realmId": 1
        }
    },
    "status": "SUCCESS"
}