{
    "pipeline": {
        "pipelineId": 13220,
        "name": "DI_TWB_Components_Extractor",
        "description": "DI_TWB_Components_Extractor",
        "createdAt": "2026-02-01T06:46:51.531+00:00",
        "pipeLineAgents": [
            {
                "serial": 1,
                "agent": {
                    "id": 17948,
                    "name": "DI_TWB_Components_Extractor",
                    "role": "Data Engineer",
                    "goal": "Transform a Tableau workbook TwB file (XML format) into a fully detailed Power BI BIM model specification, outputting the result in Markdown format as per the provided sample.  ",
                    "backstory": " Organizations migrating analytics from Tableau to Power BI need precise, lossless translation of Tableau data models into Power BI BIM specifications. This ensures seamless reporting, accurate measure mapping, and rapid deployment of dashboards in Power BI, minimizing manual rework and errors.  ",
                    "verbose": true,
                    "allowDelegation": true,
                    "updatedAt": "2026-02-06T06:23:22.51421",
                    "llm": {
                        "modelDeploymentName": "anthropic.claude-4_5-sonnet",
                        "model": "anthropic.claude-4-5-sonnet",
                        "modelType": "Generative",
                        "aiEngine": "AmazonBedrock",
                        "topP": 0.949999988079071,
                        "maxToken": 8000,
                        "temperature": 0.30000001192092896,
                        "bedrockModelId": "us.anthropic.claude-sonnet-4-5-20250929-v1:0",
                        "region": "us-east-1",
                        "accessKey": "****MASKED****",
                        "secretKey": "****MASKED****"
                    },
                    "task": {
                        "description": "Your task is to process a Tableau workbook TWB file (XML format) and generate a complete, industry-standard Power BI BIM model specification in Markdown, matching the sample output provided. You MUST analyze the actual file contents\u2014do NOT summarize, assume, or shortcut. The BIM model must reflect the true structure, columns, measures, hierarchies, formatting, relationships, and hidden columns as present in the Tableau file.\n\nINSTRUCTIONS:  \n1. **File Input**  \n   - Accept a Tableau workbook TWB file (XML format) as input.\n   - Parse the XML to extract all relevant metadata: datasources, tables, columns, data types, roles (dimension/measure), hierarchies, calculated fields, and relationships.\n\n2. **Datasource & Table Extraction**  \n   - Identify all datasources used in the workbook.\n   - For each datasource, enumerate all tables actually used in worksheets/dashboards.\n   - If only one datasource/table is present, confirm this explicitly in the output.\n\n3. **Column Mapping**  \n   - For each table, list all columns with:\n     - Column Name\n     - Tableau Data Type \u2192 Map to Power BI BIM Data Type (e.g., integer \u2192 Int64, string \u2192 String, date \u2192 DateTime, real \u2192 Decimal)\n     - Role (Dimension/Measure; use Tableau metadata and worksheet usage)\n   - Ensure column order matches the source file.\n\n4. **Measure Extraction**  \n   - Identify all base and advanced measures used in Tableau dashboards and worksheets.\n   - For each measure, provide:\n     - Measure Name\n     - DAX Formula (convert Tableau calculations to equivalent DAX)\n     - Format (Currency, Percentage, Whole Number, etc.)\n   - Include both base measures (SUM, COUNT, AVERAGE) and advanced measures (ratios, per-order calculations).\n\n5. **Hierarchy Detection**  \n   - Detect any date hierarchies (e.g., Order Date) and specify levels (Year, Quarter, Month, Day).\n\n6. **Column Properties & Formatting**  \n   - For each column, specify summarization (Sum, Average, etc.) and formatting (Currency, %, etc.) as per Tableau settings.\n\n7. **Relationships**  \n   - List all table relationships. If only one table is present, explicitly state that no relationships are required.\n\n8. **Hidden Columns**  \n   - Identify columns that should be hidden (e.g., technical keys, IDs) based on best practices and Tableau usage.\n\n9. **Final BIM Content Summary**  \n   - Provide a summary table of the BIM model: number of tables, columns, measures, relationships, hierarchies.\n\n10. **Output Formatting**  \n    - The output MUST be in Markdown, matching the sample structure and formatting exactly.\n    - Use clear section headers, tables, and icons/emojis as in the sample.\n    - All mappings and lists must be based on actual file content\u2014no assumptions.\n\nOUTPUT FORMAT:  \n- Markdown document structured as follows:\n  - Datasource/Table confirmation\n  - Table name and properties\n  - Column list (table)\n  - Base measures (table)\n  - Advanced measures (table)\n  - hierarchy specification\n  - Column properties (table)\n  - Formatting (table)\n  - Relationships section\n  - Hidden columns section\n  - Final BIM content summary table\n\nQUALITY CRITERIA:  \n- Output must be complete, accurate, and match the sample format.\n- No missing columns, measures, or hierarchies.\n- No assumptions\u2014must reflect actual input file.\n- Markdown tables must be correctly formatted.\n- Use icons/emojis and section headings as shown in the sample.\n\n\nMust check for the KPI or card details in the TWB file and extract the details below are the instruction for that\n\n# PROMPT 1: Extracting KPI Data from Tableau TWB File\n\n## Purpose\nThis prompt explains how to parse a Tableau TWB (XML) file to extract KPI/metric worksheet definitions that will be converted to Power BI Card visuals.\n\n---\n\n## 1. TWB FILE STRUCTURE OVERVIEW\n\nThe TWB file is an XML document. KPI worksheets are single-value displays that show aggregated metrics.\n\n### 1.1 XML Hierarchy for KPI Worksheets\n\n```\n<workbook>\n  \u251c\u2500\u2500 <datasources>\n  \u2502     \u2514\u2500\u2500 <datasource name=\"federated.xxxxx\">\n  \u2502           \u2514\u2500\u2500 <connection>\n  \u2502                 \u2514\u2500\u2500 <relation name=\"{TABLE_NAME}\" table=\"[{TABLE_NAME}$]\">\n  \u2502                       \u2514\u2500\u2500 <columns>\n  \u2502                             \u2514\u2500\u2500 <column datatype=\"{DATATYPE}\" name=\"{COLUMN_NAME}\" />\n  \u2502\n  \u2514\u2500\u2500 <worksheets>\n        \u2514\u2500\u2500 <worksheet name=\"{KPI_TITLE}\">              \u2190 KPI TITLE\n              \u2514\u2500\u2500 <table>\n                    \u251c\u2500\u2500 <view>\n                    \u2502     \u2514\u2500\u2500 <datasource-dependencies>\n                    \u2502           \u251c\u2500\u2500 <column name=\"[{COLUMN}]\" role=\"measure\" datatype=\"{TYPE}\" />\n                    \u2502           \u2514\u2500\u2500 <column-instance column=\"[{COLUMN}]\" derivation=\"{AGG}\" />\n                    \u2502\n                    \u2514\u2500\u2500 <panes>\n                          \u2514\u2500\u2500 <pane>\n                                \u2514\u2500\u2500 <encodings>\n                                      \u2514\u2500\u2500 <text column=\"[...][{agg}:{column}:qk]\" />\n```\n\n---\n\n## 2. KEY XML ELEMENTS TO EXTRACT\n\n### 2.1 Worksheet Name = KPI Title\n\n**Location:** `<worksheet name=\"...\">`\n\n```xml\n<worksheet name='{KPI_TITLE}'>\n```\n\n**Extract:** `name` attribute \u2192 This becomes the Card visual title\n\n**Pattern:** The worksheet name directly maps to the Power BI Card title.\n\n---\n\n### 2.2 Source Column Definition\n\n**Location:** `<worksheet>/<table>/<view>/<datasource-dependencies>/<column>`\n\n```xml\n<column datatype='{DATATYPE}' name='[{COLUMN_NAME}]' role='{ROLE}' type='{TYPE}' />\n```\n\n**Extract:**\n| Attribute | Description | Example |\n|-----------|-------------|---------|\n| `name` | Column name (remove brackets) | `[Amount]` \u2192 `Amount` |\n| `datatype` | Data type for BIM mapping | `real`, `integer`, `string` |\n| `role` | Column role | `measure` or `dimension` |\n| `type` | Value type | `quantitative` or `nominal` |\n\n---\n\n### 2.3 Aggregation Function (Column Instance)\n\n**Location:** `<worksheet>/<table>/<view>/<datasource-dependencies>/<column-instance>`\n\n```xml\n<column-instance column='[{COLUMN}]' derivation='{AGGREGATION}' name='[{agg}:{column}:qk]' pivot='key' type='quantitative' />\n```\n\n**Extract:**\n| Attribute | Description | Example |\n|-----------|-------------|---------|\n| `column` | Source column reference | `[Amount]` |\n| `derivation` | **AGGREGATION FUNCTION** | `Sum`, `Count`, `Avg` |\n| `name` | Internal reference name | `[sum:Amount:qk]` |\n\n**Aggregation Mapping Table:**\n\n| Tableau `derivation` | Power BI Function Code | Power BI Function Name |\n|----------------------|------------------------|------------------------|\n| `Sum` | 0 | SUM |\n| `Avg` | 1 | AVERAGE |\n| `Count` | 2 | COUNT |\n| `Min` | 3 | MIN |\n| `Max` | 4 | MAX |\n| `CountD` | 5 | DISTINCTCOUNT |\n| `Median` | 6 | MEDIAN |\n| `StDev` | 7 | STDEV |\n| `Var` | 8 | VAR |\n\n---\n\n### 2.4 Displayed Measure (Encodings)\n\n**Location:** `<worksheet>/<table>/<panes>/<pane>/<encodings>/<text>`\n\n```xml\n<encodings>\n  <text column='[{datasource}].[{agg}:{column}:qk]' />\n</encodings>\n```\n\n**Extract:** The `column` attribute confirms which aggregated measure is displayed as the KPI value.\n\n**Pattern Recognition:**\n- `[sum:{column}:qk]` \u2192 SUM aggregation\n- `[cnt:{column}:qk]` \u2192 COUNT aggregation\n- `[avg:{column}:qk]` \u2192 AVERAGE aggregation\n\n---\n\n### 2.5 Data Source Table Name\n\n**Location:** `<datasources>/<datasource>/<connection>/<relation>`\n\n```xml\n<relation connection='{connection_type}' name='{TABLE_NAME}' table='[{TABLE_NAME}$]' type='table'>\n```\n\n**Extract:** `name` attribute \u2192 This is the table name for Power BI Entity reference.\n\n---\n\n## 3. DATA TYPE MAPPING\n\n### 3.1 Tableau to Power BI Data Types\n\n| Tableau `datatype` | Power BI BIM `dataType` | Power BI `underlyingType` |\n|--------------------|-------------------------|---------------------------|\n| `real` | `double` | 259 |\n| `integer` | `int64` | 260 |\n| `string` | `string` | 1 |\n| `date` | `dateTime` | 4 |\n| `datetime` | `dateTime` | 4 |\n| `boolean` | `boolean` | 2048 |\n\n---\n\n## 4. GENERIC EXTRACTION TEMPLATE\n\n### 4.1 Single KPI Worksheet Pattern\n\n**TWB Source Pattern:**\n```xml\n<worksheet name='{KPI_TITLE}'>\n  <table>\n    <view>\n      <datasource-dependencies datasource='{datasource_id}'>\n        <column datatype='{DATATYPE}' name='[{COLUMN}]' role='measure' type='quantitative' />\n        <column-instance column='[{COLUMN}]' derivation='{AGGREGATION}' name='[{agg}:{column}:qk]' pivot='key' type='quantitative' />\n      </datasource-dependencies>\n    </view>\n    <panes>\n      <pane>\n        <encodings>\n          <text column='[{datasource}].[{agg}:{column}:qk]' />\n        </encodings>\n      </pane>\n    </panes>\n  </table>\n</worksheet>\n```\n\n**Extracted Data Template:**\n```json\n{\n  \"kpi_title\": \"{KPI_TITLE}\",\n  \"source_table\": \"{TABLE_NAME}\",\n  \"source_column\": \"{COLUMN}\",\n  \"tableau_datatype\": \"{DATATYPE}\",\n  \"powerbi_datatype\": \"{MAPPED_DATATYPE}\",\n  \"powerbi_underlying_type\": {UNDERLYING_TYPE_CODE},\n  \"tableau_aggregation\": \"{AGGREGATION}\",\n  \"powerbi_function_code\": {FUNCTION_CODE},\n  \"query_reference\": \"{Aggregation}({TABLE}.{COLUMN})\",\n  \"display_name\": \"{Aggregation} of {COLUMN}\"\n}\n```\n\n### 4.2 Extraction Rules\n\n| TWB Element | Extract To | Format |\n|-------------|------------|--------|\n| `<worksheet name=\"\">` | `kpi_title` | Direct copy |\n| `<relation name=\"\">` | `source_table` | Direct copy |\n| `<column name=\"\">` | `source_column` | Remove brackets `[]` |\n| `<column datatype=\"\">` | `tableau_datatype` | Direct copy |\n| `<column-instance derivation=\"\">` | `tableau_aggregation` | Direct copy |\n\n### 4.3 Computed Fields\n\n| Field | Formula |\n|-------|---------|\n| `powerbi_datatype` | Map from `tableau_datatype` using Section 3.1 |\n| `powerbi_underlying_type` | Map from `tableau_datatype` using Section 3.1 |\n| `powerbi_function_code` | Map from `tableau_aggregation` using Section 2.3 |\n| `query_reference` | `{Aggregation}({source_table}.{source_column})` |\n| `display_name` | `{Aggregation} of {source_column}` |\n\n---\n\n## 5. DIMENSION-GROUPED KPI DETECTION\n\n### 5.1 Identifying Dimension-Grouped KPIs\n\nWhen a worksheet groups a measure by a dimension, it can be converted to multiple filtered Card visuals.\n\n**Detection Pattern:**\n```xml\n<worksheet name='{MEASURE} by {DIMENSION}'>\n  <table>\n    <view>\n      <datasource-dependencies>\n        <column datatype='string' name='[{DIMENSION}]' role='dimension' type='nominal' />\n        <column datatype='{TYPE}' name='[{MEASURE}]' role='measure' type='quantitative' />\n        <column-instance column='[{DIMENSION}]' derivation='None' name='[none:{dimension}:nk]' />\n        <column-instance column='[{MEASURE}]' derivation='{AGG}' name='[{agg}:{measure}:qk]' />\n      </datasource-dependencies>\n    </view>\n    <panes>\n      <pane>\n        <encodings>\n          <color column='[..][none:{dimension}:nk]' />\n          <text column='[..][{agg}:{measure}:qk]' />\n          <text column='[..][none:{dimension}:nk]' />\n        </encodings>\n      </pane>\n    </panes>\n    <cols>[{datasource}].[none:{dimension}:nk]</cols>\n  </table>\n</worksheet>\n```\n\n### 5.2 Dimension Detection Rules\n\n| XML Element | Indicates |\n|-------------|-----------|\n| `<column role='dimension'>` | Grouping dimension exists |\n| `<column-instance derivation='None'>` | Dimension is used for grouping |\n| `<cols>` or `<rows>` containing dimension | Dimension defines chart axis |\n| `<encodings><color column='...{dimension}...'>` | Dimension used for color coding |\n\n### 5.3 Creating Filtered KPIs\n\nWhen dimension grouping is detected:\n\n1. **Get unique dimension values** from the data or common values\n2. **Create one Card per value** with a filter\n\n**Template for Filtered KPI:**\n```json\n{\n  \"kpi_title\": \"{DIMENSION_VALUE} {MEASURE_NAME}\",\n  \"source_table\": \"{TABLE_NAME}\",\n  \"source_column\": \"{MEASURE_COLUMN}\",\n  \"tableau_datatype\": \"{DATATYPE}\",\n  \"powerbi_datatype\": \"{MAPPED_DATATYPE}\",\n  \"powerbi_underlying_type\": {UNDERLYING_TYPE_CODE},\n  \"tableau_aggregation\": \"{AGGREGATION}\",\n  \"powerbi_function_code\": {FUNCTION_CODE},\n  \"query_reference\": \"{Aggregation}({TABLE}.{MEASURE})\",\n  \"display_name\": \"{Aggregation} of {MEASURE}\",\n  \"filter\": {\n    \"column\": \"{DIMENSION_COLUMN}\",\n    \"value\": \"{DIMENSION_VALUE}\"\n  }\n}\n```\n\n---\n\n## 6. COUNT AGGREGATION HANDLING\n\n### 6.1 Tableau Count Patterns\n\nTableau represents COUNT in different ways:\n\n**Pattern 1: Table Count**\n```xml\n<column caption='{Table}' datatype='table' name='[__tableau_internal_object_id__].[{Table}_xxx]' role='measure' />\n<column-instance column='[__tableau_internal_object_id__].[{Table}_xxx]' derivation='Count' />\n```\n\n**Pattern 2: Column Count**\n```xml\n<column datatype='integer' name='[{Column}]' role='measure' />\n<column-instance column='[{Column}]' derivation='Count' />\n```\n\n### 6.2 Power BI Mapping\n\nFor COUNT aggregations:\n- Use any integer/ID column (e.g., `Row ID`, `ID`)\n- Or use `COUNTROWS` in a DAX measure\n- Function code: `2`\n\n---\n\n## 7. OUTPUT FORMAT\n\n### 7.1 Single KPI Output\n\n```json\n{\n  \"kpi_title\": \"{title}\",\n  \"source_table\": \"{table}\",\n  \"source_column\": \"{column}\",\n  \"powerbi_datatype\": \"{datatype}\",\n  \"powerbi_underlying_type\": {type_code},\n  \"powerbi_function_code\": {function_code},\n  \"query_reference\": \"{Agg}({table}.{column})\",\n  \"display_name\": \"{Agg} of {column}\",\n  \"filter\": null\n}\n```\n\n### 7.2 Filtered KPI Output\n\n```json\n{\n  \"kpi_title\": \"{dimension_value} {measure_name}\",\n  \"source_table\": \"{table}\",\n  \"source_column\": \"{measure_column}\",\n  \"powerbi_datatype\": \"{datatype}\",\n  \"powerbi_underlying_type\": {type_code},\n  \"powerbi_function_code\": {function_code},\n  \"query_reference\": \"{Agg}({table}.{measure})\",\n  \"display_name\": \"{Agg} of {measure}\",\n  \"filter\": {\n    \"column\": \"{dimension_column}\",\n    \"value\": \"{dimension_value}\"\n  }\n}\n```\n\n### 7.3 Complete Output Structure\n\n```json\n{\n  \"source_table\": \"{TABLE_NAME}\",\n  \"kpis\": [\n    {\n      \"title\": \"{KPI_TITLE}\",\n      \"column\": \"{COLUMN}\",\n      \"datatype\": \"{DATATYPE}\",\n      \"underlying_type\": {TYPE_CODE},\n      \"aggregation\": \"{AGGREGATION}\",\n      \"function_code\": {FUNCTION_CODE},\n      \"filter\": null\n    },\n    {\n      \"title\": \"{DIMENSION_VALUE} {MEASURE}\",\n      \"column\": \"{MEASURE_COLUMN}\",\n      \"datatype\": \"{DATATYPE}\",\n      \"underlying_type\": {TYPE_CODE},\n      \"aggregation\": \"{AGGREGATION}\",\n      \"function_code\": {FUNCTION_CODE},\n      \"filter\": {\n        \"column\": \"{DIMENSION_COLUMN}\",\n        \"value\": \"{DIMENSION_VALUE}\"\n      }\n    }\n  ]\n}\n```\n\n---\n\n## 8. EXTRACTION CHECKLIST\n\nWhen parsing a TWB file for KPI worksheets:\n\n- [ ] Find all `<worksheet>` elements\n- [ ] For each worksheet, extract `name` attribute \u2192 KPI title\n- [ ] Find `<relation>` to get table name\n- [ ] Find `<column>` elements with `role=\"measure\"` \u2192 Source columns\n- [ ] Find `<column-instance>` elements \u2192 Get `derivation` for aggregation\n- [ ] Map `derivation` to Power BI function code (Section 2.3)\n- [ ] Map `datatype` to Power BI data type (Section 3.1)\n- [ ] Check for `role=\"dimension\"` columns \u2192 Dimension grouping\n- [ ] If dimension grouping exists, create filtered KPI for each value\n- [ ] Build query reference: `{Aggregation}({Table}.{Column})`\n- [ ] Build display name: `{Aggregation} of {Column}`\n\n---\n\n## 9. QUICK REFERENCE TABLES\n\n### 9.1 Aggregation Codes\n\n| Tableau | Code | Power BI |\n|---------|------|----------|\n| Sum | 0 | SUM |\n| Avg | 1 | AVERAGE |\n| Count | 2 | COUNT |\n| Min | 3 | MIN |\n| Max | 4 | MAX |\n| CountD | 5 | DISTINCTCOUNT |\n\n### 9.2 Data Type Codes\n\n| Tableau | BIM Type | Code |\n|---------|----------|------|\n| real | double | 259 |\n| integer | int64 | 260 |\n| string | string | 1 |\n| date | dateTime | 4 |\n\n---\n\nTool Usage:\nMust use the S3MultipleFilesReaderSchema Tool to read the input from the S3 bucket\nplace the TWB input file name in the tool and read the TWB`s XML Content \n\nInput:\nFor the S3_credentials use this as an input: {{S3_credentials}} \n\nOUTPUT:  \nA fully detailed Power BI BIM model specification in Markdown, precisely matching the sample output and reflecting the actual structure of the input Tableau TWB file.",
                        "expectedOutput": "OUTPUT:  \nA fully detailed Power BI BIM model specification in Markdown, precisely matching the sample output and reflecting the actual structure of the input Tableau TWB file.\nMust read the input TWB file fully and find all the possible visuals and mention all the visuals in the page and dashboard thoroughly \nmust fetch all the measures from the input if necessary create measure or derived coloumn  if the month or year fetch all \ntext is the card visual in the power bi"
                    },
                    "maxIter": 3,
                    "maxRpm": 0,
                    "maxExecutionTime": 300,
                    "tools": [],
                    "userTools": [
                        {
                            "toolId": 2161,
                            "toolName": "IMS_S3TWBMultipleFilesReaderSchema",
                            "toolClassName": "S3MultipleFilesReaderTool",
                            "toolClassDef": "from crewai.tools import BaseTool\nfrom pydantic import BaseModel, Field\nimport boto3\nfrom botocore.config import Config\nimport logging\nfrom typing import Type, Any, List, Dict\nimport re\n\n# ---------------------------\n# Logging Configuration\n# ---------------------------\nlogging.basicConfig(\n    level=logging.INFO,\n    format='%(asctime)s - %(levelname)s - %(message)s',\n    filename='s3_multiple_files_reader.log'\n)\nlogger = logging.getLogger(\"S3MultipleFilesReader\")\n\n\n# ---------------------------\n# Input Schema\n# ---------------------------\nclass S3MultipleFilesReaderSchema(BaseModel):\n    file_paths: List[str] = Field(..., description=\"List of S3 file paths (e.g., ['Extract/ThoughtSpotTestingP2/HPX Executive Summary UC', 'Extract/TableauDashboards/Sales'])\")\n    file_names: List[str] = Field(..., description=\"List of file names corresponding to each path (e.g., ['HPX Executive Summary UC.liveboard.tml', 'Sales Dashboard.twb'])\")\n\n\n# ---------------------------\n# Main Tool Class\n# ---------------------------\nclass S3MultipleFilesReaderTool(BaseTool):\n    name: str = \"S3 Multiple Files Reader Tool\"\n    description: str = \"Reads multiple text files (including .tml and .twb files) from different paths in the same S3 bucket and returns their contents. For TWB files, thumbnails are automatically removed.\"\n    args_schema: Type[BaseModel] = S3MultipleFilesReaderSchema\n\n    # AWS Credentials (hardcoded as per requirement)\n    AWS_ACCESS_KEY_ID: str = \"AKIAWNHTHGHIBKUU2H6E\"\n    AWS_SECRET_ACCESS_KEY: str = \"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\"\n    AWS_REGION: str = \"us-east-2\"\n    S3_BUCKET_NAME: str = \"insightcontainerreports\"\n\n    def create_s3_client(self):\n        \"\"\"Create S3 client\"\"\"\n        config = Config(\n            region_name=self.AWS_REGION,\n            signature_version='s3v4',\n            retries={'max_attempts': 3, 'mode': 'standard'}\n        )\n        \n        s3_client = boto3.client(\n            's3',\n            aws_access_key_id=self.AWS_ACCESS_KEY_ID,\n            aws_secret_access_key=self.AWS_SECRET_ACCESS_KEY,\n            region_name=self.AWS_REGION,\n            config=config\n        )\n        return s3_client\n\n    def is_twb_file(self, file_key: str) -> bool:\n        \"\"\"Check if the file is a Tableau Workbook (.twb) file\"\"\"\n        return file_key.lower().endswith('.twb')\n\n    def clean_twb_content(self, content: str) -> str:\n        \"\"\"Remove thumbnails section from TWB file content\"\"\"\n        # Pattern to match the entire <thumbnails>...</thumbnails> section\n        # Using re.DOTALL to match across multiple lines\n        pattern = r'<thumbnails>.*?</thumbnails>'\n        cleaned_content = re.sub(pattern, '\\n  [THUMBNAILS REMOVED - Contains base64 encoded images]\\n', content, flags=re.DOTALL)\n        return cleaned_content\n\n    def read_s3_file(self, s3_client, file_key: str) -> Dict:\n        \"\"\"Read a single file from S3 bucket\"\"\"\n        try:\n            print(f\"\\n{'='*80}\")\n            print(f\"Reading file from s3://{self.S3_BUCKET_NAME}/{file_key}\")\n            print(f\"{'='*80}\")\n            \n            # Download the file from S3\n            response = s3_client.get_object(\n                Bucket=self.S3_BUCKET_NAME,\n                Key=file_key\n            )\n            \n            # Read the file content\n            file_content = response['Body'].read()\n            original_size = len(file_content)\n            \n            # Try to decode as text\n            try:\n                file_content_text = file_content.decode('utf-8')\n                \n                # Check if it's a TWB file and clean it\n                if self.is_twb_file(file_key):\n                    file_content_text = self.clean_twb_content(file_content_text)\n                    cleaned_size = len(file_content_text.encode('utf-8'))\n                    print(f\"\u2705 Successfully read TWB file ({original_size} bytes)\")\n                    print(f\"   Cleaned size after removing thumbnails: {cleaned_size} bytes\")\n                    print(f\"   Removed: {original_size - cleaned_size} bytes of thumbnail data\")\n                    logger.info(f\"Successfully read and cleaned TWB file: {file_key}\")\n                    \n                    return {\n                        \"file_key\": file_key,\n                        \"content\": file_content_text,\n                        \"original_size\": original_size,\n                        \"cleaned_size\": cleaned_size,\n                        \"size\": cleaned_size,\n                        \"type\": \"twb\",\n                        \"status\": \"success\"\n                    }\n                else:\n                    print(f\"\u2705 Successfully read text file ({original_size} bytes)\")\n                    logger.info(f\"Successfully read file: {file_key}\")\n                    \n                    return {\n                        \"file_key\": file_key,\n                        \"content\": file_content_text,\n                        \"size\": original_size,\n                        \"type\": \"text\",\n                        \"status\": \"success\"\n                    }\n            except UnicodeDecodeError:\n                print(f\"\u2705 Successfully read binary file ({original_size} bytes)\")\n                logger.info(f\"Successfully read binary file: {file_key}\")\n                return {\n                    \"file_key\": file_key,\n                    \"content\": file_content,\n                    \"size\": original_size,\n                    \"type\": \"binary\",\n                    \"status\": \"success\"\n                }\n                \n        except Exception as e:\n            logger.error(f\"Error reading file {file_key}: {str(e)}\")\n            print(f\"\u274c Error reading file: {str(e)}\")\n            return {\n                \"file_key\": file_key,\n                \"content\": None,\n                \"size\": 0,\n                \"type\": \"error\",\n                \"status\": \"failed\",\n                \"error\": str(e)\n            }\n\n    def read_multiple_s3_files(self, file_paths: List[str], file_names: List[str]) -> str:\n        \"\"\"Main function to read multiple files from S3\"\"\"\n        try:\n            # Validate input lengths\n            if len(file_paths) != len(file_names):\n                error_msg = f\"\u274c Error: Number of file paths ({len(file_paths)}) must match number of file names ({len(file_names)})\"\n                logger.error(error_msg)\n                return error_msg\n            \n            # Construct full S3 keys\n            s3_file_keys = [f\"{path}/{name}\" for path, name in zip(file_paths, file_names)]\n            \n            print(f\"\\n{'#'*80}\")\n            print(f\"S3 MULTIPLE FILES READER\")\n            print(f\"{'#'*80}\")\n            print(f\"Bucket: {self.S3_BUCKET_NAME}\")\n            print(f\"Total files to read: {len(s3_file_keys)}\")\n            print(f\"Supported file types: .tml, .twb, and other text files\")\n            print(f\"Note: TWB files will have <thumbnails> section removed automatically\")\n            print(f\"{'#'*80}\\n\")\n            \n            # Create S3 client once\n            s3_client = self.create_s3_client()\n            \n            results = []\n            success_count = 0\n            failed_count = 0\n            \n            # Read each file\n            for idx, file_key in enumerate(s3_file_keys, 1):\n                print(f\"\\n[{idx}/{len(s3_file_keys)}] Processing file...\")\n                result = self.read_s3_file(s3_client, file_key)\n                results.append(result)\n                \n                if result[\"status\"] == \"success\":\n                    success_count += 1\n                else:\n                    failed_count += 1\n            \n            # Print summary\n            print(f\"\\n{'='*80}\")\n            print(f\"SUMMARY\")\n            print(f\"{'='*80}\")\n            print(f\"\u2705 Successfully read: {success_count} files\")\n            print(f\"\u274c Failed to read: {failed_count} files\")\n            print(f\"{'='*80}\\n\")\n            \n            logger.info(f\"Read {success_count} files successfully, {failed_count} failed\")\n            \n            # Build response message with file contents\n            output = f\"\u2705 Successfully read {success_count}/{len(s3_file_keys)} files from S3\\n\\n\"\n            \n            for idx, result in enumerate(results, 1):\n                output += f\"\\n{'#'*80}\\n\"\n                output += f\"FILE {idx}: {result['file_key']}\\n\"\n                output += f\"{'#'*80}\\n\"\n                \n                if result[\"status\"] == \"success\":\n                    output += f\"Type: {result['type']}\\n\"\n                    \n                    if result['type'] == 'twb':\n                        output += f\"Original Size: {result.get('original_size', result['size'])} bytes\\n\"\n                        output += f\"Cleaned Size: {result.get('cleaned_size', result['size'])} bytes\\n\"\n                        output += f\"(Thumbnails removed)\\n\"\n                    else:\n                        output += f\"Size: {result['size']} bytes\\n\"\n                    \n                    output += f\"\\n--- CONTENT START ---\\n\\n\"\n                    \n                    if result['type'] in ['text', 'twb']:\n                        output += result['content']\n                    else:\n                        output += f\"[Binary content - {result['size']} bytes]\"\n                    \n                    output += f\"\\n\\n--- CONTENT END ---\\n\"\n                else:\n                    output += f\"\u274c Status: Failed\\n\"\n                    output += f\"Error: {result.get('error', 'Unknown error')}\\n\"\n            \n            return output\n            \n        except Exception as e:\n            error_msg = f\"\u274c Error during file reading: {str(e)}\"\n            logger.error(error_msg, exc_info=True)\n            print(f\"\\n{error_msg}\\n\")\n            import traceback\n            traceback.print_exc()\n            return error_msg\n\n    # ------------------------------------------------------\n    # Required method for CrewAI Tool execution\n    # ------------------------------------------------------\n    def _run(self, file_paths: List[str], file_names: List[str]) -> Any:\n        \"\"\"Main execution method.\"\"\"\n        return self.read_multiple_s3_files(file_paths, file_names)\n\n\n# ---------------------------------\n# Interactive Main\n# ---------------------------------\nif __name__ == \"__main__\":\n    print(\"\ud83d\udd27 S3 Multiple Files Reader Tool - Interactive Mode\\n\")\n    print(\"Supported file types: .tml, .twb, and other text files\")\n    print(\"Note: TWB files will have <thumbnails> section removed automatically\\n\")\n    \n    # Get number of files\n    num_files = int(input(\"How many files do you want to read? \").strip())\n    \n    file_paths = []\n    file_names = []\n    \n    for i in range(num_files):\n        print(f\"\\n--- File {i+1} ---\")\n        file_path = input(f\"Enter file path {i+1} (e.g., Extract/TableauDashboards/Sales): \").strip()\n        file_name = input(f\"Enter file name {i+1} (e.g., Sales Dashboard.twb): \").strip()\n        file_paths.append(file_path)\n        file_names.append(file_name)\n    \n    tool = S3MultipleFilesReaderTool()\n    result = tool._run(file_paths=file_paths, file_names=file_names)\n    \n    print(\"\\n\" + \"=\"*80)\n    print(\"RESULT\")\n    print(\"=\"*80)\n    print(result)\n    print(\"=\"*80)",
                            "isApproved": false
                        }
                    ],
                    "allowCodeExecution": false,
                    "isSafeCodeExecution": true
                }
            }
        ],
        "enableAgenticMemory": false,
        "levelId": 99,
        "org": "Ascendion",
        "orgId": 1,
        "domain": "Data&Insights",
        "domainId": 96,
        "projectId": 98,
        "project": "AllProjects",
        "teamId": 99,
        "team": "AVA Team",
        "callbacks": []
    }
}