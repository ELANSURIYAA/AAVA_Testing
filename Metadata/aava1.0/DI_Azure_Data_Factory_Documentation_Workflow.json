{
    "pipeline": {
        "pipelineId": 6101,
        "name": "DI_Azure_Data_Factory_Documentation_Workflow",
        "description": "Create a detailed and structured Technical Specification document for an Azure Data Factory (ADF) Pipeline that effectively communicates its logic, dependencies, and operational details to Data Engineers and Business Analysts.",
        "createdAt": "2025-08-20T13:29:42.931+00:00",
        "pipeLineAgents": [
            {
                "serial": 1,
                "agent": {
                    "id": 8013,
                    "name": "DI_Azure_Data_Factory_Documentation",
                    "role": "Technical Documentation Specialist",
                    "goal": "Create a detailed and structured Technical Specification document for an Azure Data Factory (ADF) Pipeline that effectively communicates its logic, dependencies, and operational details to Data Engineers and Business Analysts. ",
                    "backstory": "Azure Data Factory pipelines are critical components in modern data integration and transformation workflows. Proper documentation ensures seamless onboarding for new team members, facilitates pipeline maintenance, and supports audit and compliance requirements. Without clear and structured documentation, teams may face inefficiencies, miscommunication, and challenges in understanding pipeline configurations and workflows. This document will serve as a single source of truth, bridging the gap between technical and business stakeholders while promoting operational excellence.",
                    "verbose": true,
                    "allowDelegation": true,
                    "updatedAt": "2025-09-05T11:47:01.249173",
                    "llm": {
                        "modelDeploymentName": "gpt-4.1",
                        "model": "gpt-4",
                        "modelType": "Generative",
                        "aiEngine": "AzureOpenAI",
                        "topP": 0.949999988079071,
                        "maxToken": 4500,
                        "temperature": 0.30000001192092896,
                        "llmDeploymentName": "gpt-4.1",
                        "apiKey": "****MASKED****",
                        "azureEndpoint": "https://avaplus-cognitive-account-int.openai.azure.com/",
                        "llmApiVersion": "2025-01-01-preview"
                    },
                    "embedding": [
                        {
                            "aiEngine": "AzureOpenAI",
                            "chroma_end_point": "http://chromadb.da.svc.cluster.local",
                            "chroma_port": "80",
                            "index_collection": "dI_Azure_Data_Factory_Documentation_kb",
                            "embedding_model": "text-embedding-ada-002",
                            "embedding_deployment_name": "ava-text-embedding-ada-002",
                            "embedding_api_version": "2024-09-01-preview",
                            "embedding_api_key": "****MASKED****",
                            "embedding_azure_endpoint": "https://da-cognitive-account-demo.openai.azure.com/"
                        }
                    ],
                    "task": {
                        "description": "Task:\nPlease create detailed documentation for the provided ADF Pipeline JSON file, using the knowledge base (Excel with SQL scripts and client data details) as a mandatory reference for all transformations, data mappings, and business logic.\n\nMetadata Requirements:\n\nAt the top of each generated file, add the following metadata:\n\n=============================================\nAuthor:        Ascendion AVA\nCreated on:    (Leave it empty)\nDescription:   <one-line description of the pipeline purpose>\n=============================================\n\nIf metadata already exists, update it to match this format while preserving relevant content.\n\nDocumentation Sections\n\n1) Overview of Pipeline\nExplain the business purpose of the ADF pipeline in detail.\nDescribe how the pipeline supports enterprise data integration/analytics.\nProvide a high-level summary of components (Pipelines, Activities, Datasets, Linked Services, Triggers, Integration Runtimes).\n\n2) Pipeline Structure and Design\nExplain the full structure of the pipeline.\nDocument Copy Activities, Dataflows, Stored Procedure Calls, Parameters, Dependencies.\nList all pipeline objects with dependencies and performance/optimization notes.\n\n3) Data Flow and Processing Logic\nDescribe step by step how data moves through the pipeline.\n\nFor each activity:\nExtract SQL scripts, dataset details, and transformations from the knowledge base.\nDocument filtering, joins, aggregations, lookups, and calculations in full detail.\nRepresent the flow using block-style markdown diagrams with conditional paths.\n\n4) Transformation Breakdown (Mandatory)\nFor every transformation found in the JSON or referenced SQL script, explain:\nInput source(s)\nTransformation logic (joins, filters, expressions, derived columns, aggregates, etc.)\nOutput destination(s)\nClearly state how the SQL in the knowledge base maps to the transformation in ADF.\n\n5) Data Mapping\nPresent a mapping table in the format:\nTarget Dataset | Target Field | Source Dataset | Source Field | Transformation / Rule\nEnsure transformation rules are pulled from the knowledge base Excel whenever available.\n\n6) Complexity Analysis\nProvide a table of pipeline complexity metrics (pipelines, activities, datasets, triggers, parameters, conditional logic, transformations, dependencies).\nAssign an overall complexity score from 0\u2013100.\n\n7) Key Outputs\nDescribe final outputs (tables, curated datasets, reports, files).\nPick schema/table/field names directly from the knowledge base.\nState storage format (SQL DB, Data Lake, Blob, Synapse).\nExplain how outputs align with business requirements.\n\n8) API Cost Calculations\nCalculate and explicitly mention the API call cost in USD (with full decimal values).\n\nInputs:\nADF Pipeline JSON file: {{ADF_Pipeline_File}}\nKnowledge Base (Excel): KB - DI_Azure_Data_Factory_Documentation_kb",
                        "expectedOutput": "Please create detailed documentation for the provided ADF Pipeline JSON file in markdown format.\n\nMetadata Requirements:\n=============================================\nAuthor:        Ascendion AVA+\nCreated on:   (Leave it empty)\nDescription:   <one-line description of the pipeline purpose>\n=============================================\n-If the pipeline already contains metadata headers, update them to match this format while preserving any relevant description content.\n-For the description, provide a concise summary of what the pipeline does.\n(give this only once in the top of the output)\n\nThe documentation must contain the following sections:\n-Overview of Pipeline\n-Pipeline Structure and Design\n-Data Flow and Processing Logic (with markdown block diagram)\n-Data Mapping (tabular format)\n-Complexity Analysis (tabular format)\n-Key Outputs\n-API Cost Calculations"
                    },
                    "maxIter": 25,
                    "maxRpm": 0,
                    "maxExecutionTime": 300,
                    "tools": [],
                    "userTools": [],
                    "allowCodeExecution": false,
                    "isSafeCodeExecution": true
                }
            }
        ],
        "enableAgenticMemory": false,
        "levelId": 99,
        "org": "Ascendion",
        "orgId": 1,
        "domain": "Data&Insights",
        "domainId": 96,
        "projectId": 98,
        "project": "AllProjects",
        "teamId": 99,
        "team": "AVA Team",
        "callbacks": []
    }
}