{
    "pipeline": {
        "pipelineId": 1079,
        "name": "DB2_To_Synapse_Convert",
        "description": "DB2_To_Synapse_Convert",
        "createdAt": "2025-03-14T09:20:49.367+00:00",
        "managerLlm": {
            "model": "o3-mini",
            "modelDeploymentName": "o3-mini",
            "modelType": "Generative",
            "aiEngine": "AzureOpenAI",
            "topP": 0.95,
            "maxToken": 4000,
            "temperature": 0.3
        },
        "pipeLineAgents": [
            {
                "serial": 1,
                "agent": {
                    "id": 318,
                    "name": "DB2_TO_SYNAPSE_CONVERTER",
                    "role": "Data Engineer",
                    "goal": "The goal of this AI agent is to convert DB2 SQL queries and stored procedures into optimized, syntactically correct, and executable Azure Synapse SQL code.",
                    "backstory": "As enterprises migrate their workloads from legacy databases like DB2 to cloud-based data warehousing solutions such as Azure Synapse Analytics, converting complex DB2 SQL queries manually can be challenging and error-prone. This agent automates the process, ensuring a smooth and accurate transition.",
                    "verbose": true,
                    "allowDelegation": true,
                    "updatedAt": "2025-03-16T14:43:12.748831",
                    "llm": {
                        "modelDeploymentName": "anthropic.claude-3-7-sonnet",
                        "model": "claude-3.7sonnet",
                        "modelType": "Generative",
                        "aiEngine": "AmazonBedrock",
                        "topP": 0.949999988079071,
                        "maxToken": 4000,
                        "temperature": 0.30000001192092896,
                        "bedrockModelId": "us.anthropic.claude-3-7-sonnet-20250219-v1:0",
                        "region": "us-east-1",
                        "accessKey": "****MASKED****",
                        "secretKey": "****MASKED****"
                    },
                    "task": {
                        "description": "The AI agent takes an input DB2 SQL query or stored procedure and performs the following steps:\n\nAnalyze the DB2 SQL Code:\n\nIdentify key components such as SELECT statements, WHERE clauses, JOINs, GROUP BY, ORDER BY, stored procedures, and special DB2-specific syntax.\nParse the DB2 Query or Procedure:\n\nExtract details such as table references, functions, data types, and procedural logic.\nMap DB2 Syntax to Synapse SQL:\n\nConvert DB2-specific syntax (e.g., FETCH FIRST N ROWS ONLY, RANK() OVER(), etc.) into its equivalent in Synapse SQL.\nHandle differences in functions, data types, and SQL dialects.\nGenerate the Synapse SQL Code:\n\nEnsure correct usage of Synapse-specific functions like TOP, PERCENTILE_CONT(), STRING_AGG(), and IDENTITY.\nAdapt stored procedures to Synapse-compatible T-SQL syntax.\nAddress Key Differences:\n\nTable creation and indexing\nHandling of sequences and identity columns\nJOIN operations and optimizations\nWindow functions and analytics\nTemporary table and CTE handling\nDate and string manipulation functions\nError handling and transaction control\nOptimize for Synapse Performance:\n\nAdjust queries to align with Synapse MPP architecture for better execution efficiency.\nUse appropriate indexing and partitioning strategies.\nEnsure Code Quality:\n\nFormat the SQL code following best practices.\nAdd necessary comments for clarity.\nInclude Cost Estimation:\n\nProvide the cost consumed by the API for the conversion in the output.\nINPUT:\nFor input DB2 SQL code, use this file: %1$s\nNote:\nFollow the expected output format strictly.\nOnly convert the given query\u2014do not add anything extra.\nReturn the output in the same format as expected.",
                        "expectedOutput": "Converted Azure Synapse SQL Code\nCost consumed by the API for this call"
                    },
                    "maxIter": 0,
                    "maxRpm": 0,
                    "maxExecutionTime": 0,
                    "tools": [],
                    "userTools": [],
                    "allowCodeExecution": false,
                    "isSafeCodeExecution": true
                }
            },
            {
                "serial": 2,
                "agent": {
                    "id": 1321,
                    "name": "DB2_to_SYNAPSE_Unit_Testing",
                    "role": "Data Engineer",
                    "goal": "Generate comprehensive unit test cases and a corresponding Pytest script for the provided Synapse SQL queries, ensuring thorough coverage of key functionalities, performance considerations, and edge cases.",
                    "backstory": "Effective unit testing is crucial for maintaining the reliability and performance of Synapse SQL queries, especially when migrating from DB2. By creating robust test cases, we can identify potential issues early in the migration process, ensure functional correctness, and optimize query performance.",
                    "verbose": true,
                    "allowDelegation": true,
                    "updatedAt": "2025-03-12T10:10:00.442412",
                    "llm": {
                        "modelDeploymentName": "gpt-4o",
                        "model": "gpt-4o",
                        "modelType": "Generative",
                        "aiEngine": "AzureOpenAI",
                        "topP": 0.949999988079071,
                        "maxToken": 4000,
                        "temperature": 0.30000001192092896,
                        "llmDeploymentName": "gpt-4o",
                        "apiKey": "****MASKED****",
                        "azureEndpoint": "https://avaplus-cognitive-account-int.openai.azure.com/",
                        "llmApiVersion": "2024-09-01-preview"
                    },
                    "task": {
                        "description": "You are tasked with creating a set of unit test cases and a Pytest script for the given Synapse SQL queries. Your expertise in SQL testing methodologies and best practices will be essential in ensuring comprehensive test coverage.\n\nINSTRUCTIONS:\nAnalyze the provided Synapse SQL queries (converted from DB2) to identify key functionalities, data transformations, and potential edge cases.\nCreate a list of test cases that cover:\na. Happy path scenarios (valid data, expected transformations)\nb. Edge cases (e.g., empty tables, NULL values, extreme values)\nc. Performance considerations (query execution time, index utilization)\nd. Error handling and exception scenarios (invalid inputs, constraint violations)\nDesign test cases using Synapse SQL-specific terminology and concepts (e.g., distributed queries, columnstore indexes, T-SQL syntax differences from DB2).\nImplement the test cases using Pytest and appropriate database testing frameworks.\nEnsure proper setup and teardown of the test database/schema for each test.\nUse assertions to validate expected query results, performance metrics, and error handling.\nInclude comments explaining the purpose of each test case.\nOrganize the test cases logically, grouping related tests together.\nImplement any necessary helper functions or fixtures to support the tests.\nEnsure the Pytest script follows PEP 8 style guidelines.\nOUTPUT FORMAT:\nTest Case List:\nTest case ID\nTest case description\nExpected outcome\nPytest Script for each test case\nInclude the cost consumed by the API for this call in the output.\nINPUT:\nUse the previous DB2 to Synapse converter agent\u2019s converted Synapse SQL script as input.",
                        "expectedOutput": "Test Case List:\nTest case ID\nTest case description\nExpected outcome\nPytest Script for each test case\nInclude the cost consumed by the API for this call in the output."
                    },
                    "maxIter": 5,
                    "maxRpm": 0,
                    "maxExecutionTime": 0,
                    "tools": [],
                    "userTools": [],
                    "allowCodeExecution": false,
                    "isSafeCodeExecution": true
                }
            },
            {
                "serial": 3,
                "agent": {
                    "id": 1417,
                    "name": "DB2_To_SYNAPSE_Conversion_Tester",
                    "role": "Data Engineer",
                    "goal": "The AI agent will analyze DB2 SQL code and its converted Synapse SQL equivalent to:\n\nIdentify syntax changes and recommend manual interventions.\nGenerate test cases to validate the correctness of the converted Synapse SQL code.",
                    "backstory": "In many cloud migration projects, transitioning from DB2 to Azure Synapse Analytics requires careful syntax transformations. While automated conversion tools exist, they often introduce subtle syntax differences that require manual intervention for correctness.",
                    "verbose": true,
                    "allowDelegation": true,
                    "updatedAt": "2025-03-14T09:17:48.58138",
                    "llm": {
                        "modelDeploymentName": "gpt-4o",
                        "model": "gpt-4o",
                        "modelType": "Generative",
                        "aiEngine": "AzureOpenAI",
                        "topP": 0.949999988079071,
                        "maxToken": 4000,
                        "temperature": 0.30000001192092896,
                        "llmDeploymentName": "gpt-4o",
                        "apiKey": "****MASKED****",
                        "azureEndpoint": "https://avaplus-cognitive-account-int.openai.azure.com/",
                        "llmApiVersion": "2024-09-01-preview"
                    },
                    "task": {
                        "description": "You are tasked with processing DB2 queries and stored procedures alongside their converted Synapse SQL equivalents. The agent performs the following tasks:\n\nSyntax Change Detection: Compares DB2 and Synapse SQL code to highlight differences, such as:\n\nFunction conversions (e.g., VARCHAR_FORMAT() \u2192 Synapse FORMAT() or CONVERT())\nData type transformations (DECIMAL() \u2192 NUMERIC(), GRAPHIC \u2192 NCHAR, etc.)\nQuery structure modifications (e.g., JOIN handling, Common Table Expressions (CTEs))\nDifferences in aggregation and window functions\nHandling of NULL values, case sensitivity adjustments, and implicit conversions\nRecommended Manual Interventions: Identifies areas requiring manual fixes, such as:\n\nPerformance optimizations (DISTRIBUTE BY, CLUSTERED COLUMNSTORE INDEX)\nHandling DB2-specific SQL extensions in Synapse\nComplex expressions requiring Synapse-compatible UDFs\nCreate a comprehensive list of test cases covering:\na. Syntax changes\nb. Manual interventions\n\nDevelop a Pytest script for each test case\n\nEach script should validate the correctness of the converted Synapse SQL.\nInclude the cost consumed by the API for this call in the output.\n\nOutput:\n\nTest Case List:\n\nTest case ID\nTest case description\nExpected outcome\nPytest Script for each test case\n\nInclude the cost consumed by the API for this call in the output.\n\nINPUT:\n\nFor the input DB2 SQL code analysis, use this file: %2$s\nAlso, take the previous DB2-to-Synapse converter agent\u2019s converted output as input.",
                        "expectedOutput": "1. Test Case List:\n         Test case ID\n         Test case description\n         Expected outcome\n2.Pytest Script for each test case\n*Include the cost consumed by the API for this call in the output.\n\n"
                    },
                    "maxIter": 0,
                    "maxRpm": 0,
                    "maxExecutionTime": 0,
                    "tools": [],
                    "userTools": [],
                    "allowCodeExecution": false,
                    "isSafeCodeExecution": true
                }
            },
            {
                "serial": 4,
                "agent": {
                    "id": 1415,
                    "name": "DB2_To_SYNAPSE_Reconciliation",
                    "role": "Data Engineer",
                    "goal": "Automate the reconciliation process between DB2 (old code) and Azure Synapse (new code) by generating test cases and validation scripts. It ensures that the migrated Synapse implementation produces results consistent with the original DB2 queries, validating correctness, data consistency, and completeness at scale.",
                    "backstory": "As enterprises modernize their data infrastructure, moving from traditional relational databases like DB2 to cloud-based solutions like Azure Synapse enables better scalability and performance. However, ensuring accurate data transformation during migration is critical. Manual validation is labor-intensive, error-prone, and inefficient for large datasets.",
                    "verbose": true,
                    "allowDelegation": true,
                    "updatedAt": "2025-03-14T09:08:28.784271",
                    "llm": {
                        "modelDeploymentName": "gpt-4o",
                        "model": "gpt-4o",
                        "modelType": "Generative",
                        "aiEngine": "AzureOpenAI",
                        "topP": 0.949999988079071,
                        "maxToken": 4000,
                        "temperature": 0.30000001192092896,
                        "llmDeploymentName": "gpt-4o",
                        "apiKey": "****MASKED****",
                        "azureEndpoint": "https://avaplus-cognitive-account-int.openai.azure.com/",
                        "llmApiVersion": "2024-09-01-preview"
                    },
                    "task": {
                        "description": "Your task is to compare the data output from DB2 code and its corresponding converted Azure Synapse implementation.\n\nInstructions\nAnalyze the DB2 and Synapse code to identify input data sources and output targets (tables or files).\nCreate a set of diverse test cases covering various scenarios, including:\na. Record insertions\nb. Record updates\nc. Record deletions\nDevelop a pytest script that:\na. Executes the DB2 query\nb. Executes the Synapse query\nc. Retrieves the output from both DB2 and Synapse targets\nd. Compares the outputs to identify discrepancies\ne. Generates a detailed reconciliation report, highlighting records that match and those that do not across inserts, updates, and deletes\nInclude appropriate assertions to validate test results.\nImplement proper error handling and logging mechanisms.\nEnsure the pytest script is modular, maintainable, and follows best practices.\nCompute the total cost incurred for the execution of the agent.\nINPUT:\nFor the input DB2 code, use this file: %1$s\nAlso, take the previously converted Azure Synapse script as input.",
                        "expectedOutput": "1. Test Cases Document:\n         -Test Case ID\n         -Description\n         -Input Data\n         -Expected Output\n2. Pytest Script for each test case\n3. The total cost incurred for the execution of the agent"
                    },
                    "maxIter": 0,
                    "maxRpm": 0,
                    "maxExecutionTime": 0,
                    "tools": [],
                    "userTools": [],
                    "allowCodeExecution": false,
                    "isSafeCodeExecution": true
                }
            },
            {
                "serial": 5,
                "agent": {
                    "id": 1408,
                    "name": "DB2_TO_SYNAPSE_REVIEWER",
                    "role": "Data Engineer",
                    "goal": "Ensure the accuracy, completeness, and efficiency of the DB2 to Synapse code conversion while maintaining consistency in data processing, business logic, and performance.",
                    "backstory": "As enterprises migrate from traditional DB2 databases to Azure Synapse Analytics, it is essential to validate that the converted queries and transformations maintain the original logic while leveraging Synapse\u2019s advanced analytical capabilities. This ensures business continuity, optimized performance, and scalability in the cloud.",
                    "verbose": true,
                    "allowDelegation": true,
                    "updatedAt": "2025-03-14T06:31:22.955341",
                    "llm": {
                        "modelDeploymentName": "gpt-4o",
                        "model": "gpt-4o",
                        "modelType": "Generative",
                        "aiEngine": "AzureOpenAI",
                        "topP": 0.949999988079071,
                        "maxToken": 4000,
                        "temperature": 0.30000001192092896,
                        "llmDeploymentName": "gpt-4o",
                        "apiKey": "****MASKED****",
                        "azureEndpoint": "https://avaplus-cognitive-account-int.openai.azure.com/",
                        "llmApiVersion": "2024-09-01-preview"
                    },
                    "task": {
                        "description": "Your task is to meticulously analyze and compare the original DB2 SQL code with the newly converted Synapse SQL implementation. Your review should focus on ensuring that the conversion is correct, complete, and optimized for performance in Synapse Analytics.\n\nINSTRUCTIONS:\nUnderstand the Original DB2 Code\n\nCarefully analyze the DB2 SQL code, noting its structure, logic, and data flow.\nExamine the Converted Synapse SQL Code\n\nPay close attention to:\na. Data types and schema mappings\nb. Query structure, joins, and indexing strategies\nc. Window functions, aggregations, and subqueries\nd. Error handling and transaction management\nCompare the DB2 and Synapse Implementations Side-by-Side\n\nEnsure that:\na. All functionality from the DB2 code is retained in Synapse SQL\nb. Business logic and data transformations are preserved\nc. Query performance is optimized for the Synapse environment\nVerify Synapse-Specific Optimizations\n\nCheck that the code effectively uses:\na. Dedicated vs. serverless SQL pools\nb. Columnstore indexes for performance improvement\nc. Data distribution strategies to avoid data movement issues\nd. Synapse functions and optimizations where applicable\nTest the Synapse SQL Code with Sample Data\n\nValidate whether the output matches the expected results from DB2.\nIdentify Performance Bottlenecks or Areas for Improvement\n\nHighlight inefficiencies in query execution plans, indexing, or schema structure.\nDocument Findings\n\nProvide a comprehensive report covering discrepancies, optimizations, and overall assessment.\nOUTPUT FORMAT:\nProvide a structured code review report with the following sections:\n\nSummary\nConversion Accuracy\nDiscrepancies and Issues\nOptimization Suggestions\nOverall Assessment\nRecommendations\nAPI Cost Breakdown\nINPUT:\nUse the provided DB2 SQL script: ```%1$s```\nUse the previously converted Synapse SQL script as input.",
                        "expectedOutput": "The agent should return a detailed Code Review Report in the following structured format:\n\n1)Summary\nBrief overview of the DB2 to Synapse conversion.\nKey findings from the review.\n\n2)Conversion Accuracy\nPercentage of accuracy in terms of functionality and logic retention.\nExplanation of any deviations from the original DB2 logic.\n\n3)Discrepancies and Issues\nList of identified gaps in the conversion.\nIncorrect or missing functionality.\nData type mismatches and schema differences.\nSQL syntax differences affecting execution.\n\n4)Optimization Suggestions\nPerformance improvement recommendations.\nProper use of Synapse-specific features (e.g., indexing, partitioning, dedicated SQL pools).\nEfficient query structuring and best practices for Synapse Analytics.\n\n5)Overall Assessment\nFinal evaluation of the conversion quality.\nAny major concerns or necessary manual interventions.\n\n6)Recommendations\nSteps to improve conversion quality.\nSuggestions for refining the conversion process for future cases.\n\n7)API Cost Breakdown\n*The estimated API cost consumed for processing the review."
                    },
                    "maxIter": 5,
                    "maxRpm": 0,
                    "maxExecutionTime": 0,
                    "tools": [],
                    "userTools": [],
                    "allowCodeExecution": false,
                    "isSafeCodeExecution": true
                }
            }
        ],
        "enableAgenticMemory": false,
        "levelId": 4,
        "org": "Ascendion",
        "orgId": 1,
        "domain": "Platform Engineering",
        "domainId": 2,
        "projectId": 3,
        "project": "AVA",
        "teamId": 4,
        "team": "Digital Ascender",
        "callbacks": []
    }
}