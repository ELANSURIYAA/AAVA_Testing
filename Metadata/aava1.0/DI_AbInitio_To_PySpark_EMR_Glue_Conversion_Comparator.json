{
    "pipeline": {
        "pipelineId": 8611,
        "name": "DI_AbInitio_To_PySpark_EMR_Glue_Conversion_Comparator",
        "description": "This work flow is for the Conversion",
        "createdAt": "2025-11-18T17:21:34.451+00:00",
        "pipeLineAgents": [
            {
                "serial": 1,
                "agent": {
                    "id": 11225,
                    "name": "DI_AbInitio_To_PySpark_EMR_Glue_Converter_Claude",
                    "role": "Senior Data Engineer",
                    "goal": "Convert Ab Initio .mp files into modular and maintainable PySpark EMR/Glue pipeline scripts using reusable transformation and schema modules.",
                    "backstory": "This agent was built to help migrate legacy ETL logic from Ab Initio to PySpark running on AWS EMR Glue. It relies on pre-converted reusable modules for business logic (.xfr) and schemas (.dml) to generate clean, scalable, cloud-ready pipelines.",
                    "verbose": true,
                    "allowDelegation": true,
                    "updatedAt": "2025-11-19T17:37:37.925185",
                    "llm": {
                        "modelDeploymentName": "Anthropic.claude-4-sonnet",
                        "model": "anthropic.claude-4-sonnet",
                        "modelType": "Generative",
                        "aiEngine": "AmazonBedrock",
                        "topP": 1.0,
                        "maxToken": 64000,
                        "temperature": 0.20000000298023224,
                        "bedrockModelId": "us.anthropic.claude-sonnet-4-20250514-v1:0",
                        "region": "us-east-1",
                        "accessKey": "****MASKED****",
                        "secretKey": "****MASKED****"
                    },
                    "task": {
                        "description": "Header:\n====================================================\nAuthor:        AAVA\nDate:          <leave it blank>\nDescription:   <one-line description of the purpose>\n====================================================\n\nYou are an expert in translating Ab Initio .mp (graph) files into equivalent PySpark EMR Glue pipelines.\n\nYou will receive:\n* The .mp file content (data flow logic),\n* A Python module containing transformation functions (converted from .xfr files),\n* A Python module containing reusable StructType/schema objects (converted from .dml files),\n* AbInitio actual flow as a .txt or .pdf Graph file.\n* A runtime flag indicating whether to generate EMR Glue PySpark code.\n\nTOOLS:\n* Use the github writer tool to write the converted pyspark code into the github repository:\n* The converted file name should be actual input mp file name_Converted_PySpark_Code_Claude.py\n\nFollow these steps:\n\n* Never skip or summarize column names \u2014 list all columns explicitly.\n* Ensure that the original logic, transformations, and control flow are preserved accurately.\n* Refer to the actual Ab Initio flow file to ensure the output strictly follows it.\n* The converted PySpark EMR Glue code must have the same workflow as the given Ab Initio flowchart.\n* Do not change the component order.\n* For joins, join the tables exactly as per the flowchart and maintain the same sequence.\n* Parse the .mp graph and identify data flow stages:\n    - inputs, transformations, filters, joins, outputs.\n* For each .xfr transformation used, identify and call the appropriate function from the transformation module.\n* For each input/output schema defined in .dml, import the relevant schema using:\n    - from schema_module import customer_schema\n* Build a PySpark EMR Glue script that:\n    - Initializes SparkSession (EMR)\n* If Ab Initio receives input as a table, extract the SQL query, store it, and read through JDBC/Glue Catalog\n* Reads input datasets using the correct schema\n* Applies transformation functions from the .xfr module\n* Performs all operations present in the input Ab Initio flow: joins, filters, groupings, dedup, aggregation, etc.\n* Writes the final DataFrame to output (S3 path, Glue catalog, or configured target)\n* Import only the required transformation functions and schemas.\n* Keep the code modular, readable, and follow best PySpark + AWS EMR Glue practices.\n* Do not include unnecessary placeholder code \u2014 generate complete working code directly from .mp logic.\n* Add meaningful comments and transformation notes wherever needed.\n* Do not embed full schema or transformation logic \u2014 only import and call them.\n* Continue converting until all Ab Initio logic is translated.\n* Do not use placeholder comments. Always generate actual PySpark EMR Glue code.\n* Ensure the join sequence present in the Ab Initio graph is preserved exactly in the final EMR Glue PySpark job.\n* Add the header in the top of the converted pyspark code\n\nImportant Note:\n* Strictly the converted PySpark EMR Glue job must have the same flow of work which is present in the given Ab Initio flowchart.\n\nINPUTS:\n* mp Input file: {{AbInitio_Code}}\n* xfr module (Python): {{XFR_File}}\n* dml schema module (Python): {{DML_File}}\n* AbInitio Flow Graph : {{Image_AbInitio_Flow_Chart}}\n* GitHub Repo Details : {{Github_Repo}}",
                        "expectedOutput": "A complete PySpark EMR Glue script  that implements the full logic of the given .mp file by integrating functions from the .xfr module and schema module, while preserving the exact component sequence defined in the Ab Initio flow."
                    },
                    "maxIter": 0,
                    "maxRpm": 0,
                    "maxExecutionTime": 0,
                    "tools": [],
                    "userTools": [
                        {
                            "toolId": 300,
                            "toolName": "DI_Github_File_Writer_Z",
                            "toolClassName": "GitHubFileWriterTool",
                            "toolClassDef": "from crewai.tools import BaseTool\nfrom pydantic import BaseModel, Field\nimport base64\nimport requests\nimport urllib3\nimport logging\nimport re\nfrom typing import Type, Any\n\n# ---------------------------------\n# SSL & Logging Configuration\n# ---------------------------------\nurllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\nlogging.basicConfig(\n    level=logging.INFO,\n    format=\"%(asctime)s - %(levelname)s - %(message)s\",\n    filename=\"github_file_writer.log\",\n)\nlogger = logging.getLogger(\"GitHubFileWriterTool\")\n\n\n# ---------------------------------\n# Input Schema\n# ---------------------------------\nclass GitHubFileWriterSchema(BaseModel):\n    repo: str = Field(..., description=\"GitHub repository in 'owner/repo' format\")\n    branch: str = Field(..., description=\"Branch name (e.g., 'main')\")\n    token: str = Field(..., description=\"GitHub Personal Access Token\")\n    folder_name: str = Field(..., description=\"Name of the folder to create inside the repository\")\n    file_name: str = Field(..., description=\"Name of the file to create or update in the folder\")\n    content: str = Field(..., description=\"Text content to upload into the GitHub file\")\n\n\n# ---------------------------------\n# Main Tool Class\n# ---------------------------------\nclass GitHubFileWriterTool(BaseTool):\n    name: str = \"GitHub File Writer Tool\"\n    description: str = \"Creates or updates files in a GitHub repository folder\"\n    args_schema: Type[BaseModel] = GitHubFileWriterSchema\n\n    api_url_template: str = \"https://api.github.com/repos/{repo}/contents/{path}\"\n\n    def _sanitize_path_component(self, component: str) -> str:\n        \"\"\"Remove invalid GitHub path characters.\"\"\"\n        sanitized = re.sub(r'[\\\\*?:\"<>|]', '_', component)\n        sanitized = re.sub(r'\\.\\.', '_', sanitized)\n        sanitized = sanitized.lstrip('./\\\\')\n        return sanitized if sanitized else \"default\"\n\n    def _validate_content(self, content: str) -> str:\n        \"\"\"Ensure valid string content within 10MB limit.\"\"\"\n        if not isinstance(content, str):\n            logger.warning(\"Content is not a string. Converting to string.\")\n            content = str(content)\n\n        max_size = 10 * 1024 * 1024  # 10 MB\n        if len(content.encode('utf-8')) > max_size:\n            logger.warning(\"Content exceeds 10MB limit. Truncating.\")\n            content = content[:max_size]\n\n        return content\n\n    def create_file_in_github(self, repo: str, branch: str, token: str,\n                              folder_name: str, file_name: str, content: str) -> str:\n        \"\"\"Create or update a file in GitHub repository.\"\"\"\n        sanitized_folder = self._sanitize_path_component(folder_name)\n        sanitized_file = self._sanitize_path_component(file_name)\n        validated_content = self._validate_content(content)\n\n        path = f\"{sanitized_folder}/{sanitized_file}\"\n        url = self.api_url_template.format(repo=repo, path=path)\n        headers = {\"Authorization\": f\"token {token}\", \"Content-Type\": \"application/json\"}\n\n        # Encode content\n        encoded_content = base64.b64encode(validated_content.encode()).decode()\n\n        # Check file existence to get SHA (for updating)\n        sha = None\n        try:\n            response = requests.get(url, headers=headers, params={\"ref\": branch}, verify=False)\n            if response.status_code == 200:\n                sha = response.json().get(\"sha\")\n        except Exception as e:\n            logger.error(f\"Failed to check file existence: {e}\", exc_info=True)\n\n        payload = {\"message\": f\"Add or update file: {sanitized_file}\",\n                   \"content\": encoded_content, \"branch\": branch}\n        if sha:\n            payload[\"sha\"] = sha  # Required for updating\n\n        # Upload or update file\n        try:\n            put_response = requests.put(url, json=payload, headers=headers, verify=False)\n            if put_response.status_code in [200, 201]:\n                logger.info(f\"\u2705 File '{sanitized_file}' uploaded successfully to {repo}/{sanitized_folder}\")\n                return f\"\u2705 File '{sanitized_file}' uploaded successfully to GitHub in folder '{sanitized_folder}'.\"\n            else:\n                logger.error(f\"GitHub API Error: {put_response.text}\")\n                return f\"\u274c Failed to upload file. GitHub API error: {put_response.text}\"\n        except Exception as e:\n            logger.error(f\"Failed to upload file: {e}\", exc_info=True)\n            return f\"\u274c Exception while uploading file: {str(e)}\"\n\n    # ------------------------------------------------------\n    # Required method for CrewAI Tool execution\n    # ------------------------------------------------------\n    def _run(self, repo: str, branch: str, token: str,\n             folder_name: str, file_name: str, content: str) -> Any:\n        \"\"\"Main execution method.\"\"\"\n        return self.create_file_in_github(repo, branch, token, folder_name, file_name, content)\n\n\n# ---------------------------------\n# Generalized Main (User-Parameterized)\n# ---------------------------------\nif __name__ == \"__main__\":\n    print(\"\ud83d\udd27 GitHub File Writer Tool - Interactive Mode\\n\")\n    repo = input(\"Enter GitHub repository (owner/repo): \").strip()\n    branch = input(\"Enter branch name (e.g., main): \").strip()\n    token = input(\"Enter your GitHub Personal Access Token: \").strip()\n    folder_name = input(\"Enter folder name: \").strip()\n    file_name = input(\"Enter file name (e.g., example.txt): \").strip()\n    print(\"\\nEnter the content for your file (end with a blank line):\")\n    lines = []\n    while True:\n        line = input()\n        if line == \"\":\n            break\n        lines.append(line)\n    content = \"\\n\".join(lines)\n\n    tool = GitHubFileWriterTool()\n    result = tool._run(repo=repo, branch=branch, token=token,\n                       folder_name=folder_name, file_name=file_name, content=content)\n    print(\"\\nResult:\", result)\n",
                            "isApproved": false
                        }
                    ],
                    "allowCodeExecution": false,
                    "isSafeCodeExecution": true
                }
            },
            {
                "serial": 2,
                "agent": {
                    "id": 11226,
                    "name": "DI_AbInitio_To_PySpark_EMR_Glue_Converter_GPT",
                    "role": "Senior Data Engineer",
                    "goal": "Convert Ab Initio .mp files into modular and maintainable PySpark EMR/Glue pipeline scripts using reusable transformation and schema modules.",
                    "backstory": "This agent was built to help migrate legacy ETL logic from Ab Initio to PySpark running on AWS EMR Glue. It relies on pre-converted reusable modules for business logic (.xfr) and schemas (.dml) to generate clean, scalable, cloud-ready pipelines.",
                    "verbose": true,
                    "allowDelegation": true,
                    "updatedAt": "2025-11-19T17:32:33.322642",
                    "llm": {
                        "modelDeploymentName": "gpt-4.1",
                        "model": "gpt-4",
                        "modelType": "Generative",
                        "aiEngine": "AzureOpenAI",
                        "topP": 1.0,
                        "maxToken": 32000,
                        "temperature": 0.20000000298023224,
                        "llmDeploymentName": "gpt-4.1",
                        "apiKey": "****MASKED****",
                        "azureEndpoint": "https://avaplus-cognitive-account-int.openai.azure.com/",
                        "llmApiVersion": "2025-01-01-preview"
                    },
                    "task": {
                        "description": "Header:\n====================================================\nAuthor:        AAVA\nDate:          <leave it blank>\nDescription:   <one-line description of the purpose>\n====================================================\n\nYou are an expert in translating Ab Initio .mp (graph) files into equivalent PySpark EMR Glue pipelines.\n\nYou will receive:\n* The .mp file content (data flow logic),\n* A Python module containing transformation functions (converted from .xfr files),\n* A Python module containing reusable StructType/schema objects (converted from .dml files),\n* AbInitio actual flow as a .txt or .pdf Graph file.\n* A runtime flag indicating whether to generate EMR Glue PySpark code.\n\nTOOLS:\n* Use the github writer tool to write the converted pyspark code into the github repository:\n* The converted file name should be actual input mp file name_Converted_PySpark_Code_GPT.py\n\nFollow these steps:\n\n* Never skip or summarize column names \u2014 list all columns explicitly.\n* Ensure that the original logic, transformations, and control flow are preserved accurately.\n* Refer to the actual Ab Initio flow file to ensure the output strictly follows it.\n* The converted PySpark EMR Glue code must have the same workflow as the given Ab Initio flowchart.\n* Do not change the component order.\n* For joins, join the tables exactly as per the flowchart and maintain the same sequence.\n* Parse the .mp graph and identify data flow stages:\n    - inputs, transformations, filters, joins, outputs.\n* For each .xfr transformation used, identify and call the appropriate function from the transformation module.\n* For each input/output schema defined in .dml, import the relevant schema using:\n    - from schema_module import customer_schema\n* Build a PySpark EMR Glue script that:\n    - Initializes SparkSession (EMR)\n* If Ab Initio receives input as a table, extract the SQL query, store it, and read through JDBC/Glue Catalog\n* Reads input datasets using the correct schema\n* Applies transformation functions from the .xfr module\n* Performs all operations present in the input Ab Initio flow: joins, filters, groupings, dedup, aggregation, etc.\n* Writes the final DataFrame to output (S3 path, Glue catalog, or configured target)\n* Import only the required transformation functions and schemas.\n* Keep the code modular, readable, and follow best PySpark + AWS EMR Glue practices.\n* Do not include unnecessary placeholder code \u2014 generate complete working code directly from .mp logic.\n* Add meaningful comments and transformation notes wherever needed.\n* Do not embed full schema or transformation logic \u2014 only import and call them.\n* Continue converting until all Ab Initio logic is translated.\n* Do not use placeholder comments. Always generate actual PySpark EMR Glue code.\n* Ensure the join sequence present in the Ab Initio graph is preserved exactly in the final EMR Glue PySpark job.\n* Add the header in the top of the converted pyspark code\n\nImportant Note:\n* Strictly the converted PySpark EMR Glue job must have the same flow of work which is present in the given Ab Initio flowchart.\n\nINPUTS:\n* mp Input file: {{AbInitio_Code}}\n* xfr module (Python): {{XFR_File}}\n* dml schema module (Python): {{DML_File}}\n* AbInitio Flow Graph : {{Image_AbInitio_Flow_Chart}}\n* GitHub Repo Details : {{Github_Repo}}",
                        "expectedOutput": "A complete PySpark EMR Glue script  that implements the full logic of the given .mp file by integrating functions from the .xfr module and schema module, while preserving the exact component sequence defined in the Ab Initio flow."
                    },
                    "maxIter": 0,
                    "maxRpm": 0,
                    "maxExecutionTime": 0,
                    "tools": [],
                    "userTools": [
                        {
                            "toolId": 300,
                            "toolName": "DI_Github_File_Writer_Z",
                            "toolClassName": "GitHubFileWriterTool",
                            "toolClassDef": "from crewai.tools import BaseTool\nfrom pydantic import BaseModel, Field\nimport base64\nimport requests\nimport urllib3\nimport logging\nimport re\nfrom typing import Type, Any\n\n# ---------------------------------\n# SSL & Logging Configuration\n# ---------------------------------\nurllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\nlogging.basicConfig(\n    level=logging.INFO,\n    format=\"%(asctime)s - %(levelname)s - %(message)s\",\n    filename=\"github_file_writer.log\",\n)\nlogger = logging.getLogger(\"GitHubFileWriterTool\")\n\n\n# ---------------------------------\n# Input Schema\n# ---------------------------------\nclass GitHubFileWriterSchema(BaseModel):\n    repo: str = Field(..., description=\"GitHub repository in 'owner/repo' format\")\n    branch: str = Field(..., description=\"Branch name (e.g., 'main')\")\n    token: str = Field(..., description=\"GitHub Personal Access Token\")\n    folder_name: str = Field(..., description=\"Name of the folder to create inside the repository\")\n    file_name: str = Field(..., description=\"Name of the file to create or update in the folder\")\n    content: str = Field(..., description=\"Text content to upload into the GitHub file\")\n\n\n# ---------------------------------\n# Main Tool Class\n# ---------------------------------\nclass GitHubFileWriterTool(BaseTool):\n    name: str = \"GitHub File Writer Tool\"\n    description: str = \"Creates or updates files in a GitHub repository folder\"\n    args_schema: Type[BaseModel] = GitHubFileWriterSchema\n\n    api_url_template: str = \"https://api.github.com/repos/{repo}/contents/{path}\"\n\n    def _sanitize_path_component(self, component: str) -> str:\n        \"\"\"Remove invalid GitHub path characters.\"\"\"\n        sanitized = re.sub(r'[\\\\*?:\"<>|]', '_', component)\n        sanitized = re.sub(r'\\.\\.', '_', sanitized)\n        sanitized = sanitized.lstrip('./\\\\')\n        return sanitized if sanitized else \"default\"\n\n    def _validate_content(self, content: str) -> str:\n        \"\"\"Ensure valid string content within 10MB limit.\"\"\"\n        if not isinstance(content, str):\n            logger.warning(\"Content is not a string. Converting to string.\")\n            content = str(content)\n\n        max_size = 10 * 1024 * 1024  # 10 MB\n        if len(content.encode('utf-8')) > max_size:\n            logger.warning(\"Content exceeds 10MB limit. Truncating.\")\n            content = content[:max_size]\n\n        return content\n\n    def create_file_in_github(self, repo: str, branch: str, token: str,\n                              folder_name: str, file_name: str, content: str) -> str:\n        \"\"\"Create or update a file in GitHub repository.\"\"\"\n        sanitized_folder = self._sanitize_path_component(folder_name)\n        sanitized_file = self._sanitize_path_component(file_name)\n        validated_content = self._validate_content(content)\n\n        path = f\"{sanitized_folder}/{sanitized_file}\"\n        url = self.api_url_template.format(repo=repo, path=path)\n        headers = {\"Authorization\": f\"token {token}\", \"Content-Type\": \"application/json\"}\n\n        # Encode content\n        encoded_content = base64.b64encode(validated_content.encode()).decode()\n\n        # Check file existence to get SHA (for updating)\n        sha = None\n        try:\n            response = requests.get(url, headers=headers, params={\"ref\": branch}, verify=False)\n            if response.status_code == 200:\n                sha = response.json().get(\"sha\")\n        except Exception as e:\n            logger.error(f\"Failed to check file existence: {e}\", exc_info=True)\n\n        payload = {\"message\": f\"Add or update file: {sanitized_file}\",\n                   \"content\": encoded_content, \"branch\": branch}\n        if sha:\n            payload[\"sha\"] = sha  # Required for updating\n\n        # Upload or update file\n        try:\n            put_response = requests.put(url, json=payload, headers=headers, verify=False)\n            if put_response.status_code in [200, 201]:\n                logger.info(f\"\u2705 File '{sanitized_file}' uploaded successfully to {repo}/{sanitized_folder}\")\n                return f\"\u2705 File '{sanitized_file}' uploaded successfully to GitHub in folder '{sanitized_folder}'.\"\n            else:\n                logger.error(f\"GitHub API Error: {put_response.text}\")\n                return f\"\u274c Failed to upload file. GitHub API error: {put_response.text}\"\n        except Exception as e:\n            logger.error(f\"Failed to upload file: {e}\", exc_info=True)\n            return f\"\u274c Exception while uploading file: {str(e)}\"\n\n    # ------------------------------------------------------\n    # Required method for CrewAI Tool execution\n    # ------------------------------------------------------\n    def _run(self, repo: str, branch: str, token: str,\n             folder_name: str, file_name: str, content: str) -> Any:\n        \"\"\"Main execution method.\"\"\"\n        return self.create_file_in_github(repo, branch, token, folder_name, file_name, content)\n\n\n# ---------------------------------\n# Generalized Main (User-Parameterized)\n# ---------------------------------\nif __name__ == \"__main__\":\n    print(\"\ud83d\udd27 GitHub File Writer Tool - Interactive Mode\\n\")\n    repo = input(\"Enter GitHub repository (owner/repo): \").strip()\n    branch = input(\"Enter branch name (e.g., main): \").strip()\n    token = input(\"Enter your GitHub Personal Access Token: \").strip()\n    folder_name = input(\"Enter folder name: \").strip()\n    file_name = input(\"Enter file name (e.g., example.txt): \").strip()\n    print(\"\\nEnter the content for your file (end with a blank line):\")\n    lines = []\n    while True:\n        line = input()\n        if line == \"\":\n            break\n        lines.append(line)\n    content = \"\\n\".join(lines)\n\n    tool = GitHubFileWriterTool()\n    result = tool._run(repo=repo, branch=branch, token=token,\n                       folder_name=folder_name, file_name=file_name, content=content)\n    print(\"\\nResult:\", result)\n",
                            "isApproved": false
                        }
                    ],
                    "allowCodeExecution": false,
                    "isSafeCodeExecution": true
                }
            },
            {
                "serial": 3,
                "agent": {
                    "id": 11229,
                    "name": "DI_AbInitio_To_PySpark_EMR_Glue_Reviewer_GPT",
                    "role": "Senior Data Engineer",
                    "goal": "Validate a PySpark EMR Glue script by comparing it with the corresponding Ab Initio .mp graph, .xfr transformation, and .dml schema files to ensure the logic and structure are accurately converted into EMR or AWS Glue compatible code.",
                    "backstory": "This agent assists in the migration of ETL workflows from Ab Initio to PySpark running on AWS EMR Glue. It helps developers ensure the converted PySpark code correctly reflects the logic, transformations, joins, and data structure defined in legacy Ab Initio assets.",
                    "verbose": true,
                    "allowDelegation": true,
                    "updatedAt": "2026-01-28T08:45:36.222006",
                    "llm": {
                        "modelDeploymentName": "gpt-4.1",
                        "model": "gpt-4",
                        "modelType": "Generative",
                        "aiEngine": "AzureOpenAI",
                        "topP": 1.0,
                        "maxToken": 32000,
                        "temperature": 0.20000000298023224,
                        "llmDeploymentName": "gpt-4.1",
                        "apiKey": "****MASKED****",
                        "azureEndpoint": "https://avaplus-cognitive-account-int.openai.azure.com/",
                        "llmApiVersion": "2025-01-01-preview"
                    },
                    "task": {
                        "description": "Header:\n------------------------------------------------------------------------\nAuthor:        AAVA       \nDate:          <leave it blank>\nDescription:   <one-line description of the purpose>\n------------------------------------------------------------------------\n\n\u2705 Reviewer Agent Prompt for EMR/Glue PySpark Validation\n\nYou will receive the following inputs:\nAn Ab Initio .mp file defining the overall job flow and component connections.\nThe corresponding PySpark EMR Glue code that was generated through the conversion\n\nYour job is to thoroughly validate whether the PySpark EMR Glue file correctly implements the logic, sequence, and configuration defined in the Ab Initio files. This includes structural alignment, functional correctness, syntactic accuracy, schema mapping, and completeness of transformations.\n\n1. Parse and Analyze .mp File\n* Extract component names and sequence/order (e.g., input \u2192 reformat \u2192 join \u2192 filter \u2192 output).\n* Identify connections between components and branching logic.\n* Map the flow graph and store for order comparison.\n* Validate that EMR Glue code follows the same sequence.\n\n2. Parse .xfr Files (if available)\n* Extract all transformation logic, expressions, conditional mappings, and calculations.\n* Track each transformation and its exact position in the flow.\n* Validate that each transformation is correctly implemented in the same location in PySpark EMR Glue code.\n* If .xfr files are not available, proceed with validation based on .mp file logic.\n\n3. Parse .dml Files (if available)\n* Extract schema definitions, data types, nullability, and field order.\n* Compare .dml schemas with StructTypes or DynamicFrame schema used in EMR/Glue code.\n* Verify that the schema is applied correctly in:\n* input reading\n.select()\n.withColumn()\ntransformations\njoins\noutputs\n* If .dml files are not available, validate schema based on transformations defined in .mp file.\n\n4. Analyze PySpark EMR Glue Code\n* Parse all steps: reading, transformation, joins, sorting, filtering, XFR calls, and output.\n* Extract the execution order of transformations.\n* Validate SparkSession or GlueContext initialization depending on runtime.\n* Identify .withColumn, .select, .join, .alias, .filter, UDF usage, and DynamicFrame conversions if Glue.\n* Perform line-by-line syntax validation to ensure proper PySpark, EMR, or Glue syntax.\n\n5. Validation Logic\n\u2705 Flow & Order Validation\n* Ensure the order of components in PySpark EMR Glue code matches the .mp and the Ab Initio Graph.\n* Highlight reordered or missing components.\n* Strictly the converted code should match the same flow which is present in the given AbInitio flow chart.\n\n\u2705 XFR Function Placement (if .xfr files are available)\n* Confirm that each .xfr function is used in the right position.\n* Check for missing, incorrect, or misplaced transformations.\n* Highlight any manual modifications that impacted logic.\n\n\u2705 SQL & Column Validations\n* Validate that SELECT logic from Ab Initio matches PySpark:\n* All columns exist\n* Aliases match\n* Calculations are correct\n* Expressions and conditions match\n* Highlight any missing or altered column logic.\n\n\u2705 Component Coverage\n* Verify that each component (e.g., reformat, join, filter, sort, dedup) from Ab Initio is implemented in PySpark EMR Glue.\n* Confirm that:\n    - join keys\n    - join type\n    - filters\n    - sort order\n    - partitioning\n    - layout\nare applied correctly.\n\n\u2705 Syntax Review\n* Perform line-by-line syntax validation of the PySpark EMR Glue code.\n* Highlight syntax errors, missing imports, indentation issues, wrong chaining, or misspelled functions.\n* Validate Glue-specific usage like DynamicFrame conversions.\n\n\u2705 Manual Intervention & Optimization\n* Identify hardcoded logic, incorrect assumptions, or mismatches.\n* Highlight any logic that requires manual intervention.\n* Suggest optimizations such as:\n* Use of broadcast joins\n* Avoiding unnecessary shuffles\n* Reducing repeated transformations\n* Glue optimization recommendations if applicable\n\nINPUTS:\n* Ab Initio files (zip): {{AbInitio_Code}}\n",
                        "expectedOutput": "Your output should contain:\nAdd the header in the top of the report \n\n\ud83d\udcdd Validation Report\n\nFor each component:\n\n\u2705 Correct \u2014 logic correctly implemented\n\n\u274c Incorrect \u2014 logic or structure is missing or wrong\n\n\ud83d\udd0d Needs Review \u2014 partially matched or unclear logic\n\n\ud83d\udccc Specific Checks\n\nFlow order mismatches\n\nIncorrect .xfr logic placement\n\nMissing columns in selections\n\nSchema mismatches\n\nWrong join types or missing join keys\n\nSyntax or semantic issues\n\nManual interventions required\n\nOptimization recommendations\n\n\ud83d\udcca Overall Conversion Summary\n\nConversion accuracy: xx%\n\nManual intervention level: Low / Medium / High\n\nConfidence score: High / Medium / Low"
                    },
                    "maxIter": 0,
                    "maxRpm": 0,
                    "maxExecutionTime": 0,
                    "tools": [],
                    "userTools": [
                        {
                            "toolId": 300,
                            "toolName": "DI_Github_File_Writer_Z",
                            "toolClassName": "GitHubFileWriterTool",
                            "toolClassDef": "from crewai.tools import BaseTool\nfrom pydantic import BaseModel, Field\nimport base64\nimport requests\nimport urllib3\nimport logging\nimport re\nfrom typing import Type, Any\n\n# ---------------------------------\n# SSL & Logging Configuration\n# ---------------------------------\nurllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\nlogging.basicConfig(\n    level=logging.INFO,\n    format=\"%(asctime)s - %(levelname)s - %(message)s\",\n    filename=\"github_file_writer.log\",\n)\nlogger = logging.getLogger(\"GitHubFileWriterTool\")\n\n\n# ---------------------------------\n# Input Schema\n# ---------------------------------\nclass GitHubFileWriterSchema(BaseModel):\n    repo: str = Field(..., description=\"GitHub repository in 'owner/repo' format\")\n    branch: str = Field(..., description=\"Branch name (e.g., 'main')\")\n    token: str = Field(..., description=\"GitHub Personal Access Token\")\n    folder_name: str = Field(..., description=\"Name of the folder to create inside the repository\")\n    file_name: str = Field(..., description=\"Name of the file to create or update in the folder\")\n    content: str = Field(..., description=\"Text content to upload into the GitHub file\")\n\n\n# ---------------------------------\n# Main Tool Class\n# ---------------------------------\nclass GitHubFileWriterTool(BaseTool):\n    name: str = \"GitHub File Writer Tool\"\n    description: str = \"Creates or updates files in a GitHub repository folder\"\n    args_schema: Type[BaseModel] = GitHubFileWriterSchema\n\n    api_url_template: str = \"https://api.github.com/repos/{repo}/contents/{path}\"\n\n    def _sanitize_path_component(self, component: str) -> str:\n        \"\"\"Remove invalid GitHub path characters.\"\"\"\n        sanitized = re.sub(r'[\\\\*?:\"<>|]', '_', component)\n        sanitized = re.sub(r'\\.\\.', '_', sanitized)\n        sanitized = sanitized.lstrip('./\\\\')\n        return sanitized if sanitized else \"default\"\n\n    def _validate_content(self, content: str) -> str:\n        \"\"\"Ensure valid string content within 10MB limit.\"\"\"\n        if not isinstance(content, str):\n            logger.warning(\"Content is not a string. Converting to string.\")\n            content = str(content)\n\n        max_size = 10 * 1024 * 1024  # 10 MB\n        if len(content.encode('utf-8')) > max_size:\n            logger.warning(\"Content exceeds 10MB limit. Truncating.\")\n            content = content[:max_size]\n\n        return content\n\n    def create_file_in_github(self, repo: str, branch: str, token: str,\n                              folder_name: str, file_name: str, content: str) -> str:\n        \"\"\"Create or update a file in GitHub repository.\"\"\"\n        sanitized_folder = self._sanitize_path_component(folder_name)\n        sanitized_file = self._sanitize_path_component(file_name)\n        validated_content = self._validate_content(content)\n\n        path = f\"{sanitized_folder}/{sanitized_file}\"\n        url = self.api_url_template.format(repo=repo, path=path)\n        headers = {\"Authorization\": f\"token {token}\", \"Content-Type\": \"application/json\"}\n\n        # Encode content\n        encoded_content = base64.b64encode(validated_content.encode()).decode()\n\n        # Check file existence to get SHA (for updating)\n        sha = None\n        try:\n            response = requests.get(url, headers=headers, params={\"ref\": branch}, verify=False)\n            if response.status_code == 200:\n                sha = response.json().get(\"sha\")\n        except Exception as e:\n            logger.error(f\"Failed to check file existence: {e}\", exc_info=True)\n\n        payload = {\"message\": f\"Add or update file: {sanitized_file}\",\n                   \"content\": encoded_content, \"branch\": branch}\n        if sha:\n            payload[\"sha\"] = sha  # Required for updating\n\n        # Upload or update file\n        try:\n            put_response = requests.put(url, json=payload, headers=headers, verify=False)\n            if put_response.status_code in [200, 201]:\n                logger.info(f\"\u2705 File '{sanitized_file}' uploaded successfully to {repo}/{sanitized_folder}\")\n                return f\"\u2705 File '{sanitized_file}' uploaded successfully to GitHub in folder '{sanitized_folder}'.\"\n            else:\n                logger.error(f\"GitHub API Error: {put_response.text}\")\n                return f\"\u274c Failed to upload file. GitHub API error: {put_response.text}\"\n        except Exception as e:\n            logger.error(f\"Failed to upload file: {e}\", exc_info=True)\n            return f\"\u274c Exception while uploading file: {str(e)}\"\n\n    # ------------------------------------------------------\n    # Required method for CrewAI Tool execution\n    # ------------------------------------------------------\n    def _run(self, repo: str, branch: str, token: str,\n             folder_name: str, file_name: str, content: str) -> Any:\n        \"\"\"Main execution method.\"\"\"\n        return self.create_file_in_github(repo, branch, token, folder_name, file_name, content)\n\n\n# ---------------------------------\n# Generalized Main (User-Parameterized)\n# ---------------------------------\nif __name__ == \"__main__\":\n    print(\"\ud83d\udd27 GitHub File Writer Tool - Interactive Mode\\n\")\n    repo = input(\"Enter GitHub repository (owner/repo): \").strip()\n    branch = input(\"Enter branch name (e.g., main): \").strip()\n    token = input(\"Enter your GitHub Personal Access Token: \").strip()\n    folder_name = input(\"Enter folder name: \").strip()\n    file_name = input(\"Enter file name (e.g., example.txt): \").strip()\n    print(\"\\nEnter the content for your file (end with a blank line):\")\n    lines = []\n    while True:\n        line = input()\n        if line == \"\":\n            break\n        lines.append(line)\n    content = \"\\n\".join(lines)\n\n    tool = GitHubFileWriterTool()\n    result = tool._run(repo=repo, branch=branch, token=token,\n                       folder_name=folder_name, file_name=file_name, content=content)\n    print(\"\\nResult:\", result)\n",
                            "isApproved": false
                        },
                        {
                            "toolId": 344,
                            "toolName": "DI_GitHub_File_Reader_Z",
                            "toolClassName": "GitHubFileReaderTool",
                            "toolClassDef": "from crewai.tools import BaseTool\nfrom pydantic import BaseModel, Field\nimport base64\nimport requests\nimport logging\nfrom typing import Type, Any, List, Dict\n\n# Setup logging for the GitHub File Reader Tool\nlogging.basicConfig(\n    level=logging.INFO,\n    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n    filename='github_file_reader.log'\n)\nlogger = logging.getLogger('GitHubFileReaderTool')\n\nclass GitHubFileReaderSchema(BaseModel):\n    \"\"\"Input schema for the GitHubFileReaderTool.\"\"\"\n    repo: str = Field(..., description=\"GitHub repository in the format 'owner/repo'\")\n    file_paths: List[str] = Field(..., description=\"List of file paths in the repository\")\n    branch: str = Field(..., description=\"Branch name to read the files from (e.g., 'main')\")\n    token: str = Field(..., description=\"GitHub personal access token for authorization\")\n\nclass GitHubFileReaderTool(BaseTool):\n    name: str = \"GitHub File Reader Tool\"\n    description: str = \"Reads multiple files from a GitHub repository based on user inputs.\"\n    args_schema: Type[BaseModel] = GitHubFileReaderSchema\n\n    api_url_template: str = \"https://api.github.com/repos/{repo}/contents/{file_path}\"\n\n    def fetch_file_from_github(self, repo: str, file_path: str, branch: str, token: str) -> str:\n        \"\"\"Fetches a file content from GitHub.\"\"\"\n        url = self.api_url_template.format(repo=repo, file_path=file_path)\n        headers = {\n            \"Authorization\": f\"token {token}\",\n            \"Accept\": \"application/vnd.github.v3+json\"\n        }\n        params = {\"ref\": branch}\n\n        try:\n            logger.info(f\"Fetching file '{file_path}' from repo '{repo}' on branch '{branch}'\")\n            response = requests.get(url, headers=headers, params=params)\n            response.raise_for_status()\n\n            file_data = response.json()\n            if \"content\" not in file_data:\n                raise ValueError(f\"\u274c Error: Path '{file_path}' might be a directory or missing content.\")\n\n            decoded_content = base64.b64decode(file_data['content']).decode('utf-8')\n            logger.info(f\"\u2705 Successfully fetched file '{file_path}'.\")\n            return decoded_content\n\n        except Exception as e:\n            logger.error(f\"Failed to fetch file '{file_path}': {str(e)}\", exc_info=True)\n            raise\n\n    def _run(self, repo: str, file_paths: List[str], branch: str, token: str) -> Dict[str, Any]:\n        \"\"\"Main execution logic.\"\"\"\n        all_files_content = {}\n        for file_path in file_paths:\n            try:\n                content = self.fetch_file_from_github(repo, file_path, branch, token)\n                all_files_content[file_path] = {\"status\": \"success\", \"content\": content}\n            except Exception as e:\n                all_files_content[file_path] = {\"status\": \"error\", \"message\": str(e)}\n\n        return all_files_content\n\n\n# Example Usage\nif __name__ == '__main__':\n    github_token = \"YOUR_GITHUB_TOKEN\"\n    github_repo = \"owner/repository-name\"\n    github_branch = \"main\"\n    github_files = [\n        \"path/to/file1.txt\",\n        \"path/to/file2.sql\",\n        \"path/to/file3.json\"\n    ]\n\n    if github_token == \"YOUR_GITHUB_TOKEN\":\n        print(\"\u26a0\ufe0f Please replace the placeholder values before running.\")\n    else:\n        reader_tool = GitHubFileReaderTool()\n        result = reader_tool.run(\n            repo=github_repo,\n            file_paths=github_files,\n            branch=github_branch,\n            token=github_token\n        )\n\n        for file, details in result.items():\n            print(f\"\\nFile: {file}\")\n            if details['status'] == 'success':\n                print(f\"Content:\\n{details['content'][:200]}...\")  # print first 200 characters\n            else:\n                print(f\"Error: {details['message']}\")\n",
                            "isApproved": false
                        }
                    ],
                    "allowCodeExecution": false,
                    "isSafeCodeExecution": true
                }
            },
            {
                "serial": 4,
                "agent": {
                    "id": 11228,
                    "name": "DI_AbInitio_To_PySpark_EMR_Glue_Reviewer_Claude",
                    "role": "Senior Data Engineer",
                    "goal": "Validate a PySpark EMR Glue script by comparing it with the corresponding Ab Initio .mp graph, .xfr transformation, and .dml schema files to ensure the logic and structure are accurately converted into EMR or AWS Glue compatible code.",
                    "backstory": "This agent assists in the migration of ETL workflows from Ab Initio to PySpark running on AWS EMR Glue. It helps developers ensure the converted PySpark code correctly reflects the logic, transformations, joins, and data structure defined in legacy Ab Initio assets.",
                    "verbose": true,
                    "allowDelegation": true,
                    "updatedAt": "2025-11-19T17:49:31.200021",
                    "llm": {
                        "modelDeploymentName": "Anthropic.claude-4-sonnet",
                        "model": "anthropic.claude-4-sonnet",
                        "modelType": "Generative",
                        "aiEngine": "AmazonBedrock",
                        "topP": 1.0,
                        "maxToken": 64000,
                        "temperature": 0.20000000298023224,
                        "bedrockModelId": "us.anthropic.claude-sonnet-4-20250514-v1:0",
                        "region": "us-east-1",
                        "accessKey": "****MASKED****",
                        "secretKey": "****MASKED****"
                    },
                    "task": {
                        "description": "Header:\n------------------------------------------------------------------------\nAuthor:        AAVA       \nDate:          <leave it blank>\nDescription:   <one-line description of the purpose>\n------------------------------------------------------------------------\n\n\u2705 Reviewer Agent Prompt for EMR/Glue PySpark Validation\n\nYou will receive the following inputs:\nAn Ab Initio .mp file defining the overall job flow and component connections.\nAn .xfr files containing transformation logic.\nAn .dml files containing schema definitions.\nAbInitio actual flow as a .pdf or .txt Graph file.\nThe corresponding PySpark EMR Glue code that was generated through the conversion agent take this file in the github directory.\n\nYour job is to thoroughly validate whether the PySpark EMR Glue file correctly implements the logic, sequence, and configuration defined in the Ab Initio files. This includes structural alignment, functional correctness, syntactic accuracy, schema mapping, and completeness of transformations.\n\n1. Parse and Analyze .mp File\n* Extract component names and sequence/order (e.g., input \u2192 reformat \u2192 join \u2192 filter \u2192 output).\n* Identify connections between components and branching logic.\n* Map the flow graph and store for order comparison.\n* Validate that EMR Glue code follows the same sequence.\n\n2. Parse .xfr Files\n* Extract all transformation logic, expressions, conditional mappings, and calculations.\n* Track each transformation and its exact position in the flow.\n* Validate that each transformation is correctly implemented in the same location in PySpark EMR Glue code.\n* Highlight any missing or altered .xfr logic.\n\n3. Parse .dml Files\n* Extract schema definitions, data types, nullability, and field order.\n* Compare .dml schemas with StructTypes or DynamicFrame schema used in EMR/Glue code.\n* Verify that the schema is applied correctly in:\n* input reading\n.select()\n.withColumn()\ntransformations\njoins\noutputs\n\n4. Analyze PySpark EMR Glue Code\n* Parse all steps: reading, transformation, joins, sorting, filtering, XFR calls, and output.\n* Extract the execution order of transformations.\n* Validate SparkSession or GlueContext initialization depending on runtime.\n* Identify .withColumn, .select, .join, .alias, .filter, UDF usage, and DynamicFrame conversions if Glue.\n* Perform line-by-line syntax validation to ensure proper PySpark, EMR, or Glue syntax.\n\n5. Validation Logic\n\u2705 Flow & Order Validation\n* Ensure the order of components in PySpark EMR Glue code matches the .mp and the Ab Initio Graph.\n* Highlight reordered or missing components.\n* Strictly the converted code should match the same flow which is present in the given AbInitio flow chart.\n\n\u2705 XFR Function Placement\n* Confirm that each .xfr function is used in the right position.\n* Check for missing, incorrect, or misplaced transformations.\n* Highlight any manual modifications that impacted logic.\n\n\u2705 SQL & Column Validations\n* Validate that SELECT logic from Ab Initio matches PySpark:\n* All columns exist\n* Aliases match\n* Calculations are correct\n* Expressions and conditions match\n* Highlight any missing or altered column logic.\n\n\u2705 Component Coverage\n* Verify that each component (e.g., reformat, join, filter, sort, dedup) from Ab Initio is implemented in PySpark EMR Glue.\n* Confirm that:\n    - join keys\n    - join type\n    - filters\n    - sort order\n    - partitioning\n    - layout\nare applied correctly.\n\n\u2705 Syntax Review\n* Perform line-by-line syntax validation of the PySpark EMR Glue code.\n* Highlight syntax errors, missing imports, indentation issues, wrong chaining, or misspelled functions.\n* Validate Glue-specific usage like DynamicFrame conversions.\n\n\u2705 Manual Intervention & Optimization\n* Identify hardcoded logic, incorrect assumptions, or mismatches.\n* Highlight any logic that requires manual intervention.\n* Suggest optimizations such as:\n* Use of broadcast joins\n* Avoiding unnecessary shuffles\n* Reducing repeated transformations\n* Glue optimization recommendations if applicable\n\nTool:\n* Use the Github reader tool to read the agent generated PySpark EMR Glue code in the Github directory the file name is actual input mp file name_Converted_PySpark_Code_GPT.py\n* Use the Github Writter tool to write the review report in the github directory the file name should be actual input mp file name_PySpark_Review_GPT.md\n* Other all inputs are provided as a zip file\n\nINPUTS:\n* mp Input file: {{AbInitio_Code}}\n* xfr module py Input file: {{XFR_File}}\n* dml schema py Input file: {{DML_File}}\n* AbInitio Flow Graph: {{Image_AbInitio_Flow_Chart}}\n* PySpark EMR Glue code generated by the converter agent take from the github directory, Github repo and directory detils : {{Github_Repo}}\n",
                        "expectedOutput": "Your output should contain:\nAdd the header in the top of the report \n\n\ud83d\udcdd Validation Report\n\nFor each component:\n\n\u2705 Correct \u2014 logic correctly implemented\n\n\u274c Incorrect \u2014 logic or structure is missing or wrong\n\n\ud83d\udd0d Needs Review \u2014 partially matched or unclear logic\n\n\ud83d\udccc Specific Checks\n\nFlow order mismatches\n\nIncorrect .xfr logic placement\n\nMissing columns in selections\n\nSchema mismatches\n\nWrong join types or missing join keys\n\nSyntax or semantic issues\n\nManual interventions required\n\nOptimization recommendations\n\n\ud83d\udcca Overall Conversion Summary\n\nConversion accuracy: xx%\n\nManual intervention level: Low / Medium / High\n\nConfidence score: High / Medium / Low"
                    },
                    "maxIter": 0,
                    "maxRpm": 0,
                    "maxExecutionTime": 0,
                    "tools": [],
                    "userTools": [
                        {
                            "toolId": 300,
                            "toolName": "DI_Github_File_Writer_Z",
                            "toolClassName": "GitHubFileWriterTool",
                            "toolClassDef": "from crewai.tools import BaseTool\nfrom pydantic import BaseModel, Field\nimport base64\nimport requests\nimport urllib3\nimport logging\nimport re\nfrom typing import Type, Any\n\n# ---------------------------------\n# SSL & Logging Configuration\n# ---------------------------------\nurllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\nlogging.basicConfig(\n    level=logging.INFO,\n    format=\"%(asctime)s - %(levelname)s - %(message)s\",\n    filename=\"github_file_writer.log\",\n)\nlogger = logging.getLogger(\"GitHubFileWriterTool\")\n\n\n# ---------------------------------\n# Input Schema\n# ---------------------------------\nclass GitHubFileWriterSchema(BaseModel):\n    repo: str = Field(..., description=\"GitHub repository in 'owner/repo' format\")\n    branch: str = Field(..., description=\"Branch name (e.g., 'main')\")\n    token: str = Field(..., description=\"GitHub Personal Access Token\")\n    folder_name: str = Field(..., description=\"Name of the folder to create inside the repository\")\n    file_name: str = Field(..., description=\"Name of the file to create or update in the folder\")\n    content: str = Field(..., description=\"Text content to upload into the GitHub file\")\n\n\n# ---------------------------------\n# Main Tool Class\n# ---------------------------------\nclass GitHubFileWriterTool(BaseTool):\n    name: str = \"GitHub File Writer Tool\"\n    description: str = \"Creates or updates files in a GitHub repository folder\"\n    args_schema: Type[BaseModel] = GitHubFileWriterSchema\n\n    api_url_template: str = \"https://api.github.com/repos/{repo}/contents/{path}\"\n\n    def _sanitize_path_component(self, component: str) -> str:\n        \"\"\"Remove invalid GitHub path characters.\"\"\"\n        sanitized = re.sub(r'[\\\\*?:\"<>|]', '_', component)\n        sanitized = re.sub(r'\\.\\.', '_', sanitized)\n        sanitized = sanitized.lstrip('./\\\\')\n        return sanitized if sanitized else \"default\"\n\n    def _validate_content(self, content: str) -> str:\n        \"\"\"Ensure valid string content within 10MB limit.\"\"\"\n        if not isinstance(content, str):\n            logger.warning(\"Content is not a string. Converting to string.\")\n            content = str(content)\n\n        max_size = 10 * 1024 * 1024  # 10 MB\n        if len(content.encode('utf-8')) > max_size:\n            logger.warning(\"Content exceeds 10MB limit. Truncating.\")\n            content = content[:max_size]\n\n        return content\n\n    def create_file_in_github(self, repo: str, branch: str, token: str,\n                              folder_name: str, file_name: str, content: str) -> str:\n        \"\"\"Create or update a file in GitHub repository.\"\"\"\n        sanitized_folder = self._sanitize_path_component(folder_name)\n        sanitized_file = self._sanitize_path_component(file_name)\n        validated_content = self._validate_content(content)\n\n        path = f\"{sanitized_folder}/{sanitized_file}\"\n        url = self.api_url_template.format(repo=repo, path=path)\n        headers = {\"Authorization\": f\"token {token}\", \"Content-Type\": \"application/json\"}\n\n        # Encode content\n        encoded_content = base64.b64encode(validated_content.encode()).decode()\n\n        # Check file existence to get SHA (for updating)\n        sha = None\n        try:\n            response = requests.get(url, headers=headers, params={\"ref\": branch}, verify=False)\n            if response.status_code == 200:\n                sha = response.json().get(\"sha\")\n        except Exception as e:\n            logger.error(f\"Failed to check file existence: {e}\", exc_info=True)\n\n        payload = {\"message\": f\"Add or update file: {sanitized_file}\",\n                   \"content\": encoded_content, \"branch\": branch}\n        if sha:\n            payload[\"sha\"] = sha  # Required for updating\n\n        # Upload or update file\n        try:\n            put_response = requests.put(url, json=payload, headers=headers, verify=False)\n            if put_response.status_code in [200, 201]:\n                logger.info(f\"\u2705 File '{sanitized_file}' uploaded successfully to {repo}/{sanitized_folder}\")\n                return f\"\u2705 File '{sanitized_file}' uploaded successfully to GitHub in folder '{sanitized_folder}'.\"\n            else:\n                logger.error(f\"GitHub API Error: {put_response.text}\")\n                return f\"\u274c Failed to upload file. GitHub API error: {put_response.text}\"\n        except Exception as e:\n            logger.error(f\"Failed to upload file: {e}\", exc_info=True)\n            return f\"\u274c Exception while uploading file: {str(e)}\"\n\n    # ------------------------------------------------------\n    # Required method for CrewAI Tool execution\n    # ------------------------------------------------------\n    def _run(self, repo: str, branch: str, token: str,\n             folder_name: str, file_name: str, content: str) -> Any:\n        \"\"\"Main execution method.\"\"\"\n        return self.create_file_in_github(repo, branch, token, folder_name, file_name, content)\n\n\n# ---------------------------------\n# Generalized Main (User-Parameterized)\n# ---------------------------------\nif __name__ == \"__main__\":\n    print(\"\ud83d\udd27 GitHub File Writer Tool - Interactive Mode\\n\")\n    repo = input(\"Enter GitHub repository (owner/repo): \").strip()\n    branch = input(\"Enter branch name (e.g., main): \").strip()\n    token = input(\"Enter your GitHub Personal Access Token: \").strip()\n    folder_name = input(\"Enter folder name: \").strip()\n    file_name = input(\"Enter file name (e.g., example.txt): \").strip()\n    print(\"\\nEnter the content for your file (end with a blank line):\")\n    lines = []\n    while True:\n        line = input()\n        if line == \"\":\n            break\n        lines.append(line)\n    content = \"\\n\".join(lines)\n\n    tool = GitHubFileWriterTool()\n    result = tool._run(repo=repo, branch=branch, token=token,\n                       folder_name=folder_name, file_name=file_name, content=content)\n    print(\"\\nResult:\", result)\n",
                            "isApproved": false
                        },
                        {
                            "toolId": 344,
                            "toolName": "DI_GitHub_File_Reader_Z",
                            "toolClassName": "GitHubFileReaderTool",
                            "toolClassDef": "from crewai.tools import BaseTool\nfrom pydantic import BaseModel, Field\nimport base64\nimport requests\nimport logging\nfrom typing import Type, Any, List, Dict\n\n# Setup logging for the GitHub File Reader Tool\nlogging.basicConfig(\n    level=logging.INFO,\n    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n    filename='github_file_reader.log'\n)\nlogger = logging.getLogger('GitHubFileReaderTool')\n\nclass GitHubFileReaderSchema(BaseModel):\n    \"\"\"Input schema for the GitHubFileReaderTool.\"\"\"\n    repo: str = Field(..., description=\"GitHub repository in the format 'owner/repo'\")\n    file_paths: List[str] = Field(..., description=\"List of file paths in the repository\")\n    branch: str = Field(..., description=\"Branch name to read the files from (e.g., 'main')\")\n    token: str = Field(..., description=\"GitHub personal access token for authorization\")\n\nclass GitHubFileReaderTool(BaseTool):\n    name: str = \"GitHub File Reader Tool\"\n    description: str = \"Reads multiple files from a GitHub repository based on user inputs.\"\n    args_schema: Type[BaseModel] = GitHubFileReaderSchema\n\n    api_url_template: str = \"https://api.github.com/repos/{repo}/contents/{file_path}\"\n\n    def fetch_file_from_github(self, repo: str, file_path: str, branch: str, token: str) -> str:\n        \"\"\"Fetches a file content from GitHub.\"\"\"\n        url = self.api_url_template.format(repo=repo, file_path=file_path)\n        headers = {\n            \"Authorization\": f\"token {token}\",\n            \"Accept\": \"application/vnd.github.v3+json\"\n        }\n        params = {\"ref\": branch}\n\n        try:\n            logger.info(f\"Fetching file '{file_path}' from repo '{repo}' on branch '{branch}'\")\n            response = requests.get(url, headers=headers, params=params)\n            response.raise_for_status()\n\n            file_data = response.json()\n            if \"content\" not in file_data:\n                raise ValueError(f\"\u274c Error: Path '{file_path}' might be a directory or missing content.\")\n\n            decoded_content = base64.b64decode(file_data['content']).decode('utf-8')\n            logger.info(f\"\u2705 Successfully fetched file '{file_path}'.\")\n            return decoded_content\n\n        except Exception as e:\n            logger.error(f\"Failed to fetch file '{file_path}': {str(e)}\", exc_info=True)\n            raise\n\n    def _run(self, repo: str, file_paths: List[str], branch: str, token: str) -> Dict[str, Any]:\n        \"\"\"Main execution logic.\"\"\"\n        all_files_content = {}\n        for file_path in file_paths:\n            try:\n                content = self.fetch_file_from_github(repo, file_path, branch, token)\n                all_files_content[file_path] = {\"status\": \"success\", \"content\": content}\n            except Exception as e:\n                all_files_content[file_path] = {\"status\": \"error\", \"message\": str(e)}\n\n        return all_files_content\n\n\n# Example Usage\nif __name__ == '__main__':\n    github_token = \"YOUR_GITHUB_TOKEN\"\n    github_repo = \"owner/repository-name\"\n    github_branch = \"main\"\n    github_files = [\n        \"path/to/file1.txt\",\n        \"path/to/file2.sql\",\n        \"path/to/file3.json\"\n    ]\n\n    if github_token == \"YOUR_GITHUB_TOKEN\":\n        print(\"\u26a0\ufe0f Please replace the placeholder values before running.\")\n    else:\n        reader_tool = GitHubFileReaderTool()\n        result = reader_tool.run(\n            repo=github_repo,\n            file_paths=github_files,\n            branch=github_branch,\n            token=github_token\n        )\n\n        for file, details in result.items():\n            print(f\"\\nFile: {file}\")\n            if details['status'] == 'success':\n                print(f\"Content:\\n{details['content'][:200]}...\")  # print first 200 characters\n            else:\n                print(f\"Error: {details['message']}\")\n",
                            "isApproved": false
                        }
                    ],
                    "allowCodeExecution": false,
                    "isSafeCodeExecution": true
                }
            },
            {
                "serial": 5,
                "agent": {
                    "id": 11239,
                    "name": "DI_AbInitio_To_PySpark_EMR_Glue_Model_Selection",
                    "role": "Senior Data Engineer",
                    "goal": "To compare two EMR Glue PySpark review reports generated by two different LLM models, determine which model converted the Ab Initio code more accurately, and produce a final Model Selection Report explaining the winning model, the reasons for selection, and the reasons for rejecting the other model. Finally, write the comparison report into the GitHub directory.",
                    "backstory": "Your workflow already has four agents:\n\n1. Converter Agent \u2013 Model A\n   Converts Ab Initio `.mp/.xfr/.dml` files into EMR Glue PySpark using LLM Model A and writes the output to GitHub.\n\n2. Converter Agent \u2013 Model B\n   Converts the same Ab Initio file into EMR Glue PySpark using LLM Model B and writes the output to GitHub.\n\n3. Reviewer Agent \u2013 Model A Review\n   Reviews Model A\u2019s converted output by comparing with the Ab Initio job flow and writes the review report in GitHub.\n\n4. Reviewer Agent \u2013 Model B Review\n   Reviews Model B\u2019s converted output in the same way and writes the review report in GitHub.\n\nNow the workflow needs a fifth agent.\n\nYour role (Agent 5):\nYou will read both reviewer output files from GitHub, compare the review findings, identify which LLM model performed a better Ab Initio \u2192 EMR Glue PySpark conversion, explain why, and generate a final \u201cModel Selection Report\u201d that is written back to GitHub.",
                    "verbose": true,
                    "allowDelegation": true,
                    "updatedAt": "2025-11-19T17:52:25.107693",
                    "llm": {
                        "modelDeploymentName": "anthropic.claude-4_5-sonnet",
                        "model": "anthropic.claude-4-5-sonnet",
                        "modelType": "Generative",
                        "aiEngine": "AmazonBedrock",
                        "topP": 1.0,
                        "maxToken": 64000,
                        "temperature": 0.20000000298023224,
                        "bedrockModelId": "us.anthropic.claude-sonnet-4-5-20250929-v1:0",
                        "region": "us-east-1",
                        "accessKey": "****MASKED****",
                        "secretKey": "****MASKED****"
                    },
                    "task": {
                        "description": "Header:\n------------------------------------------------------------------------\nAuthor:        AAVA       \nDate:          <leave it blank>\nDescription:   <one-line description of the purpose>\n------------------------------------------------------------------------\n\nYou will receive the following inputs:\n\n* mp Input file: {{AbInitio_Code}}\n* xfr module py Input file: {{XFR_File}}\n* dml schema py Input file: {{DML_File}}\n* Abinito graph flow chart: {{Image_AbInitio_Flow_Chart}}\n* GitHub repo and directory details \u2192 `{{Github_Repo}}` from in this directory take the both review report as a inputs, the name of the review report is actual input mp file name_PySpark_Review_GPT.md and actual input mp file name_PySpark_Review_Claude.md\n\n\nYour responsibilities:\n\n 1. Read both review reports from GitHub\n \nUse the GitHub Reader tool to read:\n* actual input mp file name_PySpark_Review_Claude.md\n* actual input mp file name_PySpark_Review_GPT.md\n\nSafely parse the entire content of both files.\n\n---\n\n 2. Identify model names\n\nExtract the LLM model identifiers from:\n\n* Input file name\n* Review file names\n\nExample models: `_GPT`, `_CLAUDE`, `_LLM_A`, `_LLM_B`\nMap them as:\n\n* Model 1 \u2192 Review file A\n* Model 2 \u2192 Review file B\n\n---\n\n 3. Extract key metrics from each review report\n\nFor both review reports, analyze and extract quality indicators related to:\n\n1. Flow & Order Alignment with `.mp` and Ab Initio flow graph\n2. XFR / transformation correctness\n3. Schema & DML alignment\n4. SQL/column logic correctness\n5. Syntax correctness & EMR Glue compatibility\n6. Component coverage\n7. Performance & optimization observations\n8. Manual effort required / final readiness score\n\nUse any numeric scores if present.\nIf not numeric, convert textual ratings into internal scale (Excellent/Good/Average/Poor \u2192 100/85/70/50).\n\n---\n\n 4. Compare both models using a weighted comparison logic\n\nAssign higher weight to:\n\n* Flow alignment\n* Transformation correctness\n* Schema correctness\n* Syntax / executability\n\nCreate a comparison matrix internally.\n\n---\n\n 5. Select the better-performing model\n\nChoose the model that:\n\n* Has fewer critical/blocker issues\n* Matches Ab Initio flow correctly\n* Preserves XFR logic\n* Matches schema precisely\n* Has cleaner syntax and fewer errors\n* Requires the least manual adjustments\n\nIf both fail badly, still choose the one that is relatively better and mention that neither is production-ready.\n\n 6. Write the final comparison report to GitHub\n\nUse the GitHub Writer tool to store a file in the github directory:\nNaming Convention:\n`<BaseNameOfInputMPFile>_PySpark_Review_Model_Selection_Report.md`\n\nThis report must contain:\n\n1. Header\n2. Input summary\n3. Comparison table\n4. Final selected model\n",
                        "expectedOutput": "A clear, structured Model Selection Report written to GitHub containing the following sections:\n\n---\n\n 1. Header \n \n 2. Summary\n\n* Input Ab Initio File\n* Model A name & review file\n* Model B name & review file\n\n---\n\n 3. Final Decision\n\n* Selected Model: `<ModelName>`\n* Rejected Model: `<ModelName>`\n* 2\u20133 line summary of the reasoning\n\n---\n\n 4. Comparison Table\n\n| Dimension / Checkpoint           | Model A | Model B | Better Model | Notes |\n| -------------------------------- | ------- | ------- | ------------ | ----- |\n| Flow & Order Alignment           |         |         |              |       |\n| Transformation (XFR) Correctness |         |         |              |       |\n| Schema & DML Alignment           |         |         |              |       |\n| SQL & Column Logic               |         |         |              |       |\n| Syntax & EMR Glue Compatibility  |         |         |              |       |\n| Component Coverage               |         |         |              |       |\n| Optimization & Performance       |         |         |              |       |\n| Overall Readiness                |         |         |              |       |\n\n---\n\n 5. Why the Selected Model is Better\n\n* Bullet points describing strengths\n* Specific technical advantages\n* Evidence from the reviewer report\n\n---\n\n 6. Why the Other Model is Rejected\n\n* Bullet points on gaps, blockers, or inconsistencies\n* High-risk issues identified\n* Flow/schema/logic mismatches\n\n---\n\n 7. Final Recommendation\n\n* Whether selected model is production-ready\n* If manual fixes are needed\n* Whether reconversion or re-review is required"
                    },
                    "maxIter": 0,
                    "maxRpm": 0,
                    "maxExecutionTime": 0,
                    "tools": [],
                    "userTools": [
                        {
                            "toolId": 300,
                            "toolName": "DI_Github_File_Writer_Z",
                            "toolClassName": "GitHubFileWriterTool",
                            "toolClassDef": "from crewai.tools import BaseTool\nfrom pydantic import BaseModel, Field\nimport base64\nimport requests\nimport urllib3\nimport logging\nimport re\nfrom typing import Type, Any\n\n# ---------------------------------\n# SSL & Logging Configuration\n# ---------------------------------\nurllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\nlogging.basicConfig(\n    level=logging.INFO,\n    format=\"%(asctime)s - %(levelname)s - %(message)s\",\n    filename=\"github_file_writer.log\",\n)\nlogger = logging.getLogger(\"GitHubFileWriterTool\")\n\n\n# ---------------------------------\n# Input Schema\n# ---------------------------------\nclass GitHubFileWriterSchema(BaseModel):\n    repo: str = Field(..., description=\"GitHub repository in 'owner/repo' format\")\n    branch: str = Field(..., description=\"Branch name (e.g., 'main')\")\n    token: str = Field(..., description=\"GitHub Personal Access Token\")\n    folder_name: str = Field(..., description=\"Name of the folder to create inside the repository\")\n    file_name: str = Field(..., description=\"Name of the file to create or update in the folder\")\n    content: str = Field(..., description=\"Text content to upload into the GitHub file\")\n\n\n# ---------------------------------\n# Main Tool Class\n# ---------------------------------\nclass GitHubFileWriterTool(BaseTool):\n    name: str = \"GitHub File Writer Tool\"\n    description: str = \"Creates or updates files in a GitHub repository folder\"\n    args_schema: Type[BaseModel] = GitHubFileWriterSchema\n\n    api_url_template: str = \"https://api.github.com/repos/{repo}/contents/{path}\"\n\n    def _sanitize_path_component(self, component: str) -> str:\n        \"\"\"Remove invalid GitHub path characters.\"\"\"\n        sanitized = re.sub(r'[\\\\*?:\"<>|]', '_', component)\n        sanitized = re.sub(r'\\.\\.', '_', sanitized)\n        sanitized = sanitized.lstrip('./\\\\')\n        return sanitized if sanitized else \"default\"\n\n    def _validate_content(self, content: str) -> str:\n        \"\"\"Ensure valid string content within 10MB limit.\"\"\"\n        if not isinstance(content, str):\n            logger.warning(\"Content is not a string. Converting to string.\")\n            content = str(content)\n\n        max_size = 10 * 1024 * 1024  # 10 MB\n        if len(content.encode('utf-8')) > max_size:\n            logger.warning(\"Content exceeds 10MB limit. Truncating.\")\n            content = content[:max_size]\n\n        return content\n\n    def create_file_in_github(self, repo: str, branch: str, token: str,\n                              folder_name: str, file_name: str, content: str) -> str:\n        \"\"\"Create or update a file in GitHub repository.\"\"\"\n        sanitized_folder = self._sanitize_path_component(folder_name)\n        sanitized_file = self._sanitize_path_component(file_name)\n        validated_content = self._validate_content(content)\n\n        path = f\"{sanitized_folder}/{sanitized_file}\"\n        url = self.api_url_template.format(repo=repo, path=path)\n        headers = {\"Authorization\": f\"token {token}\", \"Content-Type\": \"application/json\"}\n\n        # Encode content\n        encoded_content = base64.b64encode(validated_content.encode()).decode()\n\n        # Check file existence to get SHA (for updating)\n        sha = None\n        try:\n            response = requests.get(url, headers=headers, params={\"ref\": branch}, verify=False)\n            if response.status_code == 200:\n                sha = response.json().get(\"sha\")\n        except Exception as e:\n            logger.error(f\"Failed to check file existence: {e}\", exc_info=True)\n\n        payload = {\"message\": f\"Add or update file: {sanitized_file}\",\n                   \"content\": encoded_content, \"branch\": branch}\n        if sha:\n            payload[\"sha\"] = sha  # Required for updating\n\n        # Upload or update file\n        try:\n            put_response = requests.put(url, json=payload, headers=headers, verify=False)\n            if put_response.status_code in [200, 201]:\n                logger.info(f\"\u2705 File '{sanitized_file}' uploaded successfully to {repo}/{sanitized_folder}\")\n                return f\"\u2705 File '{sanitized_file}' uploaded successfully to GitHub in folder '{sanitized_folder}'.\"\n            else:\n                logger.error(f\"GitHub API Error: {put_response.text}\")\n                return f\"\u274c Failed to upload file. GitHub API error: {put_response.text}\"\n        except Exception as e:\n            logger.error(f\"Failed to upload file: {e}\", exc_info=True)\n            return f\"\u274c Exception while uploading file: {str(e)}\"\n\n    # ------------------------------------------------------\n    # Required method for CrewAI Tool execution\n    # ------------------------------------------------------\n    def _run(self, repo: str, branch: str, token: str,\n             folder_name: str, file_name: str, content: str) -> Any:\n        \"\"\"Main execution method.\"\"\"\n        return self.create_file_in_github(repo, branch, token, folder_name, file_name, content)\n\n\n# ---------------------------------\n# Generalized Main (User-Parameterized)\n# ---------------------------------\nif __name__ == \"__main__\":\n    print(\"\ud83d\udd27 GitHub File Writer Tool - Interactive Mode\\n\")\n    repo = input(\"Enter GitHub repository (owner/repo): \").strip()\n    branch = input(\"Enter branch name (e.g., main): \").strip()\n    token = input(\"Enter your GitHub Personal Access Token: \").strip()\n    folder_name = input(\"Enter folder name: \").strip()\n    file_name = input(\"Enter file name (e.g., example.txt): \").strip()\n    print(\"\\nEnter the content for your file (end with a blank line):\")\n    lines = []\n    while True:\n        line = input()\n        if line == \"\":\n            break\n        lines.append(line)\n    content = \"\\n\".join(lines)\n\n    tool = GitHubFileWriterTool()\n    result = tool._run(repo=repo, branch=branch, token=token,\n                       folder_name=folder_name, file_name=file_name, content=content)\n    print(\"\\nResult:\", result)\n",
                            "isApproved": false
                        },
                        {
                            "toolId": 344,
                            "toolName": "DI_GitHub_File_Reader_Z",
                            "toolClassName": "GitHubFileReaderTool",
                            "toolClassDef": "from crewai.tools import BaseTool\nfrom pydantic import BaseModel, Field\nimport base64\nimport requests\nimport logging\nfrom typing import Type, Any, List, Dict\n\n# Setup logging for the GitHub File Reader Tool\nlogging.basicConfig(\n    level=logging.INFO,\n    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n    filename='github_file_reader.log'\n)\nlogger = logging.getLogger('GitHubFileReaderTool')\n\nclass GitHubFileReaderSchema(BaseModel):\n    \"\"\"Input schema for the GitHubFileReaderTool.\"\"\"\n    repo: str = Field(..., description=\"GitHub repository in the format 'owner/repo'\")\n    file_paths: List[str] = Field(..., description=\"List of file paths in the repository\")\n    branch: str = Field(..., description=\"Branch name to read the files from (e.g., 'main')\")\n    token: str = Field(..., description=\"GitHub personal access token for authorization\")\n\nclass GitHubFileReaderTool(BaseTool):\n    name: str = \"GitHub File Reader Tool\"\n    description: str = \"Reads multiple files from a GitHub repository based on user inputs.\"\n    args_schema: Type[BaseModel] = GitHubFileReaderSchema\n\n    api_url_template: str = \"https://api.github.com/repos/{repo}/contents/{file_path}\"\n\n    def fetch_file_from_github(self, repo: str, file_path: str, branch: str, token: str) -> str:\n        \"\"\"Fetches a file content from GitHub.\"\"\"\n        url = self.api_url_template.format(repo=repo, file_path=file_path)\n        headers = {\n            \"Authorization\": f\"token {token}\",\n            \"Accept\": \"application/vnd.github.v3+json\"\n        }\n        params = {\"ref\": branch}\n\n        try:\n            logger.info(f\"Fetching file '{file_path}' from repo '{repo}' on branch '{branch}'\")\n            response = requests.get(url, headers=headers, params=params)\n            response.raise_for_status()\n\n            file_data = response.json()\n            if \"content\" not in file_data:\n                raise ValueError(f\"\u274c Error: Path '{file_path}' might be a directory or missing content.\")\n\n            decoded_content = base64.b64decode(file_data['content']).decode('utf-8')\n            logger.info(f\"\u2705 Successfully fetched file '{file_path}'.\")\n            return decoded_content\n\n        except Exception as e:\n            logger.error(f\"Failed to fetch file '{file_path}': {str(e)}\", exc_info=True)\n            raise\n\n    def _run(self, repo: str, file_paths: List[str], branch: str, token: str) -> Dict[str, Any]:\n        \"\"\"Main execution logic.\"\"\"\n        all_files_content = {}\n        for file_path in file_paths:\n            try:\n                content = self.fetch_file_from_github(repo, file_path, branch, token)\n                all_files_content[file_path] = {\"status\": \"success\", \"content\": content}\n            except Exception as e:\n                all_files_content[file_path] = {\"status\": \"error\", \"message\": str(e)}\n\n        return all_files_content\n\n\n# Example Usage\nif __name__ == '__main__':\n    github_token = \"YOUR_GITHUB_TOKEN\"\n    github_repo = \"owner/repository-name\"\n    github_branch = \"main\"\n    github_files = [\n        \"path/to/file1.txt\",\n        \"path/to/file2.sql\",\n        \"path/to/file3.json\"\n    ]\n\n    if github_token == \"YOUR_GITHUB_TOKEN\":\n        print(\"\u26a0\ufe0f Please replace the placeholder values before running.\")\n    else:\n        reader_tool = GitHubFileReaderTool()\n        result = reader_tool.run(\n            repo=github_repo,\n            file_paths=github_files,\n            branch=github_branch,\n            token=github_token\n        )\n\n        for file, details in result.items():\n            print(f\"\\nFile: {file}\")\n            if details['status'] == 'success':\n                print(f\"Content:\\n{details['content'][:200]}...\")  # print first 200 characters\n            else:\n                print(f\"Error: {details['message']}\")\n",
                            "isApproved": false
                        }
                    ],
                    "allowCodeExecution": false,
                    "isSafeCodeExecution": true
                }
            }
        ],
        "enableAgenticMemory": false,
        "levelId": 99,
        "org": "Ascendion",
        "orgId": 1,
        "domain": "Data&Insights",
        "domainId": 96,
        "projectId": 98,
        "project": "AllProjects",
        "teamId": 99,
        "team": "AVA Team",
        "callbacks": []
    }
}