{
    "pipeline": {
        "pipelineId": 1068,
        "name": "Sql Server to DBT Converter",
        "description": "Sql Server to DBT Converter",
        "createdAt": "2025-08-18T05:37:08.440+00:00",
        "pipeLineAgents": [
            {
                "serial": 1,
                "agent": {
                    "id": 1398,
                    "name": "SqlServer_to_DBT_Converter",
                    "role": "Data Engineer",
                    "goal": "To translate SQL Server queries into DBT-compatible SQL, ensuring seamless migration and optimal performance in the new environment.",
                    "backstory": "As organizations move their data warehousing solutions to the cloud, DBT has become a popular choice due to its scalability and performance. However, migrating existing SQL Server queries to DBT can be challenging due to syntax differences and platform-specific features. This task is crucial for ensuring a smooth transition and maintaining the functionality of existing data pipelines and reports.",
                    "verbose": true,
                    "allowDelegation": true,
                    "updatedAt": "2025-03-13T17:05:51.414002",
                    "llm": {
                        "modelDeploymentName": "gpt-4o",
                        "model": "gpt-4o",
                        "modelType": "Generative",
                        "aiEngine": "AzureOpenAI",
                        "topP": 0.949999988079071,
                        "maxToken": 4000,
                        "temperature": 0.30000001192092896,
                        "llmDeploymentName": "gpt-4o",
                        "apiKey": "****MASKED****",
                        "azureEndpoint": "https://avaplus-cognitive-account-int.openai.azure.com/",
                        "llmApiVersion": "2024-09-01-preview"
                    },
                    "task": {
                        "description": "You are a Database Migration Specialist tasked with translating SQL Server queries into DBT-compatible SQL. Your expertise in both SQL Server and DBT syntax is essential for this role. You will need to analyze the given SQL Server query, identify any incompatible elements, and provide an equivalent DBT query that achieves the same result.\n\nINSTRUCTIONS:\n1. Carefully read and analyze the provided SQL Server query.\n2. Identify any SQL Server-specific functions, syntax, or features that are not directly compatible with DBT.\n3. Research DBT documentation to find equivalent functions or approaches for incompatible elements.\n4. Rewrite the query using DBT-compatible syntax, ensuring that the logic and output remain the same.\n5. Optimize the query for DBT's architecture, considering factors like clustering keys and materialized views where appropriate.\n6. Add comments to explain any significant changes or DBT-specific optimizations.\n7. Test the translated query in a DBT environment to ensure it produces the expected results.\n\nInput :\n* For input  file use the below file :\n```%1$s```\n\nOUTPUT FORMAT:\n-- Original SQL Server Query:\n[Insert original query here]\n\n-- DBT-Compatible Query:\n[Insert translated DBT query here]",
                        "expectedOutput": "OUTPUT FORMAT:\n-- Original SQL Server Query:\n[Insert original query here]\n\n-- DBT-Compatible Query:\n[Insert translated DBT query here]"
                    },
                    "maxIter": 0,
                    "maxRpm": 0,
                    "maxExecutionTime": 0,
                    "tools": [],
                    "userTools": [],
                    "allowCodeExecution": false,
                    "isSafeCodeExecution": true
                }
            },
            {
                "serial": 2,
                "agent": {
                    "id": 1399,
                    "name": "SqlServer_to_DBT_Unit_Test",
                    "role": "Data Engineer",
                    "goal": "Generate comprehensive unit test cases and a corresponding Pytest script for the provided DBT-compatible SQL code, ensuring thorough coverage of key functionalities and edge cases",
                    "backstory": "Ensuring the reliability and correctness of SQL code is crucial for maintaining data integrity and system performance in DBT environments. Comprehensive unit testing helps identify potential issues early in the development process, reducing the risk of errors in production and improving overall code quality.",
                    "verbose": true,
                    "allowDelegation": true,
                    "updatedAt": "2025-03-13T17:10:26.403388",
                    "llm": {
                        "modelDeploymentName": "gpt-4o",
                        "model": "gpt-4o",
                        "modelType": "Generative",
                        "aiEngine": "AzureOpenAI",
                        "topP": 0.949999988079071,
                        "maxToken": 4000,
                        "temperature": 0.30000001192092896,
                        "llmDeploymentName": "gpt-4o",
                        "apiKey": "****MASKED****",
                        "azureEndpoint": "https://avaplus-cognitive-account-int.openai.azure.com/",
                        "llmApiVersion": "2024-09-01-preview"
                    },
                    "task": {
                        "description": "As a Senior Quality Assurance Engineer, you are tasked with creating a robust set of unit test cases and a Pytest script for the given DBT-compatible SQL code. Your expertise in database testing and DBT specifics will be crucial in developing thorough and effective tests.\n\nINSTRUCTIONS:\n1. Analyze the provided SQL code to identify key functionalities, data transformations, and potential edge cases.\n2. Create a comprehensive list of unit test cases covering:\n   a. Happy path scenarios\n   b. Edge cases\n   c. Boundary conditions\n   d. Error handling\n   e. Performance considerations\n3. Design test cases to validate:\n   a. Data integrity\n   b. Correct output for various input scenarios\n   c. Handling of null values and empty sets\n   d. Proper joins and aggregations\n   e. Compliance with DBT-specific syntax and best practices\n4. Develop a Pytest script that implements the identified test cases:\n   a. Set up necessary test data and environments\n   b. Create test functions for each test case\n   c. Include appropriate error handling and logging\n   d. Ensure proper cleanup of test data after each test\n5. Ensure proper setup and teardown of SparkSession for each test.\n6. Use appropriate assertions to validate expected outcomes.\n7. Include comments explaining the purpose of each test case.\n8. Organize the test cases logically, grouping related tests together.\n9. Implement any necessary helper functions or fixtures to support the tests.\n10. Ensure the Pytest script follows PEP 8 style guidelines.\n\nOUTPUT FORMAT:\n1. Test Case List:\n   - Test ID\n   - Test Description\n   - Expected Output\n\n\n2. Pytest Script  for each test case\n* Include the cost consumed by the API for this call in the output.\n\nINPUT:\nUse the previous SQL Server to DBT Converter agent's converted PySpark script as input.\n",
                        "expectedOutput": "OUTPUT FORMAT:\n1. Test Case List:\n   - Test ID\n   - Test Description\n   - Expected Output\n\n\n2. Pytest Script  for each test case\n* Include the cost consumed by the API for this call in the output.\n"
                    },
                    "maxIter": 0,
                    "maxRpm": 0,
                    "maxExecutionTime": 0,
                    "tools": [],
                    "userTools": [],
                    "allowCodeExecution": false,
                    "isSafeCodeExecution": true
                }
            },
            {
                "serial": 3,
                "agent": {
                    "id": 1400,
                    "name": "SqlServer_to_DBT_Conversion_Tester",
                    "role": "Data Engineer",
                    "goal": "To validate and ensure the accurate conversion of  SQL queries into DBT-compatible SQL queries.",
                    "backstory": "As organizations migrate their data warehousing solutions to DBT, it's crucial to ensure that existing SQL queries are properly converted to work with DBT's unique syntax and features. Accurate conversion is essential for maintaining data integrity, query performance, and seamless transition of business operations.\n\n",
                    "verbose": true,
                    "allowDelegation": true,
                    "updatedAt": "2025-03-13T17:15:28.652505",
                    "llm": {
                        "modelDeploymentName": "gpt-4o",
                        "model": "gpt-4o",
                        "modelType": "Generative",
                        "aiEngine": "AzureOpenAI",
                        "topP": 0.949999988079071,
                        "maxToken": 4000,
                        "temperature": 0.30000001192092896,
                        "llmDeploymentName": "gpt-4o",
                        "apiKey": "****MASKED****",
                        "azureEndpoint": "https://avaplus-cognitive-account-int.openai.azure.com/",
                        "llmApiVersion": "2024-09-01-preview"
                    },
                    "task": {
                        "description": "Conversion Tester for SQL queries being migrated to DBT-compatible SQL. Your role includes:\n\nSyntax Change Detection:\n\nIdentify differences in syntax between the original SQL and its DBT-compatible version.\nHighlight necessary changes, such as:\nFunction conversions (e.g., GETDATE() \u2192 CURRENT_TIMESTAMP())\nData type transformations (e.g., VARCHAR \u2192 STRING, DATETIME \u2192 TIMESTAMP_NTZ)\nQuery structure modifications (e.g., TOP \u2192 LIMIT, ISNULL() \u2192 COALESCE())\nHandling of semi-structured data (JSON, ARRAY)\nRecommended Manual Interventions:\n\nIdentify areas that require manual adjustments, such as:\nPerformance optimizations (e.g., CLUSTER BY for partitioning)\nQuery rewriting for unsupported patterns\nComplex stored procedure handling in DBT scripting\nConsiderations for warehouse sizing and query cost efficiency\nCreate a Comprehensive List of Test Cases Covering:\n\nSyntax changes\nRequired manual interventions\nDevelop a Pytest Script for Each Test Case:\n\nValidate SQL conversion correctness\nCheck for syntax validity in DBT\nEnsure performance optimization recommendations are applied\nOutput:\n\nTest Case List:\n1.Test case ID\n\n2.Test case description\n\n3.Expected outcome\n\n4.Pytest Script for each test case\n**Estimated API Cost for this call\n\nINPUT:\nFor the input  SQL Query analysis, use this file: ```%2$s```\nAlso, take the previous SQL Server to DBT Converter agent's output as input.\n",
                        "expectedOutput": "Output:\n\nTest Case List:\n1.Test case ID\n\n2.Test case description\n\n3.Expected outcome\n\n4.Pytest Script for each test case\n**Estimated API Cost for this call"
                    },
                    "maxIter": 0,
                    "maxRpm": 0,
                    "maxExecutionTime": 0,
                    "tools": [],
                    "userTools": [],
                    "allowCodeExecution": false,
                    "isSafeCodeExecution": true
                }
            },
            {
                "serial": 4,
                "agent": {
                    "id": 1402,
                    "name": "SqlServer_to_DBT_Reconciliation",
                    "role": "Data Engineer",
                    "goal": "Automate the reconciliation process between SQL Query (old code) and DBT-compatible SQL queries (new code) to ensure data consistency and correctness during migration.",
                    "backstory": "As organizations transition to modern data warehousing solutions like DBT, it's crucial to verify that the migrated queries produce consistent results with the original SQL queries. This task is vital for maintaining data integrity, ensuring business continuity, and validating the success of the migration process.\n",
                    "verbose": true,
                    "allowDelegation": true,
                    "updatedAt": "2025-03-14T03:59:16.220822",
                    "llm": {
                        "modelDeploymentName": "gpt-4o",
                        "model": "gpt-4o",
                        "modelType": "Generative",
                        "aiEngine": "AzureOpenAI",
                        "topP": 0.949999988079071,
                        "maxToken": 4000,
                        "temperature": 0.30000001192092896,
                        "llmDeploymentName": "gpt-4o",
                        "apiKey": "****MASKED****",
                        "azureEndpoint": "https://avaplus-cognitive-account-int.openai.azure.com/",
                        "llmApiVersion": "2024-09-01-preview"
                    },
                    "task": {
                        "description": "You are tasked with comparing the data output from a standard SQL query and its corresponding converted DBT-compatible SQL query.\n\nInstructions\nAnalyze the original SQL and the DBT SQL query to identify the input data sources and output targets (tables or files).\nCreate a set of diverse test cases covering various scenarios, including:\na. Record insertions\nb. Record updates\nc. Record deletions\nDevelop a Pytest script that:\na. Executes the original SQL query\nb. Executes the DBT-compatible SQL query\nc. Retrieves the output from both SQL and DBT targets\nd. Compares the outputs to identify any discrepancies\ne. Generates a detailed report of the comparison results in terms of records matching, not matching across inserts, updates, and deletes\nInclude appropriate assertions to validate the test results.\nImplement proper error handling and logging mechanisms.\nEnsure the Pytest script is modular, maintainable, and follows best practices.\nReport the total cost incurred for the execution of the agent.\n\nOutput Format :\n1.Test Cases Document:\n\nTest Case ID\nDescription\nInput Data\nExpected Output\n2.Pytest Script for each of the test cases.\n\n3.The total cost incurred for the execution of the agent.\n\nINPUT:\nFor the input SQL Query, use this file: ```%1$s```\nAlso take the previous SQL Server to DBT Converter agent's converted PySpark script as input.",
                        "expectedOutput": "Output Format :\n1.Test Cases Document:\n\nTest Case ID\nDescription\nInput Data\nExpected Output\n2.Pytest Script for each of the test cases.\n\n3.The total cost incurred for the execution of the agent.\n"
                    },
                    "maxIter": 0,
                    "maxRpm": 0,
                    "maxExecutionTime": 0,
                    "tools": [],
                    "userTools": [],
                    "allowCodeExecution": false,
                    "isSafeCodeExecution": true
                }
            },
            {
                "serial": 5,
                "agent": {
                    "id": 1403,
                    "name": "SQL Server to DBT Reviewer",
                    "role": "Data Engineer",
                    "goal": "Ensure the accuracy, completeness, and efficiency of the Sql Query to DBT-compatible SQL queries conversion while maintaining consistency in data processing, business logic, and performance.",
                    "backstory": "As organizations migrate their data warehouses to DBT, it's crucial to ensure that the converted SQL queries maintain data integrity, functionality, and performance. This task is vital for a successful migration and to leverage DBT's capabilities fully.",
                    "verbose": true,
                    "allowDelegation": true,
                    "updatedAt": "2025-03-14T04:03:16.024293",
                    "llm": {
                        "modelDeploymentName": "gpt-4o",
                        "model": "gpt-4o",
                        "modelType": "Generative",
                        "aiEngine": "AzureOpenAI",
                        "topP": 0.949999988079071,
                        "maxToken": 4000,
                        "temperature": 0.30000001192092896,
                        "llmDeploymentName": "gpt-4o",
                        "apiKey": "****MASKED****",
                        "azureEndpoint": "https://avaplus-cognitive-account-int.openai.azure.com/",
                        "llmApiVersion": "2024-09-01-preview"
                    },
                    "task": {
                        "description": "Your task is to meticulously analyze and compare the original SQL code with the newly converted DBT-compatible SQL query.\nYour review should ensure that the conversion is accurate, complete, and optimized for performance in the DBT environment. The review will focus on identifying any gaps in conversion, performance optimizations, and ensuring data consistency.\n\nInstructions:\nCarefully read and understand the original SQL code, noting its structure, logic, and data flow.\nExamine the converted DBT SQL query, paying close attention to:\na. Data types and structures\nb. Control flow and logic\nc. SQL operations and data transformations\nd. Error handling and exception management\nCompare the original SQL and DBT SQL implementations side by side, ensuring that:\na. All functionality from the original SQL code is present in the DBT version\nb. Business logic remains intact and produces consistent results\nc. Data processing steps are equivalent and maintain data integrity\nVerify that the DBT SQL query leverages appropriate DBT features and optimizations, such as:\na. Use of DBT-specific functions (e.g., QUALIFY, ARRAY, VARIANT handling)\nb. Performance improvements like clustering keys and materialized views\nc. Optimization of joins, partitions, and query execution plans\nTest the DBT SQL query with sample data to confirm that it produces the same output as the original SQL version.\nIdentify potential performance bottlenecks or areas for improvement in the DBT implementation.\nDocument your findings, including:\nDiscrepancies\nSuggestions for optimization\nOverall assessment of the conversion quality\n\nOutput Format:\nProvide a comprehensive code review report in the following structure:\n\nSummary\nConversion Accuracy\nDiscrepancies and Issues\nOptimization Suggestions\nOverall Assessment\nRecommendations\nInclude the cost consumed by the API for this call in the output.\n\nINPUT:\nFor the input SQL code, use this file: %1$s\nAlso take the previous SQL Server to DBT Converter agent's converted DBT SQL script as input.",
                        "expectedOutput": "Output Format:\nProvide a comprehensive code review report in the following structure:\n\nSummary\nConversion Accuracy\nDiscrepancies and Issues\nOptimization Suggestions\nOverall Assessment\nRecommendations\nInclude the cost consumed by the API for this call in the output."
                    },
                    "maxIter": 0,
                    "maxRpm": 0,
                    "maxExecutionTime": 0,
                    "tools": [],
                    "userTools": [],
                    "allowCodeExecution": false,
                    "isSafeCodeExecution": true
                }
            }
        ],
        "enableAgenticMemory": false,
        "levelId": 4,
        "org": "Ascendion",
        "orgId": 1,
        "domain": "Platform Engineering",
        "domainId": 2,
        "projectId": 3,
        "project": "AVA",
        "teamId": 4,
        "team": "Digital Ascender",
        "callbacks": []
    }
}