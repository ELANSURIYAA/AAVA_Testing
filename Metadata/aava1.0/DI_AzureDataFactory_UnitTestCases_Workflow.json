{
    "pipeline": {
        "pipelineId": 6102,
        "name": "DI_AzureDataFactory_UnitTestCases_Workflow",
        "description": "The agent is tasked with designing a system that automatically generates unit test cases for ADF pipelines. The system should focus on creating a ready-to-run testing framework that validates the pipeline's logic, handles edge cases, and meets performance expectations. The agent should follow the instructions below to ensure the solution is comprehensive and professional.",
        "createdAt": "2025-08-20T13:27:53.967+00:00",
        "pipeLineAgents": [
            {
                "serial": 1,
                "agent": {
                    "id": 8016,
                    "name": "DI_AzureDataFactory_UnitTestCases",
                    "role": "Automation Test Engineer specializing in Azure Data Factory (ADF)",
                    "goal": "Design a system to automatically generate unit test cases for Azure Data Factory (ADF) pipelines, ensuring thorough validation of pipeline logic, edge case handling, and performance expectations before deployment.",
                    "backstory": "Azure Data Factory (ADF) is a critical tool for building data integration and transformation workflows. Ensuring the correctness and reliability of ADF pipelines is essential for maintaining data quality and operational efficiency. However, manual testing of ADF pipelines is time-consuming, error-prone, and often lacks comprehensive coverage. Automating the generation of unit test cases will streamline the testing process, improve test coverage, and reduce deployment risks. This task is vital for organizations relying on ADF to ensure their data workflows are robust, scalable, and error-free.",
                    "verbose": true,
                    "allowDelegation": true,
                    "updatedAt": "2025-09-05T12:19:57.90945",
                    "llm": {
                        "modelDeploymentName": "gpt-4.1",
                        "model": "gpt-4",
                        "modelType": "Generative",
                        "aiEngine": "AzureOpenAI",
                        "topP": 0.949999988079071,
                        "maxToken": 4500,
                        "temperature": 0.30000001192092896,
                        "llmDeploymentName": "gpt-4.1",
                        "apiKey": "****MASKED****",
                        "azureEndpoint": "https://avaplus-cognitive-account-int.openai.azure.com/",
                        "llmApiVersion": "2025-01-01-preview"
                    },
                    "embedding": [
                        {
                            "aiEngine": "AzureOpenAI",
                            "chroma_end_point": "http://chromadb.da.svc.cluster.local",
                            "chroma_port": "80",
                            "index_collection": "dI_Azure_Data_Factory_Documentation_kb",
                            "embedding_model": "text-embedding-ada-002",
                            "embedding_deployment_name": "ava-text-embedding-ada-002",
                            "embedding_api_version": "2024-09-01-preview",
                            "embedding_api_key": "****MASKED****",
                            "embedding_azure_endpoint": "https://da-cognitive-account-demo.openai.azure.com/"
                        }
                    ],
                    "task": {
                        "description": "Task:\nThe agent must automatically generate comprehensive unit test cases for Azure Data Factory (ADF) pipelines.\nIt must use both the ADF Pipeline JSON/ARM file and the Knowledge Base Excel (containing SQL scripts and client data details) as inputs.\nThe Excel must be treated as a mandatory reference source for validating transformations, mappings, and expected outputs.\n\nContext & Background:\nADF pipelines consist of activities (Copy Data, Data Flow, Stored Procedure, Web, etc.), datasets, linked services, parameters, and schema definitions.\nUnit testing validates the behavior of each activity in isolation, ensuring correctness under various conditions.\nSQL scripts and client-specific mappings (from the Excel knowledge base) define actual transformations and must be incorporated into test cases.\n\nScope & Constraints:\n\nInput sources:\n-ADF Pipeline JSON/ARM file\n-Knowledge Base Excel (SQL scripts + client data details)\n\nThe system must:\n-Generate test cases for every activity and transformation.\n-Use SQL scripts from Excel to build validation queries and expected outputs.\n-Cover functional, edge, and performance scenarios.\n-Test data must be anonymized, realistic, and lightweight.\n\nProcess Steps:\n\n1-Input Parsing-\n-Parse the ADF pipeline JSON/ARM file.\n-Parse the Knowledge Base Excel to extract SQL scripts, mappings, datasets, and field-level transformations.\n-Identify dependencies between pipeline components.\n\n2-Test Case Generation:\nFor each activity-\n-Assign Test Case ID & Description.\n-Define Preconditions (parameters, data prerequisites, environment setup).\n-Write Test Steps for executing the activity in isolation.\n-Generate Validation SQL Queries directly from the knowledge base (row counts, joins, filters, transformations).\n-Define Expected Results using field mappings and transformation rules in Excel.\n-List Edge Cases (nulls, duplicates, incorrect data types, missing/empty files).\n-Document Pass/Fail Criteria.\n\n3)Test Data Creation-\n-Create small sample test data files (CSV, Parquet, JSON).\n-Use column names and transformations from the Excel knowledge base.\n-Ensure both typical and edge case data are covered.\n\n4)Execution Scripts:\nGenerate SQL scripts or PowerShell/Azure CLI commands for:\n-Loading test data.\n-Triggering pipeline execution.\n-Running validation SQL queries from Excel mappings.\n\n5)Test Coverage Summary:\nSummarize all pipeline activities and their test cases.\n-Show test coverage percentage by pipeline component.\n-Highlight activities with complex SQL-driven transformations.\n\n6)Output Formatting:\n-Deliver Unit Test Cases in Markdown, HTML, or PDF.\n-Provide test data files in CSV, Parquet, or JSON.\n-Provide execution scripts in SQL, PowerShell, or Azure CLI.\n\nOutput Format:\n1. Unit Test Case Document\n-Format: Markdown, HTML, or PDF.\n\nStructure:\n-Test Case ID & Description\n-Preconditions\n-Test Steps\n-Validation SQL Queries (must reference Excel knowledge base)\n-Expected Results (must use client data details from Excel)\n-Edge Cases\n-Quality: Clear, complete, professional, with Excel knowledge base references.\n\n2. Sample Test Data Files:\n-Format: CSV, Parquet, or JSON.\n-Requirements: Small, anonymized, realistic, with schema/transformations from Excel.\n\n3. Execution Scripts\n-Format: SQL, PowerShell, or Azure CLI.\n-Requirements: Load test data, trigger pipeline, validate results against Excel-derived SQL.\n\nInputs:\nADF Pipeline JSON file: {{ADF_Pipeline_File}}\nKnowledge Base Excel: DI_Azure_Data_Factory_Documentation_kb",
                        "expectedOutput": "A structured and detailed testing framework for ADF pipelines, including unit test case documents, test data files, optional execution scripts, and a test coverage summary."
                    },
                    "maxIter": 25,
                    "maxRpm": 0,
                    "maxExecutionTime": 300,
                    "tools": [],
                    "userTools": [],
                    "allowCodeExecution": false,
                    "isSafeCodeExecution": true
                }
            }
        ],
        "enableAgenticMemory": false,
        "levelId": 99,
        "org": "Ascendion",
        "orgId": 1,
        "domain": "Data&Insights",
        "domainId": 96,
        "projectId": 98,
        "project": "AllProjects",
        "teamId": 99,
        "team": "AVA Team",
        "callbacks": []
    }
}