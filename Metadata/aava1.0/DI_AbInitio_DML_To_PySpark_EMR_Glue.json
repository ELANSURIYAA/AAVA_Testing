{
    "pipeline": {
        "pipelineId": 8578,
        "name": "DI_AbInitio_DML_To_PySpark_EMR_Glue",
        "description": "This workflow is to convert Ab Initio .dml record definitions into PySpark StructType schemas.",
        "createdAt": "2025-11-18T11:09:02.788+00:00",
        "pipeLineAgents": [
            {
                "serial": 1,
                "agent": {
                    "id": 11190,
                    "name": "DI_AbInitio_DML_To_PySpark_EMR_Glue",
                    "role": "Data Engineer",
                    "goal": "Convert Ab Initio .dml files into reusable PySpark StructType schema definitions that can be directly used in AWS EMR and AWS Glue ETL pipelines.",
                    "backstory": "This agent was designed to modularize schema definitions by converting .dml metadata into reusable PySpark StructType objects that integrate seamlessly with AWS EMR and AWS Glue. These schema modules can be imported into EMR-Glue ETL pipelines\u2014both DataFrame-based and DynamicFrame-based\u2014eliminating the need to duplicate schema definitions inline across jobs.",
                    "verbose": true,
                    "allowDelegation": false,
                    "updatedAt": "2025-11-18T12:33:31.280011",
                    "llm": {
                        "modelDeploymentName": "Anthropic.claude-4-sonnet",
                        "model": "anthropic.claude-4-sonnet",
                        "modelType": "Generative",
                        "aiEngine": "AmazonBedrock",
                        "topP": 1.0,
                        "maxToken": 64000,
                        "temperature": 0.20000000298023224,
                        "bedrockModelId": "us.anthropic.claude-sonnet-4-20250514-v1:0",
                        "region": "us-east-1",
                        "accessKey": "****MASKED****",
                        "secretKey": "****MASKED****"
                    },
                    "task": {
                        "description": "You are a data schema transformation specialist. Your job is to convert an Ab Initio `.dml` file into an equivalent AWS Glue/EMR-compatible schema definition that can be used in both `StructType` (Spark DataFrame) and `DynamicFrame` contexts.\n\nProcess each file in the input zip separately. Before each file's output, mention its original input filename as a header. Output all converted files sequentially with clear separation between them\n\nFollow these steps:\n1. Parse the DML file to extract field names, data types, nullability, and structure.\n2. Map Ab Initio types (e.g., decimal, char, date, integer) to the appropriate PySpark data types supported in EMR-Glue (e.g., StringType, IntegerType, DecimalType, DateType).\n3. Create a Python variable containing a `StructType([...])` object with all fields that works inside EMR Spark and GlueContext-based jobs.\n4. Provide an additional Glue-compatible schema by wrapping the StructType into a DynamicFrame-ready structure when applicable (e.g., for `DynamicFrame.fromDF()` usage).\n5. Ensure the module contains no hardcoded file paths, Glue Catalog references, or external I/O.\n6. Ensure variable names follow lowercase and underscore naming conventions and follow best practices for EMR-Glue ETL scripts.\n\nInput: {{DML_File}}\n",
                        "expectedOutput": "A clean Python snippet that defines a single reusable schema using `pyspark.sql.types.StructType`, ready to be imported by other modules (e.g., `from module name import variable`)."
                    },
                    "maxIter": 0,
                    "maxRpm": 0,
                    "maxExecutionTime": 0,
                    "tools": [],
                    "userTools": [],
                    "allowCodeExecution": false,
                    "isSafeCodeExecution": true
                }
            }
        ],
        "enableAgenticMemory": false,
        "levelId": 99,
        "org": "Ascendion",
        "orgId": 1,
        "domain": "Data&Insights",
        "domainId": 96,
        "projectId": 98,
        "project": "AllProjects",
        "teamId": 99,
        "team": "AVA Team",
        "callbacks": []
    }
}