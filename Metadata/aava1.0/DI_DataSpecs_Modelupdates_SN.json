{
    "pipeline": {
        "pipelineId": 1594,
        "name": "DI_DataSpecs_Modelupdates_SN",
        "description": "Includes tech spec creation, functional testing with SQL scripts, and DDL-based model updates.",
        "createdAt": "2025-08-25T06:28:32.344+00:00",
        "managerLlm": {
            "model": "gpt-4",
            "modelDeploymentName": "gpt-4.1",
            "modelType": "Generative",
            "aiEngine": "AzureOpenAI",
            "topP": 0.95,
            "maxToken": 12000,
            "temperature": 0.3
        },
        "pipeLineAgents": [
            {
                "serial": 1,
                "agent": {
                    "id": 2078,
                    "name": "DI_Data_Technical_Specification_SN",
                    "role": "Data Engineer",
                    "goal": "Develop a detailed technical specification document based on the provided inputs, outlining code changes, data model updates, and source-to-target mapping with transformation rules.  ",
                    "backstory": "This task is critical for ensuring seamless integration of the new source table into the existing data pipeline and data models. A well-defined technical specification will serve as the blueprint for developers and stakeholders, reducing ambiguity, ensuring alignment, and maintaining data integrity across the system. The specification will also facilitate efficient implementation of the enhancement and help prevent downstream issues during deployment.  ",
                    "verbose": true,
                    "allowDelegation": true,
                    "updatedAt": "2025-08-05T08:21:45.427344",
                    "llm": {
                        "modelDeploymentName": "gpt-4.1",
                        "model": "gpt-4",
                        "modelType": "Generative",
                        "aiEngine": "AzureOpenAI",
                        "topP": 0.949999988079071,
                        "maxToken": 12000,
                        "temperature": 0.30000001192092896,
                        "llmDeploymentName": "gpt-4.1",
                        "apiKey": "****MASKED****",
                        "azureEndpoint": "https://avaplus-cognitive-account-int.openai.azure.com/",
                        "llmApiVersion": "2025-01-01-preview"
                    },
                    "task": {
                        "description": "The agent must create a comprehensive technical specification document based on the provided inputs:  \n- JIRA story file  \n- Confluence context file  \n- DDL file for the new source table  \n- Existing source data model  \n- Existing target data model  \n\nThe specification should include:  \n1. **Code Changes Required for the Enhancement:**  \n   - Identify the specific areas in the codebase that need modification.  \n   - Detail the logic and functionality changes required to incorporate the new source table.  \n   - Include pseudocode or code snippets where applicable.  \n\n2. **Updates to the Data Models:**  \n   - Analyze the existing source and target data models.  \n   - Define the updates required to integrate the new source table into the models.  \n   - Ensure consistency and alignment between the source and target models.  \n\n3. **Source-to-Target Mapping:**  \n   - Provide a detailed mapping of fields from the new source table to the target data model.  \n   - Include any transformation rules or business logic required for the mapping.  \n\n**INSTRUCTIONS:**  \n1. **Context and Background Information:**  \n   - Review the JIRA story file to understand the business requirements and objectives.  \n   - Refer to the Confluence context file for additional project details and constraints.  \n   - Analyze the DDL file to understand the structure and schema of the new source table.  \n   - Examine the existing source and target data models to identify dependencies and relationships.  \n\n2. **Scope and Constraints:**  \n   - Ensure the specification aligns with the business requirements outlined in the JIRA story.  \n   - Maintain compatibility with existing systems and processes.  \n   - Adhere to data governance and security standards.  \n\n3. **Process Steps to Follow:**  \n   - Step 1: Extract relevant details from the provided files.  \n   - Step 2: Identify code changes required for the enhancement, including impacted modules and functions.  \n   - Step 3: Define updates to the source and target data models, ensuring logical consistency.  \n   - Step 4: Create a detailed source-to-target mapping, including transformation rules.  \n   - Step 5: Format the technical specification document as per industry standards.  \n4. **OUTPUT FORMAT:**  \n   - **Format:** Markdown  \n   - **Structure Requirements:**  \n- **Metadata Requirements:**\n-=============================================\n-Author: Ascendion AVA+\n-Date: <Leave it blank>\n-Description: <one-line description of the purpose >\n-============================================= \n     - Title: Technical Specification for [Enhancement Name]  \n     - Sections:  \n       - Introduction  \n       - Code Changes  \n       - Data Model Updates  \n       - Source-to-Target Mapping  \n       - Assumptions and Constraints  \n       - References  \n     - Use headings, subheadings, and bullet points for clarity.  \n   - **Quality Criteria:**  \n     - Clear and concise language.  \n     - Logical flow and organization.  \n     - Accurate and complete mapping and transformation rules.  \n   - **Formatting Needs:**  \n     - Use tables for source-to-target mapping.  \n     - Include diagrams for data model updates (if applicable).  \nPoints to Remember:\nRemember Must use the Github File Writer Tool to upload the File in the Github Repo for the Environment Details for github take that from the input\nRemember for the branch input use it as \"main\" and conent is what you give as output save the file as .md format\n\n\nAll the Inputs (Jira Stories, Confluence Documentation, Source Data Model, Target Data Model) are available in the zip folder that is uploaded. *****The input file names are provided in {{Technical_Specifications}}\n* GitHub repo details : {{GitHub_Repo_Details}}\n",
                        "expectedOutput": "**OUTPUT FORMAT:**  \n   - **Format:** Markdown  \n   - **Structure Requirements:**\n- **Metadata Requirements:**\n-=============================================\n-Author: Ascendion AVA+\n-Date: <Leave it blank>\n-Description: <one-line description of the purpose >\n-=============================================  \n     - Title: Technical Specification for [Enhancement Name]  \n     - Sections:  \n       - Introduction  \n       - Code Changes  \n       - Data Model Updates  \n       - Source-to-Target Mapping  \n       - Assumptions and Constraints  \n       - References  \n     - Use headings, subheadings, and bullet points for clarity.  \n   - **Quality Criteria:**  \n     - Clear and concise language.  \n     - Logical flow and organization.  \n     - Accurate and complete mapping and transformation rules.  \n   - **Formatting Needs:**  \n     - Use tables for source-to-target mapping.  \n     - Include diagrams for data model updates (if applicable).  \n\n```||||||||Cost Estimation and Justification\n \nCost Section Instructions:\n- Calculate the total **number of input tokens** used (including this prompt + the input SQL).\n- Calculate the total **number of output tokens** used (including the converted SQL + explanation).\n- Automatically detect the model used for processing this prompt.\n- Retrieve the current pricing for that model (for both input and output tokens) from the system or environment, if available.\n-  compute the cost of running this agent:\n- Input Cost = `input_tokens * [input_cost_per_token]`\n- Output Cost = `output_tokens * [output_cost_per_token]`\n- Present the full formula and breakdown clearly:"
                    },
                    "maxIter": 25,
                    "maxRpm": 0,
                    "maxExecutionTime": 300,
                    "tools": [],
                    "userTools": [
                        {
                            "toolId": 300,
                            "toolName": "DI_Github_File_Writer_Z",
                            "toolClassName": "GitHubFileWriterTool",
                            "toolClassDef": "from crewai.tools import BaseTool\nfrom pydantic import BaseModel, Field\nimport base64\nimport requests\nimport urllib3\nimport logging\nimport re\nfrom typing import Type, Any\n\n# ---------------------------------\n# SSL & Logging Configuration\n# ---------------------------------\nurllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\nlogging.basicConfig(\n    level=logging.INFO,\n    format=\"%(asctime)s - %(levelname)s - %(message)s\",\n    filename=\"github_file_writer.log\",\n)\nlogger = logging.getLogger(\"GitHubFileWriterTool\")\n\n\n# ---------------------------------\n# Input Schema\n# ---------------------------------\nclass GitHubFileWriterSchema(BaseModel):\n    repo: str = Field(..., description=\"GitHub repository in 'owner/repo' format\")\n    branch: str = Field(..., description=\"Branch name (e.g., 'main')\")\n    token: str = Field(..., description=\"GitHub Personal Access Token\")\n    folder_name: str = Field(..., description=\"Name of the folder to create inside the repository\")\n    file_name: str = Field(..., description=\"Name of the file to create or update in the folder\")\n    content: str = Field(..., description=\"Text content to upload into the GitHub file\")\n\n\n# ---------------------------------\n# Main Tool Class\n# ---------------------------------\nclass GitHubFileWriterTool(BaseTool):\n    name: str = \"GitHub File Writer Tool\"\n    description: str = \"Creates or updates files in a GitHub repository folder\"\n    args_schema: Type[BaseModel] = GitHubFileWriterSchema\n\n    api_url_template: str = \"https://api.github.com/repos/{repo}/contents/{path}\"\n\n    def _sanitize_path_component(self, component: str) -> str:\n        \"\"\"Remove invalid GitHub path characters.\"\"\"\n        sanitized = re.sub(r'[\\\\*?:\"<>|]', '_', component)\n        sanitized = re.sub(r'\\.\\.', '_', sanitized)\n        sanitized = sanitized.lstrip('./\\\\')\n        return sanitized if sanitized else \"default\"\n\n    def _validate_content(self, content: str) -> str:\n        \"\"\"Ensure valid string content within 10MB limit.\"\"\"\n        if not isinstance(content, str):\n            logger.warning(\"Content is not a string. Converting to string.\")\n            content = str(content)\n\n        max_size = 10 * 1024 * 1024  # 10 MB\n        if len(content.encode('utf-8')) > max_size:\n            logger.warning(\"Content exceeds 10MB limit. Truncating.\")\n            content = content[:max_size]\n\n        return content\n\n    def create_file_in_github(self, repo: str, branch: str, token: str,\n                              folder_name: str, file_name: str, content: str) -> str:\n        \"\"\"Create or update a file in GitHub repository.\"\"\"\n        sanitized_folder = self._sanitize_path_component(folder_name)\n        sanitized_file = self._sanitize_path_component(file_name)\n        validated_content = self._validate_content(content)\n\n        path = f\"{sanitized_folder}/{sanitized_file}\"\n        url = self.api_url_template.format(repo=repo, path=path)\n        headers = {\"Authorization\": f\"token {token}\", \"Content-Type\": \"application/json\"}\n\n        # Encode content\n        encoded_content = base64.b64encode(validated_content.encode()).decode()\n\n        # Check file existence to get SHA (for updating)\n        sha = None\n        try:\n            response = requests.get(url, headers=headers, params={\"ref\": branch}, verify=False)\n            if response.status_code == 200:\n                sha = response.json().get(\"sha\")\n        except Exception as e:\n            logger.error(f\"Failed to check file existence: {e}\", exc_info=True)\n\n        payload = {\"message\": f\"Add or update file: {sanitized_file}\",\n                   \"content\": encoded_content, \"branch\": branch}\n        if sha:\n            payload[\"sha\"] = sha  # Required for updating\n\n        # Upload or update file\n        try:\n            put_response = requests.put(url, json=payload, headers=headers, verify=False)\n            if put_response.status_code in [200, 201]:\n                logger.info(f\"\u2705 File '{sanitized_file}' uploaded successfully to {repo}/{sanitized_folder}\")\n                return f\"\u2705 File '{sanitized_file}' uploaded successfully to GitHub in folder '{sanitized_folder}'.\"\n            else:\n                logger.error(f\"GitHub API Error: {put_response.text}\")\n                return f\"\u274c Failed to upload file. GitHub API error: {put_response.text}\"\n        except Exception as e:\n            logger.error(f\"Failed to upload file: {e}\", exc_info=True)\n            return f\"\u274c Exception while uploading file: {str(e)}\"\n\n    # ------------------------------------------------------\n    # Required method for CrewAI Tool execution\n    # ------------------------------------------------------\n    def _run(self, repo: str, branch: str, token: str,\n             folder_name: str, file_name: str, content: str) -> Any:\n        \"\"\"Main execution method.\"\"\"\n        return self.create_file_in_github(repo, branch, token, folder_name, file_name, content)\n\n\n# ---------------------------------\n# Generalized Main (User-Parameterized)\n# ---------------------------------\nif __name__ == \"__main__\":\n    print(\"\ud83d\udd27 GitHub File Writer Tool - Interactive Mode\\n\")\n    repo = input(\"Enter GitHub repository (owner/repo): \").strip()\n    branch = input(\"Enter branch name (e.g., main): \").strip()\n    token = input(\"Enter your GitHub Personal Access Token: \").strip()\n    folder_name = input(\"Enter folder name: \").strip()\n    file_name = input(\"Enter file name (e.g., example.txt): \").strip()\n    print(\"\\nEnter the content for your file (end with a blank line):\")\n    lines = []\n    while True:\n        line = input()\n        if line == \"\":\n            break\n        lines.append(line)\n    content = \"\\n\".join(lines)\n\n    tool = GitHubFileWriterTool()\n    result = tool._run(repo=repo, branch=branch, token=token,\n                       folder_name=folder_name, file_name=file_name, content=content)\n    print(\"\\nResult:\", result)\n",
                            "isApproved": false
                        }
                    ],
                    "allowCodeExecution": false,
                    "isSafeCodeExecution": true
                }
            },
            {
                "serial": 2,
                "agent": {
                    "id": 2082,
                    "name": "DI_Delta_Model_Changes_SN",
                    "role": "Data Engineer",
                    "goal": "To automate and systematize the detection, generation, and documentation of changes between the current data model and new technical specifications. DMEA ensures that schema evolution is:\n**Traceable\n**Auditable\n**Minimally disruptive\n**Backed with DDL and rollback scripts\n**Fully documented for development and governance",
                    "backstory": "Evolving data models in response to new features, regulatory changes, or refactored pipelines is often a manual, error-prone process. It risks:\n**Introducing data quality issues\n**Breaking downstream dependencies\n**Causing inconsistent documentation\n**Missing audit requirements\nTo solve this, the Data Model Evolution Agent (DMEA) was built as an intelligent intermediary between existing models and new tech specs. It acts as a diffing engine, validator, and DDL generator \u2014 keeping the data model agile, yet controlled.",
                    "verbose": true,
                    "allowDelegation": true,
                    "updatedAt": "2025-05-14T18:48:24.284306",
                    "llm": {
                        "modelDeploymentName": "gpt-4.1",
                        "model": "gpt-4",
                        "modelType": "Generative",
                        "aiEngine": "AzureOpenAI",
                        "topP": 0.949999988079071,
                        "maxToken": 12000,
                        "temperature": 0.30000001192092896,
                        "llmDeploymentName": "gpt-4.1",
                        "apiKey": "****MASKED****",
                        "azureEndpoint": "https://avaplus-cognitive-account-int.openai.azure.com/",
                        "llmApiVersion": "2025-01-01-preview"
                    },
                    "task": {
                        "description": "DMEA accepts two primary inputs:\n**The existing data model (ER diagrams, DDLs, JSON schemas, etc.)\n**The new technical specifications (manually entered or taken as input from upstream agents like TSA - Technical Specification Agent)\nIt performs the following stages:\n1. **Model Ingestion\n**Parse and map existing model: tables, fields, constraints, relationships\n**Build internal representations for current schema using graph/tree formats\n**Supports relational (PostgreSQL, MySQL, SQL Server), NoSQL (MongoDB), and modern lakehouse (Delta Lake, Snowflake, BigQuery) models\n2. **Spec Parsing & Mapping\n    Normalize inputs from tech specs to structural requirements\n    Detect:\n         **Additions (new tables/columns/indexes)\n         **Modifications (type changes, nullable, constraints)\n         **Deprecations (dropping columns, soft deletes)\n    Infer indirect changes (e.g., changed business rule implies a column constraint update)\n3. **Delta Computation\n    Compare existing vs desired model\n    Categorize deltas:\n        **New tables/fields\n        **Changed column types/nullability\n        **Added/removed constraints\n        **Modified indexes/PKs\n    Compute version bump impact (patch/minor/major)\n4. **Impact Assessment\n    --Downstream break detection (views, ETL jobs, APIs)\n    --Data loss risk (e.g., narrowing column types, dropping constraints)\n    --Foreign key ripple effects\n    --Platform-specific caveats (e.g., PostgreSQL vs MySQL)\n5. **DDL/Alter Statement Generation\n    --Forward DDLs:\n        CREATE TABLE, ALTER TABLE, ADD CONSTRAINT, DROP COLUMN\n    --Rollback support\n    --Optional zero-downtime deployment (via COPY, rename strategies)\n    --Index rebalancing if necessary\n    --Optional data migration scripts (e.g., populate new tables from old ones)\n6. **Documentation\n    --Side-by-side diff of model (before vs after)\n    --Full DDL logs with change reasons\n    --Visual diagrams (ERD updates)\n    --Change traceability matrix (tech spec section \u2192 DDL line)\n\nThe inputs for this agent which is technical specification and existing DDL's :\n--existing DDL's file names are mentioned in {{Data_Model_Delta}}\n--Take the technical specification requirement from the first agent named ------\"\"\"\"DI_Data_Technical_Specification_SN\"\"\"\" ",
                        "expectedOutput": "**Metadata Requirements:**\n- Add the following metadata at the top of the output:\n```\n=============================================\nAuthor: Ascendion AVA+\nDate: <Leave it blank>\nDescription: <one-line description of the purpose>\n=============================================\n```\n- For the description, provide a concise summary of what this output entails/captures\n\nTHEN REST AS DESCRIBED BELOW -->\n\nEach run of DMEA returns a \"Data Model Evolution Package\" or \"Data model delta update\", containing:\n1. Delta Summary Report\n    Overview of changes with impact level (low/medium/high)\n    List of:\n        **Additions\n        **Modifications\n        **Deprecations\n    Notes on detected risk (data loss, key impact)\n2. DDL Change Scripts\n    **Forward-only SQL (to evolve model)\n    **Annotated with comments, change reason, tech spec reference\n3. Data Model Documentation\n    **Annotated dictionary (columns with change metadata)\n\n|||||||||Cost Estimation and Justification\n \nCost Section Instructions:\n- Calculate the total **number of input tokens** used (including this prompt + the input SQL).\n- Calculate the total **number of output tokens** used (including the converted SQL + explanation).\n- Automatically detect the model used for processing this prompt.\n- Retrieve the current pricing for that model (for both input and output tokens) from the system or environment, if available.\n- compute cost of running this agent:\n- Input Cost = `input_tokens * [input_cost_per_token]`\n- Output Cost = `output_tokens * [output_cost_per_token]`\n- Present the full formula and breakdown clearly:\n"
                    },
                    "maxIter": 0,
                    "maxRpm": 0,
                    "maxExecutionTime": 0,
                    "tools": [],
                    "userTools": [],
                    "allowCodeExecution": false,
                    "isSafeCodeExecution": true
                }
            },
            {
                "serial": 3,
                "agent": {
                    "id": 2081,
                    "name": "DI_Functional_Test_Cases_SN",
                    "role": "Data Validation Specialist",
                    "goal": " Create detailed and specific functional test cases based on technical specifications derived from Jira, ensuring comprehensive coverage of all requirements and edge cases. ",
                    "backstory": "Functional test cases are critical for ensuring the quality and reliability of the software product. By deriving test cases from Jira technical specifications, the team can validate that the application meets all requirements and performs as expected in various scenarios, including edge cases. Comprehensive test coverage reduces the risk of defects slipping into production, improves user satisfaction, and ensures compliance with project deliverables.  ",
                    "verbose": true,
                    "allowDelegation": true,
                    "updatedAt": "2025-05-14T19:25:18.486793",
                    "llm": {
                        "modelDeploymentName": "gpt-4.1",
                        "model": "gpt-4",
                        "modelType": "Generative",
                        "aiEngine": "AzureOpenAI",
                        "topP": 0.949999988079071,
                        "maxToken": 12000,
                        "temperature": 0.30000001192092896,
                        "llmDeploymentName": "gpt-4.1",
                        "apiKey": "****MASKED****",
                        "azureEndpoint": "https://avaplus-cognitive-account-int.openai.azure.com/",
                        "llmApiVersion": "2025-01-01-preview"
                    },
                    "task": {
                        "description": "Your task is to create detailed and specific functional test cases based on the technical specifications provided in Jira. These test cases will serve as the foundation for validating the software's functionality and ensuring it meets the requirements. Follow the instructions below to ensure the test cases are comprehensive, well-structured, and adhere to industry standards.  \n\n### **INSTRUCTIONS:**  \n1. **Understand the Context:**  \n   - Review the Jira tickets provided, including technical specifications, user stories, acceptance criteria, and any attached documentation.  \n   - Identify the key functionalities, requirements, and edge cases described in the tickets.  \n\n2. **Scope and Constraints:**  \n   - Focus only on functional requirements (e.g., input validation, expected outputs, system behavior).  \n   - Exclude non-functional requirements like performance, scalability, or security unless explicitly mentioned.  \n   - Ensure test cases cover both positive and negative scenarios, as well as edge cases.  \n\n3. **Process Steps:**  \n   - **Step 1:** Extract requirements and acceptance criteria from Jira.  \n   - **Step 2:** Break down each requirement into smaller, testable components.  \n   - **Step 3:** Identify edge cases and boundary conditions for each requirement.  \n   - **Step 4:** Write test cases using a structured format (see OUTPUT FORMAT below).  \n   - **Step 5:** Ensure traceability by linking each test case to its corresponding Jira ticket.  \n   - **Step 6:** Review and validate test cases for completeness and accuracy.  \n\n4. **Output Format:**  \n   - Provide test cases in **Markdown** format.  \n   - Use the following structure for each test case:  \n\n     ```markdown\n     ### Test Case ID: TC_<JiraTicketID>_<SequentialNumber>\n     **Title:** [Brief title of the test case]  \n     **Description:** [Detailed description of the test case objective]  \n     **Preconditions:** [Any setup or prerequisites required before executing the test case]  \n     **Steps to Execute:**  \n     1. [Step 1]  \n     2. [Step 2]  \n     3. [Step N]  \n     **Expected Result:** [What the system should do after executing the steps]  \n     **Linked Jira Ticket:** [Jira ticket ID]  \n     ```\n\n\n### **SAMPLE:**  \n```markdown\n### Test Case ID: TC_JIRA1234_01  \n**Title:** Validate user login with valid credentials  \n**Description:** Ensure that a user can successfully log in using valid credentials.  \n**Preconditions:**  \n- The application is running.  \n- A user account with valid credentials exists.  \n\n**Steps to Execute:**  \n1. Navigate to the login page.  \n2. Enter valid username and password.  \n3. Click the \"Login\" button.  \n\n**Expected Result:**  \n- The user is redirected to the dashboard.  \n- A welcome message is displayed.  \n\n**Linked Jira Ticket:** JIRA1234  \n```\n\n\n---\nInput files and its names are available in \"{{Function_test_cases_input}}\"\n",
                        "expectedOutput": "**Metadata Requirements:**\n- Add the following metadata at the top of the output:\n```\n=============================================\nAuthor: Ascendion AVA+\nDate: <Leave it blank>\nDescription: <one-line description of the purpose>\n=============================================\n```\n- For the description, provide a concise summary of what this output entails/captures\n### **OUTPUT FORMAT:**  \n- Provide test cases in **Markdown** format.  \n- Ensure each test case includes all required fields (Title, Description, Preconditions, Steps to Execute, Expected Result, Linked Jira Ticket).  \n- Maintain traceability by linking test cases to Jira tickets. \n||||||Cost Estimation and Justification\n \nCost Section Instructions:\n- Calculate the total **number of input tokens** used (including this prompt + the input SQL).\n- Calculate the total **number of output tokens** used (including the converted SQL + explanation).\n- Automatically detect the model used for processing this prompt.\n- Retrieve the current pricing for that model (for both input and output tokens) from the system or environment, if available.\n-  compute the cost of running this Agent:\n- Input Cost = `input_tokens * [input_cost_per_token]`\n- Output Cost = `output_tokens * [output_cost_per_token]`\n- Present the full formula and breakdown clearly:"
                    },
                    "maxIter": 0,
                    "maxRpm": 0,
                    "maxExecutionTime": 0,
                    "tools": [],
                    "userTools": [],
                    "allowCodeExecution": false,
                    "isSafeCodeExecution": true
                }
            }
        ],
        "enableAgenticMemory": false,
        "levelId": 99,
        "org": "Ascendion",
        "orgId": 1,
        "domain": "Data&Insights",
        "domainId": 96,
        "projectId": 98,
        "project": "AllProjects",
        "teamId": 99,
        "team": "AVA Team",
        "callbacks": []
    }
}