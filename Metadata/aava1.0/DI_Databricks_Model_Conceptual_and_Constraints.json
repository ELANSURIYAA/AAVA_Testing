{
    "pipeline": {
        "pipelineId": 6254,
        "name": "DI_Databricks_Model_Conceptual_and_Constraints",
        "description": "This agent is for giving model conceptual and data constraints\n",
        "createdAt": "2025-08-22T04:19:59.669+00:00",
        "pipeLineAgents": [
            {
                "serial": 1,
                "agent": {
                    "id": 8236,
                    "name": "DI_Databricks_Model_Conceptual",
                    "role": "Senior Data Modeler",
                    "goal": "Build an agent that can either:\n1. Analyze reporting requirements to define a comprehensive conceptual data model.\n2. Update previously generated conceptual data model based on change requests.\nThis agent reads inputs from GitHub input directory using the **GitHub Reader Tool** and writes outputs to GitHub output directory using the **GitHub Writer Tool**.",
                    "backstory": "Developing a robust conceptual data model is crucial for ensuring that our reporting system accurately captures and represents the organization's data needs. This foundational step will guide the entire data architecture and reporting structure, enabling efficient data management and insightful analytics. The agent supports both **initial conceptual data model development** and **iterative updates** directly in GitHub, enabling version-controlled collaboration.",
                    "verbose": true,
                    "allowDelegation": true,
                    "updatedAt": "2025-08-22T04:16:36.946339",
                    "llm": {
                        "modelDeploymentName": "Anthropic.claude-4-sonnet",
                        "model": "anthropic.claude-4-sonnet",
                        "modelType": "Generative",
                        "aiEngine": "AmazonBedrock",
                        "topP": 1.0,
                        "maxToken": 8000,
                        "temperature": 0.10000000149011612,
                        "bedrockModelId": "us.anthropic.claude-sonnet-4-20250514-v1:0",
                        "region": "us-east-1",
                        "accessKey": "****MASKED****",
                        "secretKey": "****MASKED****"
                    },
                    "task": {
                        "description": "Before starting to process the agent, first check the value of 'Do_You_Need_Any_Changes'. Based on this, proceed accordingly.\n\n#### **1. Standard Conceptual data model Workflow (Mode 1)**\n\nExecuted when:\n* The report requirement file exists in GitHub input directory and is read using the GitHub Reader Tool.\n* If Do_You_Need_Any_Changes = \"No\", then check the output directory. If the output directory already contains the agent output file (identified by matching the actual input file name that ends with an underscore Conceptual underscore followed by a number), there is no need to do anything \u2014 simply read the existing file from the output directory and return its content as the output.\n* If Do_You_Need_Any_Changes = \"No\", then check the output directory. If the output directory does not contain any agent output file (based on the actual input file name ending with an underscore Conceptual underscore followed by a number), proceed to create the Conceptual data model for the given report requirement file from the input directory. For generating the Conceptual data model instructions and structure are given below. Once generated, store the Conceptual data model in the output directory with the file name as the actual input Report requirement file name, followed by _Conceptual_1.md.\n\nThe agent must:\n* Parse the Report requirement file.\n* Analyzing the reporting requirements to identify key components necessary for defining the conceptual data model. This process is essential for creating a solid foundation for our data architecture and reporting system.\n* Review all available documentation related to reporting requirements.\n* Identify the primary business domain(s) covered by the reports.\n* List all data entities mentioned or implied in the requirements.\n* For each entity, enumerate the relevant attributes. Give a business name to the attributes \n* Include a business description for each attribute\n* Do not include any ID attributes\n* Identify Key Performance Indicators (KPIs) mentioned in the requirements.\n* Organize the collected information into a structured format.\n* Create a visual representation of the conceptual data model (e.g., entity-relationship diagram). Clearly need to be mention one table is connected to another table by which key field \n* Validate the model against the original requirements to ensure completeness\n* Identify and list all data elements or fields that are referenced across multiple reports within the given requirements.\n* Generate Conceptual data model containing the sections listed in **Conceptual data model Structure** below.\n* Save the output file to GitHub output directory using the **GitHub Writer Tool**.\n* The output file name should be the actual input report requirement file name, followed by _Conceptual_1.md.\n* **Version rule:** Start with `_1` and increment the highest underscore number found in the GitHub path.\n\n#### **2. Update Conceptual data model Workflow (Mode 2)**\nExecuted when:\n* User indicates `Do_You_Need_Any_Changes` = `\"Yes\"`.\n* User provides `Required changes`.\n\nThe agent must:\n* Identify the Conceptual data model file in GitHub output directory with the actual input report requirement file name _Conceptual_latest version suffix (e.g., `_3` if `_1`, `_2`, `_3` exist).\n* Read that file from the github output directory using the **GitHub Reader Tool**.\n* Apply the requested changes from Required Changes.\n* Add or modify the following fields in the output Metadata \n```\n## *Version* : 2 or 3 or 4 etc...\n## *Changes*: \n## *Reason*: \n``` \n* Save the updated file to the same GitHub output directory with the with the actual input report requirement file name _Conceptual_next incremented version number (e.g., `_4`).\n* Maintain previous version in history.\n* Do **not** overwrite without version increment.\n\n## **Input Sections**\n* GitHub Credentials and Report Requirement file present in the github input directory: `{{Report_Requirement_File_And_Github_Details}}`\n\n**Update Inputs**:\n* Do_You_Need_Any_Changes: `{{Do_You_Need_Any_Changes_In_Conceptual_Data_Model_Yes_Or_No_If_Yes_Give_Required_Changes}}`\n\n## **Conceptual Data Model Structure**\n\n### **Metadata Requirements**\nAdd the following metadata at the top of each generated file:\n```\n_____________________________________________\n## *Author*: AAVA\n## *Created on*:   Leave it empty dont give any values are placeholder in this field\n## *Description*:   <one-line description of the purpose>\n## *Version*: 1 \n## *Updated on*: Leave it empty dont give any values are placeholder in this field\n_____________________________________________\n```\n1. Domain Overview\n2. List of Entity Name with a description\n3. List of Attributes for each Entity with a description for each attribute\n4. KPI List\n5. Conceptual Data Model Diagram in tabular form by one tale is having a relationship with other table by which key field\n6. Common Data Elements in Report Requirements\n7. API Cost Calculation\n   \u2013 Cost for this Call: $...\n\n## **Guidelines Policies (Both Modes)**\n\n* Assume the report requirements is provided unless explicitly stated otherwise.\n* Use the information exactly as provided in the report requirements without assuming or introducing new elements or requirements.\n* If certain details in the report requirements are ambiguous or missing, clearly state only what can be inferred based on the available input without adding unnecessary disclaimers.\n* Do not include data type along with the attributes\n* Do not include ID attributes \n* Give output in the markdown format\n* In the output add all the necessary Number bullet marks",
                        "expectedOutput": "**Mode 1 Output**:\n* Display the Conceptual data model output\n* And store the Conceptual data model output in the GitHub output directory with the file name as `actual input report requirements file name_Conceptual_<version>.md` \u2014 Contains all sections above in markdown format.\n\n**Mode 2 Output**:\n* Display the updated Conceptual data model output\n* And store the updated Conceptual data model output in the GitHub output directory with the file name as `actual input report requirements file name_Conceptual_<next_version>.md` \u2014 Updated Conceptual data model with requested changes applied, preserving structure and formatting."
                    },
                    "maxIter": 20,
                    "maxRpm": 50,
                    "maxExecutionTime": 300,
                    "tools": [],
                    "userTools": [
                        {
                            "toolId": 300,
                            "toolName": "DI_Github_File_Writer_Z",
                            "toolClassName": "GitHubFileWriterTool",
                            "toolClassDef": "from crewai.tools import BaseTool\nfrom pydantic import BaseModel, Field\nimport base64\nimport requests\nimport urllib3\nimport logging\nimport re\nfrom typing import Type, Any\n\n# ---------------------------------\n# SSL & Logging Configuration\n# ---------------------------------\nurllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\nlogging.basicConfig(\n    level=logging.INFO,\n    format=\"%(asctime)s - %(levelname)s - %(message)s\",\n    filename=\"github_file_writer.log\",\n)\nlogger = logging.getLogger(\"GitHubFileWriterTool\")\n\n\n# ---------------------------------\n# Input Schema\n# ---------------------------------\nclass GitHubFileWriterSchema(BaseModel):\n    repo: str = Field(..., description=\"GitHub repository in 'owner/repo' format\")\n    branch: str = Field(..., description=\"Branch name (e.g., 'main')\")\n    token: str = Field(..., description=\"GitHub Personal Access Token\")\n    folder_name: str = Field(..., description=\"Name of the folder to create inside the repository\")\n    file_name: str = Field(..., description=\"Name of the file to create or update in the folder\")\n    content: str = Field(..., description=\"Text content to upload into the GitHub file\")\n\n\n# ---------------------------------\n# Main Tool Class\n# ---------------------------------\nclass GitHubFileWriterTool(BaseTool):\n    name: str = \"GitHub File Writer Tool\"\n    description: str = \"Creates or updates files in a GitHub repository folder\"\n    args_schema: Type[BaseModel] = GitHubFileWriterSchema\n\n    api_url_template: str = \"https://api.github.com/repos/{repo}/contents/{path}\"\n\n    def _sanitize_path_component(self, component: str) -> str:\n        \"\"\"Remove invalid GitHub path characters.\"\"\"\n        sanitized = re.sub(r'[\\\\*?:\"<>|]', '_', component)\n        sanitized = re.sub(r'\\.\\.', '_', sanitized)\n        sanitized = sanitized.lstrip('./\\\\')\n        return sanitized if sanitized else \"default\"\n\n    def _validate_content(self, content: str) -> str:\n        \"\"\"Ensure valid string content within 10MB limit.\"\"\"\n        if not isinstance(content, str):\n            logger.warning(\"Content is not a string. Converting to string.\")\n            content = str(content)\n\n        max_size = 10 * 1024 * 1024  # 10 MB\n        if len(content.encode('utf-8')) > max_size:\n            logger.warning(\"Content exceeds 10MB limit. Truncating.\")\n            content = content[:max_size]\n\n        return content\n\n    def create_file_in_github(self, repo: str, branch: str, token: str,\n                              folder_name: str, file_name: str, content: str) -> str:\n        \"\"\"Create or update a file in GitHub repository.\"\"\"\n        sanitized_folder = self._sanitize_path_component(folder_name)\n        sanitized_file = self._sanitize_path_component(file_name)\n        validated_content = self._validate_content(content)\n\n        path = f\"{sanitized_folder}/{sanitized_file}\"\n        url = self.api_url_template.format(repo=repo, path=path)\n        headers = {\"Authorization\": f\"token {token}\", \"Content-Type\": \"application/json\"}\n\n        # Encode content\n        encoded_content = base64.b64encode(validated_content.encode()).decode()\n\n        # Check file existence to get SHA (for updating)\n        sha = None\n        try:\n            response = requests.get(url, headers=headers, params={\"ref\": branch}, verify=False)\n            if response.status_code == 200:\n                sha = response.json().get(\"sha\")\n        except Exception as e:\n            logger.error(f\"Failed to check file existence: {e}\", exc_info=True)\n\n        payload = {\"message\": f\"Add or update file: {sanitized_file}\",\n                   \"content\": encoded_content, \"branch\": branch}\n        if sha:\n            payload[\"sha\"] = sha  # Required for updating\n\n        # Upload or update file\n        try:\n            put_response = requests.put(url, json=payload, headers=headers, verify=False)\n            if put_response.status_code in [200, 201]:\n                logger.info(f\"\u2705 File '{sanitized_file}' uploaded successfully to {repo}/{sanitized_folder}\")\n                return f\"\u2705 File '{sanitized_file}' uploaded successfully to GitHub in folder '{sanitized_folder}'.\"\n            else:\n                logger.error(f\"GitHub API Error: {put_response.text}\")\n                return f\"\u274c Failed to upload file. GitHub API error: {put_response.text}\"\n        except Exception as e:\n            logger.error(f\"Failed to upload file: {e}\", exc_info=True)\n            return f\"\u274c Exception while uploading file: {str(e)}\"\n\n    # ------------------------------------------------------\n    # Required method for CrewAI Tool execution\n    # ------------------------------------------------------\n    def _run(self, repo: str, branch: str, token: str,\n             folder_name: str, file_name: str, content: str) -> Any:\n        \"\"\"Main execution method.\"\"\"\n        return self.create_file_in_github(repo, branch, token, folder_name, file_name, content)\n\n\n# ---------------------------------\n# Generalized Main (User-Parameterized)\n# ---------------------------------\nif __name__ == \"__main__\":\n    print(\"\ud83d\udd27 GitHub File Writer Tool - Interactive Mode\\n\")\n    repo = input(\"Enter GitHub repository (owner/repo): \").strip()\n    branch = input(\"Enter branch name (e.g., main): \").strip()\n    token = input(\"Enter your GitHub Personal Access Token: \").strip()\n    folder_name = input(\"Enter folder name: \").strip()\n    file_name = input(\"Enter file name (e.g., example.txt): \").strip()\n    print(\"\\nEnter the content for your file (end with a blank line):\")\n    lines = []\n    while True:\n        line = input()\n        if line == \"\":\n            break\n        lines.append(line)\n    content = \"\\n\".join(lines)\n\n    tool = GitHubFileWriterTool()\n    result = tool._run(repo=repo, branch=branch, token=token,\n                       folder_name=folder_name, file_name=file_name, content=content)\n    print(\"\\nResult:\", result)\n",
                            "isApproved": false
                        },
                        {
                            "toolId": 344,
                            "toolName": "DI_GitHub_File_Reader_Z",
                            "toolClassName": "GitHubFileReaderTool",
                            "toolClassDef": "from crewai.tools import BaseTool\nfrom pydantic import BaseModel, Field\nimport base64\nimport requests\nimport logging\nfrom typing import Type, Any, List, Dict\n\n# Setup logging for the GitHub File Reader Tool\nlogging.basicConfig(\n    level=logging.INFO,\n    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n    filename='github_file_reader.log'\n)\nlogger = logging.getLogger('GitHubFileReaderTool')\n\nclass GitHubFileReaderSchema(BaseModel):\n    \"\"\"Input schema for the GitHubFileReaderTool.\"\"\"\n    repo: str = Field(..., description=\"GitHub repository in the format 'owner/repo'\")\n    file_paths: List[str] = Field(..., description=\"List of file paths in the repository\")\n    branch: str = Field(..., description=\"Branch name to read the files from (e.g., 'main')\")\n    token: str = Field(..., description=\"GitHub personal access token for authorization\")\n\nclass GitHubFileReaderTool(BaseTool):\n    name: str = \"GitHub File Reader Tool\"\n    description: str = \"Reads multiple files from a GitHub repository based on user inputs.\"\n    args_schema: Type[BaseModel] = GitHubFileReaderSchema\n\n    api_url_template: str = \"https://api.github.com/repos/{repo}/contents/{file_path}\"\n\n    def fetch_file_from_github(self, repo: str, file_path: str, branch: str, token: str) -> str:\n        \"\"\"Fetches a file content from GitHub.\"\"\"\n        url = self.api_url_template.format(repo=repo, file_path=file_path)\n        headers = {\n            \"Authorization\": f\"token {token}\",\n            \"Accept\": \"application/vnd.github.v3+json\"\n        }\n        params = {\"ref\": branch}\n\n        try:\n            logger.info(f\"Fetching file '{file_path}' from repo '{repo}' on branch '{branch}'\")\n            response = requests.get(url, headers=headers, params=params)\n            response.raise_for_status()\n\n            file_data = response.json()\n            if \"content\" not in file_data:\n                raise ValueError(f\"\u274c Error: Path '{file_path}' might be a directory or missing content.\")\n\n            decoded_content = base64.b64decode(file_data['content']).decode('utf-8')\n            logger.info(f\"\u2705 Successfully fetched file '{file_path}'.\")\n            return decoded_content\n\n        except Exception as e:\n            logger.error(f\"Failed to fetch file '{file_path}': {str(e)}\", exc_info=True)\n            raise\n\n    def _run(self, repo: str, file_paths: List[str], branch: str, token: str) -> Dict[str, Any]:\n        \"\"\"Main execution logic.\"\"\"\n        all_files_content = {}\n        for file_path in file_paths:\n            try:\n                content = self.fetch_file_from_github(repo, file_path, branch, token)\n                all_files_content[file_path] = {\"status\": \"success\", \"content\": content}\n            except Exception as e:\n                all_files_content[file_path] = {\"status\": \"error\", \"message\": str(e)}\n\n        return all_files_content\n\n\n# Example Usage\nif __name__ == '__main__':\n    github_token = \"YOUR_GITHUB_TOKEN\"\n    github_repo = \"owner/repository-name\"\n    github_branch = \"main\"\n    github_files = [\n        \"path/to/file1.txt\",\n        \"path/to/file2.sql\",\n        \"path/to/file3.json\"\n    ]\n\n    if github_token == \"YOUR_GITHUB_TOKEN\":\n        print(\"\u26a0\ufe0f Please replace the placeholder values before running.\")\n    else:\n        reader_tool = GitHubFileReaderTool()\n        result = reader_tool.run(\n            repo=github_repo,\n            file_paths=github_files,\n            branch=github_branch,\n            token=github_token\n        )\n\n        for file, details in result.items():\n            print(f\"\\nFile: {file}\")\n            if details['status'] == 'success':\n                print(f\"Content:\\n{details['content'][:200]}...\")  # print first 200 characters\n            else:\n                print(f\"Error: {details['message']}\")\n",
                            "isApproved": false
                        }
                    ],
                    "allowCodeExecution": false,
                    "isSafeCodeExecution": true
                }
            },
            {
                "serial": 2,
                "agent": {
                    "id": 8237,
                    "name": "DI_Databricks_Model_Data_Constraints",
                    "role": "Senior Data Modeler",
                    "goal": "Build an agent that can either:\n1. Identify Data Expectations, Constraints, and Business Rules to ensure compliance and data integrity within the conceptual data model.\n2. Update previously generated Data Constraints based on change requests.\nThis agent reads inputs from GitHub input directory using the **GitHub Reader Tool** and writes outputs to GitHub output directory using the **GitHub Writer Tool**.",
                    "backstory": "A well-defined data model must adhere to business rules, constraints, and data expectations to ensure high-quality data and compliance with reporting standards. This ensures accurate, consistent, and meaningful data representation for analytics and decision-making. The agent supports both **initial Data Constraints development** and **iterative updates** directly in GitHub, enabling version-controlled collaboration.",
                    "verbose": true,
                    "allowDelegation": true,
                    "updatedAt": "2025-08-22T04:18:31.653685",
                    "llm": {
                        "modelDeploymentName": "Anthropic.claude-4-sonnet",
                        "model": "anthropic.claude-4-sonnet",
                        "modelType": "Generative",
                        "aiEngine": "AmazonBedrock",
                        "topP": 1.0,
                        "maxToken": 8000,
                        "temperature": 0.10000000149011612,
                        "bedrockModelId": "us.anthropic.claude-sonnet-4-20250514-v1:0",
                        "region": "us-east-1",
                        "accessKey": "****MASKED****",
                        "secretKey": "****MASKED****"
                    },
                    "task": {
                        "description": "Before starting to process the agent, first check the value of 'Do_You_Need_Any_Changes'. Based on this, proceed accordingly.\n\n#### **1. Standard Model Data Constraints Workflow (Mode 1)**\n\nExecuted when:\n* The report requirement file exists in GitHub input directory and is read using the GitHub Reader Tool.\n* If Do_You_Need_Any_Changes = \"No\", then check the output directory. If the output directory already contains the agent output file (identified by matching the actual input file name that ends with an underscore Constraints underscore followed by a number), there is no need to do anything \u2014 simply read the existing file from the output directory and return its content as the output.\n* If Do_You_Need_Any_Changes = \"No\", then check the output directory. If the output directory does not contain any agent output file (based on the actual input file name ending with an underscore Constraints underscore followed by a number), proceed to create the Model Data Constraints for the given report requirement file from the input directory. For generating the Model Data Constraints instructions and structure are given below. Once generated, store the Model Data Constraints in the output directory with the file name as the actual input Report requirement file name, followed by _Constraints_1.md.\n\nThe agent must:\n* Parse the Report requirement file.\n* Identifying and specifying Data Expectations, Constraints, and Business Rules related to the reporting requirements. These elements will help ensure the data model aligns with business needs and regulatory compliance.\n* Extract Data Expectations from the reporting requirements.\n* Identify and document Constraints affecting the data model.\n* Define Business Rules that govern the data structure and relationships.\n* Ensure alignment with reporting requirements and business objectives.\n* Don't give output in the JSON format, give output in the normal text format\n* Generate Model Data Constraints containing the sections listed in **Model Data Constraints Structure** below.\n* Save the output file to GitHub output directory using the **GitHub Writer Tool**.\n* The output file name should be the actual input report requirement file name, followed by _Constraints_1.md.\n* **Version rule:** Start with `_1` and increment the highest underscore number found in the GitHub path.\n\n#### **2. Update Model Data Constraints Workflow (Mode 2)**\nExecuted when:\n* User indicates `Do_You_Need_Any_Changes` = `\"Yes\"`.\n* User provides `Required changes`.\n\nThe agent must:\n* Identify the Model Data Constraints file in GitHub output directory with the actual input report requirement file name _Constraints_latest version suffix (e.g., `_3` if `_1`, `_2`, `_3` exist).\n* Read that file from the github output directory using the **GitHub Reader Tool**.\n* Apply the requested changes from Required Changes.\n* Add or modify the following fields in the output Metadata \n```\n## *Version* : 2 or 3 or 4 etc...\n## *Changes*: \n## *Reason*: \n``` \n* Save the updated file to the same GitHub output directory with the with the actual input report requirement file name _Constraints_next incremented version number (e.g., `_4`).\n* Maintain previous version in history.\n* Do **not** overwrite without version increment.\n\n## **Input Sections**\n* GitHub Credentials and Report Requirement file present in the github input directory: `{{Report_Requirement_File_And_Github_Details}}`\n\n**Update Inputs**:\n* Do_You_Need_Any_Changes: `{{Do_You_Need_Any_Changes_In_Model_Data_Constraints_Yes_Or_No_If_Yes_Give_Required_Changes}}`\n\n## **Model Data Constraints Structure**\n\n### **Metadata Requirements**\nAdd the following metadata at the top of each generated file:\n```\n____________________________________________\n## *Author*: AAVA\n## *Created on*:   Leave it empty dont give any values are placeholder in this field\n## *Description*:   <one-line description of the purpose>\n## *Version*: 1 \n## *Updated on*: Leave it empty dont give any values are placeholder in this field\n_____________________________________________\n```\n1. Data Expectations \u2013 Define expectations regarding data completeness, accuracy, format, and consistency.\n2. Constraints \u2013 Identify constraints such as mandatory fields, uniqueness, data type limitations, dependencies, and referential integrity.\n3. Business Rules \u2013 Define operational rules affecting data processing, reporting logic, and transformation guidelines.\n4. API Cost Calculation\n\u2013 Cost for this particular Api Call to LLM model: $...\n\n## **Guidelines Policies (Both Modes)**\n* Ensure Data Expectations, Constraints, and Business Rules strictly align with the reporting requirements.\n* Do not introduce new elements that are not present in the given requirements.\n* Provide precise definitions to avoid ambiguity.\n* In the output add all the necessary Number bullet marks\n* Give output in the markdown format",
                        "expectedOutput": "**Mode 1 Output**:\n* Display the Model Data Constraints output\n* And store the Model Data Constraints output in the GitHub output directory with the file name as `actual input report requirements file name_Constraints_<version>.md` \u2014 Contains all sections above in markdown format.\n\n**Mode 2 Output**:\n* Display the updated Model Data Constraints output\n* And store the updated Model Data Constraints output in the GitHub output directory with the file name as `actual input report requirements file name_Constraints_<next_version>.md` \u2014 Updated Model Data Constraints with requested changes applied, preserving structure and formatting."
                    },
                    "maxIter": 20,
                    "maxRpm": 50,
                    "maxExecutionTime": 300,
                    "tools": [],
                    "userTools": [
                        {
                            "toolId": 300,
                            "toolName": "DI_Github_File_Writer_Z",
                            "toolClassName": "GitHubFileWriterTool",
                            "toolClassDef": "from crewai.tools import BaseTool\nfrom pydantic import BaseModel, Field\nimport base64\nimport requests\nimport urllib3\nimport logging\nimport re\nfrom typing import Type, Any\n\n# ---------------------------------\n# SSL & Logging Configuration\n# ---------------------------------\nurllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\nlogging.basicConfig(\n    level=logging.INFO,\n    format=\"%(asctime)s - %(levelname)s - %(message)s\",\n    filename=\"github_file_writer.log\",\n)\nlogger = logging.getLogger(\"GitHubFileWriterTool\")\n\n\n# ---------------------------------\n# Input Schema\n# ---------------------------------\nclass GitHubFileWriterSchema(BaseModel):\n    repo: str = Field(..., description=\"GitHub repository in 'owner/repo' format\")\n    branch: str = Field(..., description=\"Branch name (e.g., 'main')\")\n    token: str = Field(..., description=\"GitHub Personal Access Token\")\n    folder_name: str = Field(..., description=\"Name of the folder to create inside the repository\")\n    file_name: str = Field(..., description=\"Name of the file to create or update in the folder\")\n    content: str = Field(..., description=\"Text content to upload into the GitHub file\")\n\n\n# ---------------------------------\n# Main Tool Class\n# ---------------------------------\nclass GitHubFileWriterTool(BaseTool):\n    name: str = \"GitHub File Writer Tool\"\n    description: str = \"Creates or updates files in a GitHub repository folder\"\n    args_schema: Type[BaseModel] = GitHubFileWriterSchema\n\n    api_url_template: str = \"https://api.github.com/repos/{repo}/contents/{path}\"\n\n    def _sanitize_path_component(self, component: str) -> str:\n        \"\"\"Remove invalid GitHub path characters.\"\"\"\n        sanitized = re.sub(r'[\\\\*?:\"<>|]', '_', component)\n        sanitized = re.sub(r'\\.\\.', '_', sanitized)\n        sanitized = sanitized.lstrip('./\\\\')\n        return sanitized if sanitized else \"default\"\n\n    def _validate_content(self, content: str) -> str:\n        \"\"\"Ensure valid string content within 10MB limit.\"\"\"\n        if not isinstance(content, str):\n            logger.warning(\"Content is not a string. Converting to string.\")\n            content = str(content)\n\n        max_size = 10 * 1024 * 1024  # 10 MB\n        if len(content.encode('utf-8')) > max_size:\n            logger.warning(\"Content exceeds 10MB limit. Truncating.\")\n            content = content[:max_size]\n\n        return content\n\n    def create_file_in_github(self, repo: str, branch: str, token: str,\n                              folder_name: str, file_name: str, content: str) -> str:\n        \"\"\"Create or update a file in GitHub repository.\"\"\"\n        sanitized_folder = self._sanitize_path_component(folder_name)\n        sanitized_file = self._sanitize_path_component(file_name)\n        validated_content = self._validate_content(content)\n\n        path = f\"{sanitized_folder}/{sanitized_file}\"\n        url = self.api_url_template.format(repo=repo, path=path)\n        headers = {\"Authorization\": f\"token {token}\", \"Content-Type\": \"application/json\"}\n\n        # Encode content\n        encoded_content = base64.b64encode(validated_content.encode()).decode()\n\n        # Check file existence to get SHA (for updating)\n        sha = None\n        try:\n            response = requests.get(url, headers=headers, params={\"ref\": branch}, verify=False)\n            if response.status_code == 200:\n                sha = response.json().get(\"sha\")\n        except Exception as e:\n            logger.error(f\"Failed to check file existence: {e}\", exc_info=True)\n\n        payload = {\"message\": f\"Add or update file: {sanitized_file}\",\n                   \"content\": encoded_content, \"branch\": branch}\n        if sha:\n            payload[\"sha\"] = sha  # Required for updating\n\n        # Upload or update file\n        try:\n            put_response = requests.put(url, json=payload, headers=headers, verify=False)\n            if put_response.status_code in [200, 201]:\n                logger.info(f\"\u2705 File '{sanitized_file}' uploaded successfully to {repo}/{sanitized_folder}\")\n                return f\"\u2705 File '{sanitized_file}' uploaded successfully to GitHub in folder '{sanitized_folder}'.\"\n            else:\n                logger.error(f\"GitHub API Error: {put_response.text}\")\n                return f\"\u274c Failed to upload file. GitHub API error: {put_response.text}\"\n        except Exception as e:\n            logger.error(f\"Failed to upload file: {e}\", exc_info=True)\n            return f\"\u274c Exception while uploading file: {str(e)}\"\n\n    # ------------------------------------------------------\n    # Required method for CrewAI Tool execution\n    # ------------------------------------------------------\n    def _run(self, repo: str, branch: str, token: str,\n             folder_name: str, file_name: str, content: str) -> Any:\n        \"\"\"Main execution method.\"\"\"\n        return self.create_file_in_github(repo, branch, token, folder_name, file_name, content)\n\n\n# ---------------------------------\n# Generalized Main (User-Parameterized)\n# ---------------------------------\nif __name__ == \"__main__\":\n    print(\"\ud83d\udd27 GitHub File Writer Tool - Interactive Mode\\n\")\n    repo = input(\"Enter GitHub repository (owner/repo): \").strip()\n    branch = input(\"Enter branch name (e.g., main): \").strip()\n    token = input(\"Enter your GitHub Personal Access Token: \").strip()\n    folder_name = input(\"Enter folder name: \").strip()\n    file_name = input(\"Enter file name (e.g., example.txt): \").strip()\n    print(\"\\nEnter the content for your file (end with a blank line):\")\n    lines = []\n    while True:\n        line = input()\n        if line == \"\":\n            break\n        lines.append(line)\n    content = \"\\n\".join(lines)\n\n    tool = GitHubFileWriterTool()\n    result = tool._run(repo=repo, branch=branch, token=token,\n                       folder_name=folder_name, file_name=file_name, content=content)\n    print(\"\\nResult:\", result)\n",
                            "isApproved": false
                        },
                        {
                            "toolId": 344,
                            "toolName": "DI_GitHub_File_Reader_Z",
                            "toolClassName": "GitHubFileReaderTool",
                            "toolClassDef": "from crewai.tools import BaseTool\nfrom pydantic import BaseModel, Field\nimport base64\nimport requests\nimport logging\nfrom typing import Type, Any, List, Dict\n\n# Setup logging for the GitHub File Reader Tool\nlogging.basicConfig(\n    level=logging.INFO,\n    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n    filename='github_file_reader.log'\n)\nlogger = logging.getLogger('GitHubFileReaderTool')\n\nclass GitHubFileReaderSchema(BaseModel):\n    \"\"\"Input schema for the GitHubFileReaderTool.\"\"\"\n    repo: str = Field(..., description=\"GitHub repository in the format 'owner/repo'\")\n    file_paths: List[str] = Field(..., description=\"List of file paths in the repository\")\n    branch: str = Field(..., description=\"Branch name to read the files from (e.g., 'main')\")\n    token: str = Field(..., description=\"GitHub personal access token for authorization\")\n\nclass GitHubFileReaderTool(BaseTool):\n    name: str = \"GitHub File Reader Tool\"\n    description: str = \"Reads multiple files from a GitHub repository based on user inputs.\"\n    args_schema: Type[BaseModel] = GitHubFileReaderSchema\n\n    api_url_template: str = \"https://api.github.com/repos/{repo}/contents/{file_path}\"\n\n    def fetch_file_from_github(self, repo: str, file_path: str, branch: str, token: str) -> str:\n        \"\"\"Fetches a file content from GitHub.\"\"\"\n        url = self.api_url_template.format(repo=repo, file_path=file_path)\n        headers = {\n            \"Authorization\": f\"token {token}\",\n            \"Accept\": \"application/vnd.github.v3+json\"\n        }\n        params = {\"ref\": branch}\n\n        try:\n            logger.info(f\"Fetching file '{file_path}' from repo '{repo}' on branch '{branch}'\")\n            response = requests.get(url, headers=headers, params=params)\n            response.raise_for_status()\n\n            file_data = response.json()\n            if \"content\" not in file_data:\n                raise ValueError(f\"\u274c Error: Path '{file_path}' might be a directory or missing content.\")\n\n            decoded_content = base64.b64decode(file_data['content']).decode('utf-8')\n            logger.info(f\"\u2705 Successfully fetched file '{file_path}'.\")\n            return decoded_content\n\n        except Exception as e:\n            logger.error(f\"Failed to fetch file '{file_path}': {str(e)}\", exc_info=True)\n            raise\n\n    def _run(self, repo: str, file_paths: List[str], branch: str, token: str) -> Dict[str, Any]:\n        \"\"\"Main execution logic.\"\"\"\n        all_files_content = {}\n        for file_path in file_paths:\n            try:\n                content = self.fetch_file_from_github(repo, file_path, branch, token)\n                all_files_content[file_path] = {\"status\": \"success\", \"content\": content}\n            except Exception as e:\n                all_files_content[file_path] = {\"status\": \"error\", \"message\": str(e)}\n\n        return all_files_content\n\n\n# Example Usage\nif __name__ == '__main__':\n    github_token = \"YOUR_GITHUB_TOKEN\"\n    github_repo = \"owner/repository-name\"\n    github_branch = \"main\"\n    github_files = [\n        \"path/to/file1.txt\",\n        \"path/to/file2.sql\",\n        \"path/to/file3.json\"\n    ]\n\n    if github_token == \"YOUR_GITHUB_TOKEN\":\n        print(\"\u26a0\ufe0f Please replace the placeholder values before running.\")\n    else:\n        reader_tool = GitHubFileReaderTool()\n        result = reader_tool.run(\n            repo=github_repo,\n            file_paths=github_files,\n            branch=github_branch,\n            token=github_token\n        )\n\n        for file, details in result.items():\n            print(f\"\\nFile: {file}\")\n            if details['status'] == 'success':\n                print(f\"Content:\\n{details['content'][:200]}...\")  # print first 200 characters\n            else:\n                print(f\"Error: {details['message']}\")\n",
                            "isApproved": false
                        }
                    ],
                    "allowCodeExecution": false,
                    "isSafeCodeExecution": true
                }
            }
        ],
        "enableAgenticMemory": false,
        "levelId": 99,
        "org": "Ascendion",
        "orgId": 1,
        "domain": "Data&Insights",
        "domainId": 96,
        "projectId": 98,
        "project": "AllProjects",
        "teamId": 99,
        "team": "AVA Team",
        "callbacks": []
    }
}