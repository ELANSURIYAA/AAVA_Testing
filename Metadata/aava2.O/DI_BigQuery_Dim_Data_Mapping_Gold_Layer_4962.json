{
  "data": {
    "message": "Workflow with agents retrieved successfully",
    "workFlowDetail": {
      "id": 4962,
      "name": "DI BigQuery Dim Data Mapping Gold Layer",
      "description": "This workflow is for recommending and creating the gold dimension data mapping",
      "createdBy": "tejas.kharche@ascendion.com",
      "modifiedBy": "tejas.kharche@ascendion.com",
      "approvedBy": "tejas.kharche@ascendion.com",
      "createdAt": "2025-11-05T12:18:39.542656",
      "modifiedAt": "2025-12-03T15:03:31.224436",
      "approvedAt": "2025-11-05T12:18:40.607587",
      "status": "APPROVED",
      "isDeleted": false,
      "parentId": -1,
      "workflowConfigs": {
        "managerLlm": [
          {}
        ],
        "enableAgenticMemory": false
      },
      "workflowAgents": [
        {
          "serial": 1,
          "agentId": 7560,
          "name": "DI BigQuery Gold Dim Transformation Recommender",
          "workflowId": 4962,
          "agentDetails": {
            "topP": 1.0,
            "maxRpm": null,
            "levelId": 99,
            "maxIter": null,
            "toolRef": [],
            "maxToken": "64000",
            "isVerbose": true,
            "temperature": 0.2,
            "allowDelegation": false,
            "maxExecutionTime": 90,
            "allowCodeExecution": false,
            "isSafeCodeExecution": true,
            "toolReferences": []
          },
          "modelDeploymentName": "gpt-4.1",
          "description": "You will read the Model Conceptual, Data Constraints, Silver Layer Physical DDL script, Gold Layer Physical DDL script and Sample Data and generate transformation rules only for Dimension tables.\n\nINSTRUCTIONS:\n\n1. Parse the Silver Layer DDL script to extract only Dimension tables and their column definitions.\n2. Analyze the Model Conceptual and Data Constraints file to identify key attributes, hierarchies, and necessary transformations for Dimension tables.\n3. Inspect Sample Data to detect patterns, anomalies, and standardization requirements specific to Dimension attributes.\n4. Generate transformation rules for Dimension tables, including:\n* Data Type Conversions: Ensure data types align with reporting and business needs.\n* Column Derivations: Define computed attributes (e.g., concatenations, name standardizations, category hierarchies).\n* Hierarchy Mapping: Define parent-child relationships within dimensions.\n* Normalization and Standardization: Ensure consistent formats (e.g., date formats, uppercase/lowercase standardization, unique key constraints).\n5. Provide SQL transformations for each rule, ensuring alignment with the Silver Layer schema.\n6. Ensure traceability of transformations by linking each rule back to its source from the Model Conceptual, Data Constraints and Silver Layer schema to Gold layer.\n\nOUTPUT FORMAT:\n\n1. Transformation Rules for Dimension Tables:\n* [Rule Name]: [Description]\n    - Rationale: [Explanation]\n    - SQL Example: [Sample SQL transformation]\n\nFor input files:\n* Model Conceptual: {{Model_Conceptual}},\n* Data Constraints: {{Data_Constraints}},\n* Sample Data: {{Sample_Data}}.\n* Silver Layer Physical DDL script: {{Silver_Layer_Physical_Model}},\n* Gold Layer Physical DDL: {{Gold_Layer_Physical_Model}}\n",
          "modelName": "model"
        },
        {
          "serial": 2,
          "agentId": 7547,
          "name": "DI BigQuery Gold Dim Transformation Data Mapping",
          "workflowId": 4962,
          "agentDetails": {
            "topP": 1.0,
            "maxRpm": null,
            "levelId": 99,
            "maxIter": null,
            "toolRef": [],
            "maxToken": "64000",
            "isVerbose": true,
            "temperature": 0.2,
            "allowDelegation": false,
            "maxExecutionTime": 90,
            "allowCodeExecution": false,
            "isSafeCodeExecution": true,
            "toolReferences": []
          },
          "modelDeploymentName": "gpt-4.1",
          "description": "You are tasked with creating a detailed data mapping specifically for Dimension tables in the Gold Layer. This mapping will incorporate necessary transformations, validations, and cleansing rules at the attribute level.\nYour work will be based on the silver and gold layer physical model provided and previous DI_BigQuery_Gold_Dim_Transformation_Recommender\nagents recommendations\n\nINSTRUCTIONS:\n1. Review the provided silver and gold layer physical model DDL script.\n2. Create a detailed data mapping for Dimension tables from the Silver to Gold Layer, ensuring:\n* Dimension attribute transformations (e.g., category mappings, hierarchical relationships, surrogate key generation etc..).\n* Data validation rules for ensuring consistency (e.g., deduplication, format standardization etc..).\n* Cleansing logic (e.g., handling missing values, removing duplicates, enforcing uniqueness constraints).\n3. Ensure all transformations and rules are compatible with BigQuery\n4. Include explanations for complex transformations and business rules.\n\nOUTPUT FORMAT:\n1. Overview: Summary of the data mapping approach and key considerations.\n2. Data Mapping for Dimension Tables:\nThe mapping output should be in tabular format with the following fields for each Dimension table and its columns:\n* Target Layer: Gold\n* Target Table: Proper table name as per the Gold Layer DDL script\n* Target Field: Proper field name as per the Gold Layer DDL script\n* Source Layer: Silver\n* Source Table: Proper table name as per the Silver Layer DDL script\n* Source Field: Proper field name as per the Silver Layer DDL script\n* Validation Rule: Required validation rules from the Data Constraints file\n* Transformation Rule: Required transformation rules from the  previous DI_BigQuery_Gold_Dim_Transformation_Recommender\n agents output recommendations (e.g., name standardization, hierarchical relationships, normalization etc..).\n\nInputs:\n* Silver Layer Physical DDL script : {{Silver_Layer_Physical_Model}},\n* Gold Layer Physical DDL script: {{Gold_Layer_Physical_Model}} \n* Also take input from previous DI_BigQuery_Gold_Dim_Transformation_Recommender Agent\u2019s output recommendations as input",
          "modelName": "model"
        },
        {
          "serial": 3,
          "agentId": 7563,
          "name": "DI BigQuery Gold Data Mapping Reviewer",
          "workflowId": 4962,
          "agentDetails": {
            "topP": 1.0,
            "maxRpm": null,
            "levelId": 99,
            "maxIter": null,
            "toolRef": [],
            "maxToken": "64000",
            "isVerbose": true,
            "temperature": 0.2,
            "allowDelegation": false,
            "maxExecutionTime": 90,
            "allowCodeExecution": false,
            "isSafeCodeExecution": true,
            "toolReferences": []
          },
          "modelDeploymentName": "gpt-4.1",
          "description": "You are tasked with meticulously reviewing the Gold Layer Data Mapping. Your review should encompass various aspects to guarantee the mapping's quality and alignment with industry standards and mention along with\u2705 for correct implementations and \u274c for wrong implementations.\n\nINSTRUCTIONS:\n1. Review the Detailed Data Mapping from Silver to Gold Layer: \n* Ensure data mapping is correctly performed, and all tables are properly structured. \n* Examine the overall structure of the Gold Layer Data Mapping.\n2. Verify data consistency across all mapped fields : \n* Validate that each column in the Silver Layer is mapped correctly to its corresponding Gold Layer destination. \n3. Verify Dimension Attribute Transformations: Ensure correct category mappings.\n4. Verify Data Validation Rules for Consistency:\n   * Confirm deduplication logic is correctly applied.\n   * Ensure format standardization for fields such as dates, IDs, and codes.\n5. Verify Cleansing Logic:\n   * Validate handling of missing values (e.g., default values, imputations).\n   * Confirm removal of duplicates and enforcement of uniqueness constraints\n6. Check for compliance with BigQuery best practices.\n7. Verifies the alignment with Business Requirements\n\nINPUT:\nUse the previous agent data mapping output as input",
          "modelName": "model"
        }
      ],
      "realmId": 32
    }
  },
  "status": "SUCCESS"
}