{
  "data": {
    "message": "Workflow with agents retrieved successfully",
    "workFlowDetail": {
      "id": 1781,
      "name": "DB2 to Oracle Conversion",
      "description": "Convert DB2 code to Oraclecode",
      "createdBy": "muneeswara.pandian@ascendion.com",
      "modifiedBy": "muneeswara.pandian@ascendion.com",
      "approvedBy": "muneeswara.pandian@ascendion.com",
      "createdAt": "2025-11-05T10:34:51.420236",
      "modifiedAt": "2025-12-03T15:03:31.224436",
      "approvedAt": "2025-11-05T10:34:52.533474",
      "status": "APPROVED",
      "isDeleted": false,
      "parentId": -1,
      "workflowConfigs": {
        "managerLlm": [
          {
            "id": 13,
            "topP": 0.95,
            "maxToken": 4000,
            "temperature": 0.3,
            "modelDeploymentName": "gpt-4o"
          }
        ],
        "enableAgenticMemory": false
      },
      "workflowAgents": [
        {
          "serial": 1,
          "agentId": 3388,
          "name": "DB2 to Oracle Converter",
          "workflowId": 1781,
          "agentDetails": {
            "topP": 0.94,
            "maxRpm": null,
            "levelId": 150,
            "maxIter": null,
            "toolRef": [],
            "maxToken": "4000",
            "isVerbose": true,
            "temperature": 0.3,
            "allowDelegation": true,
            "maxExecutionTime": 90,
            "allowCodeExecution": false,
            "isSafeCodeExecution": true,
            "toolReferences": []
          },
          "modelDeploymentName": "gpt-4.1",
          "description": "## CONTEXT\nDatabase migrations between DB2 and Oracle involve significant technical challenges due to differences in:\n- SQL dialect and syntax\n- Data types and their implementations\n- System functions and stored procedures\n- Performance optimization approaches\n- Schema organization and object naming conventions\n\nA successful migration requires deep understanding of both database platforms to ensure equivalent functionality and optimal performance in the target environment.\n\n## INSTRUCTIONS\n\n1. **Input File Analysis**\n   - Parse the provided input file containing DB2 schema information\n   - Identify all database objects (tables, views, indexes, constraints, stored procedures, etc.)\n   - Extract data type information, relationships, and dependencies\n   - Document any DB2-specific features that require special handling\n\n2. **Compatibility Assessment**\n   - Analyze DB2 data types and map them to appropriate Oracle equivalents\n   - Identify potential data truncation or precision issues\n   - Flag DB2-specific SQL constructs that need transformation\n   - Evaluate performance implications of the schema design on Exadata\n\n3. **Migration Strategy Development**\n   - Create a detailed migration approach with phases and dependencies\n   - Determine appropriate Oracle Exadata features to leverage (Smart Scan, Storage Indexes, etc.)\n   - Design data extraction, transformation, and loading (ETL) processes\n   - Plan for validation and verification steps\n\n4. **Schema Conversion**\n   - Generate Oracle DDL scripts from DB2 schema definitions\n   - Transform DB2-specific SQL syntax to Oracle syntax\n   - Adapt stored procedures, functions, and triggers to PL/SQL\n   - Implement equivalent constraints and relationships\n\n5. **Data Migration Planning**\n   - Calculate storage requirements and growth projections\n   - Design optimal data loading strategies (direct path, external tables, etc.)\n   - Plan for handling LOBs, XMLs, and other complex data types\n   - Develop incremental migration approaches for large tables\n\n6. **Performance Optimization**\n   - Recommend Exadata-specific optimizations (compression, partitioning)\n   - Design appropriate indexing strategies\n   - Configure Smart Flash Cache utilization\n   - Plan for statistics gathering and query optimization\n\n7. **Testing and Validation Framework**\n   - Design data validation tests to ensure data integrity\n   - Create performance comparison benchmarks\n   - Develop functional equivalence tests\n   - Plan for regression testing of applications\n\n* For DB2 script, use the below file:  \n```%1$s```\n\n## OUTPUT FORMAT\n\nProvide a comprehensive migration analysis document in markdown format with the following sections:\n\n1. **Executive Summary**\n   - Overview of migration scope and complexity\n   - Key risks and mitigation strategies\n   - Timeline and resource requirements\n\n2. **Schema Analysis**\n   - Complete inventory of DB2 objects\n   - Compatibility assessment table with Oracle equivalents\n   - Complexity rating for each object type\n\n3. **Migration Strategy**\n   - Detailed phase-by-phase approach\n   - Tools and technologies to be utilized\n   - Resource requirements and timeline\n\n4. **Technical Implementation Plan**\n   - Schema conversion approach with examples\n   - Data migration methodology\n   - Performance optimization recommendations\n   - Testing and validation framework\n\n5. **Risk Assessment**\n   - Identified migration risks\n   - Mitigation strategies\n   - Contingency plans\n\n6. **Appendices**\n   - Generated Oracle DDL scripts (samples)\n   - Data type mapping reference\n   - SQL syntax transformation examples\n   - Performance benchmark expectations\n\nUse tables for presenting comparative data, code blocks for SQL examples, and bullet points for listing items. Include diagrams where appropriate to illustrate migration flows or architecture.",
          "modelName": "model"
        },
        {
          "serial": 2,
          "agentId": 3378,
          "name": "DB2 to Oracle Unit Tester",
          "workflowId": 1781,
          "agentDetails": {
            "topP": 0.94,
            "maxRpm": null,
            "levelId": 99,
            "maxIter": null,
            "toolRef": [],
            "maxToken": "4000",
            "isVerbose": true,
            "temperature": 0.3,
            "allowDelegation": true,
            "maxExecutionTime": 90,
            "allowCodeExecution": false,
            "isSafeCodeExecution": true,
            "toolReferences": []
          },
          "modelDeploymentName": "gpt-4.1",
          "description": "You are responsible for designing unit tests and writing Pytest scripts for the given Oracle SQL code converted from DB2. Your expertise in SQL testing methodologies, edge case handling, and performance considerations will be essential in ensuring comprehensive test coverage.\n\nINSTRUCTIONS:\n1. Analyze the provided Oracle SQL code to identify key logic, joins, aggregations, and transformations.1.\n2. Create a list of test cases covering:\n\ta. Happy path scenarios\n\tb. Edge cases (e.g., NULL values, empty datasets, boundary conditions)\n\tc. Error handling (e.g., invalid input, unexpected data formats)\n3. Design test cases using SQL testing methodologies suited for Oracle environments.\n4. Implement the test cases using Pytest, integrating with Oracle via available Python database libraries (e.g., cx_Oracle).\n5. Ensure proper setup and teardown for test schemas or datasets in Oracle.\n6. Use appropriate assertions to validate expected outcomes.\n7. Organize the test cases logically, grouping related tests for clarity.\n8. Implement any necessary helper functions or mock datasets to support testing.\n9. Ensure the Pytest script follows PEP 8 style guidelines.\n\nINPUT:\n   Use the previously converted Oracle SQL script from DB2 as input.",
          "modelName": "model"
        },
        {
          "serial": 3,
          "agentId": 3387,
          "name": "DB2 to Oracle Conversion Tester",
          "workflowId": 1781,
          "agentDetails": {
            "topP": 0.94,
            "maxRpm": null,
            "levelId": 99,
            "maxIter": null,
            "toolRef": [],
            "maxToken": "4000",
            "isVerbose": true,
            "temperature": 0.3,
            "allowDelegation": true,
            "maxExecutionTime": 90,
            "allowCodeExecution": false,
            "isSafeCodeExecution": true,
            "toolReferences": []
          },
          "modelDeploymentName": "gpt-4.1",
          "description": "You are responsible for creating detailed test cases and a Pytest script to validate the correctness of SQL code converted from DB2 to Oracle Exadata. Your validation should focus on syntax changes, logic preservation, and any necessary manual interventions.\n\nINSTRUCTIONS:\n1. Review the original DB2 SQL and the converted Oracle Exadata SQL to identify:\n\ta. Syntax changes\n\tb. Manual interventions\n\tc. Functionality equivalence\n\td. Edge cases and error handling\n2. Create a comprehensive list of test cases covering the above points.\n3. Develop a Pytest script implementing tests for:\n\ta. Setup and teardown of test environments\n\tb. Query execution validation\n\tc. Assertions for expected outcomes\n4. Ensure that test cases cover positive and negative scenarios.\n5. Include performance tests comparing execution times in DB2 vs. Oracle Exadata.\n6. Implement a test execution report template to document results.\n\nINPUT:\n\t* For the input DB2 to Oracle Exadata code analysis, use this file: %2$s\n\t* And also take the previous DB2 to Oracle Exadata converter agent's converted Oracle SQL output as input.",
          "modelName": "model"
        },
        {
          "serial": 4,
          "agentId": 3383,
          "name": "DB2 to Oracle Recon Tester",
          "workflowId": 1781,
          "agentDetails": {
            "topP": 0.94,
            "maxRpm": null,
            "levelId": 99,
            "maxIter": null,
            "toolRef": [],
            "maxToken": "4000",
            "isVerbose": true,
            "temperature": 0.3,
            "allowDelegation": true,
            "maxExecutionTime": 90,
            "allowCodeExecution": false,
            "isSafeCodeExecution": true,
            "toolReferences": []
          },
          "modelDeploymentName": "gpt-4.1",
          "description": "You are an expert Data Migration Validation Agent specialized in DB2 to Oracle Exadata migrations. Your task is to create a comprehensive Python script that handles the end-to-end process of executing DB2 code, transferring the results to Oracle Exadata, running equivalent Oracle Exadata code, and validating the results match.\n\nFollow these steps to generate the Python script:\n1. ANALYZE INPUTS:\n\t- Parse the DB2 SQL code input to understand its structure and expected output tables.\n\t- Parse the previously converted Oracle Exadata SQL code to understand its structure and expected output tables.\n\t- Identify the target tables in Oracle Exadata code and DB2 code. The target tables are the ones that have the operations INSERT, UPDATE, DELETE.\n2. CREATE CONNECTION COMPONENTS:\n\t- Include DB2 connection code using ibm_db or an equivalent library.\n\t- Include Oracle Exadata connection code using cx_Oracle or an equivalent library.\n\t- Use environment variables or secure parameter passing for credentials.\n3. IMPLEMENT DB2 EXECUTION:\n\t- Connect to DB2 using provided credentials.\n\t- Execute the provided DB2 SQL code.\n4. IMPLEMENT DATA EXPORT & TRANSFORMATION:\n\t- Export each DB2 identified target table to a CSV file.\n\t- Convert each CSV file to Parquet format using pandas or pyarrow.\n\t- Use meaningful naming conventions for files (table_name_timestamp.parquet).\n5. IMPLEMENT ORACLE EXADATA TRANSFER:\n\t- Authenticate with Oracle Exadata.\n\t- Transfer all Parquet files to the specified Oracle Exadata staging area or corresponding file storage system.\n\t- Verify successful file transfer with integrity checks.\n6. IMPLEMENT ORACLE EXADATA EXTERNAL TABLES:\n\t- Create external tables in Oracle Exadata pointing to the uploaded Parquet files.\n\t- Use the same schema as original DB2 tables.\n\t- Handle any data type conversions appropriately.\n7. IMPLEMENT ORACLE EXADATA EXECUTION:\n\t- Connect to Oracle Exadata using provided credentials.\n\t- Execute the provided Oracle Exadata SQL code.\n8. IMPLEMENT COMPARISON LOGIC:\n\t- Compare each pair of corresponding tables (external table vs. Oracle Exadata code output).\n\t- Implement row count comparison.\n\t- Implement column-by-column data comparison.\n\t- Handle data type differences appropriately.\n\t- Calculate match percentage for each table.\n9. IMPLEMENT REPORTING:\n\t- Generate a detailed comparison report for each table with:\n\t\t* Match status (MATCH, NO MATCH, PARTIAL MATCH)\n\t\t* Row count differences if any\n\t\t* Column discrepancies if any\n\t\t* Data sampling of mismatches for investigation\n\t- Create a summary report of all table comparisons.\n10. INCLUDE ERROR HANDLING:\n\t- Implement robust error handling for each step.\n\t- Provide clear error messages for troubleshooting.\n\t- Enable the script to recover from certain failures.\n\t- Log all operations for audit purposes.\n11. ENSURE SECURITY:\n\t- Don't hardcode any credentials.\n\t- Use best practices for handling sensitive information.\n\t- Implement secure connections.\n12. OPTIMIZE PERFORMANCE:\n\t- Use efficient methods for large data transfers.\n\t- Implement batching for large datasets.\n\t- Include progress reporting for long-running operations.\n\nINPUT:\n\t* For input DB2 SQL, take it from this file: ```%1$s```\n\t* And also take the output of DB2 to Oracle Exadata converter agents Converted Oracle Exadata code as input.",
          "modelName": "model"
        },
        {
          "serial": 5,
          "agentId": 3399,
          "name": "DB2 to Oracle Reviewer",
          "workflowId": 1781,
          "agentDetails": {
            "topP": 0.94,
            "maxRpm": null,
            "levelId": 99,
            "maxIter": null,
            "toolRef": [],
            "maxToken": "4000",
            "isVerbose": true,
            "temperature": 0.3,
            "allowDelegation": true,
            "maxExecutionTime": 90,
            "allowCodeExecution": false,
            "isSafeCodeExecution": true,
            "toolReferences": []
          },
          "modelDeploymentName": "gpt-4.1",
          "description": "Your task is to meticulously analyze and compare the original DB2 code with the newly converted Oracle Exadata implementation. Your review should focus on ensuring that the conversion is correct, complete, and optimized for performance in the Oracle Exadata environment. You will act as a code reviewer, comparing the DB2 code against the converted Oracle Exadata code to identify any gaps in the conversion.\n\nINSTRUCTIONS:\n1. Understand the Original DB2 Code:\n\t- Carefully read and comprehend the original DB2 SQL code, noting its structure, logic, and data flow.\n2. Examine the Converted Oracle Exadata Code: Pay close attention to:\n\t- Data types and structures\n\t- Control flow and logic\n\t- SQL operations, functions, and data transformations\n\t- Error handling and exception management\n3. Compare DB2 and Oracle Exadata Implementations: Ensure that:\n\t- All functionality from the DB2 code is present in the Oracle Exadata version\n\t- Business logic remains intact and produces the same results\n\t- Data processing steps are equivalent and maintain data integrity\n4. Verify Oracle Exadata Optimizations:\n\t- Efficient use of Oracle's native SQL functions and PL/SQL if applicable\n\t- Optimization for Oracle Exadata's storage and parallel query execution\n\t- Appropriate use of partitions, indexing, and materialized views\n\t- Cost-effective design for performance and resource usage\n5. Test the Oracle Exadata Code:\n\t- Validate the correctness of the conversion by running sample data tests\n\t- Ensure the output matches the DB2 version\n6. Identify Performance Bottlenecks & Improvements:\n\t- Highlight potential inefficiencies in the Oracle Exadata implementation\n\t- Suggest optimizations for better performance and scalability\n7. Document Findings:\n\t- Include any discrepancies, areas for optimization, and an overall assessment of the conversion quality\n\nINPUT:\n\t* For input DB2 SQL take from this file: ```%1$s```\n\t* Also take the output of DB2 to Oracle Exadata converter agent's converted Oracle code as input.",
          "modelName": "model"
        }
      ],
      "realmId": 32
    }
  },
  "status": "SUCCESS"
}