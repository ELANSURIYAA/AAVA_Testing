{
  "data": {
    "message": "Workflow with agents retrieved successfully",
    "workFlowDetail": {
      "id": 9098,
      "name": "DI AbInitio Document To PySpark",
      "description": "Generate the Pyspark script from abinitio document",
      "createdBy": "karthikeyan.iyappan@ascendion.com",
      "modifiedBy": "karthikeyan.iyappan@ascendion.com",
      "createdAt": "2026-02-02T11:00:14.324357",
      "modifiedAt": "2026-02-02T11:00:14.784624",
      "approvedAt": "2026-02-02T11:00:14.771957",
      "status": "APPROVED",
      "isDeleted": false,
      "parentId": 9097,
      "workflowConfigs": {
        "topP": 0.95,
        "maxToken": null,
        "managerLlm": [
          {
            "id": 52,
            "topP": 0.95,
            "model": "gpt-4.1",
            "maxRpm": 0,
            "preset": "Custom",
            "aiEngine": "AzureOpenAI",
            "maxToken": null,
            "temperature": 0.1,
            "maxIteration": 2018,
            "maxExecutionTime": 727,
            "modelDeploymentName": "gpt-4.1"
          }
        ],
        "temperature": 0.1,
        "enableAgenticMemory": true
      },
      "workflowAgents": [
        {
          "serial": 1,
          "agentId": 18483,
          "name": "DI AbInitio Document To PySpark",
          "workflowId": 9098,
          "agentDetails": {
            "topP": 0.95,
            "maxRpm": 20,
            "preset": "Custom",
            "maxIter": 330,
            "temperature": 0.5,
            "guardrailIds": [],
            "allowDelegation": false,
            "maxExecutionTime": 410,
            "allowCodeExecution": false,
            "isSafeCodeExecution": false,
            "expectedOutputFormat": "",
            "toolReferences": []
          },
          "modelDeploymentName": "gpt-4.1",
          "description": "****MASKED****",
          "modelName": "model"
        },
        {
          "serial": 2,
          "agentId": 18542,
          "name": "DI AbInitio Document To PySpark Unit Tester",
          "workflowId": 9098,
          "agentDetails": {
            "topP": 0.9,
            "maxRpm": 20,
            "preset": "Custom",
            "maxIter": 4000,
            "temperature": 0.5,
            "guardrailIds": [],
            "allowDelegation": false,
            "maxExecutionTime": 455,
            "allowCodeExecution": false,
            "isSafeCodeExecution": false,
            "expectedOutputFormat": "",
            "toolReferences": []
          },
          "modelDeploymentName": "gpt-4.1",
          "description": "You are responsible for creating a robust PySpark unit test suite using Pytest for the given converted PySpark script. Your unit tests must simulate the core functionalities previously performed by Ab Initio components\u2014such as joins, transformations, lookups, filters, deduplication, and reject logic\u2014now re-implemented in PySpark.  \r\n\n### **INSTRUCTIONS:**\r\n\n1. **Analyze the PySpark script:**\r\n\n\u00a0 \u00a0- Identify major processing steps: input reading, joins, lookups, filters, business rule applications, and output generation.\r\n\n\u00a0 \u00a0- Review any `.xfr` function equivalents (custom logic), `.dml` schema references, or parameter usage.\r\n\n2. **Design a test suite covering:**\r\n\n\u00a0 \u00a0- **Happy Path** scenarios (valid inputs, expected transformations)\r\n\n\u00a0 \u00a0- **Edge Cases** such as:\r\n\n\u00a0 \u00a0 \u00a0- Null or missing fields\r\n\n\u00a0 \u00a0 \u00a0- Empty datasets\r\n\n\u00a0 \u00a0 \u00a0- Boundary values\r\n\n\u00a0 \u00a0 \u00a0- Data type mismatches\r\n\n\u00a0 \u00a0- **Negative Testing**:\r\n\n\u00a0 \u00a0 \u00a0- Missing columns\r\n\n\u00a0 \u00a0 \u00a0- Malformed input data\r\n\n\u00a0 \u00a0 \u00a0- Unexpected schemas or field order\r\n\n\u00a0 \u00a0- **Reject Handling** (if implemented)\r\n\n\u00a0 \u00a0- **Lookup miss/fail paths** (for `.xfr` logic or join mismatches)\r\n\n3. **Test Case Requirements:**\r\n\n\u00a0 \u00a0- Assign a **Test Case ID** and brief **description**\r\n\n\u00a0 \u00a0- Define **input dataset** (as Spark DataFrame literal or mocked data)\r\n\n\u00a0 \u00a0- Define **expected output dataset**\r\n\n\u00a0 \u00a0- Use `assertDataFrameEqual` (via `chispa` or `pyspark.sql.testing`) for validation\r\n\n\u00a0 \u00a0- Include setup/teardown logic as needed\r\n\n\u00a0 \u00a0- Follow PEP 8 guidelines\r\n\n4. **Test Implementation Framework:**\r\n\n\u00a0 \u00a0- Use **Pytest** for execution\r\n\n\u00a0 \u00a0- Use **PySparkSession** fixture for session creation\r\n\n\u00a0 \u00a0- Mock inputs using Pandas-to-Spark conversions or Spark SQL\r\n\n\u00a0 \u00a0- Group tests logically by transformation block\r\n\n### **OUTPUT FORMAT:**\r\n\nUse **Markdown** and include:\r\n\n#### Metadata Header\r\n\n```\r\n\n==================================================================\r\n\nAuthor:        AAVA\r\n\nCreated on:    (Leave it empty)\r\n\nDescription:   One line descriptiom\r\n\n==================================================================\r\n\n````\r\n\n#### 1. Test Case Inventory:\r\n\n| Test Case ID | Description | Scenario Type | Expected Outcome |\r\n\n|--------------|-------------|----------------|------------------|\r\n\n| TC001 | Validate successful transformation with valid input | Happy Path | Transformed DataFrame matches expected output |\r\n\n| TC002 | Test behavior with NULL values in critical columns | Edge Case | NULLs handled correctly without failure |\r\n\n| TC003 | Missing column in input | Negative Test | Raise appropriate error |\r\n\n| TC004 | Lookup failure scenario | Edge Case | Rows with no match handled per spec |\r\n\n| TC005 | Empty input dataset | Edge Case | Output DataFrame is empty but no crash |\r\n\n*Add more as needed based on code logic*\r\n\n#### 2. Pytest Script Template (example):\r\n\n```python\r\n\nimport pytest\r\n\nfrom pyspark.sql import SparkSession\r\n\nfrom chispa.dataframe_comparer import assert_df_equality\r\n\n@pytest.fixture(scope=\"session\")\r\n\ndef spark():\r\n\n\u00a0 \u00a0 return SparkSession.builder.master(\"local\").appName(\"unit-test\").getOrCreate()\r\n\ndef test_transformation_valid_input(spark):\r\n\n\u00a0 \u00a0 # Sample input DataFrame\r\n\n\u00a0 \u00a0 input_data = [(1, \"A\"), (2, \"B\")]\r\n\n\u00a0 \u00a0 input_df = spark.createDataFrame(input_data, [\"id\", \"value\"])\r\n\n\u00a0 \u00a0 # Expected output\r\n\n\u00a0 \u00a0 expected_data = [(1, \"A_transformed\"), (2, \"B_transformed\")]\r\n\n\u00a0 \u00a0 expected_df = spark.createDataFrame(expected_data, [\"id\", \"value\"])\r\n\n\u00a0 \u00a0 # Call your transformation function\r\n\n\u00a0 \u00a0 result_df = your_transform_function(input_df)\r\n\n\u00a0 \u00a0 # Compare\r\n\n\u00a0 \u00a0 assert_df_equality(result_df, expected_df)\r\n\n# Repeat for edge, null, and error scenarios\r\n\n````\r\n\n#### 3. API Cost:\r\n\napiCost: <calculated_float_value> USD\r\n\nInclude full precision (e.g., `apiCost: 0.00043752 USD`)\r\n\n### **INPUT:**\r\n\n* Take the AbInitio to Pyspark converter agent converted Pyspark code as input",
          "modelName": "model"
        },
        {
          "serial": 3,
          "agentId": 18572,
          "name": "DI AbInitio Document To PySpark Reviewer",
          "workflowId": 9098,
          "agentDetails": {
            "topP": 1.0,
            "maxRpm": 20,
            "preset": "Custom",
            "maxIter": 8000,
            "temperature": 0.6,
            "guardrailIds": [],
            "allowDelegation": false,
            "maxExecutionTime": 300,
            "allowCodeExecution": false,
            "isSafeCodeExecution": false,
            "expectedOutputFormat": "",
            "toolReferences": []
          },
          "modelDeploymentName": "gpt-4.1",
          "description": "****MASKED****",
          "modelName": "model"
        }
      ],
      "realmId": 79,
      "tags": [
        2,
        12
      ],
      "practiceArea": 6
    }
  },
  "status": "SUCCESS"
}