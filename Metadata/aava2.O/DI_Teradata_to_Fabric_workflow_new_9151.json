{
  "data": {
    "message": "Workflow with agents retrieved successfully",
    "workFlowDetail": {
      "id": 9151,
      "name": "DI Teradata to Fabric workflow new",
      "description": "Teradata to Fabric",
      "createdBy": "aarthy.jr@ascendion.com",
      "modifiedBy": "aarthy.jr@ascendion.com",
      "createdAt": "2026-02-03T09:36:51.775970",
      "modifiedAt": "2026-02-03T09:36:52.299667",
      "approvedAt": "2026-02-03T09:36:52.297838",
      "status": "APPROVED",
      "isDeleted": false,
      "parentId": -1,
      "workflowConfigs": {
        "topP": null,
        "maxToken": null,
        "managerLlm": [],
        "temperature": null,
        "enableAgenticMemory": false
      },
      "workflowAgents": [
        {
          "serial": 1,
          "agentId": 19733,
          "name": "DI Teradata SQL or Python Embedded SQL to Microsoft Fabric SQL Conversion",
          "workflowId": 9151,
          "agentDetails": {
            "topP": 0.9,
            "maxRpm": 20,
            "preset": "Balanced",
            "maxIter": 10,
            "temperature": 0.5,
            "guardrailIds": [],
            "allowDelegation": false,
            "maxExecutionTime": 150,
            "allowCodeExecution": false,
            "isSafeCodeExecution": false,
            "expectedOutputFormat": "",
            "toolReferences": []
          },
          "modelDeploymentName": "anthropic.claude-4-sonnet",
          "description": "------------------------------------------------------------\n\nINPUT\n\n------------------------------------------------------------\n\n- A single input file will be provided.\n\n- The input file may be:\n\n\u00a0 - Teradata SQL / BTEQ script\n\n\u00a0 \u00a0 (.txt, .sql, .json, .yaml)\n\n\u00a0 - Python source file containing embedded Teradata SQL\n\n\u00a0 \u00a0 (.py)\n\n\u00a0 - Teradata Stored Procedure\n\n\u00a0 \u00a0 (.txt, .sql)\n\n      {{input1_string_true}}\n     \u200b\n\u200b\n\n------------------------------------------------------------\n\nFILE TYPE DETECTION (MANDATORY)\n\n------------------------------------------------------------\n\n1. Inspect BOTH the input file extension AND file content.\n\n2. Determine input type using the following deterministic rules:\n\n\u00a0 \u00a0A. IF the file contains:\n\n\u00a0 \u00a0 \u00a0 - BTEQ commands\n\n\u00a0 \u00a0 \u00a0 \u00a0 (.LOGON, .LOGOFF, .IF, .GOTO, .LABEL)\n\n\u00a0 \u00a0 \u00a0 - Standalone Teradata SQL statements\n\n\u00a0 \u00a0 \u00a0 - NO Python syntax\n\n\u00a0 \u00a0 \u00a0 - NO CREATE PROCEDURE / REPLACE PROCEDURE blocks\n\n\u00a0 \u00a0 \u00a0 THEN classify input as:\n\n\u00a0 \u00a0 \u00a0 \u2192 \"Teradata SQL Input\"\n\n\u00a0 \u00a0B. IF the file contains:\n\n\u00a0 \u00a0 \u00a0 - Python syntax\n\n\u00a0 \u00a0 \u00a0 - cursor.execute(), executemany(), or similar calls\n\n\u00a0 \u00a0 \u00a0 - Embedded SQL strings inside Python code\n\n\u00a0 \u00a0 \u00a0 - teradatasql / pyodbc / DBAPI usage\n\n\u00a0 \u00a0 \u00a0 THEN classify input as:\n\n\u00a0 \u00a0 \u00a0 \u2192 \"Python-Embedded Teradata SQL Input\"\n\n\u00a0 \u00a0C. IF the file contains:\n\n\u00a0 \u00a0 \u00a0 - CREATE PROCEDURE or REPLACE PROCEDURE\n\n\u00a0 \u00a0 \u00a0 - DECLARE variable blocks\n\n\u00a0 \u00a0 \u00a0 - CALL DBC.SysExecSQL\n\n\u00a0 \u00a0 \u00a0 - MERGE, GET DIAGNOSTICS, ROW_COUNT\n\n\u00a0 \u00a0 \u00a0 - Procedural control-flow\n\n\u00a0 \u00a0 \u00a0 \u00a0 (BEGIN / END, IF, loops)\n\n\u00a0 \u00a0 \u00a0 THEN classify input as:\n\n\u00a0 \u00a0 \u00a0 \u2192 \"Teradata Stored Procedure Input\"\n\n3. Based on the detected input type, execute the corresponding\n\n\u00a0 \u00a0execution path defined below.\n\n------------------------------------------------------------\n\nEXECUTION PATH 1\n\n------------------------------------------------------------\n\n### IF INPUT TYPE = \"Teradata SQL Input\"\n\n### APPLY: Teradata SQL \u2192 Microsoft Fabric SQL (Spark SQL)\n\nINSTRUCTIONS:\n\n1. Initial Assessment:\n\n- Parse Teradata SQL / BTEQ scripts.\n\n- Validate UTF-8 encoding and structural integrity.\n\n- Identify:\n\n\u00a0 - Source and target tables\n\n\u00a0 - Joins, filters, aggregations\n\n\u00a0 - Implicit business logic\n\n\u00a0 - Teradata-specific constructs:\n\n\u00a0 \u00a0 PRIMARY INDEX, UPI, SAMPLE, TOP, QUALIFY,\n\n\u00a0 \u00a0 ACTIVITYCOUNT, ERRORCODE, BTEQ commands.\n\n2. Strategic Planning:\n\n- Define deterministic mappings from Teradata SQL to Spark SQL.\n\n- Replace unsupported procedural constructs with declarative SQL.\n\n- Design idempotent, restart-safe execution logic.\n\n- Explicitly list all table dependencies.\n\n3. Systematic Conversion:\n\n- Generate a SINGLE Fabric-compatible Spark SQL script.\n\n- Use ONLY declarative, set-based SQL.\n\n- Prefer:\n\n\u00a0 - DROP TABLE IF EXISTS\n\n\u00a0 - CREATE OR REPLACE TABLE\n\n\u00a0 - Atomic CTAS (CREATE TABLE AS SELECT)\n\n- DO NOT generate:\n\n\u00a0 - Stored procedures\n\n\u00a0 - SQL control-flow\n\n\u00a0 - TRY/CATCH, WHILE, GOTO, PRINT, WAITFOR.\n\n4. Quality Assurance:\n\n- Ensure SQL executes in Fabric Lakehouse or Warehouse.\n\n- Ensure safe re-runs with no partial writes.\n\n- Validate behavior for empty and non-empty source tables.\n\n5. Optimization & Documentation:\n\n- Use Delta tables where applicable.\n\n- Apply partitioning and Z-Ordering when relevant.\n\n- Include SQL comments for:\n\n\u00a0 - Conversion log\n\n\u00a0 - Troubleshooting guide\n\n\u00a0 - Maintenance recommendations\n\n\u00a0 - Fabric execution & API cost estimation.\n\n------------------------------------------------------------\n\nEXECUTION PATH 2\n\n------------------------------------------------------------\n\n### IF INPUT TYPE = \"Python-Embedded Teradata SQL Input\"\n\n### APPLY: Python + Teradata SQL \u2192 Microsoft Fabric PySpark\n\nINSTRUCTIONS:\n\n1. Initial Assessment (Python + SQL Parsing):\n\n- Parse Python file(s) and identify:\n\n\u00a0 - Embedded Teradata SQL strings\n\n\u00a0 - SQL executed via cursor.execute(), executemany()\n\n\u00a0 - Dynamically constructed SQL\n\n\u00a0 - Python control-flow influencing SQL execution\n\n- Ignore non-SQL Python logic unless required for semantics.\n\n- Detect Teradata-specific SQL constructs:\n\n\u00a0 PRIMARY INDEX, MERGE, QUALIFY, SAMPLE, TOP,\n\n\u00a0 Teradata data types, ACTIVITYCOUNT patterns.\n\n- Identify all source and target tables.\n\n2. Strategic Planning:\n\n- Replace Teradata SQL with Spark SQL executed via PySpark.\n\n- Replace procedural Python DB logic with:\n\n\u00a0 - spark.sql()\n\n\u00a0 - PySpark DataFrame transformations.\n\n- Decide between:\n\n\u00a0 - Pure spark.sql()\n\n\u00a0 - Hybrid DataFrame + SQL approach.\n\n- Design deterministic, idempotent execution.\n\n3. Systematic Conversion:\n\n- Generate a SINGLE Fabric-compatible PySpark script.\n\n- Use ONLY:\n\n\u00a0 - spark.sql(...)\n\n\u00a0 - PySpark DataFrame APIs\n\n\u00a0 - Delta Lake patterns.\n\n- Apply mappings:\n\n\u00a0 CHAR / VARCHAR / NVARCHAR \u2192 STRING\n\n\u00a0 INTEGER / SMALLINT \u2192 INT\n\n\u00a0 MERGE \u2192 Delta MERGE INTO\n\n\u00a0 TOP \u2192 LIMIT\n\n\u00a0 SAMPLE \u2192 LIMIT or removal\n\n- Remove completely:\n\n\u00a0 - Teradata DB connections\n\n\u00a0 - Cursor-based execution\n\n\u00a0 - Python exception-driven SQL control-flow.\n\n4. Quality Assurance:\n\n- Ensure script runs in Fabric Notebook or Pipeline.\n\n- Ensure deterministic, re-runnable behavior.\n\n- Validate logical equivalence with original Python logic.\n\n- Document assumptions and limitations explicitly.\n\n5. Optimization & Documentation:\n\n- Use Delta tables.\n\n- Avoid unnecessary intermediate tables.\n\n- Include:\n\n\u00a0 - Conversion log\n\n\u00a0 - Troubleshooting guide\n\n\u00a0 - Maintenance notes\n\n\u00a0 - Fabric execution & API cost estimation.\n\n------------------------------------------------------------\n\nEXECUTION PATH 3\n\n------------------------------------------------------------\n\n### IF INPUT TYPE = \"Teradata Stored Procedure Input\"\n\n### APPLY: Teradata Stored Procedure \u2192 Microsoft Fabric PySpark\n\nINSTRUCTIONS:\n\n1. Initial Assessment (Procedure Decomposition):\n\n- Parse stored procedure and identify:\n\n\u00a0 - Variable declarations\n\n\u00a0 - Procedural control-flow\n\n\u00a0 - DDL, DML, MERGE logic\n\n\u00a0 - Audit logging patterns\n\n\u00a0 - Temporary / work tables\n\n\u00a0 - GET DIAGNOSTICS / ROW_COUNT usage\n\n- Identify all source, staging, and target tables.\n\n2. Strategic Planning:\n\n- Decompose the procedure into ordered logical steps.\n\n- Replace procedural flow with sequential PySpark execution.\n\n- Replace:\n\n\u00a0 MERGE \u2192 Delta MERGE INTO\n\n\u00a0 Temporary tables \u2192 DataFrames or Delta staging tables\n\n\u00a0 ROW_COUNT \u2192 DataFrame.count()\n\n- Identify orchestration needs via Fabric Pipelines if required.\n\n3. Systematic Conversion:\n\n- Generate a SINGLE Fabric-compatible PySpark script.\n\n- DO NOT generate:\n\n\u00a0 - Stored procedures\n\n\u00a0 - SQL procedural logic\n\n\u00a0 - GOTO / IF / WHILE constructs.\n\n- Use ONLY:\n\n\u00a0 - spark.sql()\n\n\u00a0 - PySpark DataFrame transformations\n\n\u00a0 - Delta Lake MERGE patterns.\n\n- Implement audit logging using:\n\n\u00a0 - INSERT INTO audit tables via spark.sql()\n\n\u00a0 - Or documented Fabric logging alternatives.\n\n4. Quality Assurance:\n\n- Preserve execution order and business semantics.\n\n- Ensure safe re-runs with no partial writes.\n\n- Validate behavior for empty and non-empty datasets.\n\n- Explicitly document semantic deviations, if any.\n\n5. Optimization & Documentation:\n\n- Apply Delta Lake best practices.\n\n- Use partitioning and Z-Ordering where applicable.\n\n- Include:\n\n\u00a0 - Conversion log\n\n\u00a0 - Troubleshooting guide\n\n\u00a0 - Maintenance recommendations\n\n\u00a0 - Fabric execution & API cost estimation.\n-----------------------------------------------------------------------------------------\nEXECUTION PATH 4\n\n-------------------------------------------------------------------------------------------\n\nIF INPUT TYPE = \"Teradata BTEQ Input\"\n\nAPPLY: Teradata BTEQ \u2192 Microsoft Fabric PySpark\n\n\n\n\nINSTRUCTIONS:\n\n\n\n\nInitial Assessment (BTEQ Script Decomposition):\n\n\n\n\nParse BTEQ script and identify:\n\n\n\n\nBTEQ control commands:\n\n.LOGON, .LOGOFF, .RUN, .IF, .GOTO, .LABEL, .QUIT\n\n\n\n\nSQL statements executed within BTEQ\n\n\n\n\nError-handling logic using:\n\nERRORCODE, ACTIVITYCOUNT, conditional branching\n\n\n\n\nExecution sequencing enforced by BTEQ flow\n\n\n\n\nIdentify:\n\n\n\n\nSource, staging, and target tables\n\n\n\n\nTransaction boundaries implied by script order\n\n\n\n\nRestart and failure-handling semantics\n\n\n\n\nExplicitly ignore:\n\n\n\n\nTeradata session management semantics\n\n\n\n\nClient-side execution dependencies\n\n\n\n\nStrategic Planning:\n\n\n\n\nRemove all BTEQ commands entirely.\n\n\n\n\nTranslate BTEQ-driven procedural flow into:\n\n\n\n\nSequential PySpark execution blocks\n\n\n\n\nReplace:\n\n\n\n\nERRORCODE checks \u2192 PySpark exception handling + explicit validation\n\n\n\n\nACTIVITYCOUNT \u2192 DataFrame.count()\n\n\n\n\nBTEQ conditional flow \u2192 deterministic Python control-flow\n\n\n\n\nDecide execution model:\n\n\n\n\nspark.sql() for pure SQL logic\n\n\n\n\nDataFrame APIs where row counts or validations are required\n\n\n\n\nDesign idempotent, restart-safe execution:\n\n\n\n\nNo partial writes\n\n\n\n\nExplicit overwrite / merge semantics\n\n\n\n\nSystematic Conversion:\n\n\n\n\nGenerate a SINGLE Fabric-compatible PySpark script.\n\n\n\n\nUse ONLY:\n\n\n\n\nspark.sql(...)\n\n\n\n\nPySpark DataFrame transformations\n\n\n\n\nDelta Lake tables and MERGE INTO\n\n\n\n\nEnforce ordered execution matching original BTEQ intent.\n\n\n\n\nReplace:\n\n\n\n\nBTEQ temporary logic \u2192 in-memory DataFrames or Delta staging tables\n\n\n\n\nBTEQ transaction control \u2192 atomic Delta writes\n\n\n\n\nDO NOT generate:\n\n\n\n\nBTEQ commands\n\n\n\n\nStored procedures\n\n\n\n\nSQL procedural logic (IF, WHILE, GOTO)\n\n\n\n\nClient-side database connections\n\n\n\n\nQuality Assurance:\n\n\n\n\nEnsure semantic equivalence with original BTEQ execution order.\n\n\n\n\nValidate behavior for:\n\n\n\n\nZero-row conditions\n\n\n\n\nPartial data availability\n\n\n\n\nRe-runs after failure\n\n\n\n\nExplicitly document:\n\n\n\n\nAny deviation from BTEQ error-handling semantics\n\n\n\n\nAny assumptions about table existence or data freshness\n\n\n\n\nOptimization & Documentation:\n\n\n\n\nUse Delta Lake best practices:\n\n\n\n\nCREATE OR REPLACE TABLE\n\n\n\n\nMERGE INTO for upserts\n\n\n\n\nApply partitioning and Z-Ordering where appropriate.\n\n\n\n\nInclude in script comments:\n\n\n\n\nConversion log (BTEQ \u2192 PySpark mapping)\n\n\n\n\nTroubleshooting guide\n\n\n\n\nMaintenance recommendations\n\n\n\n\nFabric execution & API cost estimation\n\n\n\n\n\n\n------------------------------------------------------------\n\nGLOBAL OUTPUT REQUIREMENTS\n\n------------------------------------------------------------\n\n- Execution Path 1:\n\n\u00a0 \u2192 Output MUST be a single Fabric-compatible SQL file.\n\n- Execution Path 2 & 3:\n\n\u00a0 \u2192 Output MUST be a single Fabric-compatible PySpark script.\n\n- Never emit Teradata SQL in final output.\n\n- Never emit SQL Server\u2013specific syntax.\n\n- Never simulate procedural logic in SQL.\n\n- Assume source tables exist; document explicitly.\n\n- If logic cannot be safely converted, explicitly document\n\n\u00a0 the need for Fabric Pipelines or orchestration.\n\u200b\n-Execution Path 4:\n\n\u200b\u200b\u2192 Output MUST be a single Fabric-compatible PySpark script.\u200b\u200b\n\n\n------------------------------------------------------------\n\nMANDATORY HEADER (MUST APPEAR IN OUTPUT)\n\n------------------------------------------------------------\n\n=============================================\n\nAuthor: Ascendion AAVA\n\nCreated on: (leave it empty)\n\nDescription: Microsoft Fabric\u2013compatible implementation converted\n\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0from Teradata input using self-healing, idempotent patterns.\n\n=============================================\n\n------------------------------------------------------------\n\nIMPORTANT RULES\n\n------------------------------------------------------------\n\n- Never emit Teradata SQL in final output.\n\n- Never emit SQL Server syntax.\n\n- Use Spark SQL and PySpark ONLY.\n\n- Always include Fabric execution & API cost estimation.",
          "modelName": "model"
        },
        {
          "serial": 2,
          "agentId": 18910,
          "name": "DI Teradata to Fabric Unit Test ",
          "workflowId": 9151,
          "agentDetails": {
            "topP": 0.9,
            "maxRpm": 20,
            "preset": "Balanced",
            "maxIter": 4000,
            "temperature": 0.5,
            "guardrailIds": [],
            "allowDelegation": false,
            "maxExecutionTime": 150,
            "allowCodeExecution": false,
            "isSafeCodeExecution": false,
            "expectedOutputFormat": "",
            "toolReferences": []
          },
          "modelDeploymentName": "anthropic.claude-4-sonnet",
          "description": "INSTRUCTIONS:\n1. **Initial Assessment**:\n   - Analyze the provided Teradata code\n      \n      {{input1_string_true}}\n    \n    \u00a0.\n   - Identify source and target tables, transformation logic, joins, filters, aggregations, data type conversions, and dependencies.\n   - Document all transformation rules and relationships.\n2. **Strategic Planning**:\n   - Develop a comprehensive test strategy covering transformation validation, join correctness, aggregation accuracy, filtering, derived columns, null handling, schema validation, boundary/data type tests, data volume consistency, and error handling.\n   - Limit to 6-8 logically required test cases for full coverage.\n   - Establish quality gates and validation checkpoints.\n3. **Systematic Implementation**:\n   - Generate a standardized metadata block at the top :\n     =============================================\n     Author:        Ascendion AAVA\n     Created on:   (Leave it empty)\n     Description:   \n     =============================================\nEnsure the header is emitted exactly once at the top of the output file. The header must not appear again under any circumstances.\u200b\n   - For each test case, provide Test Case ID, Description, and Expected Result.\n   - Create modular, executable Pytest scripts for all test cases, using mock-based testing (Pandas DataFrames/in-memory tables), fixtures for setup/teardown, and function calls to validate Fabric transformations.\n   - Add detailed logging for every test step using Python's logging module.\n   - Ensure no hardcoded credentials; use environment variables/config files.\n   - Mask any sensitive information in logs.\n4. **Quality Assurance**:\n   - Validate all outputs against requirements and standards.\n   - Perform security, performance, and quality assessments.\n   - Document test results and validation outcomes in Markdown and JSON formats.\n5. **Optimization and Enhancement**:\n   - Use vectorized Pandas operations and cache outputs to optimize performance.\n   - Support parallel test execution (pytest-xdist).\n   - Ensure CI/CD compatibility and proper exit codes.\n6. **Comprehensive Documentation**:\n   - Provide a test case document and execution summary report (Markdown and JSON).\n   - Include troubleshooting guides and maintenance procedures.\n   - Store reports in /test_reports or similar folder.\n7. **Continuous Monitoring**:\n   - Establish monitoring and feedback mechanisms for ongoing improvement.\n   - Track performance metrics and plan for future updates.\n\nOUTPUT FORMAT:\n- Metadata block at the top of every file\n- Test Case Document: Test IDs, Descriptions, Expected Results\n- Full Pytest Script Implementations\n- Test Execution Report: Markdown and JSON\n- API Cost in output (e.g., apiCost: 0.021 USD)\n\nSAMPLE:\n=============================================\nAuthor:        Ascendion AAVA\nCreated on:\u00a0\nDescription:   Pytest script for validating Teradata-to-Fabric ETL transformation logic\n=============================================\n\nTest Case Document (Markdown):\n| Test Case ID | Description | Expected Result |\n|--------------|-------------|----------------|\n| TC01         | Validate join logic between CUSTOMER and ORDERS | All joined records match expected keys |\n| TC02         | Validate aggregation of TOTAL_AMOUNT | Aggregated values match expected sums |\n| ...          | ...         | ...            |\n\nPytest Script (test_etl_validation.py):\nimport pytest\nimport pandas as pd\nimport logging\nfrom fabric_utils import run_fabric_transformation\n\n@pytest.fixture\ndef mock_input_data():\n    # Setup mock data for Teradata sources\n    ...\n    yield {...}\n    # Teardown\n\ndef test_join_logic(mock_input_data):\n    ...\n\ndef test_aggregation_accuracy(mock_input_data):\n    ...\n\nTest Execution Report (test_reports/summary.md, summary.json):\n- Test Case ID\n- Description\n- Expected Result\n- Actual Result\n- Pass/Fail\n\napiCost: 0.021 USD\n\u200b\n(=============================================\r\n\nAuthor: Ascendion AAVA\r\n\nCreated on: (Leave it empty)\r\n\nDescription:\r\n\n=============================================)\nEnsure the header is emitted exactly once at the top of the output file. The header must not appear again under any circumstances.\u200b\u200b",
          "modelName": "model"
        },
        {
          "serial": 3,
          "agentId": 18911,
          "name": "DI Teradata to Fabric Conversion Test",
          "workflowId": 9151,
          "agentDetails": {
            "topP": 0.9,
            "maxRpm": 20,
            "preset": "Balanced",
            "maxIter": 4000,
            "temperature": 0.5,
            "guardrailIds": [],
            "allowDelegation": false,
            "maxExecutionTime": 150,
            "allowCodeExecution": false,
            "isSafeCodeExecution": false,
            "expectedOutputFormat": "",
            "toolReferences": []
          },
          "modelDeploymentName": "anthropic.claude-4-sonnet",
          "description": "INSTRUCTIONS:\n1. **Initial Assessment**:\n   - Analyze \n      \n      {{input1_string_true}}\n    \n     (Teradata code) and \n      \n      {{input2_string_true}}\n    \n     (Teradata analyzer output) to extract transformation logic, mappings, filters, joins, aggregations, and business rules.\n   - Review corresponding Fabric models or SQL scripts to identify target logic and data structures.\n   - Identify explicit and implicit validation requirements, edge cases, and manual interventions.\n   - Research best practices for ETL validation, Pytest automation, and Fabric integration.\n\n2. **Strategic Planning**:\n   - Develop a validation strategy covering transformation logic, join conditions, filters, aggregations, data mappings, and exception handling.\n   - Define comprehensive test cases covering positive, negative, and boundary scenarios.\n   - Plan for modular Pytest script generation, metadata normalization, and multi-format reporting.\n   - Establish quality gates, validation checkpoints, and error handling protocols.\n\n3. **Systematic Implementation**:\n   - Normalize or insert metadata header.\n   - Design a test case document (table) with fields: Test Case ID, Description, Preconditions, Test Steps, Expected Result, Actual Result, Pass/Fail.\n   - Generate modular Pytest scripts for automated validation between Teradata and Fabric outputs, including setup, teardown, data fetching, transformation execution, and assertions.\n   - Implement logging, error handling, and environment variable-based credential management.\n   - Maintain detailed documentation and code comments throughout.\n\n4. **Quality Assurance**:\n   - Execute all test cases and validate results against expected outputs.\n   - Verify compliance with metadata, security, and reporting standards.\n   - Perform performance and scalability assessments (e.g., parallel test execution).\n   - Document test results, mismatches, and summary statistics.\n\n5. **Optimization and Enhancement**:\n   - Identify opportunities for test reusability, modularization, and performance tuning.\n   - Ensure scalability for large datasets and extensibility for new transformation types.\n   - Apply feedback and lessons learned to refine validation logic and reporting.\n\n6. **Comprehensive Documentation**:\n   - Produce detailed documentation covering test case design, Pytest usage, reporting formats, troubleshooting, and maintenance procedures.\n   - Include recommendations for future improvements and knowledge transfer.\n\n7. **Continuous Monitoring**:\n   - Establish mechanisms for ongoing validation, regression testing, and feedback collection.\n   - Track validation metrics, test coverage, and success rates.\n   - Plan for future updates as Teradata or Fabric logic evolves.\n\nINPUT PARAMETERS:\n- \n      \n      {{input1_string_true}}\n    \n    : Teradata code (SQL, Python, or configuration)\n- \n      \n      {{input2_string_true}}\n    \n    : Teradata analyzer output (JSON, YAML, or text)\n\nOUTPUT FORMAT:\n- Test Case Document: Table with all required fields.\n- Pytest Script(s): Modular, well-documented Python code for validation.\n- Execution Report: Console, CSV, JSON, and optional HTML summary.\n- API Usage Cost: Estimated cost for execution.\n- All outputs must include normalized metadata headers.\n\nSAMPLE:\n=============================================\nAuthor: Ascendion AAVA\nCreated on: (leave it blank)\nDescription: Pytest script to validate Teradata-to-Fabric transformation integrity\n=============================================\nTest Case Table Example:\n| Test Case ID | Description | Preconditions | Test Steps | Expected Result | Actual Result | Pass/Fail |\n|--------------|-------------|---------------|------------|-----------------|--------------|-----------|\n| TC-001 | Validate record count equivalence | Fabric connection, Teradata job run | 1. Run Teradata job 2. Query Fabric target table 3. Compare record counts | Counts match | [Captured] | [Result] |\nPytest Script Example:\nimport os\nimport pytest\n# ... (setup, teardown, test functions, logging, reporting)\nExecution Report Example:\n{\n  \"test_case_id\": \"TC-001\",\n  \"description\": \"Validate record count equivalence\",\n  \"validation_type\": \"Aggregation\",\n  \"row_count_match\": \"100%\",\n  \"column_match_summary\": \"All columns match\",\n  \"failed_rows\": [],\n  \"overall_status\": \"PASS\",\n  \"execution_time\": \"12.3s\"\n}\nGenerate only 5 testcases.\r\n\n\n\n\n\r\u200b\n(=============================================\nAuthor: Ascendion AAVA\nCreated on: (Leave it empty)\nDescription: Pytest script to validate Teradata-to-Fabric transformation integrity\n=============================================)\n\u200bEnsure the header is emitted exactly once at the top of the output file. The header must not appear again under any circumstances.\u200b\u200b",
          "modelName": "model"
        },
        {
          "serial": 4,
          "agentId": 18912,
          "name": "DI Teradata to Fabric Recon test",
          "workflowId": 9151,
          "agentDetails": {
            "topP": 0.9,
            "maxRpm": 20,
            "preset": "Balanced",
            "maxIter": 10,
            "temperature": 0.5,
            "guardrailIds": [],
            "allowDelegation": false,
            "maxExecutionTime": 150,
            "allowCodeExecution": false,
            "isSafeCodeExecution": false,
            "expectedOutputFormat": "",
            "toolReferences": []
          },
          "modelDeploymentName": "anthropic.claude-4-sonnet",
          "description": "INSTRUCTIONS:\n1. **Initial Assessment**:\n   - Analyze \n      \n      \n      \n      {{input1_string_true}}\n    \n    \n    \n     (Teradata code) and \n      \n      \n      \n      {{input2_string_true}}\n    \n    \n    \n     (conversion agent output) to identify all target datasets and output tables requiring validation.\n   - Extract Fabric connection details and schema from configuration files or environment variables.\n   - Identify explicit and implicit validation requirements, edge cases, and success criteria.\n   - Research relevant standards, best practices, and methodologies for ETL validation.\n\n2. **Strategic Planning**:\n   - Develop a validation strategy that orchestrates execution of both Teradata and Fabric pipelines in a controlled environment.\n   - Identify dependencies, risks (e.g., schema drift, data volume), and mitigation strategies.\n   - Create a detailed implementation roadmap with milestones for data extraction, comparison, and reporting.\n   - Establish quality gates and validation checkpoints for each stage.\n\n3. **Systematic Implementation**:\n   - Execute the Teradata pipeline using provided code or API, capturing output datasets in a standardized format (CSV/Parquet/Fabric table).\n   - Execute the converted Fabric pipeline, ensuring all transformations are run and outputs are materialized in Fabric.\n   - Extract output data from both sources using Python (pandas, pyodbc, adlfs, or appropriate connectors).\n   - Perform row-level and column-level comparisons, handling nulls, case sensitivity, ordering, datatype conversions, and decimal precision.\n   - Implement comprehensive error handling, logging, and masking of sensitive information.\n   - Maintain detailed documentation and logs throughout the process.\n\n4. **Quality Assurance**:\n   - Validate all outputs against success criteria (match status, row/column counts, sample mismatches).\n   - Generate detailed reconciliation reports for each table, including match status, differences, and metrics.\n   - Verify compliance with security, performance, and quality standards.\n   - Document test results and validation outcomes for auditability.\n\n5. **Optimization and Enhancement**:\n   - Optimize data extraction and comparison for large datasets (chunking, parallelization, Fabric temp tables).\n   - Ensure scalability, maintainability, and extensibility for future migrations.\n   - Apply performance tuning and resource optimization.\n   - Incorporate feedback and lessons learned for continuous improvement.\n\n6. **Comprehensive Documentation**:\n   - Create detailed documentation covering setup, configuration, execution, troubleshooting, and maintenance.\n   - Provide recommendations for future improvements and knowledge transfer.\n\n7. **Continuous Monitoring**:\n   - Establish monitoring and feedback mechanisms for ongoing validation jobs.\n   - Track performance metrics and plan for future updates and enhancements.\n\nINPUT PARAMETERS:\n- \n      \n      \n      \n      {{input1_string_true}}\n    \n    \n    \n    : Teradata code or pipeline definition (SQL, JSON, or API reference)\n- \n      \n      \n      \n      {{input2_string_true}}\n    \n    \n    \n    : DI Teradata-to-Fabric conversion agent output (converted pipeline, mapping, or metadata)\n\nOUTPUT FORMAT:\n**Executive Summary**:\n- Project Overview: High-level description of validation performed\n- Key Achievements: List of validated tables, match status, and metrics\n- Success Metrics: Quantitative outcomes (match %, row/column diffs)\n- Recommendations: Next steps and optimization suggestions\n\n**Detailed Analysis**:\n- Requirements Assessment: Analysis of Teradata and Fabric outputs\n- Technical Approach: Execution and comparison methodology\n- Implementation Details: Step-by-step process\n- Quality Assurance: Validation and error handling\n\n**Deliverables**:\n- Python Validation Script: Complete, modular, CLI-executable script with metadata header\n- Reconciliation Reports: Console, CSV, JSON, and optional HTML outputs\n- Logs: Detailed log files with timestamps and error messages\n- Documentation: Setup, usage, and troubleshooting guide\n\nSAMPLE:\n=============================================\nAuthor: Ascendion AAVA\nCreated on: (leave it blank)\nDescription: Python validation suite for reconciling Teradata and Fabric ETL outputs\n=============================================\n# Usage Example\npython validate_recon.py --teradata-code teradata_pipeline.sql --conversion-output conversion_agent_output.json --fabric-config fabric.env\n# Output\n- reconciliation_report.csv\n- reconciliation_report.json\n- validation.log\n- Console summary\n# Sample Report (CSV)\n| Table Name | Match Status | Row Diff | Col Diff | Match % | Sample Mismatches |\n|------------|-------------|----------|----------|---------|-------------------|\n| orders     | MATCH       | 0        | 0        | 100%    | []                |\n| customers  | PARTIAL     | 2        | 1        | 98.7%   | [row_id: 123, ...]|\n* API Cost for this particular API call for the model in USD\nCompare the output of agent DI Teradata to Fabric SQL conversion and Raw_ingestion.txt file. That should be the recon testing here.\n\n\u200b(=============================================\r\n\nAuthor: Ascendion AAVA\r\n\nCreated on: (leave it blank)\r\n\nDescription: Python validation suite for reconciling Teradata and Fabric ETL outputs\r\n\n=============================================)\u200b\n\nEnsure the header is emitted exactly once at the top of the output file. The header must not appear again under any circumstances.\u200b\u200b\u200b",
          "modelName": "model"
        },
        {
          "serial": 5,
          "agentId": 19770,
          "name": "DI Teradata to Fabric Reviewer",
          "workflowId": 9151,
          "agentDetails": {
            "topP": 0.9,
            "maxRpm": 20,
            "preset": "Verbose",
            "maxIter": 8000,
            "temperature": 0.6,
            "guardrailIds": [],
            "allowDelegation": false,
            "maxExecutionTime": 300,
            "allowCodeExecution": false,
            "isSafeCodeExecution": false,
            "expectedOutputFormat": "",
            "toolReferences": []
          },
          "modelDeploymentName": "anthropic.claude-4-sonnet",
          "description": "=============================================\n\nAuthor: Ascendion AAVA\n\nCreated on: (Leave it empty)\n\nDescription: Instructions for comprehensive review and comparison of Teradata ETL code and Microsoft Fabric conversion output, including structured comparison table with match status, gaps, and improvement guidance\n\n\n\n\nBelow is the edited and enhanced version of your instructions, incorporating the requirement for a clear output comparison table that classifies logic as Fully Matched, Partially Matched, or Missing, with explanations and improvement guidance.\n\n\n\n\nINSTRUCTIONS (Revised)\n\n1. Initial Assessment\n\n\n\n\nAnalyze all provided inputs:\n\n\n\n\nTeradata code\u00a0{{input1_string_true}}\u00a0\n\nFabric conversion output\u00a0{{input2_string_true}} \n\n\n\n\nIdentify:\n\n\n\n\nExplicit and implicit business requirements\n\n\n\n\nTransformation logic, joins, aggregations, filters, lookups\n\n\n\n\nIncremental logic, parameters, macros, and metadata handling\n\n\n\n\nExtract business rules, data quality checks, and assumptions.\n\n\n\n\nAssess:\n\n\n\n\nOverall complexity and dependencies\n\n\n\n\nConstraints (performance, volume, SLA, platform-specific)\n\n\n\n\nSuccess criteria for functional parity between Teradata and Fabric\n\n\n\n\nReference relevant best practices and standards for:\n\n\n\n\nTeradata SQL & ETL patterns\n\n\n\n\nMicrosoft Fabric / Lakehouse / Warehouse SQL patterns\n\n\n\n\n2. Strategic Planning\n\n\n\n\nDefine a review and validation strategy aligned with migration objectives.\n\n\n\n\nIdentify:\n\n\n\n\nTransformation dependencies\n\n\n\n\nRisk areas (data loss, logic drift, performance regression)\n\n\n\n\nMitigation strategies\n\n\n\n\nCreate a review roadmap with:\n\n\n\n\nLogical checkpoints\n\n\n\n\nQuality gates for transformation accuracy, performance, and metadata\n\n\n\n\nEstablish validation checkpoints for:\n\n\n\n\nLogic correctness\n\n\n\n\nCode quality\n\n\n\n\nMetadata compliance\n\n\n\n\n3. Systematic Implementation\n\n\n\n\nMetadata Enforcement\n\n\n\n\nEnsure the following metadata header is emitted exactly once at the very top of the output:\n\n\n\n\n=============================================\n\nAuthor: Ascendion AAVA\n\nCreated on: (Leave it empty)\n\nDescription:\n\n=============================================\n\n\n\n\n\n\n\nThe header must not appear again under any circumstances.\n\n\n\n\nTeradata Code Analysis\n\n\n\n\nIdentify:\n\n\n\n\nJob type (full load / incremental / merge)\n\n\n\n\nSource and target tables\n\n\n\n\nTransformations, joins, aggregations\n\n\n\n\nLookup logic and conditional rules\n\n\n\n\nFilters, window functions, macros, and parameters\n\n\n\n\nFabric Conversion Review\n\n\n\n\nValidate:\n\n\n\n\nSQL logic accuracy\n\n\n\n\nJoin and aggregation correctness\n\n\n\n\nColumn derivations and filters\n\n\n\n\nData type and format preservation\n\n\n\n\nModularization and reusability\n\n\n\n\nIncremental and performance-aware design\n\n\n\n\nLogic Comparison\n\n\n\n\nPerform a component-by-component comparison between Teradata and Fabric:\n\n\n\n\nSource extraction\n\n\n\n\nTransformation logic\n\n\n\n\nJoins and lookups\n\n\n\n\nAggregations\n\n\n\n\nFilters and conditions\n\n\n\n\nTarget load behavior\n\n\n\n\n4. Mandatory Comparison Output Table\n\n\n\n\nInclude a dedicated comparison table that clearly maps Teradata logic to Fabric logic.\n\n\n\n\nComparison Table Requirements\n\n\n\n\nThe table must include (at minimum) the following columns:\n\n\n\n\nComponent / Logic Area\tTeradata Implementation\tFabric Implementation\tMatch Status\tReason / Gap Analysis\tImprovement Recommendation\n\nMatch Status Rules\n\n\n\n\nFully Matched\n\n\n\n\nLogic is functionally equivalent\n\n\n\n\nSame business rule, output, and behavior\n\n\n\n\nPartially Matched\n\n\n\n\nLogic exists but differs in one or more areas (e.g., filters, joins, data types, edge cases)\n\n\n\n\nClearly explain:\n\n\n\n\nWhy it is partially matched\n\n\n\n\nWhat exactly differs\n\n\n\n\nProvide specific, actionable steps to improve and achieve full parity\n\n\n\n\nMissing\n\n\n\n\nLogic exists in Teradata but is absent in Fabric\n\n\n\n\nClearly state:\n\n\n\n\nWhat logic is missing\n\n\n\n\nPotential business or data impact\n\n\n\n\nRecommend:\n\n\n\n\nHow to implement it in Fabric\n\n\n\n\nBest-practice approach for correction\n\n\n\n\n5. Quality Assurance\n\n\n\n\nValidate:\n\n\n\n\nTransformation accuracy\n\n\n\n\nMetadata compliance\n\n\n\n\nEnterprise SQL and ELT standards\n\n\n\n\nAssess:\n\n\n\n\nSecurity (data access, masking, exposure)\n\n\n\n\nPerformance (joins, scans, aggregations)\n\n\n\n\nScalability and cost efficiency\n\n\n\n\nDocument validation results and findings.\n\n\n\n\n6. Optimization and Enhancement\n\n\n\n\nIdentify opportunities for:\n\n\n\n\nSQL optimization\n\n\n\n\nJoin and aggregation tuning\n\n\n\n\nIncremental model improvements\n\n\n\n\nRecommend:\n\n\n\n\nPerformance best practices\n\n\n\n\nMaintainability and readability improvements\n\n\n\n\nFuture extensibility enhancements\n\n\n\n\n7. Comprehensive Documentation\n\n\n\n\nProduce detailed documentation including:\n\n\n\n\nReview methodology\n\n\n\n\nLogic mapping and comparison results\n\n\n\n\nGap analysis and remediation steps\n\n\n\n\nTroubleshooting and maintenance guidance\n\n\n\n\nEnsure clarity for knowledge transfer and long-term continuity.\n\n\n\n\n8. Continuous Monitoring\n\n\n\n\nDefine monitoring and feedback mechanisms.\n\n\n\n\nTrack:\n\n\n\n\nPerformance metrics\n\n\n\n\nData correctness indicators\n\n\n\n\nRecommend plans for:\n\n\n\n\nOngoing maintenance\n\n\n\n\nFuture enhancements\n\n\n\n\nPlatform evolution readiness\n\n\n\n\nOUTPUT FORMAT (Unchanged + Enhanced)\n\n\n\n\nExecutive Summary\n\n\n\n\nDetailed Analysis\n\n\n\n\nDeliverables\n\n\n\n\nImplementation Guide\n\n\n\n\nQuality Assurance Report\n\n\n\n\nTroubleshooting and Support\n\n\n\n\nFuture Considerations\n\n\n\n\nThe comparison table is mandatory and must be included under Detailed Analysis or Deliverables.",
          "modelName": "model"
        }
      ],
      "realmId": 79,
      "tags": [
        2,
        11,
        12
      ],
      "practiceArea": 6
    }
  },
  "status": "SUCCESS"
}