{
  "data": {
    "message": "Workflow with agents retrieved successfully",
    "workFlowDetail": {
      "id": 1836,
      "name": "DI ECL Documentation and Analyse JSON WF",
      "description": "ECL to JavaSpark Documentation, Analyse and plan (JSON) WF",
      "createdBy": "elansuriyaa.p@ascendion.com",
      "modifiedBy": "elansuriyaa.p@ascendion.com",
      "approvedBy": "elansuriyaa.p@ascendion.com",
      "createdAt": "2025-11-05T10:36:56.576781",
      "modifiedAt": "2025-12-03T15:03:31.224436",
      "approvedAt": "2025-11-05T10:36:57.789978",
      "status": "APPROVED",
      "isDeleted": false,
      "parentId": -1,
      "workflowConfigs": {
        "managerLlm": [
          {}
        ],
        "enableAgenticMemory": false
      },
      "workflowAgents": [
        {
          "serial": 1,
          "agentId": 3459,
          "name": "DI ECL Documentation JSON",
          "workflowId": 1836,
          "agentDetails": {
            "topP": 0.94,
            "maxRpm": null,
            "levelId": 154,
            "maxIter": null,
            "toolRef": [],
            "maxToken": "4000",
            "isVerbose": true,
            "temperature": 0.3,
            "allowDelegation": true,
            "maxExecutionTime": 90,
            "allowCodeExecution": false,
            "isSafeCodeExecution": true,
            "toolReferences": []
          },
          "modelDeploymentName": "gpt-4.1",
          "description": "Analyze the provided ECL script to generate detailed, program-specific documentation. The goal is to produce **accurate, readable, and context-rich markdown documentation** for both technical and non-technical stakeholders. Avoid generic language or templates. Base all sections on actual code logic, comments, data structure, and transformation flow. The respective output should be in a proper json format.\n\n## 1. Overview of Program  \n_A 5-line paragraph summarizing the script\u2019s business context, goals, and importance._  \nThen, provide a program-specific description explaining:\n- The purpose of the ECL script in its business context\n- What business problems it addresses\n- Which systems it connects to or serves\n- High-level mention of key operations it performs (e.g., arm-level metric rollups from clinical data)\n\n## 2. Code Structure and Design  \n[5-line intro]\n[Detailed paragraph explaining how the code is structured, key ECL elements used (e.g., specific RECORD definitions), and reusable logic.]\n\n## 3. Data Flow and Processing Logic  \n_A 5-line summary about tracing data from input to output._  \nThen describe:  \n- Every input dataset used (list all explicitly with full names)  \n- The flow of data: from raw inputs, through transformations, joins, filtering, aggregation  \n- Intermediate datasets and their purpose  \n- Conditional logic or branching  \n- Final transformations and output preparation  \n\n## 4. Data Mapping  \n_A 5-line intro on traceability and field-level transparency._  \nThen generate a markdown table with the following headers:  \n| Target Dataset Name | Target Field Name | Source Dataset Name | Source Field Name | Transformation Logic | Business Purpose |\n\n## 5. Performance Optimization Strategies  \n_A 5-line paragraph about performance patterns and tuning._  \nThen write a paragraph (not subheadings) covering:\n- JOIN strategies used and justification\n- Any indexing, filtering, or partitioning applied\n- Parallelism or data locality considerations\n- How script is tuned for large dataset performance\n\n## 6. Technical Elements and Best Practices  \n_A 5-line intro on code quality and maintainability._  \nThen, in paragraph form, describe:\n- What components/modules are used from libraries or external systems\n- Error handling mechanisms (explicit or implicit)\n- How the code follows modularity, naming conventions, and reusability\n- Any logging, recovery, or quality control mechanisms used\n\n## 7. Complexity Analysis  \n[5-line intro]\n[Paragraph with quantitative metrics: actual line count, number of joins, transforms, conditions, and outputs, followed by a complexity score (0\u2013100) with explanation.]\n\nNumber of Lines: Count of total lines in the ECL script.\n\nDatasets Used: Number of datasets imported or created.\n\nJoins Used: Number of JOIN operations and their types (HASH, LOOKUP, ALL, MERGE).\n\nTRANSFORM Functions: Number of TRANSFORMs used throughout the script.\n\nRECORD Definitions: Count of record structures defined for datasets.\n\nOUTPUT Statements: Total number of OUTPUT instructions.\n\nConditional Logic: Count of IF statements, CASE, ASSERT, FAILMESSAGE, and other control logic.\n\nIndexing and Lookups: Number of INDEX and BUILD operations.\n\nFunction Calls: Number of UDFs or MODULE references used.\n\nPerformance Controls: Usage of STREAMED, LOCAL, DISTRIBUTE, PARALLEL blocks.\n\nExternal Dependencies: Number and type of external services, connectors, or module imports.\n\nOverall Complexity Score: A calculated score from 0 to 100 representing code complexity, integration points, and logic density.\n\n## 8. Key Outputs  \n_A 5-line paragraph explaining the role of outputs._  \nThen write a single paragraph (not multiple subheadings) describing:\n- Final output datasets and their structure\n- How these outputs help meet business needs\n- Where outputs are stored or published\n- How outputs are consumed by downstream systems or processes\n- Any monitoring or checks tied to output validity\n\nFINAL OUTPUT:  \nReturn a **detailed markdown json** with the above structure, tailored directly to the provided ECL script. Ensure accuracy, specificity, and readability.\n\n\n\n\n\nMANDATORY REQUIREMENTS:\n\n- Replace generic bullet-point explanations (e.g., \"`JOIN`: Combines datasets...\") with **paragraph-style writeups** tied to actual code behavior.\n- **List all datasets explicitly** (not just \u201cetc.\u201d) with names and purposes.\n- **Verify and state the exact line count** and all relevant complexity metrics.\n- **Avoid boilerplate** statements; every point must refer directly to the logic and structure of the given ECL program.\n- Every section must begin with a **5-line descriptive summary** explaining its value and what readers will learn.\n- All sections must be in **markdown format**, using proper headings (e.g., `## 1. Overview of Program`).\n\nFor ECL scripts, take this ecl file or a text file which has ecl code: ```%1$s```\n\n### Special Rules  \n- Remember there should not be any comments in the output\n- Do not include full paths like `thor::jdh::fda_clinical_trials::aact201403_references_txt`, instead return `references_txt`  \n- Each referenced file/module should be a string inside the list  \n- Ensure values are deduplicated  \n-it should be in proper json format starting with { and ending with } it should not start with ```json or end with ```\n-it should not end with ```\n-the program file name you give should must end with .ecl and file name can have file extension\n-output should be in perfect json format it so that i can directly save in json file no extra character above or below the json code\n\n\n### OUTPUT  \nReturn the parsed results in valid JSON format as described above \u2014 with program names as keys and their corresponding list of unique module or dataset references as values",
          "modelName": "model"
        },
        {
          "serial": 2,
          "agentId": 3464,
          "name": "DI ECL Analyser JSON",
          "workflowId": 1836,
          "agentDetails": {
            "topP": 0.94,
            "maxRpm": null,
            "levelId": 99,
            "maxIter": null,
            "toolRef": [],
            "maxToken": "4000",
            "isVerbose": true,
            "temperature": 0.3,
            "allowDelegation": true,
            "maxExecutionTime": 90,
            "allowCodeExecution": false,
            "isSafeCodeExecution": true,
            "toolReferences": []
          },
          "modelDeploymentName": "gpt-4.1",
          "description": "Parse the provided ECL code to generate a detailed analysis and migration-readiness report.\nIf multiple files are provided, present each file\u2019s analysis in a distinct JSON session.\nEach JSON must include the following structured sections:\n\n\n1. Script Overview:\nProvide a high-level summary of the ECL program\u2019s purpose and its key business objectives.\n\nDescribe the functional modules like DATASET declarations, TRANSFORM logic, PROJECTS, and OUTPUT operations.\n\nBriefly outline the nature of the data pipelines or batch processes orchestrated by the ECL script.\n\n2. Complexity Metrics:\nCount of total lines in the ECL script.\n\nNumber of datasets (via DATASET or IMPORT statements) used.\n\nNumber and types of TRANSFORMs defined.\n\nNumber of JOINs, JOIN KINDS (e.g., INNER, LEFT), and combinatorial joins.\n\nNumber of PROJECT, SORT, DEDUP, ROLLUP operations.\n\nNumber of child workflows or nested MODULE calls.\n\nNumber of OUTPUT and STORE operations.\n\nNumber of conditional logic elements (e.g., IF, CASE, or inline boolean filters).\n\nNumber of inlined or reused MACROs or FUNCTION modules.\n\nConversion Complexity Score:\nAssign a migration complexity score (0\u2013100), based on:\n \nNumber of incompatible features.\n \nNumber of manual refactor points.\n \nWorkflow orchestration challenges.\n \nVolume and nesting of datasets or compound transforms.\n\n3. Feature Compatibility Check:\nIdentify features or constructs in ECL that have no direct Spark equivalent.\n\nHighlight constructs like:\n\nImplicit schema typing.\n\nRecordsets and RECORD structures.\n\nDataset transformations (e.g., PROJECT, ROLLUP, NORMALIZE, DENORMALIZE).\n\nGlobal aggregates (e.g., AGGREGATE with GROUP).\n\n4. Manual Adjustments for Java Spark Migration:\nRecommend how to manually adjust ECL features into Java Spark equivalents:\n\nHow to refactor TRANSFORMs into Spark UDFs.\n\nConverting RECORD structures into case classes or schema definitions.\n\nHandling JOIN logic with complex join conditions.\n\nAddressing NORMALIZE, ROLLUP, DEDUP, and other stateful ops using Spark equivalents.\n\nStrategy to rewrite OUTPUT targets to HDFS, Parquet, or other Spark-supported sinks.\n\n5. Optimization Techniques in Spark:\nSuggest Spark-side optimization strategies:\n\nUse of broadcast joins vs shuffle joins.\n\nPartitioning datasets based on key fields.\n\nCaching and checkpointing strategies.\n\nCode optimization using Catalyst optimizer hints or dataframe API improvements.\n\nRecommendation: Is it better to Refactor with minimal changes or Rebuild the logic for better alignment with Spark? Provide justification.\n\nOutput:\nReturn the parsed results in valid JSON format as described above \u2014 with program names as keys and their corresponding list of unique module or dataset references as values.\n\n### Special Rules  \n- Remember there should not be any comments in the output\n- Do not include full paths like `thor::jdh::fda_clinical_trials::aact201403_references_txt`, instead return `references_txt`  \n- Maintain the original ECL filename as the JSON key  \n- Each referenced file/module should be a string inside the list  \n- Ensure values are deduplicated  \n-it should be in proper json format starting with { and ending with } it should not start with ```json or end with ```\n-it should not end with ```\n-the program file name you give should must end with .ecl and file name can have file extension\n-output should be in perfect json format it so that i can directly save in json file no extra character above or below the json code\n\nInput:\nFor ECL script use the below ecl file(s) or text file which have ecl code:  ```%1$s```  ",
          "modelName": "model"
        },
        {
          "serial": 3,
          "agentId": 3549,
          "name": "DI ECL Plan JSON",
          "workflowId": 1836,
          "agentDetails": {
            "topP": 0.94,
            "maxRpm": null,
            "levelId": 99,
            "maxIter": null,
            "toolRef": [],
            "maxToken": "4000",
            "isVerbose": true,
            "temperature": 0.3,
            "allowDelegation": true,
            "maxExecutionTime": 90,
            "allowCodeExecution": false,
            "isSafeCodeExecution": true,
            "toolReferences": []
          },
          "modelDeploymentName": "gpt-4.1",
          "description": "You are tasked with providing a comprehensive effort and cost estimate for executing and testing Java Spark code that has been converted from ECL scripts. Use the analysis report generated during the ECL code evaluation phase to guide your estimation.\n\nINSTRUCTIONS:\n\n\n\n- Review the previously generated ECL analysis output to:\n  - Identify manually converted constructs (e.g., TRANSFORMs to UDFs, RECORDS to schemas, etc.)\n  - Determine code sections requiring logic validation or functional refactoring.\n  - Focus especially on complex JOINs, PROJECTs, and OUTPUT operations.\n\n- Estimate the effort hours for:\n  - Manual intervention and solutions of complex constructs during ECL to Spark translation.\n  - Data recon and validation testing (e.g., comparing pre- and post-migration outputs, checking intermediate stages).\n  - Syntax Differences.\n  - Optimization Techniques.\n  \n- **Do not** count effort for syntax or formatting-level transformations.\n\n- Estimate the Java Spark runtime cost by:\n  - Calculating resource requirements (e.g., number of executors, executor memory, vCPU usage, shuffle data size).\n  - Mapping execution profiles to cloud infrastructure pricing (e.g., Google Dataproc, AWS EMR, or Spark on Kubernetes).\n  - Considering both temporary and final datasets and their read/write overheads.\n\n- Include the API cost separately.\n\n**IMPORTANT:**  \nThe final output must be a **generic JSON structure** matching the following template format (replace placeholder text with your analysis results):\n\n```json\n{\n  \"1. Cost Estimation\": {\n    \"1.1 Java Spark Runtime Cost\": {\n      \"Cluster Configuration\": {\n        \"Number of Executors\": \"<number>\",\n        \"Executor Memory\": \"<size in GB>\",\n        \"Driver Memory\": \"<size in GB>\"\n      },\n      \"Approximate Data Volume Processed\": {\n        \"Input Data\": \"<estimated size and notes>\",\n        \"Output Data\": \"<estimated size and notes>\"\n      },\n      \"Time Taken for Each Phase\": {\n        \"Shuffle-heavy JOINs\": \"<time duration>\",\n        \"Wide Transforms (e.g., ROLLUP, DENORMALIZE)\": \"<time duration>\",\n        \"Output Writes\": \"<time duration>\"\n      },\n      \"Cost Model\": {\n        \"Pricing Model (e.g., DBU, vCPU Hour)\": \"<pricing description>\",\n        \"Total Runtime Cost\": \"<calculated cost and method>\"\n      },\n      \"Justification\": [\n        \"<reason 1>\",\n        \"<reason 2>\",\n        \"... add more if needed\"\n      ]\n    }\n  },\n  \"2. Code Fixing and Data Recon Testing Effort Estimation\": {\n    \"2.1 Estimated Effort in Hours\": {\n      \"Manual intervention and solutions of complex constructs during ECL to Spark translation\": \"<hours>\",\n      \"Data recon and pipeline testing, including test case creation, validation of intermediate datasets, and output comparison\": \"<hours>\",\n      \"Syntax Differences\": \"<hours>\",\n      \"Optimization Techniques\": \"<hours>\"\n    },\n    \"Major Contributors\": {\n      \"Rewriting nested TRANSFORMs or rollups\": \"<hours>\",\n      \"Refactoring OUTPUT statements for Spark write APIs\": \"<hours>\",\n      \"Managing schema consistency across distributed stages\": \"<hours>\"\n    }\n  },\n  \"3. API Cost\": {\n    \"apiCost\": \"<float in USD>\"\n  }\n}\nINPUT\n\nFor the input ECL analysis report use ecl file or text file which have ecl code the file:\n```%1$s```\n\nFor the Spark environment resource and pricing reference use the file:\n```%2$s```\n\n### Special Rules  \n- Remember there should not be any comments in the output\n- Do not include full paths like `thor::jdh::fda_clinical_trials::aact201403_references_txt`, instead return `references_txt`  \n- Maintain the original ECL filename as the JSON key  \n- Each referenced file/module should be a string inside the list  \n- Ensure values are deduplicated  \n-it should be in proper json format starting with { and ending with } it should not start with ```json or end with ```\n-it should not end with ```\n-the program file name you give should must end with .ecl and file name can have file extension\n-output should be in perfect json format it so that i can directly save in json file no extra character above or below the json code\n\n\n### OUTPUT  \nReturn the parsed results in valid JSON format as described above \u2014 with program names as keys and their corresponding list of unique module or dataset references as values.",
          "modelName": "model"
        }
      ],
      "realmId": 32
    }
  },
  "status": "SUCCESS"
}