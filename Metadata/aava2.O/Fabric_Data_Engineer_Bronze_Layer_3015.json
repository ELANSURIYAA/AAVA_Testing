{
  "data": {
    "message": "Workflow with agents retrieved successfully",
    "workFlowDetail": {
      "id": 3015,
      "name": " Fabric Data Engineer Bronze Layer",
      "description": "DE Pipeline for Bronze Layer",
      "createdBy": "default@ascendion.com",
      "modifiedBy": "default@ascendion.com",
      "approvedBy": "default@ascendion.com",
      "createdAt": "2025-11-05T11:19:31.473692",
      "modifiedAt": "2025-11-30T11:55:00.892060",
      "approvedAt": "2025-11-05T11:19:32.644495",
      "status": "APPROVED",
      "isDeleted": false,
      "parentId": -1,
      "workflowConfigs": {
        "managerLlm": [
          {}
        ],
        "enableAgenticMemory": false
      },
      "workflowAgents": [
        {
          "serial": 1,
          "agentId": 6704,
          "name": "Fabric Bronze DE Pipeline",
          "workflowId": 3015,
          "agentDetails": {
            "topP": 0.94,
            "maxRpm": null,
            "levelId": 99,
            "maxIter": null,
            "toolRef": [],
            "maxToken": "8000",
            "isVerbose": true,
            "temperature": 0.3,
            "allowDelegation": true,
            "maxExecutionTime": 90,
            "allowCodeExecution": false,
            "isSafeCodeExecution": true,
            "toolReferences": []
          },
          "modelDeploymentName": "gpt-4.1",
          "description": "****MASKED****",
          "modelName": "model"
        },
        {
          "serial": 2,
          "agentId": 6442,
          "name": "Fabric Pyspark Unit Test Case",
          "workflowId": 3015,
          "agentDetails": {
            "topP": 0.94,
            "maxRpm": null,
            "levelId": 99,
            "maxIter": null,
            "toolRef": [],
            "maxToken": "8000",
            "isVerbose": true,
            "temperature": 0.3,
            "allowDelegation": true,
            "maxExecutionTime": 90,
            "allowCodeExecution": false,
            "isSafeCodeExecution": true,
            "toolReferences": []
          },
          "modelDeploymentName": "gpt-4.1",
          "description": "You are tasked with creating unit test cases and a Pytest script for the given PySpark code that runs in Microsoft Fabric. Your expertise in PySpark testing methodologies, best practices, and Fabric-specific optimizations will be crucial in ensuring comprehensive test coverage.\n\nInstructions:\n1. Analyze the provided PySpark code to identify:\n* Key data transformations\n* Edge cases (e.g., empty DataFrames, null values, boundary conditions)\n* Error handling scenarios\n2. Design test cases covering:\n* Happy path scenarios\n* Edge cases (handling missing/null values, schema mismatches, etc.)\n* Exception scenarios (invalid data types, incorrect transformations)\n3. Use Microsoft Fabric-compatible PySpark testing techniques, including:\n* SparkSession setup and teardown in Fabric\u2019s distributed environment\n* Mocking external data sources within Fabric\u2019s Lakehouse\n* Performance testing in Fabric\u2019s Spark pools\n* Implement test cases using Pytest and Fabric-compatible PySpark testing utilities.\n* Ensure Fabric SparkSession is properly initialized and closed in test setup/teardown.\n* Use assertions to validate expected DataFrame outputs.\n* Follow PEP 8 coding style and ensure test scripts are well-commented.\n* Group related test cases into logical sections for maintainability.\n* Implement helper functions or fixtures to support Fabric-based Spark testing.\n\nGuideline:\n*Additionally, calculate and include the cost consumed by the API for this call in the output, explicitly mentioning the cost in USD. Don't consider the API cost as input and retrieve the cost of this API. \n*Ensure the cost consumed by the API is reported as a precise floating-point value, without rounding or truncation, until the first non-zero digit appears.\n*If the API returns the same cost across multiple calls, fetch real-time cost data or validate the calculation method.\n*Ensure that cost computation considers different agents and their unique execution parameters.\n*Mention the API Cost after the PySpark code ends.\n\ninput :\nUse the output of the previous agents PySpark code as input",
          "modelName": "model"
        }
      ],
      "realmId": 1
    }
  },
  "status": "SUCCESS"
}