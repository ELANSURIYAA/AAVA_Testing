{
  "data": {
    "message": "Workflow with agents retrieved successfully",
    "workFlowDetail": {
      "id": 5532,
      "name": "DI DB2(AS400) To T-SQL Doc&Analyze",
      "description": "DB2(AS400) DOCUMENTATION: Extracts and documents all DB2 AS/400 database objects, structures, and relationships.  DB2(AS400) to T SQL Analyzer: Analyzes DB2 AS/400 schemas and identifies compatibility, data type mappings, and conversion requirements for T-SQL.  DB2(AS400) to T SQL Plan: Generates a detailed migration strategy and implementation roadmap for converting DB2 AS/400 to SQL Server T-SQL.",
      "createdBy": "nishanth.janarthanan@ascendion.com",
      "modifiedBy": "nishanth.janarthanan@ascendion.com",
      "approvedBy": "muneeswara.pandian@ascendion.com",
      "createdAt": "2025-11-17T08:31:24.001469",
      "modifiedAt": "2025-12-03T15:03:31.224436",
      "approvedAt": "2025-11-28T08:14:07.263527",
      "status": "APPROVED",
      "comments": {
        "whatWentGood": "",
        "whatWentWrong": "",
        "improvements": ""
      },
      "isDeleted": false,
      "parentId": -1,
      "workflowConfigs": {
        "topP": 0.95,
        "maxToken": null,
        "managerLlm": [],
        "temperature": 0.1,
        "enableAgenticMemory": false
      },
      "workflowAgents": [
        {
          "serial": 1,
          "agentId": 8663,
          "name": "DI DB2 AS400 Documentation",
          "workflowId": 5532,
          "agentDetails": {
            "topP": 0.95,
            "maxRpm": 60,
            "preset": "Custom",
            "maxIter": 10,
            "temperature": 0.3,
            "guardrailIds": [],
            "allowDelegation": false,
            "maxExecutionTime": 300,
            "allowCodeExecution": false,
            "isSafeCodeExecution": false,
            "toolReferences": []
          },
          "modelDeploymentName": "gpt-4.1",
          "description": "Header:\r\n\n====================================================\r\n\nAuthor:        AAVA\r\n\nDate:          <leave it blank>\r\n\nDescription:   <one-line description of the purpose>\r\n\n====================================================\r\n\n- Add the header in the top of the output if the input file is already having the header then replace that with the new header\r\n\n1. Overview of Migration Component\r\n\nDescribe the purpose of the Db2 (AS400) to T-SQL migration component, such as schema conversion, data extraction, transformation, loading, or stored procedure translation.\r\n\nExplain the business logic or requirement the component addresses \u2014 for example, modernization of legacy workloads, integration with SQL Server, or enabling analytics compatibility.\r\n\n2. Component Structure and Design\r\n\nDescribe the structure and design of the migration module or workflow.\r\n\nHighlight key components such as:\r\n\n- Source (Db2 AS400 tables, views, files, etc.)\r\n\n- Schema Conversion Scripts (DDL translation)\r\n\n- Data Extraction Logic (SQL queries, unload utilities)\r\n\n- Transformation Layer (mapping rules, staging scripts, validation)\r\n\n- Stored Procedure/Function Conversion (Db2 SQL PL \u2192 T-SQL)\r\n\n- Data Loading Scripts (BCP, BULK INSERT, SSIS, or custom ETL)\r\n\n- Validation Scripts (record counts, checksum, referential integrity)\r\n\n- Error Handling and Logging\r\n\nExplain the flow between extraction, transformation, and loading steps, and the use of configuration files, parameters, or reusable templates.\r\n\n3. Data Flow and Processing Logic\r\n\nList the key source tables, staging/intermediate datasets, and target SQL Server objects.\r\n\nFor each logical step:\r\n\n- Describe what it performs (e.g., column type conversion, constraint recreation, data cleansing).\r\n\n- Mention any SQL scripts or utilities used.\r\n\n- Include any transformation logic or business rules applied during migration.\r\n\n4. Data Mapping (Lineage)\r\n\nMap fields from Db2 source tables to SQL Server target tables in the following format:\r\n\n| Target Table Name | Target Column Name | Source Table Name | Source Column Name | Remarks |\r\n\n|-------------------|--------------------|-------------------|--------------------|----------|\r\n\n| <actual target table/view> | <actual column> | <actual source table/view> | <actual column> | <1:1 Mapping \\| Transformation \\| Validation - include logic description> |\r\n\n5. Transformation Logic\r\n\nDocument each transformation or column mapping applied during migration.\r\n\nExplain what each rule or script does and which fields are involved.\r\n\nNote any reusable templates, UDFs, or migration patterns (e.g., date format conversion, string padding, null handling).\r\n\n6. Complexity Analysis\r\n\nProvide a high-level complexity summary in the following format:\r\n\n| Parameter | Value |\r\n\n|------------|--------|\r\n\n| Number of Tables Migrated | <integer> |\r\n\n| Number of Columns Transformed | <integer> |\r\n\n| Stored Procedures/Functions Converted | <count> |\r\n\n| Joins or Relationships | <list of types or None> |\r\n\n| Reference or Lookup Tables | <count or 'None'> |\r\n\n| Configuration Files/Parameters Used | <count> |\r\n\n| Output Datasets or Target Tables | <integer> |\r\n\n| Conditional Logic or Exception Handling | <count> |\r\n\n| External Dependencies | <APIs, Scripts, Tools, or Libraries> |\r\n\n| Overall Complexity Score | <0\u2013100> |\r\n\n7. Key Outputs\r\n\nDescribe the final migrated components (schemas, tables, views, stored procedures) delivered in SQL Server.\r\n\nMention the format (T-SQL scripts, CSV, BACPAC, etc.) and their intended use (e.g., production deployment, reporting, or further ETL processing).\r\n\nAPI Cost:  \r\n\n* Include the cost consumed by the API for this call in the output.  \r\n\n* Ensure the cost consumed by the API is reported as a floating-point value with currency explicitly mentioned as USD (e.g., apiCost: actual cost).\r\n\nInput:  \r\n\nAttach or provide the Db2 (AS400) to T-SQL migration artifacts such as DDL scripts, schema mapping files, stored procedure conversion outputs, data migration utilities, or validation reports.  \r\n\nAcceptable formats: plain text, zipped folder, or directory path structure: {{DB2_AS400_code}}",
          "modelName": "model"
        },
        {
          "serial": 2,
          "agentId": 8664,
          "name": "DI DB2 AS400 to T SQL Analyzer",
          "workflowId": 5532,
          "agentDetails": {
            "topP": 0.95,
            "maxRpm": 60,
            "preset": "Custom",
            "maxIter": 10,
            "temperature": 0.3,
            "guardrailIds": [],
            "allowDelegation": false,
            "maxExecutionTime": 300,
            "allowCodeExecution": false,
            "isSafeCodeExecution": false,
            "toolReferences": []
          },
          "modelDeploymentName": "gpt-4.1",
          "description": "Header:\r\n\n====================================================\r\n\nAuthor:        AAVA\r\n\nDate:          <leave it blank>\r\n\nDescription:   <one-line description of the purpose>\r\n\n====================================================\r\n\n- Add the header in the top of the output only, if the input file is already having the header then replace that with the new header and Don't repeat the Header again in between the output\r\n\nParse the provided DB2 SQL script to generate a detailed analysis and metrics report. Ensure that if multiple files are given as input, then the analysis for each file is presented as a distinct session. Each session must include:\r\n\n1. Script Overview:\r\n\n\u00a0- Provide a high-level description of the SQL script\u2019s purpose and primary business objectives.\r\n\n2. Complexity Metrics:\r\n\n\u00a0- Number of Lines: Count of lines in the SQL script.\r\n\n\u00a0- Tables Used: Number of tables referenced in the SQL script.\r\n\n\u00a0- Joins: Number of joins and the types of joins used (e.g., INNER JOIN, LEFT JOIN, CROSS JOIN).\r\n\n\u00a0- Temporary Tables: Number of declared global temporary tables and derived tables.\r\n\n\u00a0- Aggregate Functions: Number of aggregate functions, including OLAP/analytical functions.\r\n\n\u00a0- DML Statements: Number of DML statements by type such as SELECT, INSERT, UPDATE, DELETE, CALL, LOCK, LOAD, IMPORT, and EXPORT operations present in the SQL script.\r\n\n\u00a0- Conditional Logic: Number of conditional control flow elements like IF, CASE, GOTO, LABEL, etc.\r\n\n3. Syntax Differences:\r\n\n\u00a0- Identify the number of syntax differences between the DB2 SQL code and the expected T-SQL equivalent.\r\n\n4. Manual Adjustments:\r\n\n\u00a0- Recommend specific manual adjustments for functions and clauses incompatible with T-SQL, including:\r\n\n\u00a0- Function replacements (e.g., DB2-specific functions replaced with T-SQL equivalents).\r\n\n\u00a0- Syntax adjustments for date, string, and window functions.\r\n\n\u00a0- Strategies to rewrite unsupported constructs such as FETCH FIRST N ROWS ONLY or recursive SQL.\r\n\n5. Conversion Complexity:\r\n\n\u00a0- Calculate a complexity score (0\u2013100) based on syntax differences, query logic, and the level of manual adjustments required.\r\n\n\u00a0- Highlight high-complexity areas such as recursive CTEs, OLAP functions, or DB2-specific procedural logic.\r\n\n6. Optimization Techniques:\r\n\n\u00a0- Suggest optimization strategies for T-SQL, such as using parallel execution plans, partitioning, indexing strategies, and rewriting for T-SQL hints.\r\n\n\u00a0- Recommend whether to Refactor the query with minimal changes or Rebuild with significant code changes and optimization.\r\n\n\u00a0- Provide justification for the chosen recommendation (Refactor vs. Rebuild).\r\n\n7. API Cost Calculation:\r\n\n\u00a0- Include the cost consumed by the API for this call in the output.\r\n\n\u00a0- Report the API cost as a floating-point value with currency explicitly mentioned as USD (e.g., apiCost: 0.0382 USD).\r\n\n\u00a0- Ensure that all decimal values are included and accurate to the actual consumption.\r\n\nInput:\r\n\nDB2 file {{DB2_AS400_code}}",
          "modelName": "model"
        },
        {
          "serial": 3,
          "agentId": 8746,
          "name": "DI DB2 AS400 to T SQL Plan",
          "workflowId": 5532,
          "agentDetails": {
            "topP": 0.95,
            "maxRpm": 60,
            "preset": "Custom",
            "maxIter": 10,
            "temperature": 0.3,
            "guardrailIds": [],
            "allowDelegation": false,
            "maxExecutionTime": 300,
            "allowCodeExecution": false,
            "isSafeCodeExecution": false,
            "toolReferences": []
          },
          "modelDeploymentName": "gpt-4.1",
          "description": "Header:\r\n\n=====================================================\r\n\nAuthor:        AAVA\r\n\nDate:          <leave it blank>\r\n\nDescription:   <one-line description of the purpose>\r\n\n=====================================================\r\n\n- Add the header in the top of the output if the input file is already having the header then replace that with the new header\r\n\nYou are tasked with providing a comprehensive effort estimate for testing the T-SQL converted from DB2(AS400) scripts. Follow these instructions to complete the task:\r\n\nINSTRUCTIONS:\r\n\nReview the analysis of the DB2(AS400) script file and identify areas requiring manual intervention when converting to  T-SQL. Pay close attention to procedural logic, data type differences, and use of DB2-specific features.\r\n\nEstimate the effort hours required for:\r\n\nManual code fixes\r\n\nData reconciliation and validation testing effort\r\n\nDo not consider efforts for basic syntax translation, as they will be handled through automated conversion tools.\r\n\na. Factor in the number of queries, data volume processed, and use of base and temporary tables.\r\n\nINPUT:\r\n\n{{DB2_AS400_code}}\r\n\nOUTPUT FORMAT:\r\n\n1. Code Fixing and Data Recon Testing Effort Estimation\r\n\n1.1 Manual Code Fixes and Daat Recon Testing Effort (in hours)",
          "modelName": "model"
        }
      ],
      "realmId": 79,
      "tags": [
        17,
        14,
        12,
        4
      ],
      "practiceArea": 6
    }
  },
  "status": "SUCCESS"
}