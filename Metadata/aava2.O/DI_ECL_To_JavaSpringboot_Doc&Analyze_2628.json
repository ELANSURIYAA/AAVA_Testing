{
  "data": {
    "message": "Workflow with agents retrieved successfully",
    "workFlowDetail": {
      "id": 2628,
      "name": "DI ECL To JavaSpringboot Doc&Analyze",
      "description": "ECL to Java Springboot Documentation, Analysis and plan",
      "createdBy": "muneeswara.pandian@ascendion.com",
      "modifiedBy": "muneeswara.pandian@ascendion.com",
      "approvedBy": "muneeswara.pandian@ascendion.com",
      "createdAt": "2025-11-05T11:09:11.518806",
      "modifiedAt": "2025-12-03T15:03:31.224436",
      "approvedAt": "2025-11-05T11:09:12.573339",
      "status": "APPROVED",
      "isDeleted": false,
      "parentId": -1,
      "workflowConfigs": {
        "managerLlm": [
          {}
        ],
        "enableAgenticMemory": false
      },
      "workflowAgents": [
        {
          "serial": 1,
          "agentId": 7331,
          "name": "DI ECL Documentation",
          "workflowId": 2628,
          "agentDetails": {
            "topP": 0.94,
            "maxRpm": null,
            "levelId": 154,
            "maxIter": null,
            "toolRef": [],
            "maxToken": "4000",
            "isVerbose": true,
            "temperature": 0.3,
            "allowDelegation": true,
            "maxExecutionTime": 90,
            "allowCodeExecution": false,
            "isSafeCodeExecution": true,
            "toolReferences": []
          },
          "modelDeploymentName": "gpt-4.1",
          "description": "** Markdown format**\n**Metadata Requirements:**\n- Add the following metadata at the top of each converted/generated file:\n```\n=============================================\nAuthor:        Ascendion AVA+\nCreated on:   (Leave it empty)\nDescription:   <one-line description of the purpose>\n=============================================\n```\n- If the source code already contains metadata headers, update them to match this format while preserving any relevant description content.\n- For the description, provide a concise summary of what the code does.\n (give this only once in the top of the output)\n\n## 1. Overview of Program  \n_A 5-line paragraph summarizing the script\u2019s business context, goals, and importance._  \nThen, provide a program-specific description explaining:\n- The purpose of the ECL script in its business context\n- What business problems it addresses\n- Which systems it connects to or serves\n- High-level mention of key operations it performs (e.g., arm-level metric rollups from clinical data)\n\n## 2. Code Structure and Design  \n[5-line intro]\n[Detailed paragraph explaining how the code is structured, key ECL elements used (e.g., specific RECORD definitions), and reusable logic.]\n\n## 3. Data Flow and Processing Logic  \n_A 5-line summary about tracing data from input to output._  \nThen describe:  \n- Every input dataset used (list all explicitly with full names)  \n- The flow of data: \nfrom raw inputs, through transformations, joins, filtering, aggregation  \n- for each input file in the inputs give the following individually \n- Intermediate datasets and their purpose  \n- Conditional logic or branching  \n- Final transformations and output preparation  \n(give the - Intermediate datasets and their purpose,  Conditional logic or branching  and Final transformations and output preparation for each input file)\n sample structure:\ninput file name 1:\n- Intermediate datasets and their purpose  \n- Conditional logic or branching  \n- Final transformations and output preparation  \ninput file name 2:\n- Intermediate datasets and their purpose  \n- Conditional logic or branching  \n- Final transformations and output preparation  \nand so on based on the number of input files\n## 4. Data Mapping  \nA 5-line intro on traceability and field-level transparency._  \nThen generate a markdown table with the following headers:  \n| Target Dataset Name | Target Field Name | Source Dataset Name | Source Field Name | Transformation Logic | \n\n## 5. Complexity Analysis  \n[5-line intro]\n[Paragraph with quantitative metrics: actual line count, number of joins, transforms, conditions, and outputs, followed by a complexity score (0\u2013100) with explanation.]\n\nNumber of Lines: Count of total lines in the ECL script.\n\nDatasets Used: Number of datasets imported or created.\n\nJoins Used: Number of JOIN operations and their types (HASH, LOOKUP, ALL, MERGE).\n\nTRANSFORM Functions: Number of TRANSFORMs used throughout the script.\n\nRECORD Definitions: Count of record structures defined for datasets.\n\nOUTPUT Statements: Total number of OUTPUT instructions.\n\nConditional Logic: Count of IF statements, CASE, ASSERT, FAILMESSAGE, and other control logic.\n\nIndexing and Lookups: Number of INDEX and BUILD operations.\n\nFunction Calls: Number of UDFs or MODULE references used.\n\nPerformance Controls: Usage of STREAMED, LOCAL, DISTRIBUTE, PARALLEL blocks.\n\nExternal Dependencies: Number and type of external services, connectors, or module imports.\n\nOverall Complexity Score: A calculated score from 0 to 100 representing code complexity, integration points, and logic density.\n\n## 6. Key Outputs  \n_A 5-line paragraph explaining the role of outputs._  \nThen write a single paragraph (not multiple subheadings) describing:\n- Final output datasets and their structure\n- How these outputs help meet business needs\n- Where outputs are stored or published\n- How outputs are consumed by downstream systems or processes\n- Any monitoring or checks tied to output validity\n\nPoints to Remember:\nRemember the Input may contains one or more Ecl files so give the overall documentation based on all input files\nremember for the data processing logic give the details for all the input files separately \n- input would have one or more files which one file would be master file\n-so try to take all the input ecl files from the input\n\nInput:\nFor ECL scripts, take this ecl file(s) or a text file(s) which has ecl code: ```%1$s```\n\n",
          "modelName": "model"
        },
        {
          "serial": 2,
          "agentId": 7338,
          "name": "DI ECL To JavaSpringboot Analyzer",
          "workflowId": 2628,
          "agentDetails": {
            "topP": 0.94,
            "maxRpm": null,
            "levelId": 99,
            "maxIter": null,
            "toolRef": [],
            "maxToken": "4000",
            "isVerbose": true,
            "temperature": 0.3,
            "allowDelegation": true,
            "maxExecutionTime": 90,
            "allowCodeExecution": false,
            "isSafeCodeExecution": true,
            "toolReferences": []
          },
          "modelDeploymentName": "gpt-4.1",
          "description": "Parse the provided ECL code to generate a detailed analysis and migration-readiness report tailored for Java Spring Boot applications. If multiple files are provided, present each file\u2019s analysis in a distinct session. Each session must include:\n\n1. Complexity Metrics\nTotal line count of the ECL script.\n\nNumber of datasets (via DATASET or IMPORT statements) used.\n\nCount and types of TRANSFORMs defined.\n\nNumber of JOINs, including join kinds (INNER, LEFT, etc.).\n\nCount of PROJECT, SORT, DEDUP, ROLLUP operations.\n\nNumber of nested modules or subgraphs (child workflows).\n\nCount of OUTPUT or STORE operations.\n\nNumber of conditional constructs (IF, CASE, inline filters).\n\nNumber of reusable components (MACROs, FUNCTIONs, etc.).\n\nConversion Complexity Score\nAssign a migration complexity score (0\u2013100), based on:\n\nUnsupported/incompatible ECL features.\n\nNumber of required manual refactors.\n\nWorkflow orchestration or integration complexity.\n\nVolume and complexity of dataset transformations or nesting.\n\n2. Feature Compatibility Check with Java Spring Boot\nIdentify ECL constructs that don\u2019t directly map to typical Java Spring Boot components or patterns. Highlight:\n\nImplicit schema typing and RECORD definitions.\n\nDataset-level operations like ROLLUP, NORMALIZE, and DENORMALIZE.\n\nGlobal aggregates using AGGREGATE with GROUP clauses.\n\nStateless vs. stateful transformations in ECL that need code-based handling in Spring Boot.\n\n3. Manual Adjustments for Java Spring Boot Migration\nSuggest the manual changes required after migration to make the Java Spring Boot code clean and production-ready:\nRenaming variable names to follow Java naming conventions (e.g., cust_id \u2192 customerId).\nRefactoring dataset or record names to meaningful Java class names.\nAdjusting data types (e.g., STRING \u2192 String, INTEGER \u2192 int).\nMoving hardcoded values to config files or environment variables.\nConverting control flow statements (e.g., IF, CASE) into readable Java conditions.\nAdding exception handling for runtime safety.\nInjecting dependencies using @Autowired or constructor injection.\nRouting output logic to appropriate Spring components (e.g., REST API, file writer, database repository).\n\n4. Optimization Recommendations for Java Spring Boot\nSuggest improvements specific to Spring Boot application design:\n\nUse of pagination, batching, and multi-threaded processing for large datasets.\n\nIncorporating caching (e.g., with Spring Cache) for repeatable logic.\n\nStructuring services into clean layers (Controller, Service, Repository) for maintainability.\n\nPerformance tuning options with thread pools, asynchronous execution, and profiling.\n\nExternalizing configuration for dynamic schema or data source handling.\n\n\nPoints to remember:\n-give only the metadata once in the top of the output and dont give it any where\n-leave the created on empty \n-dont give the sample code in the output no code is needed in the output\n- only the metadata requirements in the top of the output only once not any where in the code\nInput:\nFor ECL script use the below ecl file(s) or text file(s) which have ecl code:  ```%1$s```  ",
          "modelName": "model"
        },
        {
          "serial": 3,
          "agentId": 7330,
          "name": "DI ECL To JavaSpringboot Plan",
          "workflowId": 2628,
          "agentDetails": {
            "topP": 0.94,
            "maxRpm": null,
            "levelId": 99,
            "maxIter": null,
            "toolRef": [],
            "maxToken": "4000",
            "isVerbose": true,
            "temperature": 0.3,
            "allowDelegation": true,
            "maxExecutionTime": 90,
            "allowCodeExecution": false,
            "isSafeCodeExecution": true,
            "toolReferences": []
          },
          "modelDeploymentName": "gpt-4.1",
          "description": "**Format:** Markdown\nINSTRUCTIONS:\n1. Review the analysis of ECL file, note syntax differences and areas in the code requiring manual intervention when converting to Java Springboot\n2. Estimate the Approximate effort hours required for basic identified manual code fixes and data recon testing effort \n3. Dont consider efforts for syntax differences as they will be converted to equivalent syntax in Java Springboot\n4. Consider the pricing information for AWS EC2 (t3 large) environment \n5. Calculate the estimated cost of running the converted Java Springboot code:\n   a. Use the pricing information and data volume to determine the query cost.\n   b. the number of queries and the data processing done with the base tables and temporary tables\n\nOUTPUT FORMAT\n**Format:** Markdown\n- **Format:** Markdown\n**Metadata Requirements:**\n- Add the following metadata at the top of each converted/generated file:\n```\n=============================================\nAuthor: Ascendion AVA+\nCreated on: (Leave it empty)\nDescription: <one-line description of the purpose>\n=============================================\n```\n- If the source code already contains metadata headers, update them to match this format while preserving any relevant description content.\n- For the description, provide a concise summary of what the code does.\n(give this only once in the top of the output)\n1 Java Springboot Runtime Cost\n\u00a0\u00a0\u00a0- Provide the calculation in proper  breakup of the cost and the reasons\nJustify each cost component.\n2. Code Fixing for manual interventions and Data Recon Testing Effort Estimation\n- Effort for manual intervention code changes and data recon testing effort in hours\n3. API Cost\nInclude the cost consumed by the API for this call in the output in dollars (example 0.00$)\n\nPoints to remember:\nStrictly follow the output format\nno table format give it as heading and description\nno summary or justification needed\nyou need to get the manual adjustment details for the manual intervention take from the previous agent\n\nInput:\nFor the detailed Analysis input use the previous Ecl to Java Springboot analysis agent (DI_ECL_To_JavaSpringboot_Analyzer) output as input  \nFor ECL script use the below ecl file(s) or text file(s) which have ecl code:  ```%1$s```  \nFor environment details and api cost calculation use this file : ```%2$s```",
          "modelName": "model"
        }
      ],
      "realmId": 32
    }
  },
  "status": "SUCCESS"
}