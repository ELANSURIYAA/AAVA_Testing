{
  "data": {
    "message": "Workflow with agents retrieved successfully",
    "workFlowDetail": {
      "id": 2110,
      "name": "DI PySpark Consolidate Design Pattern",
      "description": "PySpark Design pattern consolidate",
      "createdBy": "elansuriyaa.p@ascendion.com",
      "modifiedBy": "elansuriyaa.p@ascendion.com",
      "approvedBy": "elansuriyaa.p@ascendion.com",
      "createdAt": "2025-11-05T10:47:30.435973",
      "modifiedAt": "2025-12-03T15:03:31.224436",
      "approvedAt": "2025-11-05T10:47:31.497670",
      "status": "APPROVED",
      "isDeleted": false,
      "parentId": -1,
      "workflowConfigs": {
        "managerLlm": [
          {}
        ],
        "enableAgenticMemory": false
      },
      "workflowAgents": [
        {
          "serial": 1,
          "agentId": 3933,
          "name": "DI PySpark Consolidate Design Pattern",
          "workflowId": 2110,
          "agentDetails": {
            "topP": 0.94,
            "maxRpm": null,
            "levelId": 99,
            "maxIter": null,
            "toolRef": [],
            "maxToken": "8000",
            "isVerbose": true,
            "temperature": 0.3,
            "allowDelegation": true,
            "maxExecutionTime": 90,
            "allowCodeExecution": false,
            "isSafeCodeExecution": true,
            "toolReferences": []
          },
          "modelDeploymentName": "gpt-4.1",
          "description": "Description\n\nPattern Categories Reference:\n\nSource File (SF): Pattern involves reading from a file source (e.g., Parquet, CSV, JSON)\n\nSource Table (ST): Pattern involves reading from a managed table (Hive, Delta, Iceberg, etc.)\n\nSource External Table / API (SA): Pattern involves reading from an external table, JDBC source, or API\n\nTransformation Arithmetic Calcs (TAC): Pattern involves arithmetic calculations during transformation\n\nTransformation Stats Calcs (TSC): Pattern involves statistical calculations during transformation\n\nTransformation External Code / UDF (TX): Pattern involves calling external UDFs or Pandas UDFs during transformation\n\nTransformation Aggregate Functions (TAG): Pattern involves aggregate functions like sum, count, avg\n\nJoin with Another Dataset (JL): Pattern involves joining with another DataFrame or table\n\nTemporary Views / CTEs (TEM): Pattern involves creating or using temporary views (createOrReplaceTempView) or chained transformations instead of materializing intermediate datasets\n\nData Quality and Rejection (DQ): Pattern involves data quality checks and rejection handling\n\nWrite - Overwrite (WO): Pattern involves overwriting datasets (mode(\"overwrite\"))\n\nWrite - Append (WA): Pattern involves appending data to a dataset (mode(\"append\"))\n\nWrite - Merge/Upsert (WM): Pattern involves merge/upsert logic (using Delta Lake or equivalent)\n\nUnion Operations (UN): Pattern involves union or unionByName\n\nSort / Order By (SO): Pattern involves ordering data\n\nTarget File (TF): Pattern involves writing to a file target (Parquet, CSV, JSON)\n\nTarget Table (TT): Pattern involves writing to a managed table\n\nTarget External Table / API (TA): Pattern involves writing to an external table or API target\n\nOthers (OO): Other patterns not categorized above\n\nSteps:\n\nAnalyze the provided PySpark design pattern documentation.\n\nIdentify the most frequent design pattern combinations (not just individual patterns).\n\nProvide PySpark optimization recommendations \u2014 without code \u2014 for each combination.\n\nSpecial Rules:\n\nDo not include full paths like /mnt/data/clinical_trials/references_txt, instead return only references_txt.\n\nMaintain the original PySpark script filename as the JSON key.\n\nEach referenced table/module should be a string inside the list.\n\nEnsure values are deduplicated.\n\nOutput must be in valid JSON with no extra text above or below.\n\nProgram file names must end with .py or .ipynb.\n\nOutput must contain at least 5 design patterns.\n\nINPUT:\nRead all the input files (10 files) and generate the design pattern analysis accordingly.\n\nConsolidated design pattern documentation from multiple PySpark files: {{Design_Patterns}}",
          "modelName": "model"
        }
      ],
      "realmId": 32
    }
  },
  "status": "SUCCESS"
}