{
  "data": {
    "message": "Workflow with agents retrieved successfully",
    "workFlowDetail": {
      "id": 2624,
      "name": "DI MarkLogic to MongoDB Doc&Analyze",
      "description": "Detailed Documentation, Analysis and Plan for MarkLogic to MongoDB",
      "createdBy": "default@ascendion.com",
      "modifiedBy": "default@ascendion.com",
      "approvedBy": "default@ascendion.com",
      "createdAt": "2025-11-05T11:09:05.570695",
      "modifiedAt": "2025-12-03T15:03:31.224436",
      "approvedAt": "2025-11-05T11:09:06.624277",
      "status": "APPROVED",
      "isDeleted": false,
      "parentId": -1,
      "workflowConfigs": {
        "managerLlm": [
          {}
        ],
        "enableAgenticMemory": false
      },
      "workflowAgents": [
        {
          "serial": 1,
          "agentId": 7351,
          "name": "MarkLogic Documentation",
          "workflowId": 2624,
          "agentDetails": {
            "topP": 0.94,
            "maxRpm": null,
            "levelId": 154,
            "maxIter": null,
            "toolRef": [],
            "maxToken": "4000",
            "isVerbose": true,
            "temperature": 0.3,
            "allowDelegation": true,
            "maxExecutionTime": 90,
            "allowCodeExecution": false,
            "isSafeCodeExecution": true,
            "toolReferences": []
          },
          "modelDeploymentName": "gpt-4.1",
          "description": "This agent extracts metadata and structural details from MarkLogic, documenting database schemas, collections, indexes, stored queries, and access patterns. It provides insights into data distribution, indexing efficiency, and potential challenges for migration. The documentation will be structured for easy reference and analysis.\nThis agent analyzes a given MarkLogic implementation and provides structured documentation covering:\n1.Overview: Purpose, business alignment, and key MarkLogic components (Documents, Collections, Indexes, Queries, APIs).\n2. Code Structure: Explanation of forests, indexes, data models, and query mechanisms (XQuery, SQL, SPARQL).\n3. Data Flow & Mapping: Source-to-destination mappings, transformations, and indexing strategies.\n4. Performance Optimization: Techniques like range indexing, caching, and query tuning.\n5. Complexity Analysis: Metrics on documents, queries, dependencies, and transformations.\n6. Error Handling & Logging: Exception handling, logging mechanisms, and automated monitoring.\nExpected Output:\nA structured document containing:\n\nDetailed explanation of the MarkLogic system.\nData mapping table with transformations.\nPerformance optimization strategies.\nComplexity assessment with scoring.\nError handling and logging methodologies.\nInput: \nFor input MarkLogic code use the below mentioned file:\n```%1$s```",
          "modelName": "model"
        },
        {
          "serial": 2,
          "agentId": 7358,
          "name": "MarkLogic to MongDB Analyzer",
          "workflowId": 2624,
          "agentDetails": {
            "topP": 0.94,
            "maxRpm": null,
            "levelId": 152,
            "maxIter": null,
            "toolRef": [],
            "maxToken": "4000",
            "isVerbose": true,
            "temperature": 0.3,
            "allowDelegation": true,
            "maxExecutionTime": 90,
            "allowCodeExecution": false,
            "isSafeCodeExecution": true,
            "toolReferences": []
          },
          "modelDeploymentName": "gpt-4.1",
          "description": "You are a Database Migration Specialist tasked with analyzing a MarkLogic database and providing detailed insights for migration to MongoDB. Your analysis should be thorough and cover all aspects of the database structure, data model, and query patterns.\n\nINSTRUCTIONS:\n1. Perform a schema analysis:\n   - Identify and list all collections in the MarkLogic database\n   - Analyze document structures within each collection\n   - Identify and document all indexes (range, reverse, geospatial)\n   - Map out relationships between documents and collections\n\n2. Create a data model mapping:\n   - Analyze the XML/JSON documents in MarkLogic\n   - Propose an equivalent BSON structure for MongoDB\n   - Highlight any potential challenges in the data model conversion\n\n3. Develop an indexing strategy:\n   - Compare MarkLogic indexing mechanisms with MongoDB's capabilities\n   - Suggest equivalent or alternative indexing approaches for MongoDB\n   - Identify any indexes that may not have a direct equivalent in MongoDB\n\n4. Conduct a query analysis:\n   - Evaluate existing XQuery, SQL, or SPARQL queries\n   - Propose equivalent MongoDB aggregation pipelines or queries\n   - Highlight any queries that may require significant restructuring\n\n5. Assess performance considerations:\n   - Analyze query complexity and execution patterns\n   - Evaluate current indexing efficiency\n   - Identify optimization opportunities for the MongoDB implementation\n\n6. Perform a dependency analysis:\n   - Identify triggers, stored queries, or APIs in the MarkLogic database\n   - Suggest modifications or alternatives for these dependencies in MongoDB\n\n7. Compile all findings into a structured report\nInput: \nFor input MarkLogic code use the below mentioned file:\n```%1$s```\n",
          "modelName": "model"
        },
        {
          "serial": 3,
          "agentId": 7360,
          "name": "MarkLogic to MongDB Plan",
          "workflowId": 2624,
          "agentDetails": {
            "topP": 0.94,
            "maxRpm": null,
            "levelId": 150,
            "maxIter": null,
            "toolRef": [],
            "maxToken": "4000",
            "isVerbose": true,
            "temperature": 0.3,
            "allowDelegation": true,
            "maxExecutionTime": 90,
            "allowCodeExecution": false,
            "isSafeCodeExecution": true,
            "toolReferences": []
          },
          "modelDeploymentName": "gpt-4.1",
          "description": "You are tasked with analyzing the provided MarkLogic script and estimating the effort required to convert it to MongoDB. Your output should include an assessment of code complexity, required manual fixes, and the estimated cost of running the converted queries in MongoDB. This plan will serve as the roadmap for our technical team to execute the migration successfully.\n\nINSTRUCTIONS:\n1. Analyze the MarkLogic script\nIdentify all key functions, queries, and structures used.\nList syntax differences between MarkLogic and MongoDB.\nHighlight areas requiring manual intervention during conversion.\n\n2. Estimate effort for conversion and testing\nProvide estimated effort hours for manual code fixes required after conversion.\nEstimate effort hours for unit testing and integration testing to validate the converted MongoDB code.\n\n3. Consider MongoDB pricing and performance factors\nUse MongoDB Atlas pricing details to estimate the cost of running the converted queries.\nConsider the data processing volume, indexing requirements, and query execution costs.\n\n4. Provide a structured output\nEnsure the estimated effort and cost breakdown are clearly documented.\n\nFor input MarkLogic code use the below mentioned file:\n* Take the previous MarkLogic_to_MongDB_Analyzer agents output as input.\n* For the input MarkLogic code use this file: ```%1$s```\n* For the input MongoDB environment details use this file:  ```%2$s```",
          "modelName": "model"
        }
      ],
      "realmId": 1
    }
  },
  "status": "SUCCESS"
}