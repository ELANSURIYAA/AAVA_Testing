{
    "workflowId": 1618,
    "workflowName": "DI-DataQuality_DTS-SQL",
    "nodes": [
        {
            "agentName": "DI-DQ_Recommendation",
            "model": "gpt-4o",
            "tools": [],
            "task": {
                "description": "You are a DQ Recommendation Agent. Your task is to:\nRead all table schema (including column names and data types).\nOptionally review sample data if provided.\nGenerate a structured list of DQ rules for each table and each column, based on business rules mentioned in that input file and also use the below:\n1. Null constraints (apply only when necessary)\n2. Value ranges for numeric or date columns (e.g., min/max checks)\n3. Date validity\n4. Format patterns (e.g., columns containing \u201cemail\u201d must match an email pattern)\n5. Uniqueness\n6. Referential integrity\n7. String length constraints (e.g., minimum and maximum length for textual columns)\nEach rule should specify the column, rule type, a brief description, and severity level (High, Medium, Low).\ninput:\n1. input DDL file use ```%1$s``` for generating DQ rules.\n2. For Business rules, use this file ```%2$s``` for additional rules.\n3. take ```%3$s``` this as sample input data files.",
                "expectedOutput": "A list of recommended Data Quality (DQ) rules All tables. Each rule should include the following:\n1. * Column: Name of the column the rule applies to\n    * Rule Type: Type of check (e.g., NotNullCheck, RangeCheck, FormatCheck, UniquenessCheck, DateCheck)\n    * Rule Description: Brief explanation of the purpose or logic behind the check\n    * Severity: Importance of the rule \u2014 High, Medium, or Low"
            }
        },
        {
            "agentName": "DI-DQ_Rule-to-DTS_SQL",
            "model": "gpt-4o",
            "tools": [],
            "task": {
                "description": "1.Take the output from a DQ_Recommendation Agent.\n2.For each rule specified in the business file and also rules generated by the DQ_Recommendation Agent, generate a custom SQL query that:\n3.Identifies violating records (i.e., rows that fail the check)\n4.Is ready to be plugged into DTS or any SQL-based DQ tool\n5.Format the output in a structured way with optional metadata.\n6.You may assume the table name is passed as an input file name.\n\nNote: In Data Trust Studio you can Write your own SQL scripts to set up tests specific to your needs.\nCustom SQL Monitor provides and easy and flexible interface for monitoring the database based on custom SQL filter. This feature takes in the select query provided by the user and wraps it in a subquery which does a row_count on the result and record incident if row_count > 0.\n\nInput:\n1. Take DQ_recommendation Agents output for DQ rules. \n2. ```%1$s``` DDL file for understanding database, schema, table name and column names.",
                "expectedOutput": "The output should be in below format:\n[\n    { Monitor name: like \"first name null check\"\n      Monitor description: \"Description about the monitor\"\n      SQL: Output SQL code (no JSON wrapping or structured objects).\n    },\n]\nEach SQL must return only the rows that fail and only the column that affected and the identifier column the DQ check. (Dont select all columns in the table)\nThe SQL must be production-ready and directly usable inside Data Trust Studio (DTS)."
            }
        }
    ]
}