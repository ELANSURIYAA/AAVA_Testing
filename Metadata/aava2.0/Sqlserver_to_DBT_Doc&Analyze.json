{
  "data": {
    "message": "Workflow with agents retrieved successfully",
    "workFlowDetail": {
      "id": 4651,
      "name": "Sqlserver to DBT  Doc&Analyze",
      "description": "Sql Server to DBT",
      "createdBy": "sharmilee.d@ascendion.com",
      "modifiedBy": "sharmilee.d@ascendion.com",
      "approvedBy": "sharmilee.d@ascendion.com",
      "createdAt": "2025-11-05T12:09:05.344900",
      "modifiedAt": "2025-12-03T15:03:31.224436",
      "approvedAt": "2025-11-05T12:09:06.392898",
      "status": "APPROVED",
      "isDeleted": false,
      "parentId": -1,
      "workflowConfigs": {
        "managerLlm": [
          {}
        ],
        "enableAgenticMemory": false
      },
      "workflowAgents": [
        {
          "serial": 1,
          "agentId": 5170,
          "name": "SqlServer to DBT Documentation",
          "workflowId": 4651,
          "agentDetails": {
            "topP": 0.94,
            "maxRpm": null,
            "levelId": 99,
            "maxIter": null,
            "toolRef": [],
            "maxToken": "****MASKED****",
            "isVerbose": true,
            "temperature": 0.3,
            "allowDelegation": true,
            "maxExecutionTime": 90,
            "allowCodeExecution": false,
            "isSafeCodeExecution": true,
            "toolReferences": []
          },
          "modelDeploymentName": "gpt-4.1",
          "description": "Please create detailed documentation for the provided SQL Server code.\n\nThe documentation must contain the following sections:\n\n1. Overview of Program:\nExplain the purpose of the SQL Server query in detail.\nDescribe how this implementation aligns with enterprise data warehousing and analytics.\nExplain the business problem being addressed and its benefits.\nProvide a high-level summary of SQL Server components such as Tables, Views, Stored Procedures, Functions, Indexes, and Common Table Expressions (CTEs).\n\n2. Code Structure and Design:\nExplain the structure of the SQL Server query in detail.\nDescribe key components such as DDL (Data Definition Language), DML (Data Manipulation Language), Joins, Indexing, and Functions.\nList the primary SQL Server components used in the query:\nTables, Views, Joins, Aggregations, Temporary Tables, and Subqueries.\nUse of Common Table Expressions (CTEs) and Window Functions.\nHighlight dependencies on SQL Server objects, performance tuning techniques, or third-party integrations (if applicable).\n\n3. Data Flow and Processing Logic:\nExplain how data flows within the SQL Server query.\nList source tables, destination tables, fields, and data types.\nDescribe applied transformations such as filtering, joins, aggregations, and field calculations.\n\n4. Data Mapping:\nProvide a detailed mapping of how source columns are transformed into target columns.\nExplain transformation rules, validation rules, and any applied business logic.\n\n5. Performance Optimization Strategies:\nDescribe optimization techniques used in SQL Server:\nIndexing Strategies: Clustered and Non-Clustered Indexes.\nQuery Optimization Techniques: Execution Plan Analysis, Statistics, and Index Tuning.\nPartitioning and Table Design: Using Table Partitioning for Large Data Sets.\nCTEs vs. Temporary Tables: When to use each for performance benefits.\nReducing Query Complexity: Avoiding Nested Queries, Using Efficient Joins.\nSQL Server Caching Mechanisms: Query Result Caching, Buffer Pool Optimization.\n\n6. Technical Elements and Best Practices:\nExplain the technical elements involved in the SQL Server query.\nList SQL Server system dependencies such as:\nDatabase Connections (Linked Servers, Cross-Database Queries).\nIndexing Strategies for Query Performance.\nTransaction Management: COMMIT, ROLLBACK, SAVEPOINT.\nMention best practices such as:\nAvoiding Table Scans by using Proper Indexing.\nOptimizing Joins (Nested Loop, Merge Join, Hash Join).\nEfficient Use of Temp Tables and CTEs.\nDescribe error handling, logging, and exception tracking methods.\n\n7. Complexity Analysis:\nAnalyze and document the complexity based on the following factors:\nLines of Code in the SQL script.\nNumber of Tables Referenced in the SQL script.\nTypes of Joins Used: INNER JOIN, LEFT JOIN, CROSS JOIN, etc.\nUsage of Temporary Tables, Table Variables, and CTEs.\nNumber of Aggregate Functions (COUNT, SUM, AVG, etc.).\nNumber of DML Statements: SELECT, INSERT, UPDATE, DELETE, MERGE.\nUse of Conditional Logic (CASE Statements, IF-ELSE in Stored Procedures).\nPerformance Considerations: Query Execution Time, Memory Usage, CPU Load.\nData Volume Handling: Number of records processed in each stage.\nExternal Dependencies: SQL Server Agent Jobs, Linked Servers, SSIS Packages.\nOverall Complexity Score (0-100) based on the above factors.\n\n8. Assumptions and Dependencies:\nList system prerequisites such as database connections, table structures, and required access roles.\nMention infrastructure dependencies, including SQL Server Edition (Standard, Enterprise, Azure SQL, Managed Instance, etc.).\nNote assumptions about data consistency, schema evolution, and workload management.\n\n9. Key Outputs:\nDescribe final outputs such as Aggregated Reports, Tables, Views, or Data Exports.\nExplain how outputs align with business goals and reporting needs.\nSpecify the storage format (Permanent Tables, Temp Tables, CSV, JSON, etc.).\n\n10. Error Handling and Logging:\nExplain methods used for error identification and management, such as:\nTRY...CATCH in Stored Procedures for exception handling.\nSQL Server Error Logs and Event Handling.\nTransaction Rollback Strategies in case of failures.\nSQL Server Agent Jobs for Monitoring and Alerts.\nLogging mechanisms for capturing query execution details.\n\nAdditionally, calculate and include the cost consumed by the API for this call in the output, explicitly mentioning the cost in USD.\nEnsure the cost consumed by the API is mentioned with all decimal values included.\n\nInput:\nFor SQL scripts, use the provided file: ```%1$s```",
          "modelName": "model"
        },
        {
          "serial": 2,
          "agentId": 5179,
          "name": "SqlServer to DBT Analyzer",
          "workflowId": 4651,
          "agentDetails": {
            "topP": 0.94,
            "maxRpm": null,
            "levelId": 99,
            "maxIter": null,
            "toolRef": [],
            "maxToken": "****MASKED****",
            "isVerbose": true,
            "temperature": 0.3,
            "allowDelegation": true,
            "maxExecutionTime": 90,
            "allowCodeExecution": false,
            "isSafeCodeExecution": true,
            "toolReferences": []
          },
          "modelDeploymentName": "gpt-4.1",
          "description": "Parse the provided SQL Server query to generate a detailed analysis and metrics report. If multiple files are given as input, ensure that the analysis for each file is presented as a distinct session. Each session must include:\n\n1. Script Overview\nProvide a high-level description of the SQL script\u2019s purpose and primary business objectives.\nIdentify the key database objects involved, such as tables, views, stored procedures, and functions.\n\n2. Complexity Metrics\nNumber of Lines: Count of total lines in the SQL script.\nTables Used: Count of distinct tables referenced.\nJoins: Number of joins and the types used (INNER JOIN, LEFT JOIN, CROSS JOIN, FULL OUTER JOIN).\nCommon Table Expressions (CTEs) and Temporary Tables: Count of CTEs and temporary tables used.\nAggregate Functions: Number of COUNT, SUM, AVG, MIN, MAX, GROUP BY, and window functions used.\nDML Statements: Count of SELECT, INSERT, UPDATE, DELETE, MERGE operations present in the script.\nConditional Logic: Count of CASE statements, IF conditions, and control flow logic (e.g., WHILE, BEGIN...END).\n\n3. Syntax Analysis\nIdentify SQL Server-specific syntax patterns, such as:\nCommon Table Expressions (CTEs) and Derived Tables\nString Aggregation functions (STRING_AGG, FOR XML PATH, JSON functions, etc.)\nRanking and Window Functions (ROW_NUMBER, RANK, DENSE_RANK, LAG, LEAD)\nDynamic SQL usage\nTRY...CATCH error handling patterns\nHighlight any non-standard SQL Server functions or expressions used.\n\n4. Manual Adjustments\nRecommend specific manual adjustments for functions and clauses, including:\nFunction optimizations (e.g., alternative approaches for expensive expressions).\nSyntax adjustments for performance improvements (e.g., using proper indexing hints, replacing correlated subqueries with joins).\nQuery structure and execution optimizations, such as:\nUsing indexed views instead of complex joins.\nReplacing cursor-based logic with set-based operations.\nAvoiding nested subqueries when CTEs or joins are more efficient.\n\n5. Complexity Score\nCalculate a complexity score (0\u2013100) based on:\nNumber of joins, window functions, recursive queries, and procedural logic.\nUsage of expensive operations like CROSS JOIN, correlated subqueries, and large-scale aggregations.\nPresence of multiple layers of nested queries or dynamic SQL execution.\nHighlight high-complexity areas, such as:\nRecursive CTEs\nMultiple joins across large tables\nHeavy use of window functions and ranking functions\nStored procedure execution with complex control flow logic\n\n6. Optimization Techniques\nSuggest query tuning strategies such as:\nIndexing optimizations (e.g., covering indexes, filtered indexes, clustered vs. non-clustered indexes).\nPartitioning strategies for large tables to improve query performance.\nUsing Table Variables vs. Temporary Tables based on query patterns.\nQuery Execution Plan analysis to identify inefficient operations.\nReducing unnecessary I/O and improving memory usage through efficient joins and filtering.\n\n7. API Cost Calculation\nInclude the cost consumed by the API for this call in the output.\nEnsure the cost consumed by the API is reported as a floating-point value with currency explicitly mentioned as USD (e.g., apiCost: actual cost).\nEnsure the cost is reported with all decimal values included.\n\nInput:\nFor SQL script, use the below file: ```%1$s```",
          "modelName": "model"
        },
        {
          "serial": 3,
          "agentId": 5210,
          "name": "SqlServer to DBT Plan",
          "workflowId": 4651,
          "agentDetails": {
            "topP": 0.94,
            "maxRpm": null,
            "levelId": 99,
            "maxIter": null,
            "toolRef": [],
            "maxToken": "****MASKED****",
            "isVerbose": true,
            "temperature": 0.3,
            "allowDelegation": true,
            "maxExecutionTime": 90,
            "allowCodeExecution": false,
            "isSafeCodeExecution": true,
            "toolReferences": []
          },
          "modelDeploymentName": "gpt-4.1",
          "description": "You are responsible for providing a comprehensive effort estimate for testing the DBT Compatible Sql Query converted from a SQL scripts. Follow these instructions to complete the task:\n\n### **INSTRUCTIONS**  \nReview the analysis of the **SQL Query**  \n\n- Identify syntax differences between **SQL Query** and **DBT-compatible SQL**.  \n- Highlight areas that require **manual intervention** in the conversion.  \n\n#### **Estimate the cost of running the DBT-compatible SQL Query**  \n- Use **DBT pricing** to estimate execution cost.  \n- Consider data volume, processing complexity, and temporary table usage.  \n- Analyze the **number of operations** performed on **base tables and temporary tables**.  \n\n#### **Estimate the testing effort required for DBT conversion**  \n\n##### **Manual code fixes and unit testing effort**  \n- Time required for fixing **syntax and logic mismatches**.  \n- Handling **complex transformations, window functions, and joins**.  \n\n##### **Output validation effort**  \n- Comparing results from **SQL Query and DBT-compatible SQL execution**.  \n- Handling **edge cases and debugging discrepancies**.  \n\nUse the  SQL script from this file: ```%1$s```\nUse the DBT Compatible Sql Query Environment Details for DBT from this file: ```%2$s```\n",
          "modelName": "model"
        }
      ],
      "realmId": 32
    }
  },
  "status": "SUCCESS"
}