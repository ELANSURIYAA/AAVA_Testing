{
  "data": {
    "message": "Workflow with agents retrieved successfully",
    "workFlowDetail": {
      "id": 2786,
      "name": "DI Oracle to SF Doc&Analyze",
      "description": "Analyzing and Documenting the Oracle code",
      "createdBy": "karthikeyan.iyappan@ascendion.com",
      "modifiedBy": "karthikeyan.iyappan@ascendion.com",
      "approvedBy": "karthikeyan.iyappan@ascendion.com",
      "createdAt": "2025-11-05T11:14:32.284824",
      "modifiedAt": "2025-12-03T15:03:31.224436",
      "approvedAt": "2025-11-05T11:14:33.341256",
      "status": "APPROVED",
      "isDeleted": false,
      "parentId": -1,
      "workflowConfigs": {
        "managerLlm": [
          {}
        ],
        "enableAgenticMemory": false
      },
      "workflowAgents": [
        {
          "serial": 1,
          "agentId": 7059,
          "name": "DI Oracle Documentation",
          "workflowId": 2786,
          "agentDetails": {
            "topP": 0.94,
            "maxRpm": null,
            "levelId": 99,
            "maxIter": null,
            "toolRef": [],
            "maxToken": "****MASKED****",
            "isVerbose": true,
            "temperature": 0.3,
            "allowDelegation": true,
            "maxExecutionTime": 90,
            "allowCodeExecution": false,
            "isSafeCodeExecution": true,
            "toolReferences": []
          },
          "modelDeploymentName": "gpt-4.1",
          "description": "****MASKED****",
          "modelName": "model"
        },
        {
          "serial": 2,
          "agentId": 5557,
          "name": "DI Oracle to Snowflake Analyzer",
          "workflowId": 2786,
          "agentDetails": {
            "topP": 0.94,
            "maxRpm": null,
            "levelId": 99,
            "maxIter": null,
            "toolRef": [],
            "maxToken": "****MASKED****",
            "isVerbose": true,
            "temperature": 0.3,
            "allowDelegation": true,
            "maxExecutionTime": 90,
            "allowCodeExecution": false,
            "isSafeCodeExecution": true,
            "toolReferences": []
          },
          "modelDeploymentName": "gpt-4.1",
          "description": "****MASKED****",
          "modelName": "model"
        },
        {
          "serial": 3,
          "agentId": 4841,
          "name": "DI Oracle to Snowflake Plan",
          "workflowId": 2786,
          "agentDetails": {
            "topP": 0.94,
            "maxRpm": null,
            "levelId": 99,
            "maxIter": null,
            "toolRef": [],
            "maxToken": "****MASKED****",
            "isVerbose": true,
            "temperature": 0.3,
            "allowDelegation": true,
            "maxExecutionTime": 90,
            "allowCodeExecution": false,
            "isSafeCodeExecution": true,
            "toolReferences": []
          },
          "modelDeploymentName": "gpt-4.1",
          "description": "You are tasked with providing a detailed cost and effort estimation for executing and testing Snowflake stored procedures that were converted from Oracle PL/SQL scripts. Use the prior Oracle analysis report to drive this estimation.\n\nINSTRUCTIONS:\n1. Metadata Requirements:\n- Add the following metadata at the top of each generated file:\n```\n=============================================\nAuthor:        Ascendion AVA+\nDate: (Leave it empty)\nDescription:   <one-line description of the generated plan>\n=============================================\n```\n- For the description, provide a concise summary of what the plan does.\n\nYou are tasked with providing a comprehensive effort estimate for testing the Snowflake code converted from Oracle PL/SQL scripts. Follow these instructions to complete the task:\n\nINSTRUCTIONS:\n\nReview the analysis of the Oracle PL/SQL script file, noting logic differences and areas in the code requiring manual intervention when converting to Snowflake.\n\nEstimate the effort hours required for identified manual code fixes and data reconciliation testing efforts.\n\nDo not consider effort for pure syntax-level differences as they will be handled automatically by conversion tools.\n\nConsider the pricing information for the Snowflake environment.\n\nCalculate the estimated cost of running the converted Snowflake code:\na. Use Snowflake's pricing model and data volume to determine the query cost.\nb. Include the number of queries executed and the data processed using both temporary and permanent tables.\n- Strictly follow the ecpected output format\nOUTPUT FORMAT:\n Metadata Requirements:\n\n\n1. Cost Estimation\n   1.1 Snowflake Runtime Cost \n         - provide the calculation breakup of the cost and the reasons\n2. Code Fixing  and Testing Effort Estimation\n   2.1 Snowflake identified manual code fixes and unit testing effort in hours covering the various temp tables, calculations \n   2.2 Optimization and performance tuning of Snowflake queries.\n\n* Include the cost consumed by the API for this call in the output.\n* Ensure the cost consumed by the API is reported as a floating-point value with currency explicitly mentioned as USD (e.g., apiCost: actual cost ).\n\n-follow strictly the expected output format\nINPUT\n\nFor the input Oracle analysis report and code reference, use the file:\n{{OracleFile}}\n\nFor the Snowflake environment resource and pricing reference, use the file:\n{{EnvVariable}}",
          "modelName": "model"
        }
      ],
      "realmId": 1
    }
  },
  "status": "SUCCESS"
}