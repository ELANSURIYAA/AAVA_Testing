{
  "data": {
    "message": "Workflow with agents retrieved successfully",
    "workFlowDetail": {
      "id": 8484,
      "name": "DI AbInitio To BigQuery Doc&Analyze",
      "description": "Analyzing and Documenting the Abinitio Code",
      "createdBy": "default@ascendion.com",
      "modifiedBy": "default@ascendion.com",
      "approvedBy": "default@ascendion.com",
      "createdAt": "2026-01-16T06:46:25.672076",
      "modifiedAt": "2026-01-16T12:43:25.388189",
      "approvedAt": "2026-01-16T06:46:27.435286",
      "status": "APPROVED",
      "isDeleted": false,
      "parentId": -1,
      "workflowConfigs": {
        "managerLlm": [
          {}
        ],
        "enableAgenticMemory": false
      },
      "workflowAgents": [
        {
          "serial": 1,
          "agentId": 16704,
          "name": "DI_AbInitio_Documentation",
          "workflowId": 8484,
          "agentDetails": {
            "topP": 0.94,
            "maxRpm": null,
            "levelId": 99,
            "maxIter": null,
            "toolRef": [],
            "maxToken": "****MASKED****",
            "isVerbose": true,
            "temperature": 0.3,
            "allowDelegation": false,
            "maxExecutionTime": null,
            "allowCodeExecution": false,
            "isSafeCodeExecution": true,
            "toolReferences": []
          },
          "modelDeploymentName": "gpt-4.1",
          "description": "****MASKED****",
          "modelName": "model"
        },
        {
          "serial": 2,
          "agentId": 16729,
          "name": "DI_AbInitio_To_BigQuery_Analyzer",
          "workflowId": 8484,
          "agentDetails": {
            "topP": 1.0,
            "maxRpm": null,
            "levelId": 99,
            "maxIter": null,
            "toolRef": [],
            "maxToken": "****MASKED****",
            "isVerbose": true,
            "temperature": 0.2,
            "allowDelegation": true,
            "maxExecutionTime": null,
            "allowCodeExecution": false,
            "isSafeCodeExecution": true,
            "toolReferences": []
          },
          "modelDeploymentName": "gpt-4.1",
          "description": "This agent performs a **pre-conversion assessment** of Ab Initio code to evaluate readiness for BigQuery SQL migration. It will:\n- Break down ETL flow, transformation logic, and schema definitions.\n- Identify SQL-compatible and non-compatible elements (e.g., feedback loops, reject logic, record-level transformations).\n- Highlight areas needing manual rewriting or workaround logic in SQL.\n- Score the complexity of the conversion.\n- Recommend strategies for expressing complex logic as BigQuery SQL views, UDFs, or nested queries.\n- Suggest checkpoints for validation and data assurance post-migration.\n\n### **INSTRUCTIONS:**  \n\n1. **Process Steps to Follow:**  \n   - **Step 1:** Parse `.mp`, `.xfr`, `.dml` files. Identify key ETL steps and transformations.  \n   - **Step 2:** Highlight challenges in translating to SQL (e.g., multi-branch logic, reformatting, `.xfr` logic, procedural dependencies).  \n   - **Step 3:** Assign a conversion complexity score (0\u2013100) based on logic depth, metadata use, joins, and custom functions.  \n   - **Step 4:** Recommend SQL patterns (e.g., CTE chains, subqueries, temp tables, UDFs) to replicate logic.  \n   - **Step 5:** Identify where manual attention will be needed for performance tuning, logic validation, or syntax restructuring.\n\n### **Output Format:**  \nUse **Markdown formatting**. Include the following metadata header:\n```\n=======================================================================================\nAuthor:        Ascendion AVA+\nCreated on:    (Leave it empty)\nDescription:   Pre-conversion analysis of Ab Initio ETL flow for BigQuery SQL migration\n=======================================================================================\n```\n\n### **Sections to Include:**\n\n#### Syntax Differences:\n- Breakdown of major Ab Initio components (e.g., `Join`, `Reformat`, `Rollup`, `Broadcast`, `Filter`, `Output Table`).\n- Explain how each would map to BigQuery constructs (e.g., `JOIN`, `SELECT`, `ARRAY_AGG`, `WITH` clauses, `TEMP TABLES`, etc.).\n- Highlight incompatible or non-native SQL behaviors (e.g., reject ports, iterative components).\n\n#### Anticipated Manual Interventions:\n- Embedded `.xfr` logic needing translation to SQL expressions or UDFs.\n- `.dml` schemas requiring restructuring for SQL compatibility (e.g., record-level vs. column-level mapping).\n- Graph variables or parameter sets that require template handling in BigQuery (via scripting or external orchestration).\n- Handling of procedural constructs (e.g., conditional branching) through CTE chains or nested selects.\n\n#### Complexity Evaluation:\n- Score (0\u2013100)\n- Justify using:\n  - Number and variety of components\n  - Use of `.xfr` logic and nested expressions\n  - Depth of joins and data dependencies\n  - File types or complex formats requiring custom parsing\n  - Need for BigQuery UDFs or scripting blocks\n\n#### Optimization Recommendation:\n- **Refactor:** Mostly direct SQL mapping with moderate complexity.\n- **Rebuild:** Requires full redesign of transformation logic for BigQuery SQL compatibility.\n\n### **API Cost:**  \nReport API cost for this particular api call to the AI model:  \n`apiCost: <actual_cost> USD`\n\n### **Input:**  \n- Ab Initio Source Files: `{{AbInitio_Code}}`",
          "modelName": "model"
        },
        {
          "serial": 3,
          "agentId": 16733,
          "name": "DI_AbInitio_To_BigQuery_Plan",
          "workflowId": 8484,
          "agentDetails": {
            "topP": 1.0,
            "maxRpm": null,
            "levelId": 99,
            "maxIter": null,
            "toolRef": [],
            "maxToken": "****MASKED****",
            "isVerbose": true,
            "temperature": 0.2,
            "allowDelegation": true,
            "maxExecutionTime": null,
            "allowCodeExecution": false,
            "isSafeCodeExecution": true,
            "toolReferences": []
          },
          "modelDeploymentName": "gpt-4.1",
          "description": "You are tasked with reviewing the Ab Initio source files (e.g., `.mp`, `.xfr`, `.dml`, `.pset`) during conversion to BigQuery SQL. Your responsibilities include identifying logic gaps requiring manual SQL intervention, estimating developer/tester effort, and forecasting BigQuery query costs based on data volume and query characteristics.\n\n### **INSTRUCTIONS:**  \n1. Analyze the Ab Initio codebase and its SQL conversion implications:\n   - Focus on logic gaps (e.g., `.xfr` complexity, reject handling, branching).\n   - Exclude syntactic equivalents already handled by auto-conversion tools.\n\n2. Estimate developer/tester effort in hours for:\n   - Manual SQL rewrites (e.g., custom `.xfr` translation, conditional logic in SQL)\n   - Metadata alignment (schema transformation, data type mapping)\n   - Edge case handling (reject records, fallback branches)\n   - Data reconciliation and validation testing\n\n3. Estimate **BigQuery Query Cost** using:\n   - Expected data volume scanned per query (in GB)\n   - Number of queries per day/week/month\n   - BigQuery pricing model: e.g., `$5 per TB scanned`\n\n4. Calculate **Total Developer Cost** using a default hourly rate (e.g., $50/hr)\n\n5. Present cost metrics, effort estimation, and guidance in a structured format.\n\n### **OUTPUT FORMAT:**  \nUse **Markdown** format with the following metadata header:\n```\n==============================================================================\nAuthor:        Ascendion AVA+\nCreated on:    (Leave it empty)\nDescription:   Cost & effort planning for Ab Initio to BigQuery SQL conversion\n==============================================================================\n```\n\n#### 1. BigQuery Cost Estimation  \n##### 1.1 Query Cost Breakdown  \n- **Data Volume Estimate per Query**: `<estimated_gb>` GB  \n- **Query Frequency**: `<queries/day>`  \n- **Monthly Volume Scanned**: `<calculated>` GB  \n- **BigQuery Pricing Used**: `$5 per TB scanned`  \n- **Estimated Monthly Cost (USD)**: `<calculated_cost>`\n\n> *Cost Formula Used:*  \nMonthly Cost = (Total GB Scanned / 1024) \u00d7 $5\n\n#### 2. Manual Code Fixing and Data Reconciliation Effort  \n##### 2.1 Estimated Effort (Hours)  \n- SQL Logic Adjustments (e.g., `.xfr` logic, reformat rules): `<integer>` hrs  \n- Schema/Data Type Fixes (e.g., `.dml` mapping issues): `<integer>` hrs  \n- Reject Logic or Conditional Handling: `<integer>` hrs  \n- Output Validation & Reconciliation Testing: `<integer>` hrs  \n- **Total Estimated Effort**: `<sum>` hrs\n\n##### 2.2 Developer Cost  \n- Developer Hourly Rate: `$50/hr`  \n- **Total Developer Cost**: `<effort_hrs \u00d7 50>` USD\n\n#### 3. API Processing Cost  \n- `apiCost: <actual_cost>` USD\n\n\n### **Input:**  \n- Ab Initio Source File: `{{AbInitio_Code}}`  \n- GCP Environmental Variable details file: {{Env_Details}}",
          "modelName": "model"
        }
      ],
      "realmId": 1
    }
  },
  "status": "SUCCESS"
}