{
  "data": {
    "message": "Workflow with agents retrieved successfully",
    "workFlowDetail": {
      "id": 1897,
      "name": "DI AbInitio To PySpark Doc&Analyze",
      "description": "Analyzing and Documenting the Abinitio Code",
      "createdBy": "default@ascendion.com",
      "modifiedBy": "default@ascendion.com",
      "approvedBy": "default@ascendion.com",
      "createdAt": "2025-11-05T10:39:20.563992",
      "modifiedAt": "2025-12-03T15:03:31.224436",
      "approvedAt": "2025-11-05T10:39:21.771493",
      "status": "APPROVED",
      "isDeleted": false,
      "parentId": -1,
      "workflowConfigs": {
        "managerLlm": [
          {}
        ],
        "enableAgenticMemory": false
      },
      "workflowAgents": [
        {
          "serial": 1,
          "agentId": 3664,
          "name": "DI AbInitio Documentation",
          "workflowId": 1897,
          "agentDetails": {
            "topP": 1.0,
            "maxRpm": null,
            "levelId": 99,
            "maxIter": null,
            "toolRef": [],
            "maxToken": "8000",
            "isVerbose": true,
            "temperature": 0.2,
            "allowDelegation": true,
            "maxExecutionTime": 90,
            "allowCodeExecution": false,
            "isSafeCodeExecution": true,
            "toolReferences": []
          },
          "modelDeploymentName": "gpt-4.1",
          "description": "The documentation should include the following sections:  \n\n- **Format:** Markdown  \n- Add the following metadata at the top of each generated file:  \n```\n====================================================\nAuthor:        Ascendion AVA+\nDate:          (Leave it empty)\nDescription:   <one-line description of the purpose>\n====================================================\n````\n\n1. **Overview of Graph/Component**  \n   - Describe the purpose of the Ab Initio graph (.mp), transformation (.xfr), data definition (.dml), plan (.plan), or pset (.pset).  \n   - Explain the business logic or requirement the graph or component addresses.  \n\n2. **Component Structure and Design**  \n   - Describe the layout and logical grouping of components inside the graph or plan.  \n   - Highlight key components such as `Input File`, `Reformat`, `Join`, `Sort`, `Dedup`, `Rollup`, `Output File`, `Run Program`, and others.  \n   - Mention the connection flow between components and the use of parameters or variables.  \n\n3. **Data Flow and Processing Logic**  \n   - List the key data sources, intermediate files, and final outputs.  \n   - For each logical step:\n     - Describe what it does (e.g., filtering, joining, reformatting, aggregation).  \n     - Mention any `.xfr` or `.dml` files used.  \n     - Include any business rules or transformations applied.  \n\n4. **Data Mapping (Lineage)**  \n   - Map fields from input datasets to output datasets.  \n   - Format:\n     ```\n     Target Table Name : <actual target file/table>\n     Target Column Name : <actual column>\n     Source Table Name : <actual source file/table>\n     Source Column Name : <actual column>\n     Remarks : <1:1 Mapping | Transformation | Validation - include logic description>\n     ```\n\n5. **Transformation Logic**  \n   - Document each `.xfr` function used or called in the flow.  \n   - Explain what each function does and what fields are involved.  \n   - Note any external function calls or reusable components.  \n\n6. **Complexity Analysis**  \n   - Number of Graph Components: <integer>  \n   - Number of Lines of Code (in .xfr or .plan): <integer>  \n   - Transform Functions Used: <count>  \n   - Joins Used: <list of types or None>  \n   - Lookup Files or Datasets: <count or 'None'>  \n   - Parameter Sets (.pset) or Plan Files Used: <count>  \n   - Number of Output Datasets: <integer>  \n   - Conditional Logic or `if-else` flows: <count>  \n   - External Dependencies: <JDBC connections, shell scripts, other tools>  \n   - Overall Complexity Score: <0\u2013100>  \n\n7. **Key Outputs**  \n   - Describe what is written to the final datasets or passed to the next stages.  \n   - Mention the format (Delimited, Fixed Width, etc.) and intended use of the output (e.g., report, downstream system).  \n\n8. **Error Handling and Logging**  \n   - Document any `Reject`, `Error`, or `Log` components used.  \n   - Mention any `.xfr` based error tagging, reject thresholds, or control file usage.  \n   - Describe how errors are handled (e.g., auto-abort, routed to reject files, email alerts).\n\n9. **API Cost (Optional for Cloud Ab Initio Deployments)**  \n   - If relevant, calculate estimated compute or I/O cost based on size of data processed and component usage.  \n   - Formula or logic for cost estimation must be provided if available.\n\n**Input:**  \nAttach or provide the Ab Initio files (.mp, .xfr, .dml, .plan, .pset). Acceptable formats: plain text, zipped folder, or directory path structure : {{AbInitio_Code}}",
          "modelName": "model"
        },
        {
          "serial": 2,
          "agentId": 3665,
          "name": "DI AbInitio To PySpark Analyzer",
          "workflowId": 1897,
          "agentDetails": {
            "topP": 1.0,
            "maxRpm": null,
            "levelId": 99,
            "maxIter": null,
            "toolRef": [],
            "maxToken": "8000",
            "isVerbose": true,
            "temperature": 0.2,
            "allowDelegation": true,
            "maxExecutionTime": 90,
            "allowCodeExecution": false,
            "isSafeCodeExecution": true,
            "toolReferences": []
          },
          "modelDeploymentName": "gpt-4.1",
          "description": "This agent performs **pre-conversion analysis** of Ab Initio code to assess its readiness for PySpark transformation. It will:\n- Break down components, transformation logic, and metadata in the Ab Initio graphs.\n- Identify challenges in translation, such as nested logic, lookups, parameter sets, or complex `.xfr` functions.\n- Score the conversion complexity.\n- Recommend refactor strategies and PySpark-aligned design patterns in anticipation of the conversion.\n- List manual tasks or review checkpoints for future PySpark developers.\n\n### **INSTRUCTIONS:**  \n\n1. **Process Steps to Follow:**  \n   - **Step 1:** Parse and interpret the Ab Initio `.mp`or `.xfr` or `.dml` files. Identify major ETL flow segments and transformation logic.  \n   - **Step 2:** Highlight potential challenges in converting to PySpark (e.g., nested `.xfr`, reject flows, rollups, dynamic `.pset` usage).  \n   - **Step 3:** Assign a conversion complexity score (0\u2013100) based on transformation density, graph depth, joins, and special components.  \n   - **Step 4:** Recommend high-level design approaches for the PySpark implementation (modularization, code structure, function usage).  \n   - **Step 5:** Suggest performance strategies that should be baked into the PySpark design early on (e.g., caching, repartitioning, vectorized operations).\n\n\n### **Output Format:**  \nUse **Markdown formatting**. Include the following metadata header:\n\n```\n==================================================================================\nAuthor:        Ascendion AVA+\nCreated on:    (Leave it empty)\nDescription:   Pre-conversion analysis of Ab Initio ETL flow for PySpark migration\n==================================================================================\n```\n\n### **Sections to Include:**\n\n#### Syntax & Logical Structure Analysis:\n- Breakdown of components: e.g., `Join`, `Reformat`, `Rollup`, `Broadcast`, `Filter`, `Output Table`.\n- Detail how each component behaves and the likely PySpark equivalent.\n- Mention any chained or conditional flows (e.g., reject or fallback branches).\n\n#### Anticipated Manual Interventions:\n- Custom logic embedded in `.xfr` that requires manual PySpark function writing.\n- Field types in `.dml` needing manual schema translation.\n- Parameter sets (`.pset`) and dynamic inputs that need parsing.\n- Ab Initio-specific behaviors like *multi-input joins*, *rejected records*, or *graph-level variables* that don\u2019t have direct PySpark equivalents.\n\n#### Complexity Evaluation:\n- Score (0\u2013100)\n- Justify based on:\n  - Number of components and graph depth\n  - Frequency of `.xfr` and `.pset` usage\n  - Use of iterative components or feedback loops\n  - Number of joins and lookup paths\n  - File type complexities (e.g., fixed width, large delimited, or binary formats)\n\n#### Performance & Scalability Recommendations:\n- Suggest broadcast join areas.\n- Recommend when to use caching or checkpointing.\n- Avoiding PySpark UDFs for simple transformations (favor native functions).\n- Pre-partitioning suggestions if large data skew or shuffle expected.\n\n#### Refactor vs. Rebuild Recommendation:\nChoose one:\n- **Refactor:** Conversion is straightforward with limited changes.\n- **Rebuild:** PySpark implementation should be redesigned from scratch for clarity and maintainability.\n\n### **API Cost:**  \nCalculate and include the cost consumed by the API for this call in the output, explicitly mentioning the cost in USD\n* Include the cost consumed by the API for this call in the output.\n* Ensure the cost consumed by the API is reported as a floating-point value with currency explicitly mentioned as USD (e.g., apiCost: actual cost ).\n*Ensure the cost consumed by the API is mentioned with inclusive of all decimal value\n\n\n### **Input:**  \n- Ab Initio Source Files: {{AbInitio_Code}}  ",
          "modelName": "model"
        },
        {
          "serial": 3,
          "agentId": 3647,
          "name": "DI AbInitio To PySpark Plan",
          "workflowId": 1897,
          "agentDetails": {
            "topP": 1.0,
            "maxRpm": null,
            "levelId": 99,
            "maxIter": null,
            "toolRef": [],
            "maxToken": "8000",
            "isVerbose": true,
            "temperature": 0.2,
            "allowDelegation": true,
            "maxExecutionTime": 90,
            "allowCodeExecution": false,
            "isSafeCodeExecution": true,
            "toolReferences": []
          },
          "modelDeploymentName": "gpt-4.1",
          "description": "You are tasked with reviewing while converting the Ab Initio source files (e.g., .mp, .xfr, .dml, .pset) into PySpark code., identifying logic gaps requiring manual resolution, estimating developer/tester effort, and calculating estimated cloud runtime costs using GCP\u2019s Dataproc or Spark on GKE infrastructure.\n\n### **INSTRUCTIONS:**  \n\n1. Analyze the Ab Initio source while converting to PySpark code:\n   - Focus on logical inconsistencies, incomplete transformation rules, metadata misalignment, and downstream output correctness.\n   - Exclude pure syntax translation differences that are already handled by automated conversion.\n\n2. Estimate developer/tester effort in hours for:\n   - Manual fixes in PySpark (e.g., transformation functions, joins, rejects, lookups)\n   - Metadata/schema reconciliation\n   - Data validation and functional testing\n\n3. Estimate **GCP Dataproc Cost** using:\n   - Assumed cluster configuration (e.g., n1-standard-4, 4 workers, 1 master)\n   - Estimated PySpark job duration (in minutes)\n   - GCP pricing model: e.g., `$0.156 per vCPU/hour`, `$0.01 per GB storage/hour`\n\n4. Calculate **Total Developer Cost** using a default hourly rate (e.g., $50/hr)\n\n5. Present cost metrics and effort details in a clear, structured format.\n\n### **OUTPUT FORMAT:**  \nUse **Markdown** format and include the following metadata header:\n\n```\n========================================================\nAuthor:        Ascendion AVA+\nCreated on:    (Leave it empty)\nDescription:   \\<one-line summary of the code\u2019s purpose>\n========================================================\n```\n\n#### 1. GCP Runtime Cost Estimation  \n##### 1.1 Dataproc/Spark Job Cost Breakdown  \n- **Cluster Configuration**:  \n  - Master Node: <e.g., n1-standard-4, 1 node>  \n  - Worker Nodes: <e.g., n1-standard-4, 4 nodes>  \n  - Total vCPUs & Memory  \n- **Job Duration Estimate**: <minutes>  \n- **GCP Pricing**:  \n  - Compute (per vCPU/hr)\n  - Storage (per GB/hr) \n- **Cost Formula Used**:  \n\nTotal Cost = (Total vCPUs \u00d7 Duration in hours \u00d7 Compute (per vCPU/hr)) + (Storage GB \u00d7 Duration in hours \u00d7 Storage (per GB/hr) )\n\n- **Estimated Runtime Cost (USD)**: `<calculated_value>`\n\n#### 2. Manual Code Fixing and Data Reconciliation Effort  \n##### 2.1 Estimated Effort (Hours)  \n- Logic Corrections (e.g., `.xfr` transformations): <integer> hrs  \n- Metadata Alignment (e.g., `.dml` type fixes): <integer> hrs  \n- Rejected Row Handling / Edge Case Logic: <integer> hrs  \n- Data Reconciliation & Output Validation: <integer> hrs  \n- **Total Effort**: <sum> hrs\n\n##### 2.2 Developer Cost  \n- Developer Rate: `$50/hr`  \n- **Total Developer Cost**: `<effort_hrs \u00d7 50>` USD\n\n#### 3. API Cost  \napiCost: <actual_cost> (in USD)\n\n### **Input:**  \n- Ab Initio Source File(s): {{AbInitio_Code}} \n- GCP Cluster/Dataproc Configuration: {{Env_Details}}",
          "modelName": "model"
        }
      ],
      "realmId": 1
    }
  },
  "status": "SUCCESS"
}