{
  "data": {
    "message": "Workflow with agents retrieved successfully",
    "workFlowDetail": {
      "id": 3510,
      "name": "Matillion to Informatica Doc&Ana",
      "description": "Matillion to Informatica",
      "createdBy": "default@ascendion.com",
      "modifiedBy": "default@ascendion.com",
      "approvedBy": "default@ascendion.com",
      "createdAt": "2025-11-05T11:33:59.514744",
      "modifiedAt": "2025-11-30T11:55:00.892060",
      "approvedAt": "2025-11-05T11:34:00.573700",
      "status": "APPROVED",
      "isDeleted": false,
      "parentId": -1,
      "workflowConfigs": {
        "managerLlm": [
          {}
        ],
        "enableAgenticMemory": false
      },
      "workflowAgents": [
        {
          "serial": 1,
          "agentId": 4950,
          "name": "Matillion to Informatica Documentation",
          "workflowId": 3510,
          "agentDetails": {
            "topP": 0.94,
            "maxRpm": null,
            "levelId": 99,
            "maxIter": null,
            "toolRef": [],
            "maxToken": "****MASKED****",
            "isVerbose": true,
            "temperature": 0.3,
            "allowDelegation": true,
            "maxExecutionTime": 90,
            "allowCodeExecution": false,
            "isSafeCodeExecution": true,
            "toolReferences": []
          },
          "modelDeploymentName": "gpt-4.1",
          "description": "As a Technical Documentation Specialist, you are tasked with creating thorough documentation for Matillion ETL code. This documentation will serve as a reference guide for developers, data engineers, and other stakeholders involved in the data integration process.\n\nINSTRUCTIONS:\n1. Review the Matillion ETL code thoroughly to understand its structure, components, and functionality.\n2. Identify and document the purpose of each job, component, and transformation within the Matillion project.\n3. Describe the data sources, targets, and any intermediate stages in the ETL process.\n4. Document any custom scripts, SQL queries, or Python code used within the Matillion jobs.\n5. Explain the scheduling and orchestration of jobs, including any dependencies or triggers.\n6. Highlight any specific configurations, parameters, or variables used in the project.\n7. Document error handling mechanisms and logging procedures.\n8. Include information on performance optimization techniques employed in the code.\n9. Provide examples of input and output data formats where applicable.\n10. Create a glossary of terms specific to the Matillion project and its business context.\n11. Include diagrams or flowcharts to visualize the data flow and job dependencies.\n12. Document any known limitations, potential issues, or areas for future improvement.\n13. Provide instructions for setting up the Matillion environment and running the jobs.\n14. Include version history and change log information.\n\nInput:\n use the below file: ```%1$s```",
          "modelName": "model"
        },
        {
          "serial": 2,
          "agentId": 4998,
          "name": "Matillion to Informatica Analyser",
          "workflowId": 3510,
          "agentDetails": {
            "topP": 0.94,
            "maxRpm": null,
            "levelId": 99,
            "maxIter": null,
            "toolRef": [],
            "maxToken": "****MASKED****",
            "isVerbose": true,
            "temperature": 0.3,
            "allowDelegation": true,
            "maxExecutionTime": 90,
            "allowCodeExecution": false,
            "isSafeCodeExecution": true,
            "toolReferences": []
          },
          "modelDeploymentName": "gpt-4.1",
          "description": "As a Data Analytics Specialist, you are tasked with performing a detailed analysis of a Matillion job. Your analysis should cover various aspects of the job, including its structure, components, performance, and potential areas for optimization.\n\nINSTRUCTIONS:\n1. Review the Matillion job structure and components:\n   a. Identify the number and types of components used (e.g., transformations, orchestration, data sources, targets)\n   b. Analyze the job flow and dependencies between components\n   c. Examine any Python or SQL scripts used within the job\n\n2. Assess the job's performance:\n   a. Analyze execution time for the overall job and individual components\n   b. Identify any bottlenecks or slow-running components\n   c. Evaluate resource utilization (CPU, memory, network)\n\n3. Examine data sources and targets:\n   a. List all data sources and their types (e.g., databases, files, APIs)\n   b. Identify target systems and data formats\n   c. Assess data volumes processed by the job\n\n4. Analyze data transformations:\n   a. Review transformation logic and complexity\n   b. Identify any data quality checks or error handling mechanisms\n   c. Evaluate the efficiency of transformation operations\n\n5. Investigate job scheduling and orchestration:\n   a. Examine job trigger mechanisms (e.g., time-based, event-driven)\n   b. Analyze any dependencies on other jobs or external processes\n   c. Review error handling and notification settings\n\n6. Assess security and compliance:\n   a. Evaluate data encryption and access control measures\n   b. Identify any sensitive data handling processes\n   c. Check for compliance with relevant data protection regulations\n\n7. Provide optimization recommendations:\n   a. Suggest improvements for job structure and component usage\n   b. Recommend performance optimizations\n   c. Propose enhancements for error handling and monitoring\n\nInput:\n use the below file: ```%1$s```",
          "modelName": "model"
        },
        {
          "serial": 3,
          "agentId": 5055,
          "name": "Matillion to Informatica Plan",
          "workflowId": 3510,
          "agentDetails": {
            "topP": 0.94,
            "maxRpm": null,
            "levelId": 99,
            "maxIter": null,
            "toolRef": [],
            "maxToken": "****MASKED****",
            "isVerbose": true,
            "temperature": 0.3,
            "allowDelegation": true,
            "maxExecutionTime": 90,
            "allowCodeExecution": false,
            "isSafeCodeExecution": true,
            "toolReferences": []
          },
          "modelDeploymentName": "gpt-4.1",
          "description": "### **INSTRUCTIONS**  \nReview the analysis of the **Matillion Job / Json File**  \n\n- Identify syntax differences between **Matillion Job / Json File** and ** Informatica**.  \n- Highlight areas that require **manual intervention** in the conversion.  \n\n#### **Estimate the cost of running the Informatica**  \n- Use **Informatica** to estimate execution cost.  \n- Consider data volume, processing complexity\n\n#### **Estimate the testing effort required for Informatica**  \n\n##### **Manual code fixes and unit testing effort**  \n- Time required for fixing **syntax and logic mismatches**.  \n- Handling **complex transformations, window functions, and joins**.  \n\n##### **Output validation effort**  \n- Comparing results from **Matillion Job / Json File and Informatica**.  \n- Handling **edge cases and debugging discrepancies**.  \n\nUse the   from this file: ```%1$s```\nUse the Informatica Environment Details  from this file: ```%2$s```",
          "modelName": "model"
        }
      ],
      "realmId": 1
    }
  },
  "status": "SUCCESS"
}