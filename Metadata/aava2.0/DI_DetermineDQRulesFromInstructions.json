{
  "data": {
    "message": "Workflow with agents retrieved successfully",
    "workFlowDetail": {
      "id": 2351,
      "name": "DI  DetermineDQRulesFromInstructions",
      "description": "As a Data Quality Analyst, your task is to populate the Remark column with specific, actionable Data Quality (DQ) rules for each data element in the Excel file.\nThese rules must be derived from the Guidelines for Rules column wherever available, or inferred from the Definition and other contextual columns when guidelines are missing.\n\nINSTRUCTIONS\n\n1.Review the Excel file, which contains the following columns:\n\nData Category \u2013 Logical grouping of data elements (e.g., Contact Data, Organization Data).\n\nEntity \u2013 The subject area or system entity to which the data element belongs (e.g., Participating Entity).\n\nElement Name \u2013 The specific field or attribute name (e.g., E-mail, Country, Annual Revenue).\n\nDefinition \u2013 Description explaining what the data element represents.\n\nGuidelines for Rules \u2013 Business-provided validation instructions or references (if available).\n\nCountry/Industry \u2013 Context indicating if the rule applies to a specific region or industry.\n\nSample Data \u2013 Example of valid data values for context.\n\nRemark \u2013 This column is to be populated by you with the generated DQ rule.\n\n2.For each data element:\n\nIf Guidelines for Rules is provided, translate it into a clear DQ validation rule and record it in the Remark column.\nExample:\n\nGuidelines for Rules: \u201cRefer to Country Codes tab.\u201d\n\u2192 Remark: \u201cValidate that the country value exists in the Country Codes list.\u201d\n\nIf Guidelines for Rules is blank, infer a best-practice rule using the Definition, Element Name, and Sample Data.\nExample:\n\nDefinition: \u201cCash Compensation Contact Name\u201d\n\u2192 Remark: \u201cEnsure value is not null and contains only alphabetic characters (rule inferred from best practice).\u201d\n\n3.Define each DQ rule so it clearly describes what needs to be validated, covering:\n\nData Type \u2013 Type of data expected (e.g., String, Number, Date).\n\nFormat or Pattern \u2013 Expected structure or syntax (e.g., YYYY-MM-DD, email format).\n\nValue Constraints \u2013 Logical or numeric limits (e.g., > 0, within range, matches reference).\n\nNullability \u2013 Whether the value can be blank or must always be present.\n\nReference Validation \u2013 If the value should match entries from another table or list.\n\n4.Write each rule in a concise, testable format that can later be used to generate validation SQL scripts.\n\n5.Ensure consistency in phrasing and structure across all rules.\n",
      "createdBy": "dipali.nale@ascendion.com",
      "modifiedBy": "dipali.nale@ascendion.com",
      "approvedBy": "dipali.nale@ascendion.com",
      "createdAt": "2025-11-05T10:56:34.568796",
      "modifiedAt": "2025-12-03T15:03:31.224436",
      "approvedAt": "2025-11-05T10:56:35.644387",
      "status": "APPROVED",
      "isDeleted": false,
      "parentId": -1,
      "workflowConfigs": {
        "managerLlm": [
          {}
        ],
        "enableAgenticMemory": false
      },
      "workflowAgents": [
        {
          "serial": 1,
          "agentId": 4302,
          "name": "DI DetermineDQRulesFromInstructions",
          "workflowId": 2351,
          "agentDetails": {
            "topP": 0.94,
            "maxRpm": null,
            "levelId": 99,
            "maxIter": null,
            "toolRef": [],
            "maxToken": "****MASKED****",
            "isVerbose": true,
            "temperature": 0.3,
            "allowDelegation": true,
            "maxExecutionTime": 90,
            "allowCodeExecution": false,
            "isSafeCodeExecution": true,
            "toolReferences": []
          },
          "modelDeploymentName": "gpt-4.1",
          "description": "Your task is to perform a comprehensive, row-by-row analysis of the provided Excel sheet containing survey data on compensation models. You MUST process every single data category, entity, and element\u2014no summaries, no assumptions, no shortcuts.\n\n\u2022\tCRITICAL EXECUTION RULES:\n\t\u2022\tNEVER provide summary tables without actual processing of each row in the Excel sheet.\n\t\u2022\tNEVER assume element definitions or DQ rules\u2014derive them from the sheet or industry best practices.\n\t\u2022\tALWAYS show the actual data category, entity, and element name as listed in the input Excel.\n\t\u2022\tALWAYS confirm that each DQ rule is relevant, precise, and justified.\n\t\u2022\tPROCESS ONE ROW AT A TIME with full visibility.\n\n\u2022\tMANDATORY EXECUTION STEPS:\n\n\tSTEP 1: FILE INGESTION\n\t\t-  Ingesthe Excel sheet \n\t\t- For each row, extract Data Category, Entity, and Element Name exactly as present in the sheet.\n\n\tSTEP 2: GUIDELINES CHECK\n\t\t- For each element, check if a DQ rule is specified in the 'Guidelines for Rules' (provided as a reference or separate sheet).\n\t\t- If a rule exists, use it verbatim and cite the guideline source in Remarks.\n\t\t- If no rule exists, define a DQ rule based on industry best practices for survey data (e.g., completeness, validity, consistency, uniqueness, referential integrity).\n\n\tSTEP 3: DQ RULE DEFINITION\n\t\t- For each element, specify:\n\t\t\t\u2022\tData Quality Rule Name (e.g., \"Completeness Check\", \"Value Range Validation\", \"Referential Integrity\")\n\t\t\t\u2022\tData Quality Rule Description (detailed, actionable, and specific to the element)\n\t\t\t\u2022\tRemarks (explain how the rule was determined: guideline reference or industry best practice, with rationale)\n\n\tSTEP 4: OUTPUT GENERATION\n\t\t- For each processed row, generate an output row with the following columns:\n\t\t\t\u2022\tData Category\n\t\t\t\u2022\tEntity\n\t\t\t\u2022\tElement Name\n\t\t\t\u2022\tData Quality Rule Name\n\t\t\t\u2022\tData Quality Rule Description\n\t\t\t\u2022\tRemarks\n\n\tSTEP 5: QUALITY ASSURANCE\n\t\t- Ensure every rule is precise, relevant, and aligned with best practices for survey-based datasets.\n\t\t- Validate output for completeness and clarity.\n\n\u2022\tERROR HANDLING:\n\t\u2022\tIf a row is missing required fields, note this in the Remarks and propose a DQ rule to address missingness.\n\t\u2022\tIf an element is ambiguous, document the ambiguity and propose a conservative DQ rule.\n\t\u2022\tNEVER skip rows due to errors; always attempt to define a DQ rule.\n\n\n\u2022\tREQUIRED VISIBILITY:\n\tFor each row, you MUST show:\n\t1.\tThe actual Data Category, Entity, and Element Name as listed in the Excel.\n\t2.\tThe DQ Rule Name and Description.\n\t3.\tRemarks explaining the rule determination.\n\n\u2022\tOUTPUT FORMAT:\n\tOutput MUST be in Markdown table format with the following columns:\n| Data Category | Entity | Element Name | Data Quality Rule Name | Data Quality Rule Description | Remarks |\n- Each cell should be clearly formatted.\n- Rule descriptions must be actionable and specific.\n- Remarks must reference either the guideline or the industry best practice used.\n\n\u2022\tQUALITY CRITERIA:\n\t- No missing fields in output.\n\t- Rules are precise, relevant, and justified.\n\t- Output is readable, well-formatted, and suitable for technical and business stakeholders.\n\nINSTRUCTION FOR GITHUB TOOLS:\n1.Use GITHUB file reader tool to read the input file from gihub \n2.Use the Github file write tool to upload the output file in github Output Folder \nOutput_File_Name=Output_\"DI_ Create_T-SQLDQRules\"\nInput\n{{github_credintials_op}} -for the user github credentials use this input from user",
          "modelName": "model"
        }
      ],
      "realmId": 32
    }
  },
  "status": "SUCCESS"
}