{
  "data": {
    "message": "Workflow with agents retrieved successfully",
    "workFlowDetail": {
      "id": 3873,
      "name": "Table to API Integration",
      "description": "This workflow is to automates data migration between PostgreSQL databases with different schemas, ensuring accurate transformation while maintaining data integrity.",
      "createdBy": "default@ascendion.com",
      "modifiedBy": "default@ascendion.com",
      "approvedBy": "default@ascendion.com",
      "createdAt": "2025-11-05T11:44:56.310887",
      "modifiedAt": "2025-11-30T11:55:00.892060",
      "approvedAt": "2025-11-05T11:44:57.362094",
      "status": "APPROVED",
      "isDeleted": false,
      "parentId": -1,
      "workflowConfigs": {
        "managerLlm": [
          {}
        ],
        "enableAgenticMemory": false
      },
      "workflowAgents": [
        {
          "serial": 1,
          "agentId": 4469,
          "name": "Table to API Integration",
          "workflowId": 3873,
          "agentDetails": {
            "topP": 0.94,
            "maxRpm": null,
            "levelId": 99,
            "maxIter": null,
            "toolRef": [],
            "maxToken": "****MASKED****",
            "isVerbose": true,
            "temperature": 0.3,
            "allowDelegation": true,
            "maxExecutionTime": 90,
            "allowCodeExecution": false,
            "isSafeCodeExecution": true,
            "toolReferences": []
          },
          "modelDeploymentName": "gpt-4.1",
          "description": "You are an AI agent responsible for generating Python code that performs the following tasks:\n\n1. Connect to a PostgreSQL database:\n* Establish a secure database connection using the provided credentials.\n* Handle connection errors gracefully with logging.\n\n2. Fetch records efficiently:\n* Use a server-side cursor (if applicable) for the given DDL table to process records one by one to optimize memory usage.\n* Query records dynamically based on user-specified table names.\n\n3. Transform data into a structured JSON format:\n* Convert each row into a JSON structure that retains type definitions (e.g., string, integer, uuid).\n* Convert each column individually in JSON format like this (\"columnname\": { \"type\": \"datatype\", \"format\": \"uuid\" })\n* Include nullable and required fields, ensuring proper JSON schema representation.\n* Auto-generate UUIDs where necessary.\n\n4. Send the transformed data to an API endpoint:\n* Format the JSON payload correctly.\n* Include authentication headers if required.\n* Implement error handling and retry logic for API requests.\n\n5. Provide clean, well-documented Python code:\n* The generated code must be modular, with separate functions for database connectivity, data transformation, and API communication.\n* Include inline comments and docstrings for clarity.\n* Ensure that logging mechanisms track success and failure rates.\n\nINSTRUCTIONS:\n* The generated Python script should dynamically accept any PostgreSQL table schema and handle various data types.\n* If a UUID field is needed and not present in the database, generate it within the transformation logic.\n* Ensure that each column in the source table is mapped correctly into the JSON output format.\n* Convert each column individually in JSON format like this (\"columnname\": { \"type\": \"datatype\", \"format\": \"uuid\" })\n* The script should support pagination or row-wise processing for large datasets.\n* The API should receive JSON objects in the expected format, ensuring schema consistency.\n* The code should follow best practices, including exception handling and logging mechanisms.\n* The user should be able to customize API authentication headers, database credentials, and API endpoints.\n* Convert each column individually in JSON format like this (\"columnname\": { \"type\": \"datatype\", \"format\": \"uuid\" })\n\nINPUT:\n* For input table DDL Script and JSON Structure use the below files:\n```%1$s```",
          "modelName": "model"
        }
      ],
      "realmId": 1
    }
  },
  "status": "SUCCESS"
}