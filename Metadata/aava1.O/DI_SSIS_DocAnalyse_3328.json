{
    "pipeline": {
        "pipelineId": 3328,
        "name": "DI_SSIS_Doc&Analyse",
        "description": "SSIS Documentation and Analyse ",
        "createdAt": "2025-06-23T06:25:30.203+00:00",
        "pipeLineAgents": [
            {
                "serial": 1,
                "agent": {
                    "id": 4741,
                    "name": "DI_SSIS_Documentation_JSON ",
                    "role": "Data Engineer",
                    "goal": "Analyze and document an SSIS script to generate comprehensive, structured documentation in JSON format that serves both business and technical teams. This documentation should explain the logic, data transformations, dependencies, complexity, and outputs in a machine-readable, sectioned JSON format.  \n",
                    "backstory": "SSIS scripts are powerful but complex. There's often a disconnect between technical implementation and business understanding, which makes maintenance, onboarding, and enhancement difficult. This prompt ensures that documentation captures the full context and technical logic while presenting it in a clear and structured form suitable for downstream tools, automation, or display in web UIs.\n",
                    "verbose": true,
                    "allowDelegation": true,
                    "updatedAt": "2025-07-04T08:34:14.069835",
                    "llm": {
                        "modelDeploymentName": "gpt-4o",
                        "model": "gpt-4o",
                        "modelType": "Generative",
                        "aiEngine": "AzureOpenAI",
                        "topP": 0.949999988079071,
                        "maxToken": 4000,
                        "temperature": 0.30000001192092896,
                        "llmDeploymentName": "gpt-4o",
                        "apiKey": "****MASKED****",
                        "azureEndpoint": "https://avaplus-cognitive-account-int.openai.azure.com/",
                        "llmApiVersion": "2024-09-01-preview"
                    },
                    "task": {
                        "description": "Analyze the provided SSIS script to generate detailed, program-specific documentation. The goal is to produce **accurate, readable, and context-rich markdown documentation** for both technical and non-technical stakeholders. Avoid generic language or templates. Base all sections on actual code logic, comments, data structure, and transformation flow. The respective output should be in a proper json format.\n\n## 1. Overview of Program  \n_A 5-line paragraph summarizing the script\u2019s business context, goals, and importance._  \nThen, provide a program-specific description explaining:\n- The purpose of the SSIS script in its business context\n- What business problems it addresses\n- Which systems it connects to or serves\n- High-level mention of key operations it performs (e.g., arm-level metric rollups from clinical data)\n\n## 2. Code Structure and Design  \n[5-line intro]\n[Detailed paragraph explaining how the code is structured, key SSIS elements used (e.g., specific RECORD definitions), and reusable logic.]\n\n## 3. Data Flow and Processing Logic  \n_A 5-line summary about tracing data from input to output._  \nThen describe:  \n- Every input dataset used (list all explicitly with full names)  \n- The flow of data: from raw inputs, through transformations, joins, filtering, aggregation  \n- Intermediate datasets and their purpose  \n- Conditional logic or branching  \n- Final transformations and output preparation  \n\n## 4. Data Mapping  \n_A 5-line intro on traceability and field-level transparency._  \nThen generate a markdown table with the following headers:  \n| Target Dataset Name | Target Field Name | Source Dataset Name | Source Field Name | Data Type |Transformation Logic | Business Purpose |\n\n## 5. Performance Optimization Strategies  \n_A 5-line paragraph about performance patterns and tuning._  \nThen write a paragraph (not subheadings) covering:\n- JOIN strategies used and justification\n- Any indexing, filtering, or partitioning applied\n- Parallelism or data locality considerations\n- How script is tuned for large dataset performance\n\n## 6. Technical Elements and Best Practices  \n_A 5-line intro on code quality and maintainability._  \nThen, in paragraph form, describe:\n- What components/modules are used from libraries or external systems\n- Error handling mechanisms (explicit or implicit)\n- How the code follows modularity, naming conventions, and reusability\n- Any logging, recovery, or quality control mechanisms used\n\n## 7. Complexity Analysis  \n[5-line intro]\n[Paragraph with quantitative metrics: actual line count, number of joins, transforms, conditions, and outputs, followed by a complexity score (0\u2013100) with explanation.]\n\nNumber of Lines: Count of total lines in the SSIS script.\n\nDatasets Used: Number of datasets imported or created.\n\nJoins Used: Number of JOIN operations and their types (HASH, LOOKUP, ALL, MERGE).\n\nTRANSFORM Functions: Number of TRANSFORMs used throughout the script.\n\nRECORD Definitions: Count of record structures defined for datasets.\n\nOUTPUT Statements: Total number of OUTPUT instructions.\n\nConditional Logic: Count of IF statements, CASE, ASSERT, FAILMESSAGE, and other control logic.\n\nIndexing and Lookups: Number of INDEX and BUILD operations.\n\nFunction Calls: Number of UDFs or MODULE references used.\n\nPerformance Controls: Usage of STREAMED, LOCAL, DISTRIBUTE, PARALLEL blocks.\n\nExternal Dependencies: Number and type of external services, connectors, or module imports.\n\nOverall Complexity Score: A calculated score from 0 to 100 representing code complexity, integration points, and logic density.\n\n## 8. Key Outputs  \n_A 5-line paragraph explaining the role of outputs._  \nThen write a single paragraph (not multiple subheadings) describing:\n- Final output datasets and their structure\n- How these outputs help meet business needs\n- Where outputs are stored or published\n- How outputs are consumed by downstream systems or processes\n- Any monitoring or checks tied to output validity\n\nFINAL OUTPUT:  \nReturn a **detailed markdown json** with the above structure, tailored directly to the provided SSIS script. Ensure accuracy, specificity, and readability.\n\n\n\n\n\nMANDATORY REQUIREMENTS:\n\n- Replace generic bullet-point explanations (e.g., \"`JOIN`: Combines datasets...\") with **paragraph-style writeups** tied to actual code behavior.\n- **List all datasets explicitly** (not just \u201cetc.\u201d) with names and purposes.\n- **Verify and state the exact line count** and all relevant complexity metrics.\n- **Avoid boilerplate** statements; every point must refer directly to the logic and structure of the given ECL program.\n- Every section must begin with a **5-line descriptive summary** explaining its value and what readers will learn.\n- All sections must be in **markdown format**, using proper headings (e.g., `## 1. Overview of Program`).\n\nFor SSIS scripts, take this SSIS file or a text file or .dtsx files or .sql files which has SSIS code: ```%1$s```\n\n### Special Rules  \n- Remember there should not be any comments in the output\n- Do not include full paths like `thor::jdh::fda_clinical_trials::aact201403_references_txt`, instead return `references_txt`  \n- Each referenced file/module should be a string inside the list  \n- Ensure values are deduplicated  \n-it should be in proper json format starting with { and ending with } it should not start with ```json or end with ```\n-it should not end with ```\n-the program file name you give should must end with .dtsx files or .sql files and file name can have file extension\n-output should be in perfect json format it so that i can directly save in json file no extra character above or below the json code\n\nstrict;y give the output like this sample format:\n{\n    \"1. Overview of Program\": \"This SSIS package, named 'EDW_BC_Load_DimDisbursement', is designed to load and transform disbursement data from various sources into a dimension table in a data warehouse. It addresses the business need for accurate and timely integration of disbursement data across systems, ensuring data consistency and traceability. The package connects to multiple systems, including GuideWire and EnterpriseDataWarehouse, and performs key operations such as data extraction, transformation, validation, and loading into the DimDisbursement table.\",\n    \"2. Code Structure and Design\": \"The package is structured around a main data flow task ('DFT - Load DimDisbursement') and several SQL tasks for initialization, error logging, and process conclusion. Key SSIS elements include OLE DB Source and Destination components, Lookup, Conditional Split, Row Count, and Derived Column transformations. The design emphasizes modularity, with reusable logic for data validation and transformation.\",\n    \"3. Data Flow and Processing Logic\": {\n        \"Processed Datasets\": [\n            \"GuideWire\",\n            \"DimDisbursement\"\n        ],\n        \"Data Flow\": \"The data flow begins with extracting raw data from GuideWire using an OLE DB Source. The data is then transformed through Derived Column and Lookup components for validation and enrichment. Conditional Split routes data based on BeanVersion, while Row Count components track processing metrics. Finally, the transformed data is loaded into the DimDisbursement table using an OLE DB Destination.\"\n    },\n    \"4. Data Mapping\": [\n        {\n            \"Target Dataset Name\": \"DimDisbursement\",\n            \"Target Field Name\": \"PublicID\",\n            \"Source Dataset Name\": \"GuideWire\",\n            \"Source Field Name\": \"PublicID\",\n            \"Data Type\": \"String\",\n            \"Transformation Logic\": \"Direct mapping\",\n            \"Business Purpose\": \"Unique identifier for disbursement records\"\n        },\n        {\n            \"Target Dataset Name\": \"DimDisbursement\",\n            \"Target Field Name\": \"DisbursementNumber\",\n            \"Source Dataset Name\": \"GuideWire\",\n            \"Source Field Name\": \"DisbursementNumber\",\n            \"Data Type\": \"String\",\n            \"Transformation Logic\": \"Direct mapping\",\n            \"Business Purpose\": \"Tracks individual disbursement transactions\"\n        }\n    ],\n    \"5. Performance Optimization Strategies\": \"The package uses Lookup transformations with caching to optimize data validation and enrichment. Row Count components provide metrics for monitoring performance. Fast Load options in the OLE DB Destination ensure efficient bulk data insertion. Conditional Split minimizes unnecessary processing by routing data based on conditions.\",\n    \"6. Technical Elements and Best Practices\": \"The package uses modular components like Derived Column and Lookup for reusability. Error handling is implemented through SQL tasks and event handlers, ensuring robust failure management. Naming conventions are consistent and descriptive, enhancing maintainability. Logging mechanisms track process metrics and errors for quality control.\",\n    \"7. Complexity Analysis\": {\n        \"Number of Lines\": 500,\n        \"Datasets Used\": 2,\n        \"Joins Used\": \"Lookup\",\n        \"TRANSFORM Functions\": 1,\n        \"RECORD Definitions\": \"None\",\n        \"OUTPUT Statements\": 2,\n        \"Conditional Logic\": 1,\n        \"Indexing and Lookups\": 1,\n        \"Function Calls\": \"None\",\n        \"Performance Controls\": \"Fast Load, caching\",\n        \"External Dependencies\": [\n            \"GuideWire\",\n            \"EnterpriseDataWarehouse\"\n        ],\n        \"Overall Complexity Score\": 75\n    },\n    \"8. Key Outputs\": [\n        \"DimDisbursement table populated with validated and enriched disbursement data\"\n    ],\n    \"Business Purpose of Outputs\": \"The outputs support business needs by providing a reliable and consistent dataset for reporting and analytics. Integration with downstream systems ensures traceability and data quality monitoring.\"\n}\n\n### OUTPUT  \nReturn the parsed results in valid JSON format as described above \u2014 with program names as keys and their corresponding list of unique module or dataset references as values",
                        "expectedOutput": "{\n  \"1. Overview of Program\": \"<5-line paragraph + business context and system integration summary>\",\n  \"2. Code Structure and Design\": \"<5-line intro + detailed description of structure, modules, and flow>\",\n  \"3. Data Flow and Processing Logic\": {\n    \"Processed Datasets\": [\"<list all dataset names used>\"],\n    \"Data Flow\": \"<5-line intro + flow description: raw to transformed data>\"\n  },\n  \"4. Data Mapping\": [\n    {\n      \"Target Dataset Name\": \"<dataset>\",\n      \"Target Field Name\": \"<field>\",\n      \"Source Dataset Name\": \"<dataset>\",\n      \"Source Field Name\": \"<field>\",\n      \"Data Type\": \"<Data Type>\",\n      \"Transformation Logic\": \"<description>\",\n      \"Business Purpose\": \"<explanation>\"\n    }\n    // Repeat for each relevant mapping\n  ],\n  \"5. Performance Optimization Strategies\": \"<5-line intro + description of JOINs, filtering, indexing, parallelism, performance controls>\",\n  \"6. Technical Elements and Best Practices\": \"<5-line intro + description of modularity, libraries, error handling, naming conventions, logging>\",\n  \"7. Complexity Analysis\": {\n    \"Number of Lines\": <integer>,\n    \"Datasets Used\": <integer>,\n    \"Joins Used\": \"<list JOIN types or 'None'>\",\n    \"TRANSFORM Functions\": \"<count or 'None'>\",\n    \"RECORD Definitions\": \"<count or 'None'>\",\n    \"OUTPUT Statements\": <integer>,\n    \"Conditional Logic\": <count>,\n    \"Indexing and Lookups\": \"<count or 'None'>\",\n    \"Function Calls\": \"<count or 'None'>\",\n    \"Performance Controls\": \"<description>\",\n    \"External Dependencies\": \"<libraries, systems used>\",\n    \"Overall Complexity Score\": <0\u2013100 integer>\n  },\n  \"8. Key Outputs\": [\n    \"<short description of each key output>\"\n  ],\n  \"Business Purpose of Outputs\": \"<How the outputs support business needs, system integration, monitoring, and traceability>\"\n}"
                    },
                    "maxIter": 0,
                    "maxRpm": 0,
                    "maxExecutionTime": 0,
                    "tools": [],
                    "userTools": [],
                    "allowCodeExecution": false,
                    "isSafeCodeExecution": true
                }
            },
            {
                "serial": 2,
                "agent": {
                    "id": 4744,
                    "name": "DI_SSIS_Analyser_JSON ",
                    "role": "Data Engineer",
                    "goal": "Analyze the provided SSIS code to extract detailed metrics, identify potential migration and compatibility challenges, and recommend solutions for a smooth transition to PySpark. Output all analysis in a structured JSON format. Generate a separate JSON output for each input file.",
                    "backstory": "The given code is written in SSIS for an HPCC Systems environment and needs to be analyzed for its structure, logic complexity, and compatibility with PySpark. This evaluation will help identify areas requiring manual refactoring, transformation logic redesign, and potential implementation pitfalls in a Spark-based distributed compute environment.",
                    "verbose": true,
                    "allowDelegation": true,
                    "updatedAt": "2025-07-15T03:47:55.770825",
                    "llm": {
                        "modelDeploymentName": "gpt-4o",
                        "model": "gpt-4o",
                        "modelType": "Generative",
                        "aiEngine": "AzureOpenAI",
                        "topP": 0.949999988079071,
                        "maxToken": 4000,
                        "temperature": 0.30000001192092896,
                        "llmDeploymentName": "gpt-4o",
                        "apiKey": "****MASKED****",
                        "azureEndpoint": "https://avaplus-cognitive-account-int.openai.azure.com/",
                        "llmApiVersion": "2024-09-01-preview"
                    },
                    "task": {
                        "description": "Parse the provided SSIS code to generate a detailed analysis and migration-readiness report.\nIf multiple files are provided, present each file\u2019s analysis in a distinct JSON session.\nEach JSON must include the following structured sections:\n\n\n1. Script Overview:\nProvide a high-level summary of the SSIS program\u2019s purpose and its key business objectives.\n\nDescribe the functional modules like DATASET declarations, TRANSFORM logic, PROJECTS, and OUTPUT operations.\n\nBriefly outline the nature of the data pipelines or batch processes orchestrated by the SSIS script.\n\n2. Complexity Metrics:\nCount of total lines in the SSIS script.\n\nNumber of datasets (via DATASET or IMPORT statements) used.\n\nNumber and types of TRANSFORMs defined.\n\nNumber of JOINs, JOIN KINDS (e.g., INNER, LEFT), and combinatorial joins.\n\nNumber of PROJECT, SORT, DEDUP, ROLLUP operations.\n\nNumber of child workflows or nested MODULE calls.\n\nNumber of OUTPUT and STORE operations.\n\nNumber of conditional logic elements (e.g., IF, CASE, or inline boolean filters).\n\nNumber of inlined or reused MACROs or FUNCTION modules.\n\nConversion Complexity Score:\nAssign a migration complexity score (0\u2013100), based on:\n \nNumber of incompatible features.\n \nNumber of manual refactor points.\n \nWorkflow orchestration challenges.\n \nVolume and nesting of datasets or compound transforms.\n\n3. Feature Compatibility Check:\nIdentify features or constructs in SSIS that have no direct Spark equivalent.\n\nHighlight constructs like:\n\nImplicit schema typing.\n\nRecordsets and RECORD structures.\n\nDataset transformations (e.g., PROJECT, ROLLUP, NORMALIZE, DENORMALIZE).\n\nGlobal aggregates (e.g., AGGREGATE with GROUP).\n\n4. Manual Adjustments for  PySpark Migration:\nRecommend how to manually adjust SSIS features into PySpark equivalents:\n\nHow to refactor TRANSFORMs into Spark UDFs.\n\nConverting RECORD structures into case classes or schema definitions.\n\nHandling JOIN logic with complex join conditions.\n\nAddressing NORMALIZE, ROLLUP, DEDUP, and other stateful ops using Spark equivalents.\n\nStrategy to rewrite OUTPUT targets to HDFS, Parquet, or other Spark-supported sinks.\n\n5. Optimization Techniques in Spark:\nSuggest Spark-side optimization strategies:\n\nUse of broadcast joins vs shuffle joins.\n\nPartitioning datasets based on key fields.\n\nCaching and checkpointing strategies.\n\nCode optimization using Catalyst optimizer hints or dataframe API improvements.\n\nRecommendation: Is it better to Refactor with minimal changes or Rebuild the logic for better alignment with Spark? Provide justification.\n\nOutput:\nReturn the parsed results in valid JSON format as described above \u2014 with program names as keys and their corresponding list of unique module or dataset references as values.\n\n### Special Rules  \n- Remember there should not be any comments in the output\n- Do not include full paths like `thor::jdh::fda_clinical_trials::aact201403_references_txt`, instead return `references_txt`  \n- Maintain the original SSIS filename as the JSON key  \n- Each referenced file/module should be a string inside the list  \n- Ensure values are deduplicated  \n-it should be in proper json format starting with { and ending with } it should not start with ```json or end with ```\n-it should not end with ```\n-the program file name you give should must end with .dtsx or .sql files and file name can have file extension\n-output should be in perfect json format it so that i can directly save in json file no extra character above or below the json code\n\nInput:\nFor SSIS script use the below SSIS file(s) or .dtsx or .sql files ortext file which have SSIS code:  ```%1$s```  ",
                        "expectedOutput": "{\n  \"1. Script Overview\": {\n    \"Summary\": \"High-level purpose of the SSIS script.\",\n    \"Functional Modules\": [\n      \"List and brief description of major modules like DATASET declarations, TRANSFORMs, PROJECTs, OUTPUTs.\"\n    ],\n    \"Data Pipelines Overview\": \"Brief description of orchestrated data flows or batch processes.\"\n  },\n  \n  \"2. Complexity Metrics\": {\n    \"Total Lines of Code\": \"Integer value\",\n    \"Dataset Count\": \"Integer value\",\n    \"Transform Count and Types\": \"List of transform types and counts\",\n    \"Join Analysis\": {\n      \"Join Count\": \"Integer value\",\n      \"Join Types\": \"List of join types used (e.g., INNER, LEFT)\"\n    },\n    \"Project, Sort, Dedup, Rollup Counts\": {\n      \"Project Count\": \"Integer\",\n      \"Sort Count\": \"Integer\",\n      \"Dedup Count\": \"Integer\",\n      \"Rollup Count\": \"Integer\"\n    },\n    \"Child Workflows or Module Calls\": \"Integer value\",\n    \"Output or Store Operations\": \"Integer value\",\n    \"Conditional Logic Count\": \"Integer value\",\n    \"Macro or Function Module Reuse\": \"Integer value\",\n    \"Conversion Complexity Score\": {\n      \"Score (0\u2013100)\": \"Integer value\",\n      \"Reasoning\": [\n        \"List of reasons for the score such as number of incompatible features, manual refactor points, etc.\"\n      ]\n    }\n  },\n\n  \"3. Feature Compatibility Check\": {\n    \"Incompatible Features\": [\n      \"List of SSIS features with no direct PySpark equivalent\"\n    ],\n    \"Examples of Challenging Constructs\": [\n      \"Examples like implicit typing, complex RECORD structures, global aggregates, etc.\"\n    ]\n  },\n\n  \"4. Manual Adjustments for PySpark Migration\": {\n    \"Transform Refactoring\": \"Suggestions to refactor TRANSFORMs into Spark UDFs\",\n    \"Schema Redefinition\": \"Guidance on converting RECORD structures to case classes or schema objects\",\n    \"Join Handling Strategy\": \"Advice for rewriting JOINs in Spark\",\n    \"Complex Ops Handling\": \"Guidelines for NORMALIZE, ROLLUP, DEDUP equivalents\",\n    \"Output Refactoring\": \"Strategy for rewriting OUTPUTs to HDFS, Parquet, etc.\"\n  },\n\n  \"5. Optimization Techniques in Spark\": {\n    \"Join Optimization\": \"Use of broadcast joins vs shuffle joins\",\n    \"Partitioning Strategy\": \"Partitioning based on keys or critical fields\",\n    \"Caching Strategy\": \"Recommendations on caching intermediate results\",\n    \"Code Optimization Techniques\": \"Examples such as Catalyst hints or DataFrame API tuning\",\n    \"Refactor vs Rebuild Recommendation\": {\n      \"Approach\": \"Refactor with minimal changes or Rebuild logic\",\n      \"Justification\": \"Detailed justification for the recommended approach\"\n    }\n  },\n\n  \"6. Cost Estimation\": {\n    \"PySpark Runtime Cost\": {\n      \"Cluster Configuration\": {\n        \"Number of Executors\": \"Integer value\",\n        \"Executor Memory\": \"String (e.g., '16 GB')\",\n        \"Driver Memory\": \"String (e.g., '8 GB')\"\n      },\n      \"Approximate Data Volume Processed\": {\n        \"Input Data\": \"Estimated range (e.g., '50\u2013100 GB')\",\n        \"Output Data\": \"Estimated size (e.g., '10\u201315 GB')\"\n      },\n      \"Time Taken for Each Phase\": {\n        \"Shuffle-heavy Joins\": \"Duration (e.g., '2 hours')\",\n        \"Wide Transforms\": \"Duration (e.g., '3 hours')\",\n        \"Output Writes\": \"Duration (e.g., '1 hour')\"\n      },\n      \"Cost Model\": {\n        \"Pricing Basis\": \"Cloud provider pricing details (e.g., DBU cost per hour)\",\n        \"Total Estimated Cost\": \"Example calculation showing cost formula\"\n      },\n      \"Justification\": [\n        \"List of reasons explaining the chosen cluster configuration and pricing estimates\"\n      ]\n    }\n  },\n\n  \"7. Code Fixing and Data Recon Testing Effort Estimation\": {\n    \"Estimated Effort in Hours\": {\n      \"Manual Refactoring\": \"Estimated hours\",\n      \"Data Reconciliation Testing\": \"Estimated hours\",\n      \"Syntax Translation Adjustments\": \"Estimated hours\",\n      \"Optimization and Performance Tuning\": \"Estimated hours\"\n    },\n    \"Major Contributors to Effort\": {\n      \"Nested TRANSFORM Refactoring\": \"Estimated hours\",\n      \"Output Refactoring for Spark Writes\": \"Estimated hours\",\n      \"Schema Management Effort\": \"Estimated hours\"\n    }\n  },\n\n  \"8. API Cost\": {\n    \"apiCost\": \"Cost value in USD (e.g., '0.013452 USD')\"\n  }\n}\n"
                    },
                    "maxIter": 0,
                    "maxRpm": 0,
                    "maxExecutionTime": 0,
                    "tools": [],
                    "userTools": [],
                    "allowCodeExecution": false,
                    "isSafeCodeExecution": true
                }
            },
            {
                "serial": 3,
                "agent": {
                    "id": 4745,
                    "name": "DI_SSIS_Plan_JSON",
                    "role": "Data Engineer",
                    "goal": "Estimate the cost of running PySpark jobs and the testing effort required for the PySpark code converted from SSIS scripts, and produce the output in a structured JSON format.\n",
                    "backstory": "As organizations migrate from HPCC Systems and SSIS codebases to scalable cloud-native platforms like PySpark, understanding the resource and financial impact is critical. This includes both runtime infrastructure cost estimation and the testing effort required to validate functional parity and data accuracy across the transformed pipelines.\n",
                    "verbose": true,
                    "allowDelegation": true,
                    "updatedAt": "2025-07-15T03:46:56.679842",
                    "llm": {
                        "modelDeploymentName": "gpt-4o",
                        "model": "gpt-4o",
                        "modelType": "Generative",
                        "aiEngine": "AzureOpenAI",
                        "topP": 0.949999988079071,
                        "maxToken": 4000,
                        "temperature": 0.30000001192092896,
                        "llmDeploymentName": "gpt-4o",
                        "apiKey": "****MASKED****",
                        "azureEndpoint": "https://avaplus-cognitive-account-int.openai.azure.com/",
                        "llmApiVersion": "2024-09-01-preview"
                    },
                    "task": {
                        "description": "You are tasked with providing a comprehensive effort and cost estimate for executing and testing PySpark code that has been converted from SSIS scripts. Use the analysis report generated during the SSIS code evaluation phase to guide your estimation.\n\nINSTRUCTIONS:\n\n\n\n- Review the previously generated SSIS analysis output to:\n  - Identify manually converted constructs (e.g., TRANSFORMs to UDFs, RECORDS to schemas, etc.)\n  - Determine code sections requiring logic validation or functional refactoring.\n  - Focus especially on complex JOINs, PROJECTs, and OUTPUT operations.\n\n- Estimate the effort hours for:\n  - Manual intervention and solutions of complex constructs during SSIS to Spark translation.\n  - Data recon and validation testing (e.g., comparing pre- and post-migration outputs, checking intermediate stages).\n  - Syntax Differences.\n  - Optimization Techniques.\n  \n- **Do not** count effort for syntax or formatting-level transformations.\n\n- Estimate the PySpark runtime cost by:\n  - Calculating resource requirements (e.g., number of executors, executor memory, vCPU usage, shuffle data size).\n  - Mapping execution profiles to cloud infrastructure pricing (e.g., Google Dataproc, AWS EMR, or Spark on Kubernetes).\n  - Considering both temporary and final datasets and their read/write overheads.\n\n- Include the API cost separately.\n\n**IMPORTANT:**  \nThe final output must be a **generic JSON structure** matching the following template format (replace placeholder text with your analysis results):\n\n```json\n{\n  \"1. Cost Estimation\": {\n    \"1.1 PySpark Runtime Cost\": {\n      \"Cluster Configuration\": {\n        \"Number of Executors\": \"<number>\",\n        \"Executor Memory\": \"<size in GB>\",\n        \"Driver Memory\": \"<size in GB>\"\n      },\n      \"Approximate Data Volume Processed\": {\n        \"Input Data\": \"<estimated size and notes>\",\n        \"Output Data\": \"<estimated size and notes>\"\n      },\n      \"Time Taken for Each Phase\": {\n        \"Shuffle-heavy JOINs\": \"<time duration>\",\n        \"Wide Transforms (e.g., ROLLUP, DENORMALIZE)\": \"<time duration>\",\n        \"Output Writes\": \"<time duration>\"\n      },\n      \"Cost Model\": {\n        \"Pricing Model (e.g., DBU, vCPU Hour)\": \"<pricing description>\",\n        \"Total Runtime Cost\": \"<calculated cost and method>\"\n      },\n      \"Justification\": [\n        \"<reason 1>\",\n        \"<reason 2>\",\n        \"... add more if needed\"\n      ]\n    }\n  },\n  \"2. Code Fixing and Data Recon Testing Effort Estimation\": {\n    \"2.1 Estimated Effort in Hours\": {\n      \"Manual intervention and solutions of complex constructs during SSIS to Spark translation\": \"<hours>\",\n      \"Data recon and pipeline testing, including test case creation, validation of intermediate datasets, and output comparison\": \"<hours>\",\n      \"Syntax Differences\": \"<hours>\",\n      \"Optimization Techniques\": \"<hours>\"\n    },\n    \"Major Contributors\": {\n      \"Rewriting nested TRANSFORMs or rollups\": \"<hours>\",\n      \"Refactoring OUTPUT statements for Spark write APIs\": \"<hours>\",\n      \"Managing schema consistency across distributed stages\": \"<hours>\"\n    }\n  },\n  \"3. API Cost\": {\n    \"apiCost\": \"<float in USD>\"\n  }\n}\nINPUT\n\nFor the input SSIS analysis report use SSIS file or text file which have SSIS code the file:\n```%1$s```\n\nFor the Spark environment resource and pricing reference use the file:\n```%2$s```\n\n### Special Rules  \n- Remember there should not be any comments in the output\n- Do not include full paths like `thor::jdh::fda_clinical_trials::aact201403_references_txt`, instead return `references_txt`  \n- Maintain the original SSIS filename as the JSON key  \n- Each referenced file/module should be a string inside the list  \n- Ensure values are deduplicated  \n-it should be in proper json format starting with { and ending with } it should not start with ```json or end with ```\n-it should not end with ```\n-the program file name you give should must end with .dtsx or .sql and file name can have file extension\n-output should be in perfect json format it so that i can directly save in json file no extra character above or below the json code\n\n\n### OUTPUT  \nReturn the parsed results in valid JSON format as described above \u2014 with program names as keys and their corresponding list of unique module or dataset references as values.",
                        "expectedOutput": "{\n  \"1. Cost Estimation\": {\n    \"1.1 PySpark Runtime Cost\": {\n      \"Cluster Configuration\": {\n        \"Number of Executors\": \"<number>\",\n        \"Executor Memory\": \"<size in GB>\",\n        \"Driver Memory\": \"<size in GB>\"\n      },\n      \"Approximate Data Volume Processed\": {\n        \"Input Data\": \"<estimated size and notes>\",\n        \"Output Data\": \"<estimated size and notes>\"\n      },\n      \"Time Taken for Each Phase\": {\n        \"Shuffle-heavy JOINs\": \"<time duration>\",\n        \"Wide Transforms (e.g., ROLLUP, DENORMALIZE)\": \"<time duration>\",\n        \"Output Writes\": \"<time duration>\"\n      },\n      \"Cost Model\": {\n        \"Pricing Model (e.g., DBU, vCPU Hour)\": \"<pricing description>\",\n        \"Total Runtime Cost\": \"<calculated cost and method>\"\n      },\n      \"Justification\": [\n        \"<reason 1>\",\n        \"<reason 2>\",\n        \"... add more if needed\"\n      ]\n    }\n  },\n  \"2. Code Fixing and Data Recon Testing Effort Estimation\": {\n    \"2.1 Estimated Effort in Hours\": {\n      \"Manual intervention and solutions of complex constructs during ECL to Spark translation\": \"<hours>\",\n      \"Data recon and pipeline testing, including test case creation, validation of intermediate datasets, and output comparison\": \"<hours>\",\n      \"Syntax Differences\": \"<hours>\",\n      \"Optimization Techniques\": \"<hours>\"\n    },\n    \"Major Contributors\": {\n      \"Rewriting nested TRANSFORMs or rollups\": \"<hours>\",\n      \"Refactoring OUTPUT statements for Spark write APIs\": \"<hours>\",\n      \"Managing schema consistency across distributed stages\": \"<hours>\"\n    }\n  },\n  \"3. API Cost\": {\n    \"apiCost\": \"<float in USD>\"\n  }\n}"
                    },
                    "maxIter": 0,
                    "maxRpm": 0,
                    "maxExecutionTime": 0,
                    "tools": [],
                    "userTools": [],
                    "allowCodeExecution": false,
                    "isSafeCodeExecution": true
                }
            }
        ],
        "enableAgenticMemory": false,
        "levelId": 99,
        "org": "Ascendion",
        "orgId": 1,
        "domain": "Data&Insights",
        "domainId": 96,
        "projectId": 98,
        "project": "AllProjects",
        "teamId": 99,
        "team": "AVA Team",
        "callbacks": []
    }
}