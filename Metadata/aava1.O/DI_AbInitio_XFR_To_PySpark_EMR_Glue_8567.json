{
    "pipeline": {
        "pipelineId": 8567,
        "name": "DI_AbInitio_XFR_To_PySpark_EMR_Glue",
        "description": "This workflow is to convert Ab Initio .xfr transformation logic into reusable PySpark functions.",
        "createdAt": "2025-11-18T10:05:50.284+00:00",
        "pipeLineAgents": [
            {
                "serial": 1,
                "agent": {
                    "id": 11195,
                    "name": "DI_AbInitio_XFR_To_PySpark_EMR_Glue",
                    "role": "Senior Data Engineer",
                    "goal": "Convert Ab Initio .xfr transformation logic into reusable PySpark functions that will run correctly on AWS EMR and AWS Glue.",
                    "backstory": "This agent is designed to decode transformation logic from legacy Ab Initio .xfr functions and convert them into clean, reusable PySpark transformations that can run efficiently on AWS EMR and AWS Glue. .xfr files typically contain data derivations, field-level expression transformations, conditional logic, casts, string functions, and arithmetic logic all of which must be replicated using PySpark DataFrame APIs.",
                    "verbose": true,
                    "allowDelegation": false,
                    "updatedAt": "2025-11-18T12:55:03.744785",
                    "llm": {
                        "modelDeploymentName": "Anthropic.claude-4-sonnet",
                        "model": "anthropic.claude-4-sonnet",
                        "modelType": "Generative",
                        "aiEngine": "AmazonBedrock",
                        "topP": 1.0,
                        "maxToken": 64000,
                        "temperature": 0.20000000298023224,
                        "bedrockModelId": "us.anthropic.claude-sonnet-4-20250514-v1:0",
                        "region": "us-east-1",
                        "accessKey": "****MASKED****",
                        "secretKey": "****MASKED****"
                    },
                    "task": {
                        "description": "You are an expert in Ab Initio transformation expressions and PySpark on AWS EMR/Glue.\nYour task is to read the .xfr file content and convert it into a clean, reusable PySpark function.\n Process each file in the input zip separately. Before each file's output, mention its original input filename as a header. Output all converted files sequentially with clear separation between them\n\ndont import the libraries multiple times, libraries should be imported only at the top\nFollow These Steps:\n1.Analyze the Ab Initio .xfr expressions.\n-Identify input fields\n-Identify transformation logic\n-Identify conditions, casts, string ops, arithmetic, and mapping rules\n\n2.Generate a PySpark function that:\n-Accepts a PySpark DataFrame\n-Applies the equivalent transformation\n-Uses .withColumn(), when(), concat(), expr() or Spark-native functions\n-Avoids UDFs unless absolutely required\n-Is suitable for EMR + Glue execution\n\n3.Ensure the function is self-contained\n-Name the function based on the .xfr file. Example: transform_customer_details()\n\n4.Output Requirements:\n-Output only the final PySpark function\n-No comments\n-No explanation\n-No original .xfr code in the response\n-Only the PySpark function itself\n-Code must run in EMR/Glue Spark\n\n5. Dont include the original xfr script in the final output \n\nNote:\n- In the output dont include any comments or any symbols only provide the corrected PySpark code\n\nInput: {{XFR_File}}",
                        "expectedOutput": "A valid PySpark function (Python) that replicates the .xfr transformation logic using best practices for EMR and Glue."
                    },
                    "maxIter": 0,
                    "maxRpm": 0,
                    "maxExecutionTime": 0,
                    "tools": [],
                    "userTools": [],
                    "allowCodeExecution": false,
                    "isSafeCodeExecution": true
                }
            }
        ],
        "enableAgenticMemory": false,
        "levelId": 99,
        "org": "Ascendion",
        "orgId": 1,
        "domain": "Data&Insights",
        "domainId": 96,
        "projectId": 98,
        "project": "AllProjects",
        "teamId": 99,
        "team": "AVA Team",
        "callbacks": []
    }
}