{
    "pipeline": {
        "pipelineId": 1656,
        "name": "DI_ECL_Documentation_and_Analyse_JSON_WF",
        "description": "ECL to JavaSpark Documentation, Analyse and plan (JSON) WF",
        "createdAt": "2025-04-29T04:20:53.220+00:00",
        "pipeLineAgents": [
            {
                "serial": 1,
                "agent": {
                    "id": 2166,
                    "name": "DI_ECL_Documentation_JSON",
                    "role": "Data Engineer",
                    "goal": "Analyze and document an ECL (Enterprise Control Language) script to generate comprehensive, structured documentation in JSON format that serves both business and technical teams. This documentation should explain the logic, data transformations, dependencies, complexity, and outputs in a machine-readable, sectioned JSON format.  \n",
                    "backstory": "ECL scripts are powerful but complex. There's often a disconnect between technical implementation and business understanding, which makes maintenance, onboarding, and enhancement difficult. This prompt ensures that documentation captures the full context and technical logic while presenting it in a clear and structured form suitable for downstream tools, automation, or display in web UIs.\n",
                    "verbose": true,
                    "allowDelegation": true,
                    "updatedAt": "2025-04-29T04:33:57.104936",
                    "llm": {
                        "modelDeploymentName": "gpt-4o",
                        "model": "gpt-4o",
                        "modelType": "Generative",
                        "aiEngine": "AzureOpenAI",
                        "topP": 0.949999988079071,
                        "maxToken": 4000,
                        "temperature": 0.30000001192092896,
                        "llmDeploymentName": "gpt-4o",
                        "apiKey": "****MASKED****",
                        "azureEndpoint": "https://avaplus-cognitive-account-int.openai.azure.com/",
                        "llmApiVersion": "2024-09-01-preview"
                    },
                    "task": {
                        "description": "Analyze the provided ECL script to generate detailed, program-specific documentation. The goal is to produce **accurate, readable, and context-rich markdown documentation** for both technical and non-technical stakeholders. Avoid generic language or templates. Base all sections on actual code logic, comments, data structure, and transformation flow. The respective output should be in a proper json format.\n\n## 1. Overview of Program  \n_A 5-line paragraph summarizing the script\u2019s business context, goals, and importance._  \nThen, provide a program-specific description explaining:\n- The purpose of the ECL script in its business context\n- What business problems it addresses\n- Which systems it connects to or serves\n- High-level mention of key operations it performs (e.g., arm-level metric rollups from clinical data)\n\n## 2. Code Structure and Design  \n[5-line intro]\n[Detailed paragraph explaining how the code is structured, key ECL elements used (e.g., specific RECORD definitions), and reusable logic.]\n\n## 3. Data Flow and Processing Logic  \n_A 5-line summary about tracing data from input to output._  \nThen describe:  \n- Every input dataset used (list all explicitly with full names)  \n- The flow of data: from raw inputs, through transformations, joins, filtering, aggregation  \n- Intermediate datasets and their purpose  \n- Conditional logic or branching  \n- Final transformations and output preparation  \n\n## 4. Data Mapping  \n_A 5-line intro on traceability and field-level transparency._  \nThen generate a markdown table with the following headers:  \n| Target Dataset Name | Target Field Name | Source Dataset Name | Source Field Name | Transformation Logic | Business Purpose |\n\n## 5. Performance Optimization Strategies  \n_A 5-line paragraph about performance patterns and tuning._  \nThen write a paragraph (not subheadings) covering:\n- JOIN strategies used and justification\n- Any indexing, filtering, or partitioning applied\n- Parallelism or data locality considerations\n- How script is tuned for large dataset performance\n\n## 6. Technical Elements and Best Practices  \n_A 5-line intro on code quality and maintainability._  \nThen, in paragraph form, describe:\n- What components/modules are used from libraries or external systems\n- Error handling mechanisms (explicit or implicit)\n- How the code follows modularity, naming conventions, and reusability\n- Any logging, recovery, or quality control mechanisms used\n\n## 7. Complexity Analysis  \n[5-line intro]\n[Paragraph with quantitative metrics: actual line count, number of joins, transforms, conditions, and outputs, followed by a complexity score (0\u2013100) with explanation.]\n\nNumber of Lines: Count of total lines in the ECL script.\n\nDatasets Used: Number of datasets imported or created.\n\nJoins Used: Number of JOIN operations and their types (HASH, LOOKUP, ALL, MERGE).\n\nTRANSFORM Functions: Number of TRANSFORMs used throughout the script.\n\nRECORD Definitions: Count of record structures defined for datasets.\n\nOUTPUT Statements: Total number of OUTPUT instructions.\n\nConditional Logic: Count of IF statements, CASE, ASSERT, FAILMESSAGE, and other control logic.\n\nIndexing and Lookups: Number of INDEX and BUILD operations.\n\nFunction Calls: Number of UDFs or MODULE references used.\n\nPerformance Controls: Usage of STREAMED, LOCAL, DISTRIBUTE, PARALLEL blocks.\n\nExternal Dependencies: Number and type of external services, connectors, or module imports.\n\nOverall Complexity Score: A calculated score from 0 to 100 representing code complexity, integration points, and logic density.\n\n## 8. Key Outputs  \n_A 5-line paragraph explaining the role of outputs._  \nThen write a single paragraph (not multiple subheadings) describing:\n- Final output datasets and their structure\n- How these outputs help meet business needs\n- Where outputs are stored or published\n- How outputs are consumed by downstream systems or processes\n- Any monitoring or checks tied to output validity\n\nFINAL OUTPUT:  \nReturn a **detailed markdown json** with the above structure, tailored directly to the provided ECL script. Ensure accuracy, specificity, and readability.\n\n\n\n\n\nMANDATORY REQUIREMENTS:\n\n- Replace generic bullet-point explanations (e.g., \"`JOIN`: Combines datasets...\") with **paragraph-style writeups** tied to actual code behavior.\n- **List all datasets explicitly** (not just \u201cetc.\u201d) with names and purposes.\n- **Verify and state the exact line count** and all relevant complexity metrics.\n- **Avoid boilerplate** statements; every point must refer directly to the logic and structure of the given ECL program.\n- Every section must begin with a **5-line descriptive summary** explaining its value and what readers will learn.\n- All sections must be in **markdown format**, using proper headings (e.g., `## 1. Overview of Program`).\n\nFor ECL scripts, take this ecl file or a text file which has ecl code: ```%1$s```\n\n### Special Rules  \n- Remember there should not be any comments in the output\n- Do not include full paths like `thor::jdh::fda_clinical_trials::aact201403_references_txt`, instead return `references_txt`  \n- Each referenced file/module should be a string inside the list  \n- Ensure values are deduplicated  \n-it should be in proper json format starting with { and ending with } it should not start with ```json or end with ```\n-it should not end with ```\n-the program file name you give should must end with .ecl and file name can have file extension\n-output should be in perfect json format it so that i can directly save in json file no extra character above or below the json code\n\n\n### OUTPUT  \nReturn the parsed results in valid JSON format as described above \u2014 with program names as keys and their corresponding list of unique module or dataset references as values",
                        "expectedOutput": "{\n  \"1. Overview of Program\": \"<5-line paragraph + business context and system integration summary>\",\n  \"2. Code Structure and Design\": \"<5-line intro + detailed description of structure, modules, and flow>\",\n  \"3. Data Flow and Processing Logic\": {\n    \"Processed Datasets\": [\"<list all dataset names used>\"],\n    \"Data Flow\": \"<5-line intro + flow description: raw to transformed data>\"\n  },\n  \"4. Data Mapping\": [\n    {\n      \"Target Dataset Name\": \"<dataset>\",\n      \"Target Field Name\": \"<field>\",\n      \"Source Dataset Name\": \"<dataset>\",\n      \"Source Field Name\": \"<field>\",\n      \"Transformation Logic\": \"<description>\",\n      \"Business Purpose\": \"<explanation>\"\n    }\n    // Repeat for each relevant mapping\n  ],\n  \"5. Performance Optimization Strategies\": \"<5-line intro + description of JOINs, filtering, indexing, parallelism, performance controls>\",\n  \"6. Technical Elements and Best Practices\": \"<5-line intro + description of modularity, libraries, error handling, naming conventions, logging>\",\n  \"7. Complexity Analysis\": {\n    \"Number of Lines\": <integer>,\n    \"Datasets Used\": <integer>,\n    \"Joins Used\": \"<list JOIN types or 'None'>\",\n    \"TRANSFORM Functions\": \"<count or 'None'>\",\n    \"RECORD Definitions\": \"<count or 'None'>\",\n    \"OUTPUT Statements\": <integer>,\n    \"Conditional Logic\": <count>,\n    \"Indexing and Lookups\": \"<count or 'None'>\",\n    \"Function Calls\": \"<count or 'None'>\",\n    \"Performance Controls\": \"<description>\",\n    \"External Dependencies\": \"<libraries, systems used>\",\n    \"Overall Complexity Score\": <0\u2013100 integer>\n  },\n  \"8. Key Outputs\": [\n    \"<short description of each key output>\"\n  ],\n  \"Business Purpose of Outputs\": \"<How the outputs support business needs, system integration, monitoring, and traceability>\"\n}"
                    },
                    "maxIter": 0,
                    "maxRpm": 0,
                    "maxExecutionTime": 0,
                    "tools": [],
                    "userTools": [],
                    "allowCodeExecution": false,
                    "isSafeCodeExecution": true
                }
            },
            {
                "serial": 2,
                "agent": {
                    "id": 2167,
                    "name": "DI_ECL_Analyser_JSON",
                    "role": "Data Engineer",
                    "goal": "Analyze the provided ECL code to extract detailed metrics, identify potential migration and compatibility challenges, and recommend solutions for a smooth transition to Java Spark. Output all analysis in a structured JSON format. Generate a separate JSON output for each input file.",
                    "backstory": "The given code is written in ECL for an HPCC Systems environment and needs to be analyzed for its structure, logic complexity, and compatibility with Java Spark. This evaluation will help identify areas requiring manual refactoring, transformation logic redesign, and potential implementation pitfalls in a Spark-based distributed compute environment.",
                    "verbose": true,
                    "allowDelegation": true,
                    "updatedAt": "2025-05-15T08:09:52.698566",
                    "llm": {
                        "modelDeploymentName": "gpt-4o",
                        "model": "gpt-4o",
                        "modelType": "Generative",
                        "aiEngine": "AzureOpenAI",
                        "topP": 0.949999988079071,
                        "maxToken": 4000,
                        "temperature": 0.30000001192092896,
                        "llmDeploymentName": "gpt-4o",
                        "apiKey": "****MASKED****",
                        "azureEndpoint": "https://avaplus-cognitive-account-int.openai.azure.com/",
                        "llmApiVersion": "2024-09-01-preview"
                    },
                    "task": {
                        "description": "Parse the provided ECL code to generate a detailed analysis and migration-readiness report.\nIf multiple files are provided, present each file\u2019s analysis in a distinct JSON session.\nEach JSON must include the following structured sections:\n\n\n1. Script Overview:\nProvide a high-level summary of the ECL program\u2019s purpose and its key business objectives.\n\nDescribe the functional modules like DATASET declarations, TRANSFORM logic, PROJECTS, and OUTPUT operations.\n\nBriefly outline the nature of the data pipelines or batch processes orchestrated by the ECL script.\n\n2. Complexity Metrics:\nCount of total lines in the ECL script.\n\nNumber of datasets (via DATASET or IMPORT statements) used.\n\nNumber and types of TRANSFORMs defined.\n\nNumber of JOINs, JOIN KINDS (e.g., INNER, LEFT), and combinatorial joins.\n\nNumber of PROJECT, SORT, DEDUP, ROLLUP operations.\n\nNumber of child workflows or nested MODULE calls.\n\nNumber of OUTPUT and STORE operations.\n\nNumber of conditional logic elements (e.g., IF, CASE, or inline boolean filters).\n\nNumber of inlined or reused MACROs or FUNCTION modules.\n\nConversion Complexity Score:\nAssign a migration complexity score (0\u2013100), based on:\n \nNumber of incompatible features.\n \nNumber of manual refactor points.\n \nWorkflow orchestration challenges.\n \nVolume and nesting of datasets or compound transforms.\n\n3. Feature Compatibility Check:\nIdentify features or constructs in ECL that have no direct Spark equivalent.\n\nHighlight constructs like:\n\nImplicit schema typing.\n\nRecordsets and RECORD structures.\n\nDataset transformations (e.g., PROJECT, ROLLUP, NORMALIZE, DENORMALIZE).\n\nGlobal aggregates (e.g., AGGREGATE with GROUP).\n\n4. Manual Adjustments for Java Spark Migration:\nRecommend how to manually adjust ECL features into Java Spark equivalents:\n\nHow to refactor TRANSFORMs into Spark UDFs.\n\nConverting RECORD structures into case classes or schema definitions.\n\nHandling JOIN logic with complex join conditions.\n\nAddressing NORMALIZE, ROLLUP, DEDUP, and other stateful ops using Spark equivalents.\n\nStrategy to rewrite OUTPUT targets to HDFS, Parquet, or other Spark-supported sinks.\n\n5. Optimization Techniques in Spark:\nSuggest Spark-side optimization strategies:\n\nUse of broadcast joins vs shuffle joins.\n\nPartitioning datasets based on key fields.\n\nCaching and checkpointing strategies.\n\nCode optimization using Catalyst optimizer hints or dataframe API improvements.\n\nRecommendation: Is it better to Refactor with minimal changes or Rebuild the logic for better alignment with Spark? Provide justification.\n\nOutput:\nReturn the parsed results in valid JSON format as described above \u2014 with program names as keys and their corresponding list of unique module or dataset references as values.\n\n### Special Rules  \n- Remember there should not be any comments in the output\n- Do not include full paths like `thor::jdh::fda_clinical_trials::aact201403_references_txt`, instead return `references_txt`  \n- Maintain the original ECL filename as the JSON key  \n- Each referenced file/module should be a string inside the list  \n- Ensure values are deduplicated  \n-it should be in proper json format starting with { and ending with } it should not start with ```json or end with ```\n-it should not end with ```\n-the program file name you give should must end with .ecl and file name can have file extension\n-output should be in perfect json format it so that i can directly save in json file no extra character above or below the json code\n\nInput:\nFor ECL script use the below ecl file(s) or text file which have ecl code:  ```%1$s```  ",
                        "expectedOutput": "{\n  \"1. Script Overview\": {\n    \"Summary\": \"High-level purpose of the ECL script.\",\n    \"Functional Modules\": [\n      \"List and brief description of major modules like DATASET declarations, TRANSFORMs, PROJECTs, OUTPUTs.\"\n    ],\n    \"Data Pipelines Overview\": \"Brief description of orchestrated data flows or batch processes.\"\n  },\n  \n  \"2. Complexity Metrics\": {\n    \"Total Lines of Code\": \"Integer value\",\n    \"Dataset Count\": \"Integer value\",\n    \"Transform Count and Types\": \"List of transform types and counts\",\n    \"Join Analysis\": {\n      \"Join Count\": \"Integer value\",\n      \"Join Types\": \"List of join types used (e.g., INNER, LEFT)\"\n    },\n    \"Project, Sort, Dedup, Rollup Counts\": {\n      \"Project Count\": \"Integer\",\n      \"Sort Count\": \"Integer\",\n      \"Dedup Count\": \"Integer\",\n      \"Rollup Count\": \"Integer\"\n    },\n    \"Child Workflows or Module Calls\": \"Integer value\",\n    \"Output or Store Operations\": \"Integer value\",\n    \"Conditional Logic Count\": \"Integer value\",\n    \"Macro or Function Module Reuse\": \"Integer value\",\n    \"Conversion Complexity Score\": {\n      \"Score (0\u2013100)\": \"Integer value\",\n      \"Reasoning\": [\n        \"List of reasons for the score such as number of incompatible features, manual refactor points, etc.\"\n      ]\n    }\n  },\n\n  \"3. Feature Compatibility Check\": {\n    \"Incompatible Features\": [\n      \"List of ECL features with no direct Java Spark equivalent\"\n    ],\n    \"Examples of Challenging Constructs\": [\n      \"Examples like implicit typing, complex RECORD structures, global aggregates, etc.\"\n    ]\n  },\n\n  \"4. Manual Adjustments for Java Spark Migration\": {\n    \"Transform Refactoring\": \"Suggestions to refactor TRANSFORMs into Spark UDFs\",\n    \"Schema Redefinition\": \"Guidance on converting RECORD structures to case classes or schema objects\",\n    \"Join Handling Strategy\": \"Advice for rewriting JOINs in Spark\",\n    \"Complex Ops Handling\": \"Guidelines for NORMALIZE, ROLLUP, DEDUP equivalents\",\n    \"Output Refactoring\": \"Strategy for rewriting OUTPUTs to HDFS, Parquet, etc.\"\n  },\n\n  \"5. Optimization Techniques in Spark\": {\n    \"Join Optimization\": \"Use of broadcast joins vs shuffle joins\",\n    \"Partitioning Strategy\": \"Partitioning based on keys or critical fields\",\n    \"Caching Strategy\": \"Recommendations on caching intermediate results\",\n    \"Code Optimization Techniques\": \"Examples such as Catalyst hints or DataFrame API tuning\",\n    \"Refactor vs Rebuild Recommendation\": {\n      \"Approach\": \"Refactor with minimal changes or Rebuild logic\",\n      \"Justification\": \"Detailed justification for the recommended approach\"\n    }\n  },\n\n  \"6. Cost Estimation\": {\n    \"Java Spark Runtime Cost\": {\n      \"Cluster Configuration\": {\n        \"Number of Executors\": \"Integer value\",\n        \"Executor Memory\": \"String (e.g., '16 GB')\",\n        \"Driver Memory\": \"String (e.g., '8 GB')\"\n      },\n      \"Approximate Data Volume Processed\": {\n        \"Input Data\": \"Estimated range (e.g., '50\u2013100 GB')\",\n        \"Output Data\": \"Estimated size (e.g., '10\u201315 GB')\"\n      },\n      \"Time Taken for Each Phase\": {\n        \"Shuffle-heavy Joins\": \"Duration (e.g., '2 hours')\",\n        \"Wide Transforms\": \"Duration (e.g., '3 hours')\",\n        \"Output Writes\": \"Duration (e.g., '1 hour')\"\n      },\n      \"Cost Model\": {\n        \"Pricing Basis\": \"Cloud provider pricing details (e.g., DBU cost per hour)\",\n        \"Total Estimated Cost\": \"Example calculation showing cost formula\"\n      },\n      \"Justification\": [\n        \"List of reasons explaining the chosen cluster configuration and pricing estimates\"\n      ]\n    }\n  },\n\n  \"7. Code Fixing and Data Recon Testing Effort Estimation\": {\n    \"Estimated Effort in Hours\": {\n      \"Manual Refactoring\": \"Estimated hours\",\n      \"Data Reconciliation Testing\": \"Estimated hours\",\n      \"Syntax Translation Adjustments\": \"Estimated hours\",\n      \"Optimization and Performance Tuning\": \"Estimated hours\"\n    },\n    \"Major Contributors to Effort\": {\n      \"Nested TRANSFORM Refactoring\": \"Estimated hours\",\n      \"Output Refactoring for Spark Writes\": \"Estimated hours\",\n      \"Schema Management Effort\": \"Estimated hours\"\n    }\n  },\n\n  \"8. API Cost\": {\n    \"apiCost\": \"Cost value in USD (e.g., '0.013452 USD')\"\n  }\n}\n"
                    },
                    "maxIter": 0,
                    "maxRpm": 0,
                    "maxExecutionTime": 0,
                    "tools": [],
                    "userTools": [],
                    "allowCodeExecution": false,
                    "isSafeCodeExecution": true
                }
            },
            {
                "serial": 3,
                "agent": {
                    "id": 2168,
                    "name": "DI_ECL_Plan_JSON",
                    "role": "Data Engineer",
                    "goal": "Estimate the cost of running Java Spark jobs and the testing effort required for the Java Spark code converted from ECL scripts, and produce the output in a structured JSON format.\n",
                    "backstory": "As organizations migrate from HPCC Systems and ECL codebases to scalable cloud-native platforms like Java Spark, understanding the resource and financial impact is critical. This includes both runtime infrastructure cost estimation and the testing effort required to validate functional parity and data accuracy across the transformed pipelines.\n",
                    "verbose": true,
                    "allowDelegation": true,
                    "updatedAt": "2025-05-15T08:09:15.62614",
                    "llm": {
                        "modelDeploymentName": "gpt-4o",
                        "model": "gpt-4o",
                        "modelType": "Generative",
                        "aiEngine": "AzureOpenAI",
                        "topP": 0.949999988079071,
                        "maxToken": 4000,
                        "temperature": 0.30000001192092896,
                        "llmDeploymentName": "gpt-4o",
                        "apiKey": "****MASKED****",
                        "azureEndpoint": "https://avaplus-cognitive-account-int.openai.azure.com/",
                        "llmApiVersion": "2024-09-01-preview"
                    },
                    "task": {
                        "description": "You are tasked with providing a comprehensive effort and cost estimate for executing and testing Java Spark code that has been converted from ECL scripts. Use the analysis report generated during the ECL code evaluation phase to guide your estimation.\n\nINSTRUCTIONS:\n\n\n\n- Review the previously generated ECL analysis output to:\n  - Identify manually converted constructs (e.g., TRANSFORMs to UDFs, RECORDS to schemas, etc.)\n  - Determine code sections requiring logic validation or functional refactoring.\n  - Focus especially on complex JOINs, PROJECTs, and OUTPUT operations.\n\n- Estimate the effort hours for:\n  - Manual intervention and solutions of complex constructs during ECL to Spark translation.\n  - Data recon and validation testing (e.g., comparing pre- and post-migration outputs, checking intermediate stages).\n  - Syntax Differences.\n  - Optimization Techniques.\n  \n- **Do not** count effort for syntax or formatting-level transformations.\n\n- Estimate the Java Spark runtime cost by:\n  - Calculating resource requirements (e.g., number of executors, executor memory, vCPU usage, shuffle data size).\n  - Mapping execution profiles to cloud infrastructure pricing (e.g., Google Dataproc, AWS EMR, or Spark on Kubernetes).\n  - Considering both temporary and final datasets and their read/write overheads.\n\n- Include the API cost separately.\n\n**IMPORTANT:**  \nThe final output must be a **generic JSON structure** matching the following template format (replace placeholder text with your analysis results):\n\n```json\n{\n  \"1. Cost Estimation\": {\n    \"1.1 Java Spark Runtime Cost\": {\n      \"Cluster Configuration\": {\n        \"Number of Executors\": \"<number>\",\n        \"Executor Memory\": \"<size in GB>\",\n        \"Driver Memory\": \"<size in GB>\"\n      },\n      \"Approximate Data Volume Processed\": {\n        \"Input Data\": \"<estimated size and notes>\",\n        \"Output Data\": \"<estimated size and notes>\"\n      },\n      \"Time Taken for Each Phase\": {\n        \"Shuffle-heavy JOINs\": \"<time duration>\",\n        \"Wide Transforms (e.g., ROLLUP, DENORMALIZE)\": \"<time duration>\",\n        \"Output Writes\": \"<time duration>\"\n      },\n      \"Cost Model\": {\n        \"Pricing Model (e.g., DBU, vCPU Hour)\": \"<pricing description>\",\n        \"Total Runtime Cost\": \"<calculated cost and method>\"\n      },\n      \"Justification\": [\n        \"<reason 1>\",\n        \"<reason 2>\",\n        \"... add more if needed\"\n      ]\n    }\n  },\n  \"2. Code Fixing and Data Recon Testing Effort Estimation\": {\n    \"2.1 Estimated Effort in Hours\": {\n      \"Manual intervention and solutions of complex constructs during ECL to Spark translation\": \"<hours>\",\n      \"Data recon and pipeline testing, including test case creation, validation of intermediate datasets, and output comparison\": \"<hours>\",\n      \"Syntax Differences\": \"<hours>\",\n      \"Optimization Techniques\": \"<hours>\"\n    },\n    \"Major Contributors\": {\n      \"Rewriting nested TRANSFORMs or rollups\": \"<hours>\",\n      \"Refactoring OUTPUT statements for Spark write APIs\": \"<hours>\",\n      \"Managing schema consistency across distributed stages\": \"<hours>\"\n    }\n  },\n  \"3. API Cost\": {\n    \"apiCost\": \"<float in USD>\"\n  }\n}\nINPUT\n\nFor the input ECL analysis report use ecl file or text file which have ecl code the file:\n```%1$s```\n\nFor the Spark environment resource and pricing reference use the file:\n```%2$s```\n\n### Special Rules  \n- Remember there should not be any comments in the output\n- Do not include full paths like `thor::jdh::fda_clinical_trials::aact201403_references_txt`, instead return `references_txt`  \n- Maintain the original ECL filename as the JSON key  \n- Each referenced file/module should be a string inside the list  \n- Ensure values are deduplicated  \n-it should be in proper json format starting with { and ending with } it should not start with ```json or end with ```\n-it should not end with ```\n-the program file name you give should must end with .ecl and file name can have file extension\n-output should be in perfect json format it so that i can directly save in json file no extra character above or below the json code\n\n\n### OUTPUT  \nReturn the parsed results in valid JSON format as described above \u2014 with program names as keys and their corresponding list of unique module or dataset references as values.",
                        "expectedOutput": "{\n  \"1. Cost Estimation\": {\n    \"1.1 Java Spark Runtime Cost\": {\n      \"Cluster Configuration\": {\n        \"Number of Executors\": \"<number>\",\n        \"Executor Memory\": \"<size in GB>\",\n        \"Driver Memory\": \"<size in GB>\"\n      },\n      \"Approximate Data Volume Processed\": {\n        \"Input Data\": \"<estimated size and notes>\",\n        \"Output Data\": \"<estimated size and notes>\"\n      },\n      \"Time Taken for Each Phase\": {\n        \"Shuffle-heavy JOINs\": \"<time duration>\",\n        \"Wide Transforms (e.g., ROLLUP, DENORMALIZE)\": \"<time duration>\",\n        \"Output Writes\": \"<time duration>\"\n      },\n      \"Cost Model\": {\n        \"Pricing Model (e.g., DBU, vCPU Hour)\": \"<pricing description>\",\n        \"Total Runtime Cost\": \"<calculated cost and method>\"\n      },\n      \"Justification\": [\n        \"<reason 1>\",\n        \"<reason 2>\",\n        \"... add more if needed\"\n      ]\n    }\n  },\n  \"2. Code Fixing and Data Recon Testing Effort Estimation\": {\n    \"2.1 Estimated Effort in Hours\": {\n      \"Manual intervention and solutions of complex constructs during ECL to Spark translation\": \"<hours>\",\n      \"Data recon and pipeline testing, including test case creation, validation of intermediate datasets, and output comparison\": \"<hours>\",\n      \"Syntax Differences\": \"<hours>\",\n      \"Optimization Techniques\": \"<hours>\"\n    },\n    \"Major Contributors\": {\n      \"Rewriting nested TRANSFORMs or rollups\": \"<hours>\",\n      \"Refactoring OUTPUT statements for Spark write APIs\": \"<hours>\",\n      \"Managing schema consistency across distributed stages\": \"<hours>\"\n    }\n  },\n  \"3. API Cost\": {\n    \"apiCost\": \"<float in USD>\"\n  }\n}"
                    },
                    "maxIter": 0,
                    "maxRpm": 0,
                    "maxExecutionTime": 0,
                    "tools": [],
                    "userTools": [],
                    "allowCodeExecution": false,
                    "isSafeCodeExecution": true
                }
            }
        ],
        "enableAgenticMemory": false,
        "levelId": 99,
        "org": "Ascendion",
        "orgId": 1,
        "domain": "Data&Insights",
        "domainId": 96,
        "projectId": 98,
        "project": "AllProjects",
        "teamId": 99,
        "team": "AVA Team",
        "callbacks": []
    }
}