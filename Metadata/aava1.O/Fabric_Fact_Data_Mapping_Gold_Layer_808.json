{
    "pipeline": {
        "pipelineId": 808,
        "name": "Fabric Fact Data Mapping Gold Layer",
        "description": "This workflow is for recommending and creating the gold Fact data mapping",
        "createdAt": "2025-02-28T07:24:18.779+00:00",
        "pipeLineAgents": [
            {
                "serial": 1,
                "agent": {
                    "id": 1071,
                    "name": "Fabric Gold Fact Transformation Recommender",
                    "role": "Data modeler",
                    "goal": "Analyze the Model Conceptual, Data Constraints, Silver Layer Physical DDL script, Gold Layer Physical DDL script, and Sample Data to generate comprehensive transformation rules specifically for Fact tables in the Gold layer.",
                    "backstory": "Data transformation for Fact tables is critical for maintaining accuracy, consistency, and completeness before they are used in analytical reporting. By automatically generating transformation rules for Fact tables, we ensure that key metrics, aggregations, and relationships are structured correctly, enriched with necessary data points, and aligned with reporting and performance optimization needs.",
                    "verbose": true,
                    "allowDelegation": true,
                    "updatedAt": "2025-06-25T11:24:55.538782",
                    "llm": {
                        "modelDeploymentName": "gpt-4.1",
                        "model": "gpt-4",
                        "modelType": "Generative",
                        "aiEngine": "AzureOpenAI",
                        "topP": 0.949999988079071,
                        "maxToken": 8000,
                        "temperature": 0.30000001192092896,
                        "llmDeploymentName": "gpt-4.1",
                        "apiKey": "****MASKED****",
                        "azureEndpoint": "https://avaplus-cognitive-account-int.openai.azure.com/",
                        "llmApiVersion": "2025-01-01-preview"
                    },
                    "task": {
                        "description": "You will read the Model Conceptual, Data Constraints, Silver Layer Physical DDL script, Gold Layer Physical DDL script, and Sample Data and generate transformation rules only for Fact tables.\n\nINSTRUCTIONS:\n\n1. Parse the Silver Layer DDL script to extract only Fact tables and their column definitions.\n2. Analyze the Model Conceptual and Data Constraints to identify business-critical metrics, aggregations, and necessary transformations for Fact tables.\n3. Inspect Sample Data to detect patterns, outliers, and potential standardization requirements for Fact metrics.\n4. Generate transformation rules for Fact tables, including:\n* Metric Standardization: Ensure key measures are formatted correctly and align with business KPIs.\n* Fact-Dimension Mapping: Ensure foreign keys link correctly to Dimension tables (e.g., surrogate keys, natural key mapping).\n* Data Aggregation Rules: Define pre-aggregations (e.g., monthly/quarterly summaries) where applicable.\n* Normalization and Standardization: Ensure consistency in numeric values (e.g., currency conversions, percentage calculations, rounding rules).\n* Handling Missing or Invalid Data: Define strategies for handling NULL values, missing records, or outlier data points.\n5. Provide SQL transformations for each rule, ensuring alignment with the Silver Layer schema.\n6. Ensure traceability of transformations by linking each rule back to its source from the Model Conceptual, Data Constraints, and Silver Layer schema to Gold Layer.\n\nOUTPUT FORMAT:\n1. Transformation Rules for Fact Tables:\n* [Rule Name]: [Description]\n    - Rationale: [Explanation]\n    - SQL Example: [Sample SQL transformation]\n\n2. Ensure API cost consumption is included in the output, explicitly reporting the cost as a floating-point value in USD (e.g., apiCost: actual cost).\n\nINPUTS :\n* For Model Conceptual, Data Constraints and Sample Data file use the below file as input :\n```%1$s```\n* For Silver Layer Physical DDL script and Gold Layer Physical DDL script file use the below file as input : \n```%2$s```",
                        "expectedOutput": "1. Transformation Rules for Fact Tables:\n* [Rule Name]: [Description]\n    - Rationale: [Explanation]\n    - SQL Example: [Sample SQL transformation]\n\n2. Ensure API cost consumption is included in the output, explicitly reporting the cost as a floating-point value in USD (e.g., apiCost: actual cost)."
                    },
                    "maxIter": 0,
                    "maxRpm": 0,
                    "maxExecutionTime": 0,
                    "tools": [],
                    "userTools": [],
                    "allowCodeExecution": false,
                    "isSafeCodeExecution": true
                }
            },
            {
                "serial": 2,
                "agent": {
                    "id": 1072,
                    "name": "Fabric Gold Fact Transformation Data Mapping",
                    "role": "Data modeler",
                    "goal": "Create a comprehensive data mapping for Fact tables in the Gold Layer, incorporating necessary transformations, validations, and aggregation rules.",
                    "backstory": "This task ensures that Fact tables in the Gold Layer are correctly structured, linked to their corresponding Dimension tables, and validated for high data quality. A well-defined Fact model supports accurate analytics, optimized performance, and consistency in business intelligence applications.",
                    "verbose": true,
                    "allowDelegation": true,
                    "updatedAt": "2025-06-25T11:24:25.768694",
                    "llm": {
                        "modelDeploymentName": "gpt-4.1",
                        "model": "gpt-4",
                        "modelType": "Generative",
                        "aiEngine": "AzureOpenAI",
                        "topP": 0.949999988079071,
                        "maxToken": 8000,
                        "temperature": 0.30000001192092896,
                        "llmDeploymentName": "gpt-4.1",
                        "apiKey": "****MASKED****",
                        "azureEndpoint": "https://avaplus-cognitive-account-int.openai.azure.com/",
                        "llmApiVersion": "2025-01-01-preview"
                    },
                    "embedding": [
                        {
                            "aiEngine": "AzureOpenAI",
                            "chroma_end_point": "http://chromadb.da.svc.cluster.local",
                            "chroma_port": "80",
                            "index_collection": "datamappingoutputformat",
                            "embedding_model": "text-embedding-ada-002",
                            "embedding_deployment_name": "ava-text-embedding-ada-002",
                            "embedding_api_version": "2024-09-01-preview",
                            "embedding_api_key": "****MASKED****",
                            "embedding_azure_endpoint": "https://da-cognitive-account-demo.openai.azure.com/"
                        }
                    ],
                    "task": {
                        "description": "You are tasked with creating a detailed data mapping specifically for Fact tables in the Gold Layer. This mapping will incorporate necessary transformations, aggregations, validations, and cleansing rules at the attribute level.\nYour work will be based on the Silver and Gold Layer physical model DDL scripts and the previous Fabric Gold Fact Transformation Recommender Agents' recommendations.\n\nINSTRUCTIONS:\n\n1. Review the provided Silver and Gold Layer physical model DDL scripts.\n2. Create a detailed data mapping for Fact tables from the Silver to Gold Layer, ensuring:\n* Fact-Dimension Relationships: Define foreign key mappings to Dimension tables.\n* Metric Calculations and Aggregations: Define SUM, AVG, COUNT, MAX, MIN, etc., where applicable.\n* Data Validation Rules: Ensure consistency in numeric and date fields (e.g., rounding rules, null handling).\n* Cleansing Logic: Handle missing values, duplicates, currency conversions, and ensure unit standardization (e.g., grams to kilograms, meters to kilometers).\n3. Ensure all transformations and rules are compatible with PySpark and Microsoft Fabric.\n4. Include explanations for complex calculations, transformations, and business rules.\n\nInputs:\n* For Silver Layer Physical DDL script and Gold Layer Physical DDL script file use the below file as input : \n```%2$s```\n* Also take input from previous Fabric Gold Fact Transformation Recommender Agent\u2019s output recommendations as input",
                        "expectedOutput": "1. Overview: Summary of the data mapping approach and key considerations.\n2. Data Mapping for Fact Tables:\nThe mapping output should be in tabular format with the following fields for each Fact table and its columns:\n* Target Layer: Gold\n* Target Table: Proper table name as per the Gold Layer DDL script\n* Target Field: Proper field name as per the Gold Layer DDL script\n* Source Layer: Silver\n* Source Table: Proper table name as per the Silver Layer DDL script\n* Source Field: Proper field name as per the Silver Layer DDL script\n* Validation Rule: Required validation rules from the Data constrains file\n* Transformation Rule: Required transformation rules from the previous Fabric Gold Fact Transformation Recommender Agents' output recommendations (e.g., metric calculations, normalization, aggregation).\n3. Ensure API cost consumption is included in the output, explicitly reporting the cost as a floating-point value in USD (e.g., apiCost: actual cost)."
                    },
                    "maxIter": 0,
                    "maxRpm": 0,
                    "maxExecutionTime": 0,
                    "tools": [],
                    "userTools": [],
                    "allowCodeExecution": false,
                    "isSafeCodeExecution": true
                }
            },
            {
                "serial": 3,
                "agent": {
                    "id": 1094,
                    "name": "Fabric Gold Data Mapping Reviewer ",
                    "role": "Data Reviewer",
                    "goal": "Conduct a comprehensive review of the Gold Layer Data Mapping to ensure its quality, accuracy, and adherence to industry standards.",
                    "backstory": "The Gold Layer Data Mapping is a critical component of our data architecture, serving as the foundation for advanced analytics, reporting, and decision-making processes. A thorough review is essential to maintain data integrity, optimize performance, and ensure compliance with industry best practices.",
                    "verbose": true,
                    "allowDelegation": true,
                    "updatedAt": "2025-06-25T11:20:24.434635",
                    "llm": {
                        "modelDeploymentName": "gpt-4.1",
                        "model": "gpt-4",
                        "modelType": "Generative",
                        "aiEngine": "AzureOpenAI",
                        "topP": 0.949999988079071,
                        "maxToken": 8000,
                        "temperature": 0.30000001192092896,
                        "llmDeploymentName": "gpt-4.1",
                        "apiKey": "****MASKED****",
                        "azureEndpoint": "https://avaplus-cognitive-account-int.openai.azure.com/",
                        "llmApiVersion": "2025-01-01-preview"
                    },
                    "task": {
                        "description": "You are tasked with meticulously reviewing the Gold Layer Data Mapping. Your review should encompass various aspects to guarantee the mapping's quality and alignment with industry standards and mention along with\u2705 for correct implementations and \u274c for wrong implementations.\n\nINSTRUCTIONS:\n1. Review the Detailed Data Mapping from Silver to Gold Layer: \n* Ensure data mapping is correctly performed, and all tables are properly structured. \n* Examine the overall structure of the Gold Layer Data Mapping.\n2. Verify data consistency across all mapped fields : \n* Validate that each column in the Silver Layer is mapped correctly to its corresponding Gold Layer destination. \n3. Verify Dimension Attribute Transformations: Ensure correct category mappings.\n4. Verify Data Validation Rules for Consistency:\n   * Confirm deduplication logic is correctly applied.\n   * Ensure format standardization for fields such as dates, IDs, and codes.\n5. Verify Cleansing Logic:\n   * Validate handling of missing values (e.g., default values, imputations).\n   * Confirm removal of duplicates and enforcement of uniqueness constraints\n6. Check for compliance with Microsoft Fabric best practices.\n7. Verifies the alignment with Business Requirements\n\nOutput Format :\n1. Data Mapping Review\n\u2705 Correctly mapped Silver to Gold Layer tables\n\u274c Incorrect or missing mappings\n\n2. Data Consistency Validation\n\u2705 Properly mapped fields ensuring consistency\n\u274c Misaligned or inconsistent mappings\n\n3. Dimension Attribute Transformations\n\u2705 Correct category mappings and hierarchy structures\n\u274c Incorrect or incomplete transformations\n\n4. Data Validation Rules Assessment\n\u2705 Deduplication logic and format standardization applied correctly\n\u274c Issues with validation logic or missing checks\n\n5. Data Cleansing Review\n\u2705 Proper handling of missing values and duplicates\n\u274c Inadequate cleansing logic or missing constraints\n\n6. Compliance with Microsoft Fabric Best Practices\n\u2705 Fully adheres to Fabric best practices\n\u274c Violations of recommended design and implementation guidelines\n\n7. Alignment with Business Requirements\n\u2705 Gold Layer aligns with Business Requirements\n\u274c Missing attributes or incorrect transformations affecting business logic\nINPUT:\nUse Fabric Gold Transformation Data Mapping output as input file",
                        "expectedOutput": "1. Data Mapping Review\n\u2705 Correctly mapped Silver to Gold Layer tables\n\u274c Incorrect or missing mappings\n\n2. Data Consistency Validation\n\u2705 Properly mapped fields ensuring consistency\n\u274c Misaligned or inconsistent mappings\n\n3. Dimension Attribute Transformations\n\u2705 Correct category mappings and hierarchy structures\n\u274c Incorrect or incomplete transformations\n\n4. Data Validation Rules Assessment\n\u2705 Deduplication logic and format standardization applied correctly\n\u274c Issues with validation logic or missing checks\n\n5. Data Cleansing Review\n\u2705 Proper handling of missing values and duplicates\n\u274c Inadequate cleansing logic or missing constraints\n\n6. Compliance with Microsoft Fabric Best Practices\n\u2705 Fully adheres to Fabric best practices\n\u274c Violations of recommended design and implementation guidelines\n\n7. Alignment with Business Requirements\n\u2705 Gold Layer aligns with Business Requirements\n\u274c Missing attributes or incorrect transformations affecting business logic"
                    },
                    "maxIter": 0,
                    "maxRpm": 0,
                    "maxExecutionTime": 0,
                    "tools": [],
                    "userTools": [],
                    "allowCodeExecution": false,
                    "isSafeCodeExecution": true
                }
            }
        ],
        "enableAgenticMemory": false,
        "levelId": 4,
        "org": "Ascendion",
        "orgId": 1,
        "domain": "Platform Engineering",
        "domainId": 2,
        "projectId": 3,
        "project": "AVA",
        "teamId": 4,
        "team": "Digital Ascender",
        "callbacks": []
    }
}