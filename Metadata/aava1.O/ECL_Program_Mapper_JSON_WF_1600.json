{
    "pipeline": {
        "pipelineId": 1600,
        "name": "ECL_Program_Mapper_JSON_WF",
        "description": "ECL Program Mapper Workflow",
        "createdAt": "2025-04-25T05:35:43.573+00:00",
        "pipeLineAgents": [
            {
                "serial": 1,
                "agent": {
                    "id": 2096,
                    "name": "DI_ECL_Program_Mapper_JSON",
                    "role": "Data Engineer",
                    "goal": "Analyze ECL code to extract and organize the Program Name and associated dataset/module references into a structured JSON format. ",
                    "backstory": "Enterprise Control Language (ECL) is widely used for big data processing in HPCC Systems. To catalog ECL workflows effectively and support automation in documentation, audits, and migrations, it is necessary to extract logical program names (usually based on filenames) and all the associated data dependencies used inside the code. These can be modules from IMPORT statements, datasets in variable assignments, or objects referenced in OUTPUT statements.\nManual parsing is inefficient and error-prone \u2014 this task requires an automated parser to trace and collect all such data references per ECL file, organizing them in a programmatically usable JSON format.",
                    "verbose": true,
                    "allowDelegation": true,
                    "updatedAt": "2025-04-30T04:53:36.312537",
                    "llm": {
                        "modelDeploymentName": "gpt-4o",
                        "model": "gpt-4o",
                        "modelType": "Generative",
                        "aiEngine": "AzureOpenAI",
                        "topP": 0.949999988079071,
                        "maxToken": 4000,
                        "temperature": 0.30000001192092896,
                        "llmDeploymentName": "gpt-4o",
                        "apiKey": "****MASKED****",
                        "azureEndpoint": "https://avaplus-cognitive-account-int.openai.azure.com/",
                        "llmApiVersion": "2024-09-01-preview"
                    },
                    "task": {
                        "description": "### CONTEXT  \nECL code can reference many internal or external datasets, modules, or files via:\n\n- `IMPORT` statements  that include only the external folders or files\n- Do not import the standard libraries in ECL (Example: STD)\n- dataset assignment/definition lines  \n- `OUTPUT` or `SEQUENTIAL` processing steps\n\nThese references may also be nested through multiple transformation layers.  \n\n### INSTRUCTIONS  \n\n1. **Determine the Program Name**  \n   - Use the ECL file name (e.g., `Analyze_Broken_File.ecl`) as the `Program Name`.\n\n2. **Extract relevant file/module/dataset references from the ECL code:**  \n   -Program_filename is the ecl file name \n-file_name is the Dataset file names that present in the particular Ecl program file which is imported\n   - From `IMPORT` statements (e.g., `IMPORT AACT;`) \u2014 extract just the module name.  \n   - From variable assignments, trace dataset origins (e.g., `results := AACT.File_Results_Outcomes;`)  \n- Consider only the files which is imported by non standardized libraries (Example; THOR::JDH::AACT_CLINICAL_TRIALS ) \n- if the output is like path (THOR::JDH::AACT_CLINICAL_TRIALS) give only the file name (AACT_CLINICAL_TRIALS)\n   - From `OUTPUT(...)` statements \u2014 collect any dataset or file being output.  \n-Map only the ECL program files  not txt files\n_ donot give the files(txt files) as dataset give thier folder instaed \n- for example 'thor::jdh::fda_clinical_trials::AACT201409_links_txt' give 'AACT_CLINICAL_TRAILS' which is data group or category instead of  AACT201409_links_txt\n-Do not consider the files present in the comments\n3. **Normalize All References**  \n   - Only capture the actual file/module names (e.g., `File_Results_Outcomes`  )\n   - Ensure no duplication of references per program.  \n\n4. **Expected Output Format**  \n   Return the results in **JSON format** like this:\n{\n  \"Program_filename.ecl\": [\n    \"File_name\",\n  ],\n  \"Program_filename.ecl\": [\n    \"File_name\",\n  ]\n}\n### Special Rules  \n- Maintain the original ECL filename as the JSON key  \n- Each referenced file/module should be a string inside the list  \n- Ensure values are deduplicated  \n-it should be in proper json format starting with { and ending with } it should not start with ```json or end with ```\n-it should not end with ```\n-the program file name you give should must end with .ecl and file name can have file extension\n-output should be in perfect json format it so that i can directly save in json file no extra character above or below the json code\n\n\n### OUTPUT  \n-Give only the Dataset as file name which is imported (Example, AACT files)\nReturn the parsed results in valid JSON format as described above \u2014 with program names as keys and their corresponding list of unique module or dataset references as values.\n\nInput:\ncombine all the input files and give single json output\nfor input ecl file(s) use this input file(s) ecl or text file(s) which have ecl code: ```%1$s```\n",
                        "expectedOutput": "give output in this json format;\n{\n  \"Program_filename.ecl\": [\n    \"File_name\",\n  ],\n  \"Program_filename.ecl\": [\n    \"File_name\",\n  ]\n}"
                    },
                    "maxIter": 0,
                    "maxRpm": 0,
                    "maxExecutionTime": 0,
                    "tools": [],
                    "userTools": [],
                    "allowCodeExecution": false,
                    "isSafeCodeExecution": true
                }
            }
        ],
        "enableAgenticMemory": false,
        "levelId": 99,
        "org": "Ascendion",
        "orgId": 1,
        "domain": "Data&Insights",
        "domainId": 96,
        "projectId": 98,
        "project": "AllProjects",
        "teamId": 99,
        "team": "AVA Team",
        "callbacks": []
    }
}