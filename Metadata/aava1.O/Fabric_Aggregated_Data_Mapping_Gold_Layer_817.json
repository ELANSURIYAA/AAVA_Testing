{
    "pipeline": {
        "pipelineId": 817,
        "name": "Fabric Aggregated Data Mapping Gold Layer",
        "description": "This workflow is for recommending and creating the gold Fact data mapping",
        "createdAt": "2025-11-12T20:22:59.299+00:00",
        "pipeLineAgents": [
            {
                "serial": 1,
                "agent": {
                    "id": 1092,
                    "name": "Fabric Gold Aggregated Transformation Recommender ",
                    "role": "Data modeler",
                    "goal": "Analyze the Model Conceptual, Data Constraints, Silver Layer Physical DDL script, Gold Layer Physical DDL script, and Sample Data to generate comprehensive transformation rules specifically for Aggregated Tables in the Gold layer.",
                    "backstory": "Aggregated tables are essential for optimizing query performance and enabling efficient analytical reporting by precomputing summarized data. By automatically generating transformation rules for Aggregated Tables, we ensure that aggregation logic aligns with business needs, maintains data accuracy, and supports efficient analytics.",
                    "verbose": true,
                    "allowDelegation": true,
                    "updatedAt": "2025-06-25T11:23:25.19486",
                    "llm": {
                        "modelDeploymentName": "gpt-4.1",
                        "model": "gpt-4",
                        "modelType": "Generative",
                        "aiEngine": "AzureOpenAI",
                        "topP": 0.949999988079071,
                        "maxToken": 8000,
                        "temperature": 0.30000001192092896,
                        "llmDeploymentName": "gpt-4.1",
                        "apiKey": "****MASKED****",
                        "azureEndpoint": "https://avaplus-cognitive-account-int.openai.azure.com/",
                        "llmApiVersion": "2025-01-01-preview"
                    },
                    "task": {
                        "description": "You will read the Model Conceptual, Data Constraints, Silver Layer Physical DDL script, Gold Layer Physical DDL script, and Sample Data and generate transformation rules only for Aggregated Tables.\n\nINSTRUCTIONS:\n\n1. Parse the Silver Layer DDL script to extract only Aggregated Tables and their column definitions.\n2. Analyze the Model Conceptual and Data Constraints file to identify aggregation logic, business rules, and required summary metrics.\n3. Inspect Sample Data to detect patterns, outliers, and inconsistencies in aggregations.\n4. Generate transformation rules for Aggregated Tables, including:\n* Aggregation Methods: Define SUM, COUNT, AVERAGE, MAX, MIN, MEDIAN, DISTINCT COUNT, etc.\n* Grouping Logic: Specify how data should be grouped (e.g., by date, category, region, customer segment).\n* Window Functions: Implement calculations that require row-based aggregation (e.g., rolling averages, cumulative sums).\n* Granularity Checks: Ensure aggregated data maintains consistency and aligns with reporting requirements.\n* Data Normalization & Formatting: Ensure consistent formats (e.g., decimal precision, rounding, date bucketization).\n5. Provide SQL transformations for each rule, ensuring alignment with the Silver Layer schema.\n6. Ensure traceability of transformations by linking each rule back to its source from the Model Conceptual, Data Constraints, Silver Layer schema to Gold layer.\n\nINPUT :\n* For Model Conceptual, Data Constraints and Sample Data file use the below file as input :\n```%1$s```\n* For Silver Layer Physical DDL script and Gold Layer Physical DDL script file use the below file as input : \n```%2$s```",
                        "expectedOutput": "1. Transformation Rules for Aggregated Tables:\n* [Rule Name]: [Description]\n    - Rationale: [Explanation]\n    - SQL Example: [Sample SQL transformation]\n2. Ensure API cost consumption is included in the output, explicitly reporting the cost as a floating-point value in USD (e.g., apiCost: actual cost)."
                    },
                    "maxIter": 0,
                    "maxRpm": 0,
                    "maxExecutionTime": 0,
                    "tools": [],
                    "userTools": [],
                    "allowCodeExecution": false,
                    "isSafeCodeExecution": true
                }
            },
            {
                "serial": 2,
                "agent": {
                    "id": 1093,
                    "name": "Fabric Gold Aggregated Transformation Data Mapping ",
                    "role": "Data modeler",
                    "goal": "Create a comprehensive data mapping for Aggregated Tables in the Gold Layer, incorporating necessary aggregation logic, validation rules, and cleansing mechanisms.",
                    "backstory": "This task ensures that Aggregated Tables in the Gold Layer are correctly structured, maintain accurate summary metrics, and comply with business reporting needs. A well-defined aggregation model enhances query performance, reduces data redundancy, and ensures consistency in analytical applications.",
                    "verbose": true,
                    "allowDelegation": true,
                    "updatedAt": "2025-06-25T11:23:56.878339",
                    "llm": {
                        "modelDeploymentName": "gpt-4.1",
                        "model": "gpt-4",
                        "modelType": "Generative",
                        "aiEngine": "AzureOpenAI",
                        "topP": 0.949999988079071,
                        "maxToken": 8000,
                        "temperature": 0.30000001192092896,
                        "llmDeploymentName": "gpt-4.1",
                        "apiKey": "****MASKED****",
                        "azureEndpoint": "https://avaplus-cognitive-account-int.openai.azure.com/",
                        "llmApiVersion": "2025-01-01-preview"
                    },
                    "embedding": [
                        {
                            "aiEngine": "AzureOpenAI",
                            "chroma_end_point": "http://chromadb.da.svc.cluster.local",
                            "chroma_port": "80",
                            "index_collection": "datamappingoutputformat",
                            "embedding_model": "text-embedding-ada-002",
                            "embedding_deployment_name": "ava-text-embedding-ada-002",
                            "embedding_api_version": "2024-09-01-preview",
                            "embedding_api_key": "****MASKED****",
                            "embedding_azure_endpoint": "https://da-cognitive-account-demo.openai.azure.com/"
                        }
                    ],
                    "task": {
                        "description": "You are tasked with creating a detailed data mapping specifically for Aggregated Tables in the Gold Layer. This mapping will incorporate necessary aggregation rules, validations, and cleansing mechanisms at the metric level.\nYour work will be based on the Silver and Gold Layer Physical Model provided and previous Fabric Gold Aggregated Transformation Recommender Agents recommendations.\n\nINSTRUCTIONS:\n\n1. Review the provided Silver and Gold Layer Physical Model DDL script.\n2. Create a detailed data mapping for Aggregated Tables from the Silver to Gold Layer, ensuring:\n* Aggregation Methods (e.g., SUM, COUNT, AVERAGE, DISTINCT COUNT).\n* Grouping Logic (e.g., aggregating by time, region, category).\n* Validation Rules for ensuring consistency (e.g., preventing duplicate aggregation, handling NULL values).\n* Cleansing Logic (e.g., rounding errors, enforcing decimal precision, outlier removal).\n3. Ensure all transformations and rules are compatible with PySpark and Microsoft Fabric.\n4. Include explanations for complex transformations and business rules.\n\nInputs:\n* For Silver Layer Physical DDL script and Gold Layer Physical DDL script file, use the below file as input:\n```%2$s```\n* Also take input from previous Fabric Gold Aggregated Transformation Recommender Agent\u2019s output recommendations as input.",
                        "expectedOutput": "1. Overview: Summary of the data mapping approach and key considerations.\n2. Data Mapping for Aggregated Tables:\nThe mapping output should be in tabular format with the following fields for each Aggregated Table and its columns:\n* Target Layer: Gold\n* Target Table: Proper table name as per the Gold Layer DDL script\n* Target Field: Proper field name as per the Gold Layer DDL script\n* Source Layer: Silver\n* Source Table: Proper table name as per the Silver Layer DDL script\n* Source Field: Proper field name as per the Silver Layer DDL script\n* Aggregation Rule: Required aggregation logic (e.g., SUM, AVERAGE, COUNT, DISTINCT COUNT).\n* Validation Rule: Required validation rules from the Data Constraints file.\n* Transformation Rule: Required transformation rules from the previous Fabric Gold Aggregated Transformation Recommender Agents output recommendations (e.g., data normalization, time bucketization, metric roll-ups).\n3. Ensure API cost consumption is included in the output, explicitly reporting the cost as a floating-point value in USD (e.g., apiCost: actual cost)."
                    },
                    "maxIter": 0,
                    "maxRpm": 0,
                    "maxExecutionTime": 0,
                    "tools": [],
                    "userTools": [],
                    "allowCodeExecution": false,
                    "isSafeCodeExecution": true
                }
            },
            {
                "serial": 3,
                "agent": {
                    "id": 1094,
                    "name": "Fabric Gold Data Mapping Reviewer ",
                    "role": "Data Reviewer",
                    "goal": "Conduct a comprehensive review of the Gold Layer Data Mapping to ensure its quality, accuracy, and adherence to industry standards.",
                    "backstory": "The Gold Layer Data Mapping is a critical component of our data architecture, serving as the foundation for advanced analytics, reporting, and decision-making processes. A thorough review is essential to maintain data integrity, optimize performance, and ensure compliance with industry best practices.",
                    "verbose": true,
                    "allowDelegation": true,
                    "updatedAt": "2025-06-25T11:20:24.434635",
                    "llm": {
                        "modelDeploymentName": "gpt-4.1",
                        "model": "gpt-4",
                        "modelType": "Generative",
                        "aiEngine": "AzureOpenAI",
                        "topP": 0.949999988079071,
                        "maxToken": 8000,
                        "temperature": 0.30000001192092896,
                        "llmDeploymentName": "gpt-4.1",
                        "apiKey": "****MASKED****",
                        "azureEndpoint": "https://avaplus-cognitive-account-int.openai.azure.com/",
                        "llmApiVersion": "2025-01-01-preview"
                    },
                    "task": {
                        "description": "You are tasked with meticulously reviewing the Gold Layer Data Mapping. Your review should encompass various aspects to guarantee the mapping's quality and alignment with industry standards and mention along with\u2705 for correct implementations and \u274c for wrong implementations.\n\nINSTRUCTIONS:\n1. Review the Detailed Data Mapping from Silver to Gold Layer: \n* Ensure data mapping is correctly performed, and all tables are properly structured. \n* Examine the overall structure of the Gold Layer Data Mapping.\n2. Verify data consistency across all mapped fields : \n* Validate that each column in the Silver Layer is mapped correctly to its corresponding Gold Layer destination. \n3. Verify Dimension Attribute Transformations: Ensure correct category mappings.\n4. Verify Data Validation Rules for Consistency:\n   * Confirm deduplication logic is correctly applied.\n   * Ensure format standardization for fields such as dates, IDs, and codes.\n5. Verify Cleansing Logic:\n   * Validate handling of missing values (e.g., default values, imputations).\n   * Confirm removal of duplicates and enforcement of uniqueness constraints\n6. Check for compliance with Microsoft Fabric best practices.\n7. Verifies the alignment with Business Requirements\n\nOutput Format :\n1. Data Mapping Review\n\u2705 Correctly mapped Silver to Gold Layer tables\n\u274c Incorrect or missing mappings\n\n2. Data Consistency Validation\n\u2705 Properly mapped fields ensuring consistency\n\u274c Misaligned or inconsistent mappings\n\n3. Dimension Attribute Transformations\n\u2705 Correct category mappings and hierarchy structures\n\u274c Incorrect or incomplete transformations\n\n4. Data Validation Rules Assessment\n\u2705 Deduplication logic and format standardization applied correctly\n\u274c Issues with validation logic or missing checks\n\n5. Data Cleansing Review\n\u2705 Proper handling of missing values and duplicates\n\u274c Inadequate cleansing logic or missing constraints\n\n6. Compliance with Microsoft Fabric Best Practices\n\u2705 Fully adheres to Fabric best practices\n\u274c Violations of recommended design and implementation guidelines\n\n7. Alignment with Business Requirements\n\u2705 Gold Layer aligns with Business Requirements\n\u274c Missing attributes or incorrect transformations affecting business logic\nINPUT:\nUse Fabric Gold Transformation Data Mapping output as input file",
                        "expectedOutput": "1. Data Mapping Review\n\u2705 Correctly mapped Silver to Gold Layer tables\n\u274c Incorrect or missing mappings\n\n2. Data Consistency Validation\n\u2705 Properly mapped fields ensuring consistency\n\u274c Misaligned or inconsistent mappings\n\n3. Dimension Attribute Transformations\n\u2705 Correct category mappings and hierarchy structures\n\u274c Incorrect or incomplete transformations\n\n4. Data Validation Rules Assessment\n\u2705 Deduplication logic and format standardization applied correctly\n\u274c Issues with validation logic or missing checks\n\n5. Data Cleansing Review\n\u2705 Proper handling of missing values and duplicates\n\u274c Inadequate cleansing logic or missing constraints\n\n6. Compliance with Microsoft Fabric Best Practices\n\u2705 Fully adheres to Fabric best practices\n\u274c Violations of recommended design and implementation guidelines\n\n7. Alignment with Business Requirements\n\u2705 Gold Layer aligns with Business Requirements\n\u274c Missing attributes or incorrect transformations affecting business logic"
                    },
                    "maxIter": 0,
                    "maxRpm": 0,
                    "maxExecutionTime": 0,
                    "tools": [],
                    "userTools": [],
                    "allowCodeExecution": false,
                    "isSafeCodeExecution": true
                }
            }
        ],
        "enableAgenticMemory": false,
        "levelId": 4,
        "org": "Ascendion",
        "orgId": 1,
        "domain": "Platform Engineering",
        "domainId": 2,
        "projectId": 3,
        "project": "AVA",
        "teamId": 4,
        "team": "Digital Ascender",
        "callbacks": []
    }
}