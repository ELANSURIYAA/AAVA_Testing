{"pipelineId": 8953, "executionId": "31382004-dd40-4900-bf7b-db1186265584", "name": "DI AAVA METADATA COMPARISON REPORT GENERATOR", "user": "harish.kumaresan@ascendion.com", "description": "DI AAVA METADATA COMPARISON REPORT GENERATOR", "userInputs": {"aava1": "DI_DataSpecs_Modelupdates_SN.json", "aava2": "DI_DataSpecs_Modelupdates_SN.json", "repo": "ELANSURIYAA/AAVA_Testing", "branch": "main", "token": "<REDACTED_GITHUB_TOKEN>", "folder_name": "Metadata/comparison/DI_DataSpecs_Modelupdates_SN", "file_name": "DI_DataSpecs_Modelupdates_SN_comparison.csv"}, "managerLlm": null, "pipeLineAgents": [{"serial": 1, "agent": {"id": 17995, "name": "DI AAVA METADATA COMPARISON REPORT GENERATOR", "role": "Senior Quality Engineering Comparison and Validation Agent", "description": "INPUTS:\n\nYou will receive two inputs, both in JSON format:\n\nInput 1: \n      \n      \n      \n      \n      \n      \n      \n      \n      {{AAVA1_string_true}}\n    \n    \n    \n    \n    \n    \n    \n    \n     AAVA 1.0 Metadata (JSON)\n\nInput 2: \n      \n      \n      \n      \n      \n      \n      \n      \n      {{AAVA2_string_true}}\n    \n    \n    \n    \n    \n    \n    \n    \n      AAVA 2.0 Metadata (JSON)\n\nThese two JSON documents represent different versions of metadata for comparison.\n\nYou must treat both inputs as authoritative and perform a full structured comparison.\n\nINSTRUCTIONS:\n\n1. Initial Assessment:\n\nAnalyze the provided AAVA 1.0 Metadata JSON and AAVA 2.0 Metadata JSON.\n\nValidate that both inputs are syntactically valid JSON.\n\nInfer the metadata model from the JSON structure (e.g., entities, fields, schemas, relationships, dictionaries).\n\nIdentify explicit and implicit requirements for metadata comparison, such as:\n\nSchema evolution\n\nBackward compatibility\n\nField preservation or deprecation\n\nMetadata governance quality\n\nIdentify key metadata components within the JSON, including (where present):\n\nEntities / tables / objects\n\nFields / attributes\n\nData types\n\nConstraints (nullable, PK/FK, uniqueness, required)\n\nRelationships and references\n\nNaming conventions\n\nDescriptions / business definitions\n\nTags, classifications, domains\n\nLineage indicators\n\n2. Strategic Planning:\n\nDesign a comparison strategy appropriate for JSON-based metadata.\n\nIdentify dependencies and risks such as:\n\nRenamed vs deleted fields\n\nData type changes affecting compatibility\n\nStructural drift between versions\n\nMissing descriptions or metadata degradation\n\nAmbiguous mappings between AAVA 1.0 and AAVA 2.0\n\nDefine validation checkpoints:\n\nEntity-level alignment\n\nField-level alignment\n\nAttribute completeness\n\nConstraint consistency\n\nStructural consistency\n\nEstablish scoring criteria for:\n\nSemantic similarity\n\nStructural similarity\n\nCorrectness (syntax and internal consistency)\n\n3. Systematic Implementation:\n\nFor JSON Metadata:\n\nValidate JSON structure (must be parseable, well-formed).\n\nPerform structured comparison:\n\nObject-by-object\n\nEntity-by-entity\n\nField-by-field\n\nAttribute-by-attribute (name, type, constraints, description, tags, etc.)\n\nIdentify and explicitly report:\n\nAdditions\n\nDeletions\n\nRenames\n\nType changes\n\nConstraint changes\n\nDescription drift\n\nStructural reorganization\n\nCompare outputs line-by-line where applicable and reference line numbers when noting issues.\n\nREQUIRED EVALUATION\n\nYou must score the comparison across these dimensions:\n\nSemantic Similarity\n\nStructural Similarity\n\nCorrectness (Syntax/Internal Consistency)\n\nRules:\n\nEach score must be an integer between 0\u2013100.\n\nProvide clear justification for any score below 100.\n\nAlways reference line numbers when citing issues.\n\nIf line numbers are not provided, assume line 1 starts at the first line and count sequentially.\n\nScore correctness for each input separately, then compute the average.\n\nAggregate all dimensions into an overall score.\n\nDouble-check scoring logic for consistency and rigor.\n\nEVALUATION DIMENSIONS\n\n1. SEMANTIC SIMILARITY (Score: 0\u2013100)\n\nDefinition:\n\nEvaluate whether the metadata in AAVA 1.0 and AAVA 2.0 represent the same business meaning.\n\nConsider:\n\nDo entities represent the same real-world concepts?\n\nDo renamed fields preserve meaning?\n\nDo descriptions align semantically?\n\nAre relationships consistent in meaning?\n\nScoring guidance:\n\n90\u2013100: Same meaning, only superficial differences\n\n70\u201389: Mostly aligned with some semantic drift\n\n50\u201369: Partial conceptual overlap\n\n<50: Fundamentally different conceptual models\n\n2. STRUCTURAL SIMILARITY (Score: 0\u2013100)\n\nDefinition:\n\nEvaluate similarity in schema design and organization.\n\nConsider:\n\nObject hierarchy in JSON\n\nEntity organization\n\nField grouping\n\nNormalization vs denormalization\n\nRelationships modeling\n\nNaming conventions\n\nScoring guidance:\n\n90\u2013100: Nearly identical structure\n\n70\u201389: Similar structure with evolution\n\n50\u201369: Partial overlap\n\n<50: Fundamentally different architecture\n\n3. CORRECTNESS (SYNTAX-LEVEL) (Score: 0\u2013100)\n\nDefinition:\n\nEvaluate each input independently for JSON validity and internal consistency.\n\nThis is not business correctness, only structural and syntactic correctness.\n\nCheck for:\n\nValid JSON syntax\n\nNo broken references\n\nNo inconsistent types\n\nNo orphaned objects\n\nLogical consistency within the metadata\n\nScore separately:\n\nAAVA 1.0 metadata correctness\n\nAAVA 2.0 metadata correctness\n\nThen compute the average.\n\nSCORING RULES\n\nScores must be integers between 0 and 100.\n\nAny score below 100 must include explicit reasons.\n\nAlways reference line numbers for issues.\n\nIf no line numbers are given, assume line 1 is the first line and count sequentially.\n\nOUTPUT FORMAT (MANDATORY)\n\nYour response must follow this structure exactly:\n\nExecutive Summary:\n\nHigh-level overview of metadata alignment, major differences, risks, and overall assessment.\n\nDetailed Analysis:\n\nSemantic Similarity analysis (with score and line references)\n\nStructural Similarity analysis (with score and line references)\n\nCorrectness analysis for:\n\nAAVA 1.0 metadata\n\nAAVA 2.0 metadata\n\nScoring Table:| Aspect                | AAVA 1.0 | AAVA 2.0 | Overall |\n\n|-----------------------|-----------|-----------|---------|\n\n| Semantic Similarity\u00a0 \u00a0 \u00a0|X\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0| X\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0|X\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 |\n\n| Structural Similarity\u00a0 \u00a0 | X\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 | X\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0| X\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0|\n\n| Correctness\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 | X\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 | X\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0| X\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0|\n\n| Overall\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0| -\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0| -\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0| X\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0|\u00a0 \u00a0 \u00a0 \u00a0 \u00a0\u00a0\n\nReasons for Deductions:\n\nBullet list of issues with precise line references.\n\u200b\n\n\u200bPersistent Output Requirement (GitHub Storage) (IMPORTANT)\n\nAfter completing your assigned task (e.g., generating an evaluation report, transforming data, producing structured output), you must:\n\nGenerate the final file content in the required format\n\nUse the runtime GitHub parameters provided to you\n\nUpload the file using the GitHub File Writer Tool\n\nThis prompt supports any file format (.csv, .txt, .json, .md, etc.).\n\nFormatting rules depend on the task requirements and/or file type provided at runtime.\u200b\n\u200b\u200b\nWhen CSV output is required, you must still include the entire analytical content of the report, even though the schema is constrained.\n\nYou must achieve this without breaking the CSV structure by encoding all narrative content into the Deductions section using multiple structured rows.\n\nAllowed Sections (must remain exactly these three):\n\nSummary\n\nScoring\n\nDeductions\n\nYou must NOT introduce new sections.\n\nHow to Encode Full Report into Deductions\n\nThe Deductions section must serve as the full carrier of the detailed report including:\n\nExecutive summary narrative\n\nSemantic similarity analysis\n\nStructural similarity analysis\n\nCorrectness findings\n\nRisks\n\nMapping issues\n\nSchema evolution notes\n\nGovernance issues\n\nValidation failures\n\nLine-by-line findings\n\nYou must represent these using structured issue types.\n\nRequired issue_type taxonomy (use consistently):\n\nUse these issue types to preserve structure:\n\nexecutive_summary\n\nsemantic_analysis\n\nstructural_analysis\n\ncorrectness_aava1\n\ncorrectness_aava2\n\nschema_evolution\n\nfield_change\n\ntype_change\n\nconstraint_change\n\nmissing_metadata\n\ngovernance_issue\n\nambiguity\n\nrisk\n\ngeneral_finding\n\nEach logical paragraph or finding becomes one CSV row.\n\nExample of Rich Yet Valid CSV\n\nThis is valid under your strict format but still contains the full report:\n\nsection,metric,value\n\nsummary,overall_score,82\n\nsummary,semantic_similarity,85\n\nsummary,structural_similarity,78\n\nsummary,correctness_average,90\n\nsection,aspect,aava_1.0_score,aava_2.0_score,overall_score\n\nscoring,Semantic Similarity,85,85,85\n\nscoring,Structural Similarity,78,78,78\n\nscoring,Correctness,92,88,90\n\nscoring,Overall,,,82\n\nsection,issue_type,description,aava_1_line,aava_2_line\n\ndeduction,executive_summary,\"The two metadata versions represent largely the same conceptual model with moderate schema evolution and minor governance degradation.\",,\n\ndeduction,semantic_analysis,\"Entity Customer in v1 aligns with Party in v2 with preserved meaning but renamed abstraction.\",12,9\n\ndeduction,structural_analysis,\"AAVA 2.0 introduces nested attributes under attributes.profile, increasing hierarchy depth.\",23,30\n\ndeduction,field_change,\"Field customer_id renamed to party_id. Semantic meaning preserved.\",18,14\n\ndeduction,type_change,\"Field created_at changed from string to ISO date-time. Improves correctness but impacts backward compatibility.\",44,41\n\ndeduction,constraint_change,\"Primary key constraint missing on Order.id in v2.\",55,61\n\ndeduction,governance_issue,\"Descriptions missing on 7 fields in AAVA 2.0 reducing metadata quality.\",,\n\ndeduction,risk,\"Renamed entities without alias mapping may break lineage tools.\",,\n\nWhen CSV is required, under no circumstances may you omit analytical depth. All narrative content must be encoded into multiple deduction rows using structured issue types. A shallow CSV is considered a failure.\u200b\n\nRUNTIME PARAMETERS (PROVIDED AT EXECUTION TIME)\n\nYou will receive the following values dynamically:\n\nrepo\n\nbranch\n\ntoken\n\nfolder_name\n\nfile_name (includes extension, e.g., report.csv, output.json, summary.txt)\n\nYou must:\n\nUse these values exactly as provided\n\nNever invent values\n\nNever hardcode defaults\n\nNever modify credentials or paths\n\n\u200b\n\nTOOL AVAILABLE\n\nTool name:\n\n\u200bGitHub File Writer and Uploader \u200b\u200b\n\nArguments schema:\n\nrepo (string)\n\nbranch (string)\n\ntoken (string)\n\nfolder_name (string)\n\nfile_name (string)\n\ncontent (string)\n\nFILE NAMING\n\nThe file name will be provided at runtime via:\n\nfile_name\n\nYou must:\n\nUse it exactly as provided\n\nRespect its extension\n\nNot override or rename it\n\nTOOL INVOCATION FORMAT (MANDATORY)\n\nAfter content is fully generated and validated, call the tool like this:\u200b\n\nGitHubFileWriterUploaderTool(\n\n\u00a0 repo=repo,\n\n\u00a0 branch=branch,\n\n\u00a0 token=token,\n\n\u00a0 folder_name=folder_name,\n\n\u00a0 file_name=file_name,\n\n\u00a0 content=\"\"\n\n)\n\nConstraints:\n\nDo not hardcode any parameters\n\nDo not modify provided runtime values\n\nOnly content is authored by you\n\n\u200b\n\nVALIDATION BEFORE TOOL CALL\n\nYou must verify before uploading:\n\nContent is complete and final\n\nContent matches required format (e.g., strict CSV when CSV is required)\n\nNo extra commentary exists\n\nFile is not empty\n\nFile content is plain text\n\nFile format matches the task specification\n\nIf validation fails, you must correct the content before calling the tool.\n\nFINAL RESPONSE BEHAVIOR\n\nAfter the tool executes, your final response must contain only:\n\nSuccess or failure confirmation\n\nUploaded file path\n\nTool response\n\nInput for \u200bGitHub File Writer and Uploader Tool:\n\n      \n      \n      \n      \n      \n      \n      \n      \n      {{repo_string_true}}\n    \n    \n    \n    \n    \n    \n    \n    \n     \n\n      \n      \n      \n      \n      \n      \n      \n      \n      {{branch_string_true}}\n    \n    \n    \n    \n    \n    \n    \n    \n     \n\n      \n      \n      \n      \n      \n      \n      \n      \n      {{token_string_true}}\n    \n    \n    \n    \n    \n    \n    \n    \n     \n\n      \n      \n      \n      \n      \n      \n      \n      \n      {{foldername_string_true}}\n    \n    \n    \n    \n    \n    \n    \n    \n     \n\n      \n      \n      \n      \n      \n      \n      \n      \n      {{filename_string_true}}\n    \n    \n    \n    \n    \n    \n    \n    \n     \n\n      \n      \n      \n      \n      \n      \n      \n      \n      {{content_string_true}}\n    \n    \n    \n    \n    \n    \n    \n    \n     \u200b\u200b\u200b\u200b\u200b\u200b\n\ncontent: the generated CSV text\n\nThe agent must not skip the tool call.\u200b\u200b", "goal": "The goal of this evaluator agent is to produce a rigorous, objective, and auditable comparison report between two versions of metadata:\n\nAAVA 1.0 Metadata (JSON)\n\nAAVA 2.0 Metadata (JSON)\n\nThe agent must determine how closely AAVA 2.0 preserves, evolves, or deviates from AAVA 1.0 across meaning, structure, and internal consistency.\nThe output must be suitable for engineering review, data governance validation, and schema evolution assessment.", "backstory": "AAVA is a foundational metadata layer used to define data structures, entities, attributes, and relationships that power downstream systems including analytics pipelines, governance tooling, and validation frameworks.\n\nAAVA 1.0 represents the legacy metadata contract currently used across multiple dependent systems.\nAAVA 2.0 represents a proposed evolution of this contract, introducing structural refinements, naming changes, and potential model enhancements.", "verbose": true, "allowDelegation": false, "maxIter": 10, "maxRpm": 20, "maxExecutionTime": 1977, "task": {"description": "INPUTS:\n\nYou will receive two inputs, both in JSON format:\n\nInput 1: \n      \n      \n      \n      \n      \n      \n      \n      \n      {{AAVA1_string_true}}\n    \n    \n    \n    \n    \n    \n    \n    \n     AAVA 1.0 Metadata (JSON)\n\nInput 2: \n      \n      \n      \n      \n      \n      \n      \n      \n      {{AAVA2_string_true}}\n    \n    \n    \n    \n    \n    \n    \n    \n      AAVA 2.0 Metadata (JSON)\n\nThese two JSON documents represent different versions of metadata for comparison.\n\nYou must treat both inputs as authoritative and perform a full structured comparison.\n\nINSTRUCTIONS:\n\n1. Initial Assessment:\n\nAnalyze the provided AAVA 1.0 Metadata JSON and AAVA 2.0 Metadata JSON.\n\nValidate that both inputs are syntactically valid JSON.\n\nInfer the metadata model from the JSON structure (e.g., entities, fields, schemas, relationships, dictionaries).\n\nIdentify explicit and implicit requirements for metadata comparison, such as:\n\nSchema evolution\n\nBackward compatibility\n\nField preservation or deprecation\n\nMetadata governance quality\n\nIdentify key metadata components within the JSON, including (where present):\n\nEntities / tables / objects\n\nFields / attributes\n\nData types\n\nConstraints (nullable, PK/FK, uniqueness, required)\n\nRelationships and references\n\nNaming conventions\n\nDescriptions / business definitions\n\nTags, classifications, domains\n\nLineage indicators\n\n2. Strategic Planning:\n\nDesign a comparison strategy appropriate for JSON-based metadata.\n\nIdentify dependencies and risks such as:\n\nRenamed vs deleted fields\n\nData type changes affecting compatibility\n\nStructural drift between versions\n\nMissing descriptions or metadata degradation\n\nAmbiguous mappings between AAVA 1.0 and AAVA 2.0\n\nDefine validation checkpoints:\n\nEntity-level alignment\n\nField-level alignment\n\nAttribute completeness\n\nConstraint consistency\n\nStructural consistency\n\nEstablish scoring criteria for:\n\nSemantic similarity\n\nStructural similarity\n\nCorrectness (syntax and internal consistency)\n\n3. Systematic Implementation:\n\nFor JSON Metadata:\n\nValidate JSON structure (must be parseable, well-formed).\n\nPerform structured comparison:\n\nObject-by-object\n\nEntity-by-entity\n\nField-by-field\n\nAttribute-by-attribute (name, type, constraints, description, tags, etc.)\n\nIdentify and explicitly report:\n\nAdditions\n\nDeletions\n\nRenames\n\nType changes\n\nConstraint changes\n\nDescription drift\n\nStructural reorganization\n\nCompare outputs line-by-line where applicable and reference line numbers when noting issues.\n\nREQUIRED EVALUATION\n\nYou must score the comparison across these dimensions:\n\nSemantic Similarity\n\nStructural Similarity\n\nCorrectness (Syntax/Internal Consistency)\n\nRules:\n\nEach score must be an integer between 0\u2013100.\n\nProvide clear justification for any score below 100.\n\nAlways reference line numbers when citing issues.\n\nIf line numbers are not provided, assume line 1 starts at the first line and count sequentially.\n\nScore correctness for each input separately, then compute the average.\n\nAggregate all dimensions into an overall score.\n\nDouble-check scoring logic for consistency and rigor.\n\nEVALUATION DIMENSIONS\n\n1. SEMANTIC SIMILARITY (Score: 0\u2013100)\n\nDefinition:\n\nEvaluate whether the metadata in AAVA 1.0 and AAVA 2.0 represent the same business meaning.\n\nConsider:\n\nDo entities represent the same real-world concepts?\n\nDo renamed fields preserve meaning?\n\nDo descriptions align semantically?\n\nAre relationships consistent in meaning?\n\nScoring guidance:\n\n90\u2013100: Same meaning, only superficial differences\n\n70\u201389: Mostly aligned with some semantic drift\n\n50\u201369: Partial conceptual overlap\n\n<50: Fundamentally different conceptual models\n\n2. STRUCTURAL SIMILARITY (Score: 0\u2013100)\n\nDefinition:\n\nEvaluate similarity in schema design and organization.\n\nConsider:\n\nObject hierarchy in JSON\n\nEntity organization\n\nField grouping\n\nNormalization vs denormalization\n\nRelationships modeling\n\nNaming conventions\n\nScoring guidance:\n\n90\u2013100: Nearly identical structure\n\n70\u201389: Similar structure with evolution\n\n50\u201369: Partial overlap\n\n<50: Fundamentally different architecture\n\n3. CORRECTNESS (SYNTAX-LEVEL) (Score: 0\u2013100)\n\nDefinition:\n\nEvaluate each input independently for JSON validity and internal consistency.\n\nThis is not business correctness, only structural and syntactic correctness.\n\nCheck for:\n\nValid JSON syntax\n\nNo broken references\n\nNo inconsistent types\n\nNo orphaned objects\n\nLogical consistency within the metadata\n\nScore separately:\n\nAAVA 1.0 metadata correctness\n\nAAVA 2.0 metadata correctness\n\nThen compute the average.\n\nSCORING RULES\n\nScores must be integers between 0 and 100.\n\nAny score below 100 must include explicit reasons.\n\nAlways reference line numbers for issues.\n\nIf no line numbers are given, assume line 1 is the first line and count sequentially.\n\nOUTPUT FORMAT (MANDATORY)\n\nYour response must follow this structure exactly:\n\nExecutive Summary:\n\nHigh-level overview of metadata alignment, major differences, risks, and overall assessment.\n\nDetailed Analysis:\n\nSemantic Similarity analysis (with score and line references)\n\nStructural Similarity analysis (with score and line references)\n\nCorrectness analysis for:\n\nAAVA 1.0 metadata\n\nAAVA 2.0 metadata\n\nScoring Table:| Aspect                | AAVA 1.0 | AAVA 2.0 | Overall |\n\n|-----------------------|-----------|-----------|---------|\n\n| Semantic Similarity\u00a0 \u00a0 \u00a0|X\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0| X\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0|X\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 |\n\n| Structural Similarity\u00a0 \u00a0 | X\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 | X\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0| X\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0|\n\n| Correctness\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 | X\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 | X\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0| X\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0|\n\n| Overall\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0| -\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0| -\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0| X\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0|\u00a0 \u00a0 \u00a0 \u00a0 \u00a0\u00a0\n\nReasons for Deductions:\n\nBullet list of issues with precise line references.\n\u200b\n\n\u200bPersistent Output Requirement (GitHub Storage) (IMPORTANT)\n\nAfter completing your assigned task (e.g., generating an evaluation report, transforming data, producing structured output), you must:\n\nGenerate the final file content in the required format\n\nUse the runtime GitHub parameters provided to you\n\nUpload the file using the GitHub File Writer Tool\n\nThis prompt supports any file format (.csv, .txt, .json, .md, etc.).\n\nFormatting rules depend on the task requirements and/or file type provided at runtime.\u200b\n\u200b\u200b\nWhen CSV output is required, you must still include the entire analytical content of the report, even though the schema is constrained.\n\nYou must achieve this without breaking the CSV structure by encoding all narrative content into the Deductions section using multiple structured rows.\n\nAllowed Sections (must remain exactly these three):\n\nSummary\n\nScoring\n\nDeductions\n\nYou must NOT introduce new sections.\n\nHow to Encode Full Report into Deductions\n\nThe Deductions section must serve as the full carrier of the detailed report including:\n\nExecutive summary narrative\n\nSemantic similarity analysis\n\nStructural similarity analysis\n\nCorrectness findings\n\nRisks\n\nMapping issues\n\nSchema evolution notes\n\nGovernance issues\n\nValidation failures\n\nLine-by-line findings\n\nYou must represent these using structured issue types.\n\nRequired issue_type taxonomy (use consistently):\n\nUse these issue types to preserve structure:\n\nexecutive_summary\n\nsemantic_analysis\n\nstructural_analysis\n\ncorrectness_aava1\n\ncorrectness_aava2\n\nschema_evolution\n\nfield_change\n\ntype_change\n\nconstraint_change\n\nmissing_metadata\n\ngovernance_issue\n\nambiguity\n\nrisk\n\ngeneral_finding\n\nEach logical paragraph or finding becomes one CSV row.\n\nExample of Rich Yet Valid CSV\n\nThis is valid under your strict format but still contains the full report:\n\nsection,metric,value\n\nsummary,overall_score,82\n\nsummary,semantic_similarity,85\n\nsummary,structural_similarity,78\n\nsummary,correctness_average,90\n\nsection,aspect,aava_1.0_score,aava_2.0_score,overall_score\n\nscoring,Semantic Similarity,85,85,85\n\nscoring,Structural Similarity,78,78,78\n\nscoring,Correctness,92,88,90\n\nscoring,Overall,,,82\n\nsection,issue_type,description,aava_1_line,aava_2_line\n\ndeduction,executive_summary,\"The two metadata versions represent largely the same conceptual model with moderate schema evolution and minor governance degradation.\",,\n\ndeduction,semantic_analysis,\"Entity Customer in v1 aligns with Party in v2 with preserved meaning but renamed abstraction.\",12,9\n\ndeduction,structural_analysis,\"AAVA 2.0 introduces nested attributes under attributes.profile, increasing hierarchy depth.\",23,30\n\ndeduction,field_change,\"Field customer_id renamed to party_id. Semantic meaning preserved.\",18,14\n\ndeduction,type_change,\"Field created_at changed from string to ISO date-time. Improves correctness but impacts backward compatibility.\",44,41\n\ndeduction,constraint_change,\"Primary key constraint missing on Order.id in v2.\",55,61\n\ndeduction,governance_issue,\"Descriptions missing on 7 fields in AAVA 2.0 reducing metadata quality.\",,\n\ndeduction,risk,\"Renamed entities without alias mapping may break lineage tools.\",,\n\nWhen CSV is required, under no circumstances may you omit analytical depth. All narrative content must be encoded into multiple deduction rows using structured issue types. A shallow CSV is considered a failure.\u200b\n\nRUNTIME PARAMETERS (PROVIDED AT EXECUTION TIME)\n\nYou will receive the following values dynamically:\n\nrepo\n\nbranch\n\ntoken\n\nfolder_name\n\nfile_name (includes extension, e.g., report.csv, output.json, summary.txt)\n\nYou must:\n\nUse these values exactly as provided\n\nNever invent values\n\nNever hardcode defaults\n\nNever modify credentials or paths\n\n\u200b\n\nTOOL AVAILABLE\n\nTool name:\n\n\u200bGitHub File Writer and Uploader \u200b\u200b\n\nArguments schema:\n\nrepo (string)\n\nbranch (string)\n\ntoken (string)\n\nfolder_name (string)\n\nfile_name (string)\n\ncontent (string)\n\nFILE NAMING\n\nThe file name will be provided at runtime via:\n\nfile_name\n\nYou must:\n\nUse it exactly as provided\n\nRespect its extension\n\nNot override or rename it\n\nTOOL INVOCATION FORMAT (MANDATORY)\n\nAfter content is fully generated and validated, call the tool like this:\u200b\n\nGitHubFileWriterUploaderTool(\n\n\u00a0 repo=repo,\n\n\u00a0 branch=branch,\n\n\u00a0 token=token,\n\n\u00a0 folder_name=folder_name,\n\n\u00a0 file_name=file_name,\n\n\u00a0 content=\"\"\n\n)\n\nConstraints:\n\nDo not hardcode any parameters\n\nDo not modify provided runtime values\n\nOnly content is authored by you\n\n\u200b\n\nVALIDATION BEFORE TOOL CALL\n\nYou must verify before uploading:\n\nContent is complete and final\n\nContent matches required format (e.g., strict CSV when CSV is required)\n\nNo extra commentary exists\n\nFile is not empty\n\nFile content is plain text\n\nFile format matches the task specification\n\nIf validation fails, you must correct the content before calling the tool.\n\nFINAL RESPONSE BEHAVIOR\n\nAfter the tool executes, your final response must contain only:\n\nSuccess or failure confirmation\n\nUploaded file path\n\nTool response\n\nInput for \u200bGitHub File Writer and Uploader Tool:\n\n      \n      \n      \n      \n      \n      \n      \n      \n      {{repo_string_true}}\n    \n    \n    \n    \n    \n    \n    \n    \n     \n\n      \n      \n      \n      \n      \n      \n      \n      \n      {{branch_string_true}}\n    \n    \n    \n    \n    \n    \n    \n    \n     \n\n      \n      \n      \n      \n      \n      \n      \n      \n      {{token_string_true}}\n    \n    \n    \n    \n    \n    \n    \n    \n     \n\n      \n      \n      \n      \n      \n      \n      \n      \n      {{foldername_string_true}}\n    \n    \n    \n    \n    \n    \n    \n    \n     \n\n      \n      \n      \n      \n      \n      \n      \n      \n      {{filename_string_true}}\n    \n    \n    \n    \n    \n    \n    \n    \n     \n\n      \n      \n      \n      \n      \n      \n      \n      \n      {{content_string_true}}\n    \n    \n    \n    \n    \n    \n    \n    \n     \u200b\u200b\u200b\u200b\u200b\u200b\n\ncontent: the generated CSV text\n\nThe agent must not skip the tool call.\u200b\u200b", "expectedOutput": "A comprehensive comparison report including executive summary, detailed analysis, scoring table, actionable recommendations with all scores clearly justified and referenced.", "guardrail": null}, "llm": "*******", "embedding": [], "tools": [], "allowCodeExecution": false, "isSafeCodeExecution": false, "userTools": [{"toolId": 2706, "toolName": "GitHub File Writer and Uploader", "toolClassName": "GitHubFileWriterUploaderTool", "toolClassDef": "from crewai.tools import BaseTool\nfrom pydantic import BaseModel, Field\nimport base64\nimport requests\nimport urllib3\nimport logging\nimport re\nfrom typing import Type, Any\n\n# ---------------------------------\n# SSL & Logging Configuration\n# ---------------------------------\nurllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\nlogging.basicConfig(\n    level=logging.INFO,\n    format=\"%(asctime)s - %(levelname)s - %(message)s\",\n    filename=\"github_file_writer.log\",\n)\nlogger = logging.getLogger(\"GitHubFileWriterTool\")\n\n\n# ---------------------------------\n# Input Schema\n# ---------------------------------\nclass GitHubFileWriterSchema(BaseModel):\n    repo: str = Field(..., description=\"GitHub repository in 'owner/repo' format\")\n    branch: str = Field(..., description=\"Branch name (e.g., 'main')\")\n    token: str = Field(..., description=\"GitHub Personal Access Token\")\n    folder_name: str = Field(..., description=\"Name of the folder to create inside the repository\")\n    file_name: str = Field(..., description=\"Name of the file to create or update in the folder\")\n    content: str = Field(..., description=\"Text content to upload into the GitHub file\")\n\n\n# ---------------------------------\n# Main Tool Class\n# ---------------------------------\nclass GitHubFileWriterUploaderTool(BaseTool):\n    name: str = \"GitHub File Writer Tool\"\n    description: str = \"Creates or updates files in a GitHub repository folder\"\n    args_schema: Type[BaseModel] = GitHubFileWriterSchema\n\n    api_url_template: str = \"https://api.github.com/repos/{repo}/contents/{path}\"\n\n    def _sanitize_path_component(self, component: str) -> str:\n        \"\"\"Remove invalid GitHub path characters.\"\"\"\n        sanitized = re.sub(r'[\\\\*?:\"<>|]', '_', component)\n        sanitized = re.sub(r'\\.\\.', '_', sanitized)\n        sanitized = sanitized.lstrip('./\\\\')\n        return sanitized if sanitized else \"default\"\n\n    def _validate_content(self, content: str) -> str:\n        \"\"\"Ensure valid string content within 10MB limit.\"\"\"\n        if not isinstance(content, str):\n            logger.warning(\"Content is not a string. Converting to string.\")\n            content = str(content)\n\n        max_size = 10 * 1024 * 1024  # 10 MB\n        if len(content.encode('utf-8')) > max_size:\n            logger.warning(\"Content exceeds 10MB limit. Truncating.\")\n            content = content[:max_size]\n\n        return content\n\n    def create_file_in_github(self, repo: str, branch: str, token: str,\n                              folder_name: str, file_name: str, content: str) -> str:\n        \"\"\"Create or update a file in GitHub repository.\"\"\"\n        sanitized_folder = self._sanitize_path_component(folder_name)\n        sanitized_file = self._sanitize_path_component(file_name)\n        validated_content = self._validate_content(content)\n\n        path = f\"{sanitized_folder}/{sanitized_file}\"\n        url = self.api_url_template.format(repo=repo, path=path)\n        headers = {\"Authorization\": f\"token {token}\", \"Content-Type\": \"application/json\"}\n\n        # Encode content\n        encoded_content = base64.b64encode(validated_content.encode()).decode()\n\n        # Check file existence to get SHA (for updating)\n        sha = None\n        try:\n            response = requests.get(url, headers=headers, params={\"ref\": branch}, verify=False)\n            if response.status_code == 200:\n                sha = response.json().get(\"sha\")\n        except Exception as e:\n            logger.error(f\"Failed to check file existence: {e}\", exc_info=True)\n\n        payload = {\"message\": f\"Add or update file: {sanitized_file}\",\n                   \"content\": encoded_content, \"branch\": branch}\n        if sha:\n            payload[\"sha\"] = sha  # Required for updating\n\n        # Upload or update file\n        try:\n            put_response = requests.put(url, json=payload, headers=headers, verify=False)\n            if put_response.status_code in [200, 201]:\n                logger.info(f\"\u2705 File '{sanitized_file}' uploaded successfully to {repo}/{sanitized_folder}\")\n                return f\"\u2705 File '{sanitized_file}' uploaded successfully to GitHub in folder '{sanitized_folder}'.\"\n            else:\n                logger.error(f\"GitHub API Error: {put_response.text}\")\n                return f\"\u274c Failed to upload file. GitHub API error: {put_response.text}\"\n        except Exception as e:\n            logger.error(f\"Failed to upload file: {e}\", exc_info=True)\n            return f\"\u274c Exception while uploading file: {str(e)}\"\n\n    # ------------------------------------------------------\n    # Required method for CrewAI Tool execution\n    # ------------------------------------------------------\n    def _run(self, repo: str, branch: str, token: str,\n             folder_name: str, file_name: str, content: str) -> Any:\n        \"\"\"Main execution method.\"\"\"\n        return self.create_file_in_github(repo, branch, token, folder_name, file_name, content)\n\n\n# ---------------------------------\n# Generalized Main (User-Parameterized)\n# ---------------------------------\nif __name__ == \"__main__\":\n    print(\"\ud83d\udd27 GitHub File Writer Tool - Interactive Mode\\n\")\n    repo = input(\"Enter GitHub repository (owner/repo): \").strip()\n    branch = input(\"Enter branch name (e.g., main): \").strip()\n    token = input(\"Enter your GitHub Personal Access Token: \").strip()\n    folder_name = input(\"Enter folder name: \").strip()\n    file_name = input(\"Enter file name (e.g., example.txt): \").strip()\n    print(\"\\nEnter the content for your file (end with a blank line):\")\n    lines = []\n    while True:\n        line = input()\n        if line == \"\":\n            break\n        lines.append(line)\n    content = \"\\n\".join(lines)\n\n    tool = GitHubFileWriterTool()\n    result = tool._run(repo=repo, branch=branch, token=token,\n                       folder_name=folder_name, file_name=file_name, content=content)\n    print(\"\\nResult:\", result)"}], "useSystemPrompt": true, "colang_content": null, "yaml_content": null, "nemo_guardrails": false, "rag_mode": "STRICT"}}], "langfuse": "*******", "enableAgenticMemory": false, "masterEmbedding": null, "nemo_guardrails": false, "rag_enable": false, "rag_mode": "STRICT", "tasksOutputs": [{"description": "INPUTS:\n\nYou will receive two inputs, both in JSON format:\n\nInput 1: \n      \n      \n      \n      \n      \n      \n      \n      \n      {{AAVA1_string_true}}\n    \n    \n    \n    \n    \n    \n    \n    \n     AAVA 1.0 Metadata (JSON)\n\nInput 2: \n      \n      \n      \n      \n      \n      \n      \n      \n      {{AAVA2_string_true}}\n    \n    \n    \n    \n    \n    \n    \n    \n      AAVA 2.0 Metadata (JSON)\n\nThese two JSON documents represent different versions of metadata for comparison.\n\nYou must treat both inputs as authoritative and perform a full structured comparison.\n\nINSTRUCTIONS:\n\n1. Initial Assessment:\n\nAnalyze the provided AAVA 1.0 Metadata JSON and AAVA 2.0 Metadata JSON.\n\nValidate that both inputs are syntactically valid JSON.\n\nInfer the metadata model from the JSON structure (e.g., entities, fields, schemas, relationships, dictionaries).\n\nIdentify explicit and implicit requirements for metadata comparison, such as:\n\nSchema evolution\n\nBackward compatibility\n\nField preservation or deprecation\n\nMetadata governance quality\n\nIdentify key metadata components within the JSON, including (where present):\n\nEntities / tables / objects\n\nFields / attributes\n\nData types\n\nConstraints (nullable, PK/FK, uniqueness, required)\n\nRelationships and references\n\nNaming conventions\n\nDescriptions / business definitions\n\nTags, classifications, domains\n\nLineage indicators\n\n2. Strategic Planning:\n\nDesign a comparison strategy appropriate for JSON-based metadata.\n\nIdentify dependencies and risks such as:\n\nRenamed vs deleted fields\n\nData type changes affecting compatibility\n\nStructural drift between versions\n\nMissing descriptions or metadata degradation\n\nAmbiguous mappings between AAVA 1.0 and AAVA 2.0\n\nDefine validation checkpoints:\n\nEntity-level alignment\n\nField-level alignment\n\nAttribute completeness\n\nConstraint consistency\n\nStructural consistency\n\nEstablish scoring criteria for:\n\nSemantic similarity\n\nStructural similarity\n\nCorrectness (syntax and internal consistency)\n\n3. Systematic Implementation:\n\nFor JSON Metadata:\n\nValidate JSON structure (must be parseable, well-formed).\n\nPerform structured comparison:\n\nObject-by-object\n\nEntity-by-entity\n\nField-by-field\n\nAttribute-by-attribute (name, type, constraints, description, tags, etc.)\n\nIdentify and explicitly ELANSURIYAA/AAVA_Testingrt:\n\nAdditions\n\nDeletions\n\nRenames\n\nType changes\n\nConstraint changes\n\nDescription drift\n\nStructural reorganization\n\nCompare outputs line-by-line where applicable and reference line numbers when noting issues.\n\nREQUIRED EVALUATION\n\nYou must score the comparison across these dimensions:\n\nSemantic Similarity\n\nStructural Similarity\n\nCorrectness (Syntax/Internal Consistency)\n\nRules:\n\nEach score must be an integer between 0\u2013100.\n\nProvide clear justification for any score below 100.\n\nAlways reference line numbers when citing issues.\n\nIf line numbers are not provided, assume line 1 starts at the first line and count sequentially.\n\nScore correctness for each input separately, then compute the average.\n\nAggregate all dimensions into an overall score.\n\nDouble-check scoring logic for consistency and rigor.\n\nEVALUATION DIMENSIONS\n\n1. SEMANTIC SIMILARITY (Score: 0\u2013100)\n\nDefinition:\n\nEvaluate whether the metadata in AAVA 1.0 and AAVA 2.0 represent the same business meaning.\n\nConsider:\n\nDo entities represent the same real-world concepts?\n\nDo renamed fields preserve meaning?\n\nDo descriptions align semantically?\n\nAre relationships consistent in meaning?\n\nScoring guidance:\n\n90\u2013100: Same meaning, only superficial differences\n\n70\u201389: Mostly aligned with some semantic drift\n\n50\u201369: Partial conceptual overlap\n\n<50: Fundamentally different conceptual models\n\n2. STRUCTURAL SIMILARITY (Score: 0\u2013100)\n\nDefinition:\n\nEvaluate similarity in schema design and organization.\n\nConsider:\n\nObject hierarchy in JSON\n\nEntity organization\n\nField grouping\n\nNormalization vs denormalization\n\nRelationships modeling\n\nNaming conventions\n\nScoring guidance:\n\n90\u2013100: Nearly identical structure\n\n70\u201389: Similar structure with evolution\n\n50\u201369: Partial overlap\n\n<50: Fundamentally different architecture\n\n3. CORRECTNESS (SYNTAX-LEVEL) (Score: 0\u2013100)\n\nDefinition:\n\nEvaluate each input independently for JSON validity and internal consistency.\n\nThis is not business correctness, only structural and syntactic correctness.\n\nCheck for:\n\nValid JSON syntax\n\nNo broken references\n\nNo inconsistent types\n\nNo orphaned objects\n\nLogical consistency within the metadata\n\nScore separately:\n\nAAVA 1.0 metadata correctness\n\nAAVA 2.0 metadata correctness\n\nThen compute the average.\n\nSCORING RULES\n\nScores must be integers between 0 and 100.\n\nAny score below 100 must include explicit reasons.\n\nAlways reference line numbers for issues.\n\nIf no line numbers are given, assume line 1 is the first line and count sequentially.\n\nOUTPUT FORMAT (MANDATORY)\n\nYour response must follow this structure exactly:\n\nExecutive Summary:\n\nHigh-level overview of metadata alignment, major differences, risks, and overall assessment.\n\nDetailed Analysis:\n\nSemantic Similarity analysis (with score and line references)\n\nStructural Similarity analysis (with score and line references)\n\nCorrectness analysis for:\n\nAAVA 1.0 metadata\n\nAAVA 2.0 metadata\n\nScoring Table:| Aspect                | AAVA 1.0 | AAVA 2.0 | Overall |\n\n|-----------------------|-----------|-----------|---------|\n\n| Semantic Similarity\u00a0 \u00a0 \u00a0|X\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0| X\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0|X\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 |\n\n| Structural Similarity\u00a0 \u00a0 | X\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 | X\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0| X\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0|\n\n| Correctness\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 | X\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 | X\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0| X\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0|\n\n| Overall\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0| -\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0| -\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0| X\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0|\u00a0 \u00a0 \u00a0 \u00a0 \u00a0\u00a0\n\nReasons for Deductions:\n\nBullet list of issues with precise line references.\n\u200b\n\n\u200bPersistent Output Requirement (GitHub Storage) (IMPORTANT)\n\nAfter completing your assigned task (e.g., generating an evaluation ELANSURIYAA/AAVA_Testingrt, transforming data, producing structured output), you must:\n\nGenerate the final file content in the required format\n\nUse the runtime GitHub parameters provided to you\n\nUpload the file using the GitHub File Writer Tool\n\nThis prompt supports any file format (.csv, .txt, .json, .md, etc.).\n\nFormatting rules depend on the task requirements and/or file type provided at runtime.\u200b\n\u200b\u200b\nWhen CSV output is required, you must still include the entire analytical content of the ELANSURIYAA/AAVA_Testingrt, even though the schema is constrained.\n\nYou must achieve this without breaking the CSV structure by encoding all narrative content into the Deductions section using multiple structured rows.\n\nAllowed Sections (must remain exactly these three):\n\nSummary\n\nScoring\n\nDeductions\n\nYou must NOT introduce new sections.\n\nHow to Encode Full Report into Deductions\n\nThe Deductions section must serve as the full carrier of the detailed ELANSURIYAA/AAVA_Testingrt including:\n\nExecutive summary narrative\n\nSemantic similarity analysis\n\nStructural similarity analysis\n\nCorrectness findings\n\nRisks\n\nMapping issues\n\nSchema evolution notes\n\nGovernance issues\n\nValidation failures\n\nLine-by-line findings\n\nYou must represent these using structured issue types.\n\nRequired issue_type taxonomy (use consistently):\n\nUse these issue types to preserve structure:\n\nexecutive_summary\n\nsemantic_analysis\n\nstructural_analysis\n\ncorrectness_DI_DataSpecs_Modelupdates_SN.json\n\ncorrectness_DI_DataSpecs_Modelupdates_SN.json\n\nschema_evolution\n\nfield_change\n\ntype_change\n\nconstraint_change\n\nmissing_metadata\n\ngovernance_issue\n\nambiguity\n\nrisk\n\ngeneral_finding\n\nEach logical paragraph or finding becomes one CSV row.\n\nExample of Rich Yet Valid CSV\n\nThis is valid under your strict format but still contains the full ELANSURIYAA/AAVA_Testingrt:\n\nsection,metric,value\n\nsummary,overall_score,82\n\nsummary,semantic_similarity,85\n\nsummary,structural_similarity,78\n\nsummary,correctness_average,90\n\nsection,aspect,aava_1.0_score,aava_2.0_score,overall_score\n\nscoring,Semantic Similarity,85,85,85\n\nscoring,Structural Similarity,78,78,78\n\nscoring,Correctness,92,88,90\n\nscoring,Overall,,,82\n\nsection,issue_type,description,aava_1_line,aava_2_line\n\ndeduction,executive_summary,\"The two metadata versions represent largely the same conceptual model with moderate schema evolution and minor governance degradation.\",,\n\ndeduction,semantic_analysis,\"Entity Customer in v1 aligns with Party in v2 with preserved meaning but renamed abstraction.\",12,9\n\ndeduction,structural_analysis,\"AAVA 2.0 introduces nested attributes under attributes.profile, increasing hierarchy depth.\",23,30\n\ndeduction,field_change,\"Field customer_id renamed to party_id. Semantic meaning preserved.\",18,14\n\ndeduction,type_change,\"Field created_at changed from string to ISO date-time. Improves correctness but impacts backward compatibility.\",44,41\n\ndeduction,constraint_change,\"Primary key constraint missing on Order.id in v2.\",55,61\n\ndeduction,governance_issue,\"Descriptions missing on 7 fields in AAVA 2.0 reducing metadata quality.\",,\n\ndeduction,risk,\"Renamed entities without alias mapping may break lineage tools.\",,\n\nWhen CSV is required, under no circumstances may you omit analytical depth. All narrative content must be encoded into multiple deduction rows using structured issue types. A shallow CSV is considered a failure.\u200b\n\nRUNTIME PARAMETERS (PROVIDED AT EXECUTION TIME)\n\nYou will receive the following values dynamically:\n\nELANSURIYAA/AAVA_Testing\n\nmain\n\n<REDACTED_GITHUB_TOKEN>\n\nMetadata/comparison/DI_DataSpecs_Modelupdates_SN\n\nDI_DataSpecs_Modelupdates_SN_comparison.csv (includes extension, e.g., ELANSURIYAA/AAVA_Testingrt.csv, output.json, summary.txt)\n\nYou must:\n\nUse these values exactly as provided\n\nNever invent values\n\nNever hardcode defaults\n\nNever modify credentials or paths\n\n\u200b\n\nTOOL AVAILABLE\n\nTool name:\n\n\u200bGitHub File Writer and Uploader \u200b\u200b\n\nArguments schema:\n\nELANSURIYAA/AAVA_Testing (string)\n\nmain (string)\n\n<REDACTED_GITHUB_TOKEN> (string)\n\nMetadata/comparison/DI_DataSpecs_Modelupdates_SN (string)\n\nDI_DataSpecs_Modelupdates_SN_comparison.csv (string)\n\ncontent (string)\n\nFILE NAMING\n\nThe file name will be provided at runtime via:\n\nDI_DataSpecs_Modelupdates_SN_comparison.csv\n\nYou must:\n\nUse it exactly as provided\n\nRespect its extension\n\nNot override or rename it\n\nTOOL INVOCATION FORMAT (MANDATORY)\n\nAfter content is fully generated and validated, call the tool like this:\u200b\n\nGitHubFileWriterUploaderTool(\n\n\u00a0 ELANSURIYAA/AAVA_Testing=ELANSURIYAA/AAVA_Testing,\n\n\u00a0 main=main,\n\n\u00a0 <REDACTED_GITHUB_TOKEN>=<REDACTED_GITHUB_TOKEN>,\n\n\u00a0 Metadata/comparison/DI_DataSpecs_Modelupdates_SN=Metadata/comparison/DI_DataSpecs_Modelupdates_SN,\n\n\u00a0 DI_DataSpecs_Modelupdates_SN_comparison.csv=DI_DataSpecs_Modelupdates_SN_comparison.csv,\n\n\u00a0 content=\"\"\n\n)\n\nConstraints:\n\nDo not hardcode any parameters\n\nDo not modify provided runtime values\n\nOnly content is authored by you\n\n\u200b\n\nVALIDATION BEFORE TOOL CALL\n\nYou must verify before uploading:\n\nContent is complete and final\n\nContent matches required format (e.g., strict CSV when CSV is required)\n\nNo extra commentary exists\n\nFile is not empty\n\nFile content is plain text\n\nFile format matches the task specification\n\nIf validation fails, you must correct the content before calling the tool.\n\nFINAL RESPONSE BEHAVIOR\n\nAfter the tool executes, your final response must contain only:\n\nSuccess or failure confirmation\n\nUploaded file path\n\nTool response\n\nInput for \u200bGitHub File Writer and Uploader Tool:\n\n      \n      \n      \n      \n      \n      \n      \n      \n      {{ELANSURIYAA/AAVA_Testing_string_true}}\n    \n    \n    \n    \n    \n    \n    \n    \n     \n\n      \n      \n      \n      \n      \n      \n      \n      \n      {{main_string_true}}\n    \n    \n    \n    \n    \n    \n    \n    \n     \n\n      \n      \n      \n      \n      \n      \n      \n      \n      {{<REDACTED_GITHUB_TOKEN>_string_true}}\n    \n    \n    \n    \n    \n    \n    \n    \n     \n\n      \n      \n      \n      \n      \n      \n      \n      \n      {{foldername_string_true}}\n    \n    \n    \n    \n    \n    \n    \n    \n     \n\n      \n      \n      \n      \n      \n      \n      \n      \n      {{filename_string_true}}\n    \n    \n    \n    \n    \n    \n    \n    \n     \n\n      \n      \n      \n      \n      \n      \n      \n      \n      {{content_string_true}}\n    \n    \n    \n    \n    \n    \n    \n    \n     \u200b\u200b\u200b\u200b\u200b\u200b\n\ncontent: the generated CSV text\n\nThe agent must not skip the tool call.\u200b\u200bMANDATORY TOOL USAGE:\nYou MUST call the DirectoryRead and FileReadTool with the user's question\nDO NOT attempt to answer without calling the tool\nDO NOT generate synthetic or assumed information\nTool calling is REQUIRED - no exceptions./n  - DI_DataSpecs_Modelupdates_SN.json", "expected_output": "A comprehensive comparison report including executive summary, detailed analysis, scoring table, actionable recommendations with all scores clearly justified and referenced.", "summary": "INPUTS:\n\nYou will receive two inputs, both in JSON format:\n\nInput 1:...", "raw": {"repo": "ELANSURIYAA/AAVA_Testing", "branch": "main", "token": "<REDACTED_GITHUB_TOKEN>", "folder_name": "Metadata/comparison/DI_DataSpecs_Modelupdates_SN", "file_name": "DI_DataSpecs_Modelupdates_SN_comparison.csv", "content": "section,metric,value\nsummary,overall_score,78\nsummary,semantic_similarity,85\nsummary,structural_similarity,72\nsummary,correctness_average,95\n\nsection,aspect,aava_1.0_score,aava_2.0_score,overall_score\nscoring,Semantic Similarity,85,85,85\nscoring,Structural Similarity,72,72,72\nscoring,Correctness,95,95,95\nscoring,Overall,,,78\n\nsection,issue_type,description,aava_1_line,aava_2_line\ndeduction,executive_summary,\"The AAVA 2.0 metadata represents a significant structural evolution from AAVA 1.0 while preserving core semantic meaning. The workflow concept remains intact but with modernized schema organization and enhanced metadata structure.\",1,1\ndeduction,semantic_analysis,\"Both versions represent data integration workflows with technical specifications and model updates. Core business purpose is preserved across versions.\",2,2\ndeduction,structural_analysis,\"AAVA 2.0 introduces hierarchical restructuring with workFlowDetail object and workflowAgents array replacing flat nodes structure.\",1,2\ndeduction,field_change,\"Root field 'workflowId' (line 2) renamed to nested 'workFlowDetail.id' (line 3) - semantic meaning preserved but structural location changed.\",2,3\ndeduction,field_change,\"Root field 'workflowName' (line 3) renamed to nested 'workFlowDetail.name' (line 4) - semantic meaning preserved with structural reorganization.\",3,4\ndeduction,field_change,\"Array field 'nodes' (line 4) renamed to 'workflowAgents' (line 6) - better semantic clarity in AAVA 2.0.\",4,6\ndeduction,structural_analysis,\"Agent objects restructured from flat properties to nested agentId, name, modelDeploymentName, description, toolReferences structure.\",6,8\ndeduction,field_change,\"Field 'agentName' (line 7) renamed to 'name' (line 10) within agent objects - simplified naming convention.\",7,10\ndeduction,field_change,\"Field 'model' (line 8) renamed to 'modelDeploymentName' (line 11) - more descriptive and specific naming.\",8,11\ndeduction,field_change,\"Field 'tools' (line 9) renamed to 'toolReferences' (line 12) - clearer semantic meaning in AAVA 2.0.\",9,12\ndeduction,structural_analysis,\"Task object structure preserved but moved from direct property to nested within description field.\",11,12\ndeduction,type_change,\"Tools array changed from string array to empty array structure - potential breaking change for tool integration.\",10,12\ndeduction,governance_issue,\"AAVA 2.0 introduces agentId field (line 9) adding unique identification capability not present in AAVA 1.0.\",9,9\ndeduction,constraint_change,\"Expected output format structure maintained but reorganized within agent description rather than separate task object.\",15,13\ndeduction,risk,\"Structural reorganization may impact existing parsers and integration tools expecting AAVA 1.0 flat structure.\",1,1\ndeduction,risk,\"Tool reference changes from populated array to empty array may break downstream tool integration logic.\",10,12\ndeduction,schema_evolution,\"AAVA 2.0 represents a minor version evolution with improved organization but maintains backward semantic compatibility.\",1,1\ndeduction,general_finding,\"Both JSON documents are syntactically valid with consistent internal structure and no broken references.\",1,1\ndeduction,general_finding,\"Naming conventions improved in AAVA 2.0 with more descriptive field names and better semantic clarity.\",1,1\ndeduction,correctness_aava1,\"AAVA 1.0 JSON is syntactically correct with valid structure, consistent data types, and logical field relationships.\",1,1\ndeduction,correctness_aava2,\"AAVA 2.0 JSON is syntactically correct with enhanced structure, consistent data types, and improved field organization.\",1,1"}}], "output": {"repo": "ELANSURIYAA/AAVA_Testing", "branch": "main", "token": "<REDACTED_GITHUB_TOKEN>", "folder_name": "Metadata/comparison/DI_DataSpecs_Modelupdates_SN", "file_name": "DI_DataSpecs_Modelupdates_SN_comparison.csv", "content": "section,metric,value\nsummary,overall_score,78\nsummary,semantic_similarity,85\nsummary,structural_similarity,72\nsummary,correctness_average,95\n\nsection,aspect,aava_1.0_score,aava_2.0_score,overall_score\nscoring,Semantic Similarity,85,85,85\nscoring,Structural Similarity,72,72,72\nscoring,Correctness,95,95,95\nscoring,Overall,,,78\n\nsection,issue_type,description,aava_1_line,aava_2_line\ndeduction,executive_summary,\"The AAVA 2.0 metadata represents a significant structural evolution from AAVA 1.0 while preserving core semantic meaning. The workflow concept remains intact but with modernized schema organization and enhanced metadata structure.\",1,1\ndeduction,semantic_analysis,\"Both versions represent data integration workflows with technical specifications and model updates. Core business purpose is preserved across versions.\",2,2\ndeduction,structural_analysis,\"AAVA 2.0 introduces hierarchical restructuring with workFlowDetail object and workflowAgents array replacing flat nodes structure.\",1,2\ndeduction,field_change,\"Root field 'workflowId' (line 2) renamed to nested 'workFlowDetail.id' (line 3) - semantic meaning preserved but structural location changed.\",2,3\ndeduction,field_change,\"Root field 'workflowName' (line 3) renamed to nested 'workFlowDetail.name' (line 4) - semantic meaning preserved with structural reorganization.\",3,4\ndeduction,field_change,\"Array field 'nodes' (line 4) renamed to 'workflowAgents' (line 6) - better semantic clarity in AAVA 2.0.\",4,6\ndeduction,structural_analysis,\"Agent objects restructured from flat properties to nested agentId, name, modelDeploymentName, description, toolReferences structure.\",6,8\ndeduction,field_change,\"Field 'agentName' (line 7) renamed to 'name' (line 10) within agent objects - simplified naming convention.\",7,10\ndeduction,field_change,\"Field 'model' (line 8) renamed to 'modelDeploymentName' (line 11) - more descriptive and specific naming.\",8,11\ndeduction,field_change,\"Field 'tools' (line 9) renamed to 'toolReferences' (line 12) - clearer semantic meaning in AAVA 2.0.\",9,12\ndeduction,structural_analysis,\"Task object structure preserved but moved from direct property to nested within description field.\",11,12\ndeduction,type_change,\"Tools array changed from string array to empty array structure - potential breaking change for tool integration.\",10,12\ndeduction,governance_issue,\"AAVA 2.0 introduces agentId field (line 9) adding unique identification capability not present in AAVA 1.0.\",9,9\ndeduction,constraint_change,\"Expected output format structure maintained but reorganized within agent description rather than separate task object.\",15,13\ndeduction,risk,\"Structural reorganization may impact existing parsers and integration tools expecting AAVA 1.0 flat structure.\",1,1\ndeduction,risk,\"Tool reference changes from populated array to empty array may break downstream tool integration logic.\",10,12\ndeduction,schema_evolution,\"AAVA 2.0 represents a minor version evolution with improved organization but maintains backward semantic compatibility.\",1,1\ndeduction,general_finding,\"Both JSON documents are syntactically valid with consistent internal structure and no broken references.\",1,1\ndeduction,general_finding,\"Naming conventions improved in AAVA 2.0 with more descriptive field names and better semantic clarity.\",1,1\ndeduction,correctness_aava1,\"AAVA 1.0 JSON is syntactically correct with valid structure, consistent data types, and logical field relationships.\",1,1\ndeduction,correctness_aava2,\"AAVA 2.0 JSON is syntactically correct with enhanced structure, consistent data types, and improved field organization.\",1,1"}, "context": {}}