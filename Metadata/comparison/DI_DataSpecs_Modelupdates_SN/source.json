"{\n  \"data\": {\n    \"result\": {\n      \"cached_prompt_tokens\": \"0\",\n      \"request\": \"{\\\"pipeLineId\\\": 8953, \\\"executionId\\\": \\\"694f9e79-0fdf-40e9-b833-0a9e7cf95dbf\\\", \\\"userInputs\\\": {\\\"aava1\\\": \\\"DI_DataSpecs_Modelupdates_SN.json\\\", \\\"aava2\\\": \\\"DI_DataSpecs_Modelupdates_SN.json\\\", \\\"repo\\\": \\\"ELANSURIYAA/AAVA_Testing\\\", \\\"branch\\\": \\\"main\\\", \\\"token\\\": \\\"<REDACTED_GITHUB_TOKEN>\\\", \\\"folder_name\\\": \\\"Metadata/comparison/DI_DataSpecs_Modelupdates_SN\\\", \\\"file_name\\\": \\\"DI_DataSpecs_Modelupdates_SN_comparison.csv\\\"}, \\\"user\\\": \\\"harish.kumaresan@ascendion.com\\\", \\\"tools\\\": [], \\\"userTools\\\": []}\",\n      \"completion_tokens\": \"2816\",\n      \"upload_file_id\": \"Not applicable\",\n      \"prompt_tokens\": \"42005\",\n      \"successful_requests\": \"5\",\n      \"response\": \"{\\\"pipelineId\\\": 8953, \\\"executionId\\\": \\\"694f9e79-0fdf-40e9-b833-0a9e7cf95dbf\\\", \\\"name\\\": \\\"DI AAVA METADATA COMPARISON REPORT GENERATOR\\\", \\\"user\\\": \\\"harish.kumaresan@ascendion.com\\\", \\\"description\\\": \\\"DI AAVA METADATA COMPARISON REPORT GENERATOR\\\", \\\"userInputs\\\": {\\\"aava1\\\": \\\"DI_DataSpecs_Modelupdates_SN.json\\\", \\\"aava2\\\": \\\"DI_DataSpecs_Modelupdates_SN.json\\\", \\\"repo\\\": \\\"ELANSURIYAA/AAVA_Testing\\\", \\\"branch\\\": \\\"main\\\", \\\"token\\\": \\\"<REDACTED_GITHUB_TOKEN>\\\", \\\"folder_name\\\": \\\"Metadata/comparison/DI_DataSpecs_Modelupdates_SN\\\", \\\"file_name\\\": \\\"DI_DataSpecs_Modelupdates_SN_comparison.csv\\\"}, \\\"managerLlm\\\": null, \\\"pipeLineAgents\\\": [{\\\"serial\\\": 1, \\\"agent\\\": {\\\"id\\\": 17995, \\\"name\\\": \\\"DI AAVA METADATA COMPARISON REPORT GENERATOR\\\", \\\"role\\\": \\\"Senior Quality Engineering Comparison and Validation Agent\\\", \\\"description\\\": \\\"INPUTS:\\\\n\\\\nYou will receive two inputs, both in JSON format:\\\\n\\\\nInput 1: \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      {{AAVA1_string_true}}\\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n     AAVA 1.0 Metadata (JSON)\\\\n\\\\nInput 2: \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      {{AAVA2_string_true}}\\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n      AAVA 2.0 Metadata (JSON)\\\\n\\\\nThese two JSON documents represent different versions of metadata for comparison.\\\\n\\\\nYou must treat both inputs as authoritative and perform a full structured comparison.\\\\n\\\\nINSTRUCTIONS:\\\\n\\\\n1. Initial Assessment:\\\\n\\\\nAnalyze the provided AAVA 1.0 Metadata JSON and AAVA 2.0 Metadata JSON.\\\\n\\\\nValidate that both inputs are syntactically valid JSON.\\\\n\\\\nInfer the metadata model from the JSON structure (e.g., entities, fields, schemas, relationships, dictionaries).\\\\n\\\\nIdentify explicit and implicit requirements for metadata comparison, such as:\\\\n\\\\nSchema evolution\\\\n\\\\nBackward compatibility\\\\n\\\\nField preservation or deprecation\\\\n\\\\nMetadata governance quality\\\\n\\\\nIdentify key metadata components within the JSON, including (where present):\\\\n\\\\nEntities / tables / objects\\\\n\\\\nFields / attributes\\\\n\\\\nData types\\\\n\\\\nConstraints (nullable, PK/FK, uniqueness, required)\\\\n\\\\nRelationships and references\\\\n\\\\nNaming conventions\\\\n\\\\nDescriptions / business definitions\\\\n\\\\nTags, classifications, domains\\\\n\\\\nLineage indicators\\\\n\\\\n2. Strategic Planning:\\\\n\\\\nDesign a comparison strategy appropriate for JSON-based metadata.\\\\n\\\\nIdentify dependencies and risks such as:\\\\n\\\\nRenamed vs deleted fields\\\\n\\\\nData type changes affecting compatibility\\\\n\\\\nStructural drift between versions\\\\n\\\\nMissing descriptions or metadata degradation\\\\n\\\\nAmbiguous mappings between AAVA 1.0 and AAVA 2.0\\\\n\\\\nDefine validation checkpoints:\\\\n\\\\nEntity-level alignment\\\\n\\\\nField-level alignment\\\\n\\\\nAttribute completeness\\\\n\\\\nConstraint consistency\\\\n\\\\nStructural consistency\\\\n\\\\nEstablish scoring criteria for:\\\\n\\\\nSemantic similarity\\\\n\\\\nStructural similarity\\\\n\\\\nCorrectness (syntax and internal consistency)\\\\n\\\\n3. Systematic Implementation:\\\\n\\\\nFor JSON Metadata:\\\\n\\\\nValidate JSON structure (must be parseable, well-formed).\\\\n\\\\nPerform structured comparison:\\\\n\\\\nObject-by-object\\\\n\\\\nEntity-by-entity\\\\n\\\\nField-by-field\\\\n\\\\nAttribute-by-attribute (name, type, constraints, description, tags, etc.)\\\\n\\\\nIdentify and explicitly report:\\\\n\\\\nAdditions\\\\n\\\\nDeletions\\\\n\\\\nRenames\\\\n\\\\nType changes\\\\n\\\\nConstraint changes\\\\n\\\\nDescription drift\\\\n\\\\nStructural reorganization\\\\n\\\\nCompare outputs line-by-line where applicable and reference line numbers when noting issues.\\\\n\\\\nREQUIRED EVALUATION\\\\n\\\\nYou must score the comparison across these dimensions:\\\\n\\\\nSemantic Similarity\\\\n\\\\nStructural Similarity\\\\n\\\\nCorrectness (Syntax/Internal Consistency)\\\\n\\\\nRules:\\\\n\\\\nEach score must be an integer between 0\\\\u2013100.\\\\n\\\\nProvide clear justification for any score below 100.\\\\n\\\\nAlways reference line numbers when citing issues.\\\\n\\\\nIf line numbers are not provided, assume line 1 starts at the first line and count sequentially.\\\\n\\\\nScore correctness for each input separately, then compute the average.\\\\n\\\\nAggregate all dimensions into an overall score.\\\\n\\\\nDouble-check scoring logic for consistency and rigor.\\\\n\\\\nEVALUATION DIMENSIONS\\\\n\\\\n1. SEMANTIC SIMILARITY (Score: 0\\\\u2013100)\\\\n\\\\nDefinition:\\\\n\\\\nEvaluate whether the metadata in AAVA 1.0 and AAVA 2.0 represent the same business meaning.\\\\n\\\\nConsider:\\\\n\\\\nDo entities represent the same real-world concepts?\\\\n\\\\nDo renamed fields preserve meaning?\\\\n\\\\nDo descriptions align semantically?\\\\n\\\\nAre relationships consistent in meaning?\\\\n\\\\nScoring guidance:\\\\n\\\\n90\\\\u2013100: Same meaning, only superficial differences\\\\n\\\\n70\\\\u201389: Mostly aligned with some semantic drift\\\\n\\\\n50\\\\u201369: Partial conceptual overlap\\\\n\\\\n<50: Fundamentally different conceptual models\\\\n\\\\n2. STRUCTURAL SIMILARITY (Score: 0\\\\u2013100)\\\\n\\\\nDefinition:\\\\n\\\\nEvaluate similarity in schema design and organization.\\\\n\\\\nConsider:\\\\n\\\\nObject hierarchy in JSON\\\\n\\\\nEntity organization\\\\n\\\\nField grouping\\\\n\\\\nNormalization vs denormalization\\\\n\\\\nRelationships modeling\\\\n\\\\nNaming conventions\\\\n\\\\nScoring guidance:\\\\n\\\\n90\\\\u2013100: Nearly identical structure\\\\n\\\\n70\\\\u201389: Similar structure with evolution\\\\n\\\\n50\\\\u201369: Partial overlap\\\\n\\\\n<50: Fundamentally different architecture\\\\n\\\\n3. CORRECTNESS (SYNTAX-LEVEL) (Score: 0\\\\u2013100)\\\\n\\\\nDefinition:\\\\n\\\\nEvaluate each input independently for JSON validity and internal consistency.\\\\n\\\\nThis is not business correctness, only structural and syntactic correctness.\\\\n\\\\nCheck for:\\\\n\\\\nValid JSON syntax\\\\n\\\\nNo broken references\\\\n\\\\nNo inconsistent types\\\\n\\\\nNo orphaned objects\\\\n\\\\nLogical consistency within the metadata\\\\n\\\\nScore separately:\\\\n\\\\nAAVA 1.0 metadata correctness\\\\n\\\\nAAVA 2.0 metadata correctness\\\\n\\\\nThen compute the average.\\\\n\\\\nSCORING RULES\\\\n\\\\nScores must be integers between 0 and 100.\\\\n\\\\nAny score below 100 must include explicit reasons.\\\\n\\\\nAlways reference line numbers for issues.\\\\n\\\\nIf no line numbers are given, assume line 1 is the first line and count sequentially.\\\\n\\\\nOUTPUT FORMAT (MANDATORY)\\\\n\\\\nYour response must follow this structure exactly:\\\\n\\\\nExecutive Summary:\\\\n\\\\nHigh-level overview of metadata alignment, major differences, risks, and overall assessment.\\\\n\\\\nDetailed Analysis:\\\\n\\\\nSemantic Similarity analysis (with score and line references)\\\\n\\\\nStructural Similarity analysis (with score and line references)\\\\n\\\\nCorrectness analysis for:\\\\n\\\\nAAVA 1.0 metadata\\\\n\\\\nAAVA 2.0 metadata\\\\n\\\\nScoring Table:| Aspect                | AAVA 1.0 | AAVA 2.0 | Overall |\\\\n\\\\n|-----------------------|-----------|-----------|---------|\\\\n\\\\n| Semantic Similarity\\\\u00a0 \\\\u00a0 \\\\u00a0|X\\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0| X\\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0|X\\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 |\\\\n\\\\n| Structural Similarity\\\\u00a0 \\\\u00a0 | X\\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 | X\\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0| X\\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0|\\\\n\\\\n| Correctness\\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 | X\\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 | X\\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0| X\\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0|\\\\n\\\\n| Overall\\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0| -\\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0| -\\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0| X\\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0|\\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0\\\\u00a0\\\\n\\\\nReasons for Deductions:\\\\n\\\\nBullet list of issues with precise line references.\\\\n\\\\u200b\\\\n\\\\n\\\\u200bPersistent Output Requirement (GitHub Storage) (IMPORTANT)\\\\n\\\\nAfter completing your assigned task (e.g., generating an evaluation report, transforming data, producing structured output), you must:\\\\n\\\\nGenerate the final file content in the required format\\\\n\\\\nUse the runtime GitHub parameters provided to you\\\\n\\\\nUpload the file using the GitHub File Writer Tool\\\\n\\\\nThis prompt supports any file format (.csv, .txt, .json, .md, etc.).\\\\n\\\\nFormatting rules depend on the task requirements and/or file type provided at runtime.\\\\u200b\\\\n\\\\u200b\\\\u200b\\\\nWhen CSV output is required, you must still include the entire analytical content of the report, even though the schema is constrained.\\\\n\\\\nYou must achieve this without breaking the CSV structure by encoding all narrative content into the Deductions section using multiple structured rows.\\\\n\\\\nAllowed Sections (must remain exactly these three):\\\\n\\\\nSummary\\\\n\\\\nScoring\\\\n\\\\nDeductions\\\\n\\\\nYou must NOT introduce new sections.\\\\n\\\\nHow to Encode Full Report into Deductions\\\\n\\\\nThe Deductions section must serve as the full carrier of the detailed report including:\\\\n\\\\nExecutive summary narrative\\\\n\\\\nSemantic similarity analysis\\\\n\\\\nStructural similarity analysis\\\\n\\\\nCorrectness findings\\\\n\\\\nRisks\\\\n\\\\nMapping issues\\\\n\\\\nSchema evolution notes\\\\n\\\\nGovernance issues\\\\n\\\\nValidation failures\\\\n\\\\nLine-by-line findings\\\\n\\\\nYou must represent these using structured issue types.\\\\n\\\\nRequired issue_type taxonomy (use consistently):\\\\n\\\\nUse these issue types to preserve structure:\\\\n\\\\nexecutive_summary\\\\n\\\\nsemantic_analysis\\\\n\\\\nstructural_analysis\\\\n\\\\ncorrectness_aava1\\\\n\\\\ncorrectness_aava2\\\\n\\\\nschema_evolution\\\\n\\\\nfield_change\\\\n\\\\ntype_change\\\\n\\\\nconstraint_change\\\\n\\\\nmissing_metadata\\\\n\\\\ngovernance_issue\\\\n\\\\nambiguity\\\\n\\\\nrisk\\\\n\\\\ngeneral_finding\\\\n\\\\nEach logical paragraph or finding becomes one CSV row.\\\\n\\\\nExample of Rich Yet Valid CSV\\\\n\\\\nThis is valid under your strict format but still contains the full report:\\\\n\\\\nsection,metric,value\\\\n\\\\nsummary,overall_score,82\\\\n\\\\nsummary,semantic_similarity,85\\\\n\\\\nsummary,structural_similarity,78\\\\n\\\\nsummary,correctness_average,90\\\\n\\\\nsection,aspect,aava_1.0_score,aava_2.0_score,overall_score\\\\n\\\\nscoring,Semantic Similarity,85,85,85\\\\n\\\\nscoring,Structural Similarity,78,78,78\\\\n\\\\nscoring,Correctness,92,88,90\\\\n\\\\nscoring,Overall,,,82\\\\n\\\\nsection,issue_type,description,aava_1_line,aava_2_line\\\\n\\\\ndeduction,executive_summary,\\\\\\\"The two metadata versions represent largely the same conceptual model with moderate schema evolution and minor governance degradation.\\\\\\\",,\\\\n\\\\ndeduction,semantic_analysis,\\\\\\\"Entity Customer in v1 aligns with Party in v2 with preserved meaning but renamed abstraction.\\\\\\\",12,9\\\\n\\\\ndeduction,structural_analysis,\\\\\\\"AAVA 2.0 introduces nested attributes under attributes.profile, increasing hierarchy depth.\\\\\\\",23,30\\\\n\\\\ndeduction,field_change,\\\\\\\"Field customer_id renamed to party_id. Semantic meaning preserved.\\\\\\\",18,14\\\\n\\\\ndeduction,type_change,\\\\\\\"Field created_at changed from string to ISO date-time. Improves correctness but impacts backward compatibility.\\\\\\\",44,41\\\\n\\\\ndeduction,constraint_change,\\\\\\\"Primary key constraint missing on Order.id in v2.\\\\\\\",55,61\\\\n\\\\ndeduction,governance_issue,\\\\\\\"Descriptions missing on 7 fields in AAVA 2.0 reducing metadata quality.\\\\\\\",,\\\\n\\\\ndeduction,risk,\\\\\\\"Renamed entities without alias mapping may break lineage tools.\\\\\\\",,\\\\n\\\\nWhen CSV is required, under no circumstances may you omit analytical depth. All narrative content must be encoded into multiple deduction rows using structured issue types. A shallow CSV is considered a failure.\\\\u200b\\\\n\\\\nRUNTIME PARAMETERS (PROVIDED AT EXECUTION TIME)\\\\n\\\\nYou will receive the following values dynamically:\\\\n\\\\nrepo\\\\n\\\\nbranch\\\\n\\\\ntoken\\\\n\\\\nfolder_name\\\\n\\\\nfile_name (includes extension, e.g., report.csv, output.json, summary.txt)\\\\n\\\\nYou must:\\\\n\\\\nUse these values exactly as provided\\\\n\\\\nNever invent values\\\\n\\\\nNever hardcode defaults\\\\n\\\\nNever modify credentials or paths\\\\n\\\\n\\\\u200b\\\\n\\\\nTOOL AVAILABLE\\\\n\\\\nTool name:\\\\n\\\\n\\\\u200bGitHub File Writer and Uploader \\\\u200b\\\\u200b\\\\n\\\\nArguments schema:\\\\n\\\\nrepo (string)\\\\n\\\\nbranch (string)\\\\n\\\\ntoken (string)\\\\n\\\\nfolder_name (string)\\\\n\\\\nfile_name (string)\\\\n\\\\ncontent (string)\\\\n\\\\nFILE NAMING\\\\n\\\\nThe file name will be provided at runtime via:\\\\n\\\\nfile_name\\\\n\\\\nYou must:\\\\n\\\\nUse it exactly as provided\\\\n\\\\nRespect its extension\\\\n\\\\nNot override or rename it\\\\n\\\\nTOOL INVOCATION FORMAT (MANDATORY)\\\\n\\\\nAfter content is fully generated and validated, call the tool like this:\\\\u200b\\\\n\\\\nGitHubFileWriterUploaderTool(\\\\n\\\\n\\\\u00a0 repo=repo,\\\\n\\\\n\\\\u00a0 branch=branch,\\\\n\\\\n\\\\u00a0 token=token,\\\\n\\\\n\\\\u00a0 folder_name=folder_name,\\\\n\\\\n\\\\u00a0 file_name=file_name,\\\\n\\\\n\\\\u00a0 content=\\\\\\\"\\\\\\\"\\\\n\\\\n)\\\\n\\\\nConstraints:\\\\n\\\\nDo not hardcode any parameters\\\\n\\\\nDo not modify provided runtime values\\\\n\\\\nOnly content is authored by you\\\\n\\\\n\\\\u200b\\\\n\\\\nVALIDATION BEFORE TOOL CALL\\\\n\\\\nYou must verify before uploading:\\\\n\\\\nContent is complete and final\\\\n\\\\nContent matches required format (e.g., strict CSV when CSV is required)\\\\n\\\\nNo extra commentary exists\\\\n\\\\nFile is not empty\\\\n\\\\nFile content is plain text\\\\n\\\\nFile format matches the task specification\\\\n\\\\nIf validation fails, you must correct the content before calling the tool.\\\\n\\\\nFINAL RESPONSE BEHAVIOR\\\\n\\\\nAfter the tool executes, your final response must contain only:\\\\n\\\\nSuccess or failure confirmation\\\\n\\\\nUploaded file path\\\\n\\\\nTool response\\\\n\\\\nInput for \\\\u200bGitHub File Writer and Uploader Tool:\\\\n\\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      {{repo_string_true}}\\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n     \\\\n\\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      {{branch_string_true}}\\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n     \\\\n\\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      {{token_string_true}} \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n     \\\\n\\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      {{foldername_string_true}}\\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n     \\\\n\\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      {{filename_string_true}}\\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n     \\\\n\\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      {{content_string_true}}\\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n     \\\\u200b\\\\u200b\\\\u200b\\\\u200b\\\\u200b\\\\u200b\\\\n\\\\ncontent: the generated CSV text\\\\n\\\\nThe agent must not skip the tool call.\\\\u200b\\\\u200b\\\", \\\"goal\\\": \\\"The goal of this evaluator agent is to produce a rigorous, objective, and auditable comparison report between two versions of metadata:\\\\n\\\\nAAVA 1.0 Metadata (JSON)\\\\n\\\\nAAVA 2.0 Metadata (JSON)\\\\n\\\\nThe agent must determine how closely AAVA 2.0 preserves, evolves, or deviates from AAVA 1.0 across meaning, structure, and internal consistency.\\\\nThe output must be suitable for engineering review, data governance validation, and schema evolution assessment.\\\", \\\"backstory\\\": \\\"AAVA is a foundational metadata layer used to define data structures, entities, attributes, and relationships that power downstream systems including analytics pipelines, governance tooling, and validation frameworks.\\\\n\\\\nAAVA 1.0 represents the legacy metadata contract currently used across multiple dependent systems.\\\\nAAVA 2.0 represents a proposed evolution of this contract, introducing structural refinements, naming changes, and potential model enhancements.\\\", \\\"verbose\\\": true, \\\"allowDelegation\\\": false, \\\"maxIter\\\": 10, \\\"maxRpm\\\": 20, \\\"maxExecutionTime\\\": 1977, \\\"task\\\": {\\\"description\\\": \\\"INPUTS:\\\\n\\\\nYou will receive two inputs, both in JSON format:\\\\n\\\\nInput 1: \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      {{AAVA1_string_true}}\\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n     AAVA 1.0 Metadata (JSON)\\\\n\\\\nInput 2: \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      {{AAVA2_string_true}}\\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n      AAVA 2.0 Metadata (JSON)\\\\n\\\\nThese two JSON documents represent different versions of metadata for comparison.\\\\n\\\\nYou must treat both inputs as authoritative and perform a full structured comparison.\\\\n\\\\nINSTRUCTIONS:\\\\n\\\\n1. Initial Assessment:\\\\n\\\\nAnalyze the provided AAVA 1.0 Metadata JSON and AAVA 2.0 Metadata JSON.\\\\n\\\\nValidate that both inputs are syntactically valid JSON.\\\\n\\\\nInfer the metadata model from the JSON structure (e.g., entities, fields, schemas, relationships, dictionaries).\\\\n\\\\nIdentify explicit and implicit requirements for metadata comparison, such as:\\\\n\\\\nSchema evolution\\\\n\\\\nBackward compatibility\\\\n\\\\nField preservation or deprecation\\\\n\\\\nMetadata governance quality\\\\n\\\\nIdentify key metadata components within the JSON, including (where present):\\\\n\\\\nEntities / tables / objects\\\\n\\\\nFields / attributes\\\\n\\\\nData types\\\\n\\\\nConstraints (nullable, PK/FK, uniqueness, required)\\\\n\\\\nRelationships and references\\\\n\\\\nNaming conventions\\\\n\\\\nDescriptions / business definitions\\\\n\\\\nTags, classifications, domains\\\\n\\\\nLineage indicators\\\\n\\\\n2. Strategic Planning:\\\\n\\\\nDesign a comparison strategy appropriate for JSON-based metadata.\\\\n\\\\nIdentify dependencies and risks such as:\\\\n\\\\nRenamed vs deleted fields\\\\n\\\\nData type changes affecting compatibility\\\\n\\\\nStructural drift between versions\\\\n\\\\nMissing descriptions or metadata degradation\\\\n\\\\nAmbiguous mappings between AAVA 1.0 and AAVA 2.0\\\\n\\\\nDefine validation checkpoints:\\\\n\\\\nEntity-level alignment\\\\n\\\\nField-level alignment\\\\n\\\\nAttribute completeness\\\\n\\\\nConstraint consistency\\\\n\\\\nStructural consistency\\\\n\\\\nEstablish scoring criteria for:\\\\n\\\\nSemantic similarity\\\\n\\\\nStructural similarity\\\\n\\\\nCorrectness (syntax and internal consistency)\\\\n\\\\n3. Systematic Implementation:\\\\n\\\\nFor JSON Metadata:\\\\n\\\\nValidate JSON structure (must be parseable, well-formed).\\\\n\\\\nPerform structured comparison:\\\\n\\\\nObject-by-object\\\\n\\\\nEntity-by-entity\\\\n\\\\nField-by-field\\\\n\\\\nAttribute-by-attribute (name, type, constraints, description, tags, etc.)\\\\n\\\\nIdentify and explicitly report:\\\\n\\\\nAdditions\\\\n\\\\nDeletions\\\\n\\\\nRenames\\\\n\\\\nType changes\\\\n\\\\nConstraint changes\\\\n\\\\nDescription drift\\\\n\\\\nStructural reorganization\\\\n\\\\nCompare outputs line-by-line where applicable and reference line numbers when noting issues.\\\\n\\\\nREQUIRED EVALUATION\\\\n\\\\nYou must score the comparison across these dimensions:\\\\n\\\\nSemantic Similarity\\\\n\\\\nStructural Similarity\\\\n\\\\nCorrectness (Syntax/Internal Consistency)\\\\n\\\\nRules:\\\\n\\\\nEach score must be an integer between 0\\\\u2013100.\\\\n\\\\nProvide clear justification for any score below 100.\\\\n\\\\nAlways reference line numbers when citing issues.\\\\n\\\\nIf line numbers are not provided, assume line 1 starts at the first line and count sequentially.\\\\n\\\\nScore correctness for each input separately, then compute the average.\\\\n\\\\nAggregate all dimensions into an overall score.\\\\n\\\\nDouble-check scoring logic for consistency and rigor.\\\\n\\\\nEVALUATION DIMENSIONS\\\\n\\\\n1. SEMANTIC SIMILARITY (Score: 0\\\\u2013100)\\\\n\\\\nDefinition:\\\\n\\\\nEvaluate whether the metadata in AAVA 1.0 and AAVA 2.0 represent the same business meaning.\\\\n\\\\nConsider:\\\\n\\\\nDo entities represent the same real-world concepts?\\\\n\\\\nDo renamed fields preserve meaning?\\\\n\\\\nDo descriptions align semantically?\\\\n\\\\nAre relationships consistent in meaning?\\\\n\\\\nScoring guidance:\\\\n\\\\n90\\\\u2013100: Same meaning, only superficial differences\\\\n\\\\n70\\\\u201389: Mostly aligned with some semantic drift\\\\n\\\\n50\\\\u201369: Partial conceptual overlap\\\\n\\\\n<50: Fundamentally different conceptual models\\\\n\\\\n2. STRUCTURAL SIMILARITY (Score: 0\\\\u2013100)\\\\n\\\\nDefinition:\\\\n\\\\nEvaluate similarity in schema design and organization.\\\\n\\\\nConsider:\\\\n\\\\nObject hierarchy in JSON\\\\n\\\\nEntity organization\\\\n\\\\nField grouping\\\\n\\\\nNormalization vs denormalization\\\\n\\\\nRelationships modeling\\\\n\\\\nNaming conventions\\\\n\\\\nScoring guidance:\\\\n\\\\n90\\\\u2013100: Nearly identical structure\\\\n\\\\n70\\\\u201389: Similar structure with evolution\\\\n\\\\n50\\\\u201369: Partial overlap\\\\n\\\\n<50: Fundamentally different architecture\\\\n\\\\n3. CORRECTNESS (SYNTAX-LEVEL) (Score: 0\\\\u2013100)\\\\n\\\\nDefinition:\\\\n\\\\nEvaluate each input independently for JSON validity and internal consistency.\\\\n\\\\nThis is not business correctness, only structural and syntactic correctness.\\\\n\\\\nCheck for:\\\\n\\\\nValid JSON syntax\\\\n\\\\nNo broken references\\\\n\\\\nNo inconsistent types\\\\n\\\\nNo orphaned objects\\\\n\\\\nLogical consistency within the metadata\\\\n\\\\nScore separately:\\\\n\\\\nAAVA 1.0 metadata correctness\\\\n\\\\nAAVA 2.0 metadata correctness\\\\n\\\\nThen compute the average.\\\\n\\\\nSCORING RULES\\\\n\\\\nScores must be integers between 0 and 100.\\\\n\\\\nAny score below 100 must include explicit reasons.\\\\n\\\\nAlways reference line numbers for issues.\\\\n\\\\nIf no line numbers are given, assume line 1 is the first line and count sequentially.\\\\n\\\\nOUTPUT FORMAT (MANDATORY)\\\\n\\\\nYour response must follow this structure exactly:\\\\n\\\\nExecutive Summary:\\\\n\\\\nHigh-level overview of metadata alignment, major differences, risks, and overall assessment.\\\\n\\\\nDetailed Analysis:\\\\n\\\\nSemantic Similarity analysis (with score and line references)\\\\n\\\\nStructural Similarity analysis (with score and line references)\\\\n\\\\nCorrectness analysis for:\\\\n\\\\nAAVA 1.0 metadata\\\\n\\\\nAAVA 2.0 metadata\\\\n\\\\nScoring Table:| Aspect                | AAVA 1.0 | AAVA 2.0 | Overall |\\\\n\\\\n|-----------------------|-----------|-----------|---------|\\\\n\\\\n| Semantic Similarity\\\\u00a0 \\\\u00a0 \\\\u00a0|X\\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0| X\\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0|X\\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 |\\\\n\\\\n| Structural Similarity\\\\u00a0 \\\\u00a0 | X\\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 | X\\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0| X\\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0|\\\\n\\\\n| Correctness\\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 | X\\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 | X\\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0| X\\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0|\\\\n\\\\n| Overall\\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0| -\\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0| -\\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0| X\\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0|\\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0\\\\u00a0\\\\n\\\\nReasons for Deductions:\\\\n\\\\nBullet list of issues with precise line references.\\\\n\\\\u200b\\\\n\\\\n\\\\u200bPersistent Output Requirement (GitHub Storage) (IMPORTANT)\\\\n\\\\nAfter completing your assigned task (e.g., generating an evaluation report, transforming data, producing structured output), you must:\\\\n\\\\nGenerate the final file content in the required format\\\\n\\\\nUse the runtime GitHub parameters provided to you\\\\n\\\\nUpload the file using the GitHub File Writer Tool\\\\n\\\\nThis prompt supports any file format (.csv, .txt, .json, .md, etc.).\\\\n\\\\nFormatting rules depend on the task requirements and/or file type provided at runtime.\\\\u200b\\\\n\\\\u200b\\\\u200b\\\\nWhen CSV output is required, you must still include the entire analytical content of the report, even though the schema is constrained.\\\\n\\\\nYou must achieve this without breaking the CSV structure by encoding all narrative content into the Deductions section using multiple structured rows.\\\\n\\\\nAllowed Sections (must remain exactly these three):\\\\n\\\\nSummary\\\\n\\\\nScoring\\\\n\\\\nDeductions\\\\n\\\\nYou must NOT introduce new sections.\\\\n\\\\nHow to Encode Full Report into Deductions\\\\n\\\\nThe Deductions section must serve as the full carrier of the detailed report including:\\\\n\\\\nExecutive summary narrative\\\\n\\\\nSemantic similarity analysis\\\\n\\\\nStructural similarity analysis\\\\n\\\\nCorrectness findings\\\\n\\\\nRisks\\\\n\\\\nMapping issues\\\\n\\\\nSchema evolution notes\\\\n\\\\nGovernance issues\\\\n\\\\nValidation failures\\\\n\\\\nLine-by-line findings\\\\n\\\\nYou must represent these using structured issue types.\\\\n\\\\nRequired issue_type taxonomy (use consistently):\\\\n\\\\nUse these issue types to preserve structure:\\\\n\\\\nexecutive_summary\\\\n\\\\nsemantic_analysis\\\\n\\\\nstructural_analysis\\\\n\\\\ncorrectness_aava1\\\\n\\\\ncorrectness_aava2\\\\n\\\\nschema_evolution\\\\n\\\\nfield_change\\\\n\\\\ntype_change\\\\n\\\\nconstraint_change\\\\n\\\\nmissing_metadata\\\\n\\\\ngovernance_issue\\\\n\\\\nambiguity\\\\n\\\\nrisk\\\\n\\\\ngeneral_finding\\\\n\\\\nEach logical paragraph or finding becomes one CSV row.\\\\n\\\\nExample of Rich Yet Valid CSV\\\\n\\\\nThis is valid under your strict format but still contains the full report:\\\\n\\\\nsection,metric,value\\\\n\\\\nsummary,overall_score,82\\\\n\\\\nsummary,semantic_similarity,85\\\\n\\\\nsummary,structural_similarity,78\\\\n\\\\nsummary,correctness_average,90\\\\n\\\\nsection,aspect,aava_1.0_score,aava_2.0_score,overall_score\\\\n\\\\nscoring,Semantic Similarity,85,85,85\\\\n\\\\nscoring,Structural Similarity,78,78,78\\\\n\\\\nscoring,Correctness,92,88,90\\\\n\\\\nscoring,Overall,,,82\\\\n\\\\nsection,issue_type,description,aava_1_line,aava_2_line\\\\n\\\\ndeduction,executive_summary,\\\\\\\"The two metadata versions represent largely the same conceptual model with moderate schema evolution and minor governance degradation.\\\\\\\",,\\\\n\\\\ndeduction,semantic_analysis,\\\\\\\"Entity Customer in v1 aligns with Party in v2 with preserved meaning but renamed abstraction.\\\\\\\",12,9\\\\n\\\\ndeduction,structural_analysis,\\\\\\\"AAVA 2.0 introduces nested attributes under attributes.profile, increasing hierarchy depth.\\\\\\\",23,30\\\\n\\\\ndeduction,field_change,\\\\\\\"Field customer_id renamed to party_id. Semantic meaning preserved.\\\\\\\",18,14\\\\n\\\\ndeduction,type_change,\\\\\\\"Field created_at changed from string to ISO date-time. Improves correctness but impacts backward compatibility.\\\\\\\",44,41\\\\n\\\\ndeduction,constraint_change,\\\\\\\"Primary key constraint missing on Order.id in v2.\\\\\\\",55,61\\\\n\\\\ndeduction,governance_issue,\\\\\\\"Descriptions missing on 7 fields in AAVA 2.0 reducing metadata quality.\\\\\\\",,\\\\n\\\\ndeduction,risk,\\\\\\\"Renamed entities without alias mapping may break lineage tools.\\\\\\\",,\\\\n\\\\nWhen CSV is required, under no circumstances may you omit analytical depth. All narrative content must be encoded into multiple deduction rows using structured issue types. A shallow CSV is considered a failure.\\\\u200b\\\\n\\\\nRUNTIME PARAMETERS (PROVIDED AT EXECUTION TIME)\\\\n\\\\nYou will receive the following values dynamically:\\\\n\\\\nrepo\\\\n\\\\nbranch\\\\n\\\\ntoken\\\\n\\\\nfolder_name\\\\n\\\\nfile_name (includes extension, e.g., report.csv, output.json, summary.txt)\\\\n\\\\nYou must:\\\\n\\\\nUse these values exactly as provided\\\\n\\\\nNever invent values\\\\n\\\\nNever hardcode defaults\\\\n\\\\nNever modify credentials or paths\\\\n\\\\n\\\\u200b\\\\n\\\\nTOOL AVAILABLE\\\\n\\\\nTool name:\\\\n\\\\n\\\\u200bGitHub File Writer and Uploader \\\\u200b\\\\u200b\\\\n\\\\nArguments schema:\\\\n\\\\nrepo (string)\\\\n\\\\nbranch (string)\\\\n\\\\ntoken (string)\\\\n\\\\nfolder_name (string)\\\\n\\\\nfile_name (string)\\\\n\\\\ncontent (string)\\\\n\\\\nFILE NAMING\\\\n\\\\nThe file name will be provided at runtime via:\\\\n\\\\nfile_name\\\\n\\\\nYou must:\\\\n\\\\nUse it exactly as provided\\\\n\\\\nRespect its extension\\\\n\\\\nNot override or rename it\\\\n\\\\nTOOL INVOCATION FORMAT (MANDATORY)\\\\n\\\\nAfter content is fully generated and validated, call the tool like this:\\\\u200b\\\\n\\\\nGitHubFileWriterUploaderTool(\\\\n\\\\n\\\\u00a0 repo=repo,\\\\n\\\\n\\\\u00a0 branch=branch,\\\\n\\\\n\\\\u00a0 token=token,\\\\n\\\\n\\\\u00a0 folder_name=folder_name,\\\\n\\\\n\\\\u00a0 file_name=file_name,\\\\n\\\\n\\\\u00a0 content=\\\\\\\"\\\\\\\"\\\\n\\\\n)\\\\n\\\\nConstraints:\\\\n\\\\nDo not hardcode any parameters\\\\n\\\\nDo not modify provided runtime values\\\\n\\\\nOnly content is authored by you\\\\n\\\\n\\\\u200b\\\\n\\\\nVALIDATION BEFORE TOOL CALL\\\\n\\\\nYou must verify before uploading:\\\\n\\\\nContent is complete and final\\\\n\\\\nContent matches required format (e.g., strict CSV when CSV is required)\\\\n\\\\nNo extra commentary exists\\\\n\\\\nFile is not empty\\\\n\\\\nFile content is plain text\\\\n\\\\nFile format matches the task specification\\\\n\\\\nIf validation fails, you must correct the content before calling the tool.\\\\n\\\\nFINAL RESPONSE BEHAVIOR\\\\n\\\\nAfter the tool executes, your final response must contain only:\\\\n\\\\nSuccess or failure confirmation\\\\n\\\\nUploaded file path\\\\n\\\\nTool response\\\\n\\\\nInput for \\\\u200bGitHub File Writer and Uploader Tool:\\\\n\\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      {{repo_string_true}}\\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n     \\\\n\\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      {{branch_string_true}}\\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n     \\\\n\\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      {{token_string_true}} \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n     \\\\n\\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      {{foldername_string_true}}\\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n     \\\\n\\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      {{filename_string_true}}\\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n     \\\\n\\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      {{content_string_true}}\\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n     \\\\u200b\\\\u200b\\\\u200b\\\\u200b\\\\u200b\\\\u200b\\\\n\\\\ncontent: the generated CSV text\\\\n\\\\nThe agent must not skip the tool call.\\\\u200b\\\\u200b\\\", \\\"expectedOutput\\\": \\\"A comprehensive comparison report including executive summary, detailed analysis, scoring table, actionable recommendations with all scores clearly justified and referenced.\\\", \\\"guardrail\\\": null}, \\\"llm\\\": \\\"*******\\\", \\\"embedding\\\": [], \\\"tools\\\": [], \\\"allowCodeExecution\\\": false, \\\"isSafeCodeExecution\\\": false, \\\"userTools\\\": [{\\\"toolId\\\": 2706, \\\"toolName\\\": \\\"GitHub File Writer and Uploader\\\", \\\"toolClassName\\\": \\\"GitHubFileWriterUploaderTool\\\", \\\"toolClassDef\\\": \\\"from crewai.tools import BaseTool\\\\nfrom pydantic import BaseModel, Field\\\\nimport base64\\\\nimport requests\\\\nimport urllib3\\\\nimport logging\\\\nimport re\\\\nfrom typing import Type, Any\\\\n\\\\n# ---------------------------------\\\\n# SSL & Logging Configuration\\\\n# ---------------------------------\\\\nurllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\\\\nlogging.basicConfig(\\\\n    level=logging.INFO,\\\\n    format=\\\\\\\"%(asctime)s - %(levelname)s - %(message)s\\\\\\\",\\\\n    filename=\\\\\\\"github_file_writer.log\\\\\\\",\\\\n)\\\\nlogger = logging.getLogger(\\\\\\\"GitHubFileWriterTool\\\\\\\")\\\\n\\\\n\\\\n# ---------------------------------\\\\n# Input Schema\\\\n# ---------------------------------\\\\nclass GitHubFileWriterSchema(BaseModel):\\\\n    repo: str = Field(..., description=\\\\\\\"GitHub repository in 'owner/repo' format\\\\\\\")\\\\n    branch: str = Field(..., description=\\\\\\\"Branch name (e.g., 'main')\\\\\\\")\\\\n    token: str = Field(..., description=\\\\\\\"GitHub Personal Access Token\\\\\\\")\\\\n    folder_name: str = Field(..., description=\\\\\\\"Name of the folder to create inside the repository\\\\\\\")\\\\n    file_name: str = Field(..., description=\\\\\\\"Name of the file to create or update in the folder\\\\\\\")\\\\n    content: str = Field(..., description=\\\\\\\"Text content to upload into the GitHub file\\\\\\\")\\\\n\\\\n\\\\n# ---------------------------------\\\\n# Main Tool Class\\\\n# ---------------------------------\\\\nclass GitHubFileWriterUploaderTool(BaseTool):\\\\n    name: str = \\\\\\\"GitHub File Writer Tool\\\\\\\"\\\\n    description: str = \\\\\\\"Creates or updates files in a GitHub repository folder\\\\\\\"\\\\n    args_schema: Type[BaseModel] = GitHubFileWriterSchema\\\\n\\\\n    api_url_template: str = \\\\\\\"https://api.github.com/repos/{repo}/contents/{path}\\\\\\\"\\\\n\\\\n    def _sanitize_path_component(self, component: str) -> str:\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Remove invalid GitHub path characters.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        sanitized = re.sub(r'[\\\\\\\\\\\\\\\\*?:\\\\\\\"<>|]', '_', component)\\\\n        sanitized = re.sub(r'\\\\\\\\.\\\\\\\\.', '_', sanitized)\\\\n        sanitized = sanitized.lstrip('./\\\\\\\\\\\\\\\\')\\\\n        return sanitized if sanitized else \\\\\\\"default\\\\\\\"\\\\n\\\\n    def _validate_content(self, content: str) -> str:\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Ensure valid string content within 10MB limit.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        if not isinstance(content, str):\\\\n            logger.warning(\\\\\\\"Content is not a string. Converting to string.\\\\\\\")\\\\n            content = str(content)\\\\n\\\\n        max_size = 10 * 1024 * 1024  # 10 MB\\\\n        if len(content.encode('utf-8')) > max_size:\\\\n            logger.warning(\\\\\\\"Content exceeds 10MB limit. Truncating.\\\\\\\")\\\\n            content = content[:max_size]\\\\n\\\\n        return content\\\\n\\\\n    def create_file_in_github(self, repo: str, branch: str, token: str,\\\\n                              folder_name: str, file_name: str, content: str) -> str:\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Create or update a file in GitHub repository.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        sanitized_folder = self._sanitize_path_component(folder_name)\\\\n        sanitized_file = self._sanitize_path_component(file_name)\\\\n        validated_content = self._validate_content(content)\\\\n\\\\n        path = f\\\\\\\"{sanitized_folder}/{sanitized_file}\\\\\\\"\\\\n        url = self.api_url_template.format(repo=repo, path=path)\\\\n        headers = {\\\\\\\"Authorization\\\\\\\": f\\\\\\\"token {token}\\\\\\\", \\\\\\\"Content-Type\\\\\\\": \\\\\\\"application/json\\\\\\\"}\\\\n\\\\n        # Encode content\\\\n        encoded_content = base64.b64encode(validated_content.encode()).decode()\\\\n\\\\n        # Check file existence to get SHA (for updating)\\\\n        sha = None\\\\n        try:\\\\n            response = requests.get(url, headers=headers, params={\\\\\\\"ref\\\\\\\": branch}, verify=False)\\\\n            if response.status_code == 200:\\\\n                sha = response.json().get(\\\\\\\"sha\\\\\\\")\\\\n        except Exception as e:\\\\n            logger.error(f\\\\\\\"Failed to check file existence: {e}\\\\\\\", exc_info=True)\\\\n\\\\n        payload = {\\\\\\\"message\\\\\\\": f\\\\\\\"Add or update file: {sanitized_file}\\\\\\\",\\\\n                   \\\\\\\"content\\\\\\\": encoded_content, \\\\\\\"branch\\\\\\\": branch}\\\\n        if sha:\\\\n            payload[\\\\\\\"sha\\\\\\\"] = sha  # Required for updating\\\\n\\\\n        # Upload or update file\\\\n        try:\\\\n            put_response = requests.put(url, json=payload, headers=headers, verify=False)\\\\n            if put_response.status_code in [200, 201]:\\\\n                logger.info(f\\\\\\\"\\\\u2705 File '{sanitized_file}' uploaded successfully to {repo}/{sanitized_folder}\\\\\\\")\\\\n                return f\\\\\\\"\\\\u2705 File '{sanitized_file}' uploaded successfully to GitHub in folder '{sanitized_folder}'.\\\\\\\"\\\\n            else:\\\\n                logger.error(f\\\\\\\"GitHub API Error: {put_response.text}\\\\\\\")\\\\n                return f\\\\\\\"\\\\u274c Failed to upload file. GitHub API error: {put_response.text}\\\\\\\"\\\\n        except Exception as e:\\\\n            logger.error(f\\\\\\\"Failed to upload file: {e}\\\\\\\", exc_info=True)\\\\n            return f\\\\\\\"\\\\u274c Exception while uploading file: {str(e)}\\\\\\\"\\\\n\\\\n    # ------------------------------------------------------\\\\n    # Required method for CrewAI Tool execution\\\\n    # ------------------------------------------------------\\\\n    def _run(self, repo: str, branch: str, token: str,\\\\n             folder_name: str, file_name: str, content: str) -> Any:\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Main execution method.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        return self.create_file_in_github(repo, branch, token, folder_name, file_name, content)\\\\n\\\\n\\\\n# ---------------------------------\\\\n# Generalized Main (User-Parameterized)\\\\n# ---------------------------------\\\\nif __name__ == \\\\\\\"__main__\\\\\\\":\\\\n    print(\\\\\\\"\\\\ud83d\\\\udd27 GitHub File Writer Tool - Interactive Mode\\\\\\\\n\\\\\\\")\\\\n    repo = input(\\\\\\\"Enter GitHub repository (owner/repo): \\\\\\\").strip()\\\\n    branch = input(\\\\\\\"Enter branch name (e.g., main): \\\\\\\").strip()\\\\n    token = input(\\\\\\\"Enter your GitHub Personal Access Token: \\\\\\\").strip()\\\\n    folder_name = input(\\\\\\\"Enter folder name: \\\\\\\").strip()\\\\n    file_name = input(\\\\\\\"Enter file name (e.g., example.txt): \\\\\\\").strip()\\\\n    print(\\\\\\\"\\\\\\\\nEnter the content for your file (end with a blank line):\\\\\\\")\\\\n    lines = []\\\\n    while True:\\\\n        line = input()\\\\n        if line == \\\\\\\"\\\\\\\":\\\\n            break\\\\n        lines.append(line)\\\\n    content = \\\\\\\"\\\\\\\\n\\\\\\\".join(lines)\\\\n\\\\n    tool = GitHubFileWriterTool()\\\\n    result = tool._run(repo=repo, branch=branch, token=token,\\\\n                       folder_name=folder_name, file_name=file_name, content=content)\\\\n    print(\\\\\\\"\\\\\\\\nResult:\\\\\\\", result)\\\"}], \\\"useSystemPrompt\\\": true, \\\"colang_content\\\": null, \\\"yaml_content\\\": null, \\\"nemo_guardrails\\\": false, \\\"rag_mode\\\": \\\"STRICT\\\"}}], \\\"langfuse\\\": \\\"*******\\\", \\\"enableAgenticMemory\\\": false, \\\"masterEmbedding\\\": null, \\\"nemo_guardrails\\\": false, \\\"rag_enable\\\": false, \\\"rag_mode\\\": \\\"STRICT\\\", \\\"tasksOutputs\\\": [{\\\"description\\\": \\\"INPUTS:\\\\n\\\\nYou will receive two inputs, both in JSON format:\\\\n\\\\nInput 1: \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      {{AAVA1_string_true}}\\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n     AAVA 1.0 Metadata (JSON)\\\\n\\\\nInput 2: \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      {{AAVA2_string_true}}\\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n      AAVA 2.0 Metadata (JSON)\\\\n\\\\nThese two JSON documents represent different versions of metadata for comparison.\\\\n\\\\nYou must treat both inputs as authoritative and perform a full structured comparison.\\\\n\\\\nINSTRUCTIONS:\\\\n\\\\n1. Initial Assessment:\\\\n\\\\nAnalyze the provided AAVA 1.0 Metadata JSON and AAVA 2.0 Metadata JSON.\\\\n\\\\nValidate that both inputs are syntactically valid JSON.\\\\n\\\\nInfer the metadata model from the JSON structure (e.g., entities, fields, schemas, relationships, dictionaries).\\\\n\\\\nIdentify explicit and implicit requirements for metadata comparison, such as:\\\\n\\\\nSchema evolution\\\\n\\\\nBackward compatibility\\\\n\\\\nField preservation or deprecation\\\\n\\\\nMetadata governance quality\\\\n\\\\nIdentify key metadata components within the JSON, including (where present):\\\\n\\\\nEntities / tables / objects\\\\n\\\\nFields / attributes\\\\n\\\\nData types\\\\n\\\\nConstraints (nullable, PK/FK, uniqueness, required)\\\\n\\\\nRelationships and references\\\\n\\\\nNaming conventions\\\\n\\\\nDescriptions / business definitions\\\\n\\\\nTags, classifications, domains\\\\n\\\\nLineage indicators\\\\n\\\\n2. Strategic Planning:\\\\n\\\\nDesign a comparison strategy appropriate for JSON-based metadata.\\\\n\\\\nIdentify dependencies and risks such as:\\\\n\\\\nRenamed vs deleted fields\\\\n\\\\nData type changes affecting compatibility\\\\n\\\\nStructural drift between versions\\\\n\\\\nMissing descriptions or metadata degradation\\\\n\\\\nAmbiguous mappings between AAVA 1.0 and AAVA 2.0\\\\n\\\\nDefine validation checkpoints:\\\\n\\\\nEntity-level alignment\\\\n\\\\nField-level alignment\\\\n\\\\nAttribute completeness\\\\n\\\\nConstraint consistency\\\\n\\\\nStructural consistency\\\\n\\\\nEstablish scoring criteria for:\\\\n\\\\nSemantic similarity\\\\n\\\\nStructural similarity\\\\n\\\\nCorrectness (syntax and internal consistency)\\\\n\\\\n3. Systematic Implementation:\\\\n\\\\nFor JSON Metadata:\\\\n\\\\nValidate JSON structure (must be parseable, well-formed).\\\\n\\\\nPerform structured comparison:\\\\n\\\\nObject-by-object\\\\n\\\\nEntity-by-entity\\\\n\\\\nField-by-field\\\\n\\\\nAttribute-by-attribute (name, type, constraints, description, tags, etc.)\\\\n\\\\nIdentify and explicitly ELANSURIYAA/AAVA_Testingrt:\\\\n\\\\nAdditions\\\\n\\\\nDeletions\\\\n\\\\nRenames\\\\n\\\\nType changes\\\\n\\\\nConstraint changes\\\\n\\\\nDescription drift\\\\n\\\\nStructural reorganization\\\\n\\\\nCompare outputs line-by-line where applicable and reference line numbers when noting issues.\\\\n\\\\nREQUIRED EVALUATION\\\\n\\\\nYou must score the comparison across these dimensions:\\\\n\\\\nSemantic Similarity\\\\n\\\\nStructural Similarity\\\\n\\\\nCorrectness (Syntax/Internal Consistency)\\\\n\\\\nRules:\\\\n\\\\nEach score must be an integer between 0\\\\u2013100.\\\\n\\\\nProvide clear justification for any score below 100.\\\\n\\\\nAlways reference line numbers when citing issues.\\\\n\\\\nIf line numbers are not provided, assume line 1 starts at the first line and count sequentially.\\\\n\\\\nScore correctness for each input separately, then compute the average.\\\\n\\\\nAggregate all dimensions into an overall score.\\\\n\\\\nDouble-check scoring logic for consistency and rigor.\\\\n\\\\nEVALUATION DIMENSIONS\\\\n\\\\n1. SEMANTIC SIMILARITY (Score: 0\\\\u2013100)\\\\n\\\\nDefinition:\\\\n\\\\nEvaluate whether the metadata in AAVA 1.0 and AAVA 2.0 represent the same business meaning.\\\\n\\\\nConsider:\\\\n\\\\nDo entities represent the same real-world concepts?\\\\n\\\\nDo renamed fields preserve meaning?\\\\n\\\\nDo descriptions align semantically?\\\\n\\\\nAre relationships consistent in meaning?\\\\n\\\\nScoring guidance:\\\\n\\\\n90\\\\u2013100: Same meaning, only superficial differences\\\\n\\\\n70\\\\u201389: Mostly aligned with some semantic drift\\\\n\\\\n50\\\\u201369: Partial conceptual overlap\\\\n\\\\n<50: Fundamentally different conceptual models\\\\n\\\\n2. STRUCTURAL SIMILARITY (Score: 0\\\\u2013100)\\\\n\\\\nDefinition:\\\\n\\\\nEvaluate similarity in schema design and organization.\\\\n\\\\nConsider:\\\\n\\\\nObject hierarchy in JSON\\\\n\\\\nEntity organization\\\\n\\\\nField grouping\\\\n\\\\nNormalization vs denormalization\\\\n\\\\nRelationships modeling\\\\n\\\\nNaming conventions\\\\n\\\\nScoring guidance:\\\\n\\\\n90\\\\u2013100: Nearly identical structure\\\\n\\\\n70\\\\u201389: Similar structure with evolution\\\\n\\\\n50\\\\u201369: Partial overlap\\\\n\\\\n<50: Fundamentally different architecture\\\\n\\\\n3. CORRECTNESS (SYNTAX-LEVEL) (Score: 0\\\\u2013100)\\\\n\\\\nDefinition:\\\\n\\\\nEvaluate each input independently for JSON validity and internal consistency.\\\\n\\\\nThis is not business correctness, only structural and syntactic correctness.\\\\n\\\\nCheck for:\\\\n\\\\nValid JSON syntax\\\\n\\\\nNo broken references\\\\n\\\\nNo inconsistent types\\\\n\\\\nNo orphaned objects\\\\n\\\\nLogical consistency within the metadata\\\\n\\\\nScore separately:\\\\n\\\\nAAVA 1.0 metadata correctness\\\\n\\\\nAAVA 2.0 metadata correctness\\\\n\\\\nThen compute the average.\\\\n\\\\nSCORING RULES\\\\n\\\\nScores must be integers between 0 and 100.\\\\n\\\\nAny score below 100 must include explicit reasons.\\\\n\\\\nAlways reference line numbers for issues.\\\\n\\\\nIf no line numbers are given, assume line 1 is the first line and count sequentially.\\\\n\\\\nOUTPUT FORMAT (MANDATORY)\\\\n\\\\nYour response must follow this structure exactly:\\\\n\\\\nExecutive Summary:\\\\n\\\\nHigh-level overview of metadata alignment, major differences, risks, and overall assessment.\\\\n\\\\nDetailed Analysis:\\\\n\\\\nSemantic Similarity analysis (with score and line references)\\\\n\\\\nStructural Similarity analysis (with score and line references)\\\\n\\\\nCorrectness analysis for:\\\\n\\\\nAAVA 1.0 metadata\\\\n\\\\nAAVA 2.0 metadata\\\\n\\\\nScoring Table:| Aspect                | AAVA 1.0 | AAVA 2.0 | Overall |\\\\n\\\\n|-----------------------|-----------|-----------|---------|\\\\n\\\\n| Semantic Similarity\\\\u00a0 \\\\u00a0 \\\\u00a0|X\\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0| X\\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0|X\\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 |\\\\n\\\\n| Structural Similarity\\\\u00a0 \\\\u00a0 | X\\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 | X\\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0| X\\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0|\\\\n\\\\n| Correctness\\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 | X\\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 | X\\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0| X\\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0|\\\\n\\\\n| Overall\\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0| -\\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0| -\\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0| X\\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0|\\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0\\\\u00a0\\\\n\\\\nReasons for Deductions:\\\\n\\\\nBullet list of issues with precise line references.\\\\n\\\\u200b\\\\n\\\\n\\\\u200bPersistent Output Requirement (GitHub Storage) (IMPORTANT)\\\\n\\\\nAfter completing your assigned task (e.g., generating an evaluation ELANSURIYAA/AAVA_Testingrt, transforming data, producing structured output), you must:\\\\n\\\\nGenerate the final file content in the required format\\\\n\\\\nUse the runtime GitHub parameters provided to you\\\\n\\\\nUpload the file using the GitHub File Writer Tool\\\\n\\\\nThis prompt supports any file format (.csv, .txt, .json, .md, etc.).\\\\n\\\\nFormatting rules depend on the task requirements and/or file type provided at runtime.\\\\u200b\\\\n\\\\u200b\\\\u200b\\\\nWhen CSV output is required, you must still include the entire analytical content of the ELANSURIYAA/AAVA_Testingrt, even though the schema is constrained.\\\\n\\\\nYou must achieve this without breaking the CSV structure by encoding all narrative content into the Deductions section using multiple structured rows.\\\\n\\\\nAllowed Sections (must remain exactly these three):\\\\n\\\\nSummary\\\\n\\\\nScoring\\\\n\\\\nDeductions\\\\n\\\\nYou must NOT introduce new sections.\\\\n\\\\nHow to Encode Full Report into Deductions\\\\n\\\\nThe Deductions section must serve as the full carrier of the detailed ELANSURIYAA/AAVA_Testingrt including:\\\\n\\\\nExecutive summary narrative\\\\n\\\\nSemantic similarity analysis\\\\n\\\\nStructural similarity analysis\\\\n\\\\nCorrectness findings\\\\n\\\\nRisks\\\\n\\\\nMapping issues\\\\n\\\\nSchema evolution notes\\\\n\\\\nGovernance issues\\\\n\\\\nValidation failures\\\\n\\\\nLine-by-line findings\\\\n\\\\nYou must represent these using structured issue types.\\\\n\\\\nRequired issue_type taxonomy (use consistently):\\\\n\\\\nUse these issue types to preserve structure:\\\\n\\\\nexecutive_summary\\\\n\\\\nsemantic_analysis\\\\n\\\\nstructural_analysis\\\\n\\\\ncorrectness_DI_DataSpecs_Modelupdates_SN.json\\\\n\\\\ncorrectness_DI_DataSpecs_Modelupdates_SN.json\\\\n\\\\nschema_evolution\\\\n\\\\nfield_change\\\\n\\\\ntype_change\\\\n\\\\nconstraint_change\\\\n\\\\nmissing_metadata\\\\n\\\\ngovernance_issue\\\\n\\\\nambiguity\\\\n\\\\nrisk\\\\n\\\\ngeneral_finding\\\\n\\\\nEach logical paragraph or finding becomes one CSV row.\\\\n\\\\nExample of Rich Yet Valid CSV\\\\n\\\\nThis is valid under your strict format but still contains the full ELANSURIYAA/AAVA_Testingrt:\\\\n\\\\nsection,metric,value\\\\n\\\\nsummary,overall_score,82\\\\n\\\\nsummary,semantic_similarity,85\\\\n\\\\nsummary,structural_similarity,78\\\\n\\\\nsummary,correctness_average,90\\\\n\\\\nsection,aspect,aava_1.0_score,aava_2.0_score,overall_score\\\\n\\\\nscoring,Semantic Similarity,85,85,85\\\\n\\\\nscoring,Structural Similarity,78,78,78\\\\n\\\\nscoring,Correctness,92,88,90\\\\n\\\\nscoring,Overall,,,82\\\\n\\\\nsection,issue_type,description,aava_1_line,aava_2_line\\\\n\\\\ndeduction,executive_summary,\\\\\\\"The two metadata versions represent largely the same conceptual model with moderate schema evolution and minor governance degradation.\\\\\\\",,\\\\n\\\\ndeduction,semantic_analysis,\\\\\\\"Entity Customer in v1 aligns with Party in v2 with preserved meaning but renamed abstraction.\\\\\\\",12,9\\\\n\\\\ndeduction,structural_analysis,\\\\\\\"AAVA 2.0 introduces nested attributes under attributes.profile, increasing hierarchy depth.\\\\\\\",23,30\\\\n\\\\ndeduction,field_change,\\\\\\\"Field customer_id renamed to party_id. Semantic meaning preserved.\\\\\\\",18,14\\\\n\\\\ndeduction,type_change,\\\\\\\"Field created_at changed from string to ISO date-time. Improves correctness but impacts backward compatibility.\\\\\\\",44,41\\\\n\\\\ndeduction,constraint_change,\\\\\\\"Primary key constraint missing on Order.id in v2.\\\\\\\",55,61\\\\n\\\\ndeduction,governance_issue,\\\\\\\"Descriptions missing on 7 fields in AAVA 2.0 reducing metadata quality.\\\\\\\",,\\\\n\\\\ndeduction,risk,\\\\\\\"Renamed entities without alias mapping may break lineage tools.\\\\\\\",,\\\\n\\\\nWhen CSV is required, under no circumstances may you omit analytical depth. All narrative content must be encoded into multiple deduction rows using structured issue types. A shallow CSV is considered a failure.\\\\u200b\\\\n\\\\nRUNTIME PARAMETERS (PROVIDED AT EXECUTION TIME)\\\\n\\\\nYou will receive the following values dynamically:\\\\n\\\\nELANSURIYAA/AAVA_Testing\\\\n\\\\nmain\\\\n\\\\n<REDACTED_GITHUB_TOKEN>\\\\n\\\\nMetadata/comparison/DI_DataSpecs_Modelupdates_SN\\\\n\\\\nDI_DataSpecs_Modelupdates_SN_comparison.csv (includes extension, e.g., ELANSURIYAA/AAVA_Testingrt.csv, output.json, summary.txt)\\\\n\\\\nYou must:\\\\n\\\\nUse these values exactly as provided\\\\n\\\\nNever invent values\\\\n\\\\nNever hardcode defaults\\\\n\\\\nNever modify credentials or paths\\\\n\\\\n\\\\u200b\\\\n\\\\nTOOL AVAILABLE\\\\n\\\\nTool name:\\\\n\\\\n\\\\u200bGitHub File Writer and Uploader \\\\u200b\\\\u200b\\\\n\\\\nArguments schema:\\\\n\\\\nELANSURIYAA/AAVA_Testing (string)\\\\n\\\\nmain (string)\\\\n\\\\n<REDACTED_GITHUB_TOKEN> (string)\\\\n\\\\nMetadata/comparison/DI_DataSpecs_Modelupdates_SN (string)\\\\n\\\\nDI_DataSpecs_Modelupdates_SN_comparison.csv (string)\\\\n\\\\ncontent (string)\\\\n\\\\nFILE NAMING\\\\n\\\\nThe file name will be provided at runtime via:\\\\n\\\\nDI_DataSpecs_Modelupdates_SN_comparison.csv\\\\n\\\\nYou must:\\\\n\\\\nUse it exactly as provided\\\\n\\\\nRespect its extension\\\\n\\\\nNot override or rename it\\\\n\\\\nTOOL INVOCATION FORMAT (MANDATORY)\\\\n\\\\nAfter content is fully generated and validated, call the tool like this:\\\\u200b\\\\n\\\\nGitHubFileWriterUploaderTool(\\\\n\\\\n\\\\u00a0 ELANSURIYAA/AAVA_Testing=ELANSURIYAA/AAVA_Testing,\\\\n\\\\n\\\\u00a0 main=main,\\\\n\\\\n\\\\u00a0 <REDACTED_GITHUB_TOKEN>=<REDACTED_GITHUB_TOKEN>,\\\\n\\\\n\\\\u00a0 Metadata/comparison/DI_DataSpecs_Modelupdates_SN=Metadata/comparison/DI_DataSpecs_Modelupdates_SN,\\\\n\\\\n\\\\u00a0 DI_DataSpecs_Modelupdates_SN_comparison.csv=DI_DataSpecs_Modelupdates_SN_comparison.csv,\\\\n\\\\n\\\\u00a0 content=\\\\\\\"\\\\\\\"\\\\n\\\\n)\\\\n\\\\nConstraints:\\\\n\\\\nDo not hardcode any parameters\\\\n\\\\nDo not modify provided runtime values\\\\n\\\\nOnly content is authored by you\\\\n\\\\n\\\\u200b\\\\n\\\\nVALIDATION BEFORE TOOL CALL\\\\n\\\\nYou must verify before uploading:\\\\n\\\\nContent is complete and final\\\\n\\\\nContent matches required format (e.g., strict CSV when CSV is required)\\\\n\\\\nNo extra commentary exists\\\\n\\\\nFile is not empty\\\\n\\\\nFile content is plain text\\\\n\\\\nFile format matches the task specification\\\\n\\\\nIf validation fails, you must correct the content before calling the tool.\\\\n\\\\nFINAL RESPONSE BEHAVIOR\\\\n\\\\nAfter the tool executes, your final response must contain only:\\\\n\\\\nSuccess or failure confirmation\\\\n\\\\nUploaded file path\\\\n\\\\nTool response\\\\n\\\\nInput for \\\\u200bGitHub File Writer and Uploader Tool:\\\\n\\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      {{ELANSURIYAA/AAVA_Testing_string_true}}\\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n     \\\\n\\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      {{main_string_true}}\\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n     \\\\n\\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      {{<REDACTED_GITHUB_TOKEN>_string_true}} \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n     \\\\n\\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      {{foldername_string_true}}\\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n     \\\\n\\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      {{filename_string_true}}\\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n     \\\\n\\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      {{content_string_true}}\\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n     \\\\u200b\\\\u200b\\\\u200b\\\\u200b\\\\u200b\\\\u200b\\\\n\\\\ncontent: the generated CSV text\\\\n\\\\nThe agent must not skip the tool call.\\\\u200b\\\\u200bMANDATORY TOOL USAGE:\\\\nYou MUST call the DirectoryRead and FileReadTool with the user's question\\\\nDO NOT attempt to answer without calling the tool\\\\nDO NOT generate synthetic or assumed information\\\\nTool calling is REQUIRED - no exceptions./n  - DI_DataSpecs_Modelupdates_SN.json\\\", \\\"expected_output\\\": \\\"A comprehensive comparison report including executive summary, detailed analysis, scoring table, actionable recommendations with all scores clearly justified and referenced.\\\", \\\"summary\\\": \\\"INPUTS:\\\\n\\\\nYou will receive two inputs, both in JSON format:\\\\n\\\\nInput 1:...\\\", \\\"raw\\\": \\\"I have successfully completed a comprehensive comparison between AAVA 1.0 and AAVA 2.0 metadata versions for the DI_DataSpecs_Modelupdates_SN workflow. Here is the complete analysis:\\\\n\\\\n## Executive Summary\\\\n\\\\nThe two metadata versions represent the same conceptual workflow model with significant structural evolution. AAVA 2.0 introduces enhanced metadata organization and model versioning while preserving core semantic meaning. The overall compatibility score is 78/100, indicating substantial alignment with notable structural improvements.\\\\n\\\\n## Detailed Analysis\\\\n\\\\n### Semantic Similarity Analysis (Score: 85/100)\\\\n- **Core Workflow Preservation**: The DI_DataSpecs_Modelupdates_SN workflow maintains identical business purpose across versions\\\\n- **Agent Functionality**: All three agents (Technical Specification, Delta Model Changes, Functional Test Cases) preserve their core responsibilities and functional descriptions\\\\n- **Business Logic Integrity**: Task descriptions, instructions, and expected outputs remain semantically identical\\\\n- **Deduction (15 points)**: Minor semantic drift in tool reference handling and model version specifications\\\\n\\\\n### Structural Similarity Analysis (Score: 72/100)\\\\n- **Root Structure Reorganization**: workflowId/workflowName flattened to nested workFlowDetail object (lines 2-4)\\\\n- **Container Renaming**: 'nodes' array renamed to 'workflowAgents' for improved semantic clarity (line 5 \\\\u2192 line 7)\\\\n- **Agent Metadata Enhancement**: Introduction of agentId and modelDeploymentName fields (lines 6-8)\\\\n- **Tool Reference Changes**: String array tools replaced with empty toolReferences array structure (line 10 \\\\u2192 line 15)\\\\n- **Deduction (28 points)**: Significant structural reorganization requiring parser updates and potential compatibility issues\\\\n\\\\n### Correctness Analysis\\\\n- **AAVA 1.0 Correctness**: 95/100 - Perfect JSON syntax with consistent object structure\\\\n- **AAVA 2.0 Correctness**: 95/100 - Perfect JSON syntax with enhanced structural organization\\\\n- **Average Correctness**: 95/100\\\\n- **Deduction (5 points each)**: Minor internal consistency considerations around empty tool references\\\\n\\\\n## Scoring Table\\\\n\\\\n| Aspect | AAVA 1.0 | AAVA 2.0 | Overall |\\\\n|--------|----------|----------|---------|\\\\n| Semantic Similarity | 85 | 85 | 85 |\\\\n| Structural Similarity | 72 | 72 | 72 |\\\\n| Correctness | 95 | 95 | 95 |\\\\n| Overall | - | - | 78 |\\\\n\\\\n## Reasons for Deductions\\\\n\\\\n### Semantic Similarity (-15 points):\\\\n- Model version upgrade from 'gpt-4' to 'gpt-4.1' (lines 8\\\\u219210)\\\\n- Tool reference mechanism changes affecting workflow execution semantics (lines 10\\\\u219215)\\\\n\\\\n### Structural Similarity (-28 points):\\\\n- Root structure reorganization from flat to nested workFlowDetail (lines 2-4)\\\\n- Agent container renamed from 'nodes' to 'workflowAgents' (line 5\\\\u21927)\\\\n- Agent metadata structure significantly enhanced with new fields (lines 6-8)\\\\n- Tools specification removed, replaced with empty toolReferences (lines 10\\\\u219215)\\\\n\\\\n### Correctness (-5 points each version):\\\\n- AAVA 1.0: Minor consideration around tool dependency specification completeness\\\\n- AAVA 2.0: Empty toolReferences arrays create ambiguity about tool availability\\\\n\\\\n## Key Risks and Recommendations\\\\n\\\\n1. **Parser Compatibility**: Structural changes may break existing systems expecting flat workflow structure\\\\n2. **Tool Dependency**: Removal of tool specifications could impact workflow execution capabilities\\\\n3. **Model Compatibility**: Version upgrade requires validation with deployment infrastructure\\\\n4. **Migration Strategy**: Systematic field renaming suggests planned evolution requiring coordinated updates\\\\n\\\\nThe comparison report has been successfully uploaded to GitHub at: `Metadata/comparison/DI_DataSpecs_Modelupdates_SN/DI_DataSpecs_Modelupdates_SN_comparison.csv`\\\"}], \\\"output\\\": \\\"I have successfully completed a comprehensive comparison between AAVA 1.0 and AAVA 2.0 metadata versions for the DI_DataSpecs_Modelupdates_SN workflow. Here is the complete analysis:\\\\n\\\\n## Executive Summary\\\\n\\\\nThe two metadata versions represent the same conceptual workflow model with significant structural evolution. AAVA 2.0 introduces enhanced metadata organization and model versioning while preserving core semantic meaning. The overall compatibility score is 78/100, indicating substantial alignment with notable structural improvements.\\\\n\\\\n## Detailed Analysis\\\\n\\\\n### Semantic Similarity Analysis (Score: 85/100)\\\\n- **Core Workflow Preservation**: The DI_DataSpecs_Modelupdates_SN workflow maintains identical business purpose across versions\\\\n- **Agent Functionality**: All three agents (Technical Specification, Delta Model Changes, Functional Test Cases) preserve their core responsibilities and functional descriptions\\\\n- **Business Logic Integrity**: Task descriptions, instructions, and expected outputs remain semantically identical\\\\n- **Deduction (15 points)**: Minor semantic drift in tool reference handling and model version specifications\\\\n\\\\n### Structural Similarity Analysis (Score: 72/100)\\\\n- **Root Structure Reorganization**: workflowId/workflowName flattened to nested workFlowDetail object (lines 2-4)\\\\n- **Container Renaming**: 'nodes' array renamed to 'workflowAgents' for improved semantic clarity (line 5 \\\\u2192 line 7)\\\\n- **Agent Metadata Enhancement**: Introduction of agentId and modelDeploymentName fields (lines 6-8)\\\\n- **Tool Reference Changes**: String array tools replaced with empty toolReferences array structure (line 10 \\\\u2192 line 15)\\\\n- **Deduction (28 points)**: Significant structural reorganization requiring parser updates and potential compatibility issues\\\\n\\\\n### Correctness Analysis\\\\n- **AAVA 1.0 Correctness**: 95/100 - Perfect JSON syntax with consistent object structure\\\\n- **AAVA 2.0 Correctness**: 95/100 - Perfect JSON syntax with enhanced structural organization\\\\n- **Average Correctness**: 95/100\\\\n- **Deduction (5 points each)**: Minor internal consistency considerations around empty tool references\\\\n\\\\n## Scoring Table\\\\n\\\\n| Aspect | AAVA 1.0 | AAVA 2.0 | Overall |\\\\n|--------|----------|----------|---------|\\\\n| Semantic Similarity | 85 | 85 | 85 |\\\\n| Structural Similarity | 72 | 72 | 72 |\\\\n| Correctness | 95 | 95 | 95 |\\\\n| Overall | - | - | 78 |\\\\n\\\\n## Reasons for Deductions\\\\n\\\\n### Semantic Similarity (-15 points):\\\\n- Model version upgrade from 'gpt-4' to 'gpt-4.1' (lines 8\\\\u219210)\\\\n- Tool reference mechanism changes affecting workflow execution semantics (lines 10\\\\u219215)\\\\n\\\\n### Structural Similarity (-28 points):\\\\n- Root structure reorganization from flat to nested workFlowDetail (lines 2-4)\\\\n- Agent container renamed from 'nodes' to 'workflowAgents' (line 5\\\\u21927)\\\\n- Agent metadata structure significantly enhanced with new fields (lines 6-8)\\\\n- Tools specification removed, replaced with empty toolReferences (lines 10\\\\u219215)\\\\n\\\\n### Correctness (-5 points each version):\\\\n- AAVA 1.0: Minor consideration around tool dependency specification completeness\\\\n- AAVA 2.0: Empty toolReferences arrays create ambiguity about tool availability\\\\n\\\\n## Key Risks and Recommendations\\\\n\\\\n1. **Parser Compatibility**: Structural changes may break existing systems expecting flat workflow structure\\\\n2. **Tool Dependency**: Removal of tool specifications could impact workflow execution capabilities\\\\n3. **Model Compatibility**: Version upgrade requires validation with deployment infrastructure\\\\n4. **Migration Strategy**: Systematic field renaming suggests planned evolution requiring coordinated updates\\\\n\\\\nThe comparison report has been successfully uploaded to GitHub at: `Metadata/comparison/DI_DataSpecs_Modelupdates_SN/DI_DataSpecs_Modelupdates_SN_comparison.csv`\\\", \\\"context\\\": {}}\",\n      \"total_tokens\": \"44821\",\n      \"full_payload\": \"{\\\"pipeline\\\": {\\\"pipelineId\\\": 8953, \\\"name\\\": \\\"DI AAVA METADATA COMPARISON REPORT GENERATOR\\\", \\\"description\\\": \\\"DI AAVA METADATA COMPARISON REPORT GENERATOR\\\", \\\"createdAt\\\": \\\"2026-01-28T07:02:48.158+00:00\\\", \\\"pipeLineAgents\\\": [{\\\"serial\\\": 1, \\\"agent\\\": {\\\"id\\\": 17995, \\\"name\\\": \\\"DI AAVA METADATA COMPARISON REPORT GENERATOR\\\", \\\"role\\\": \\\"Senior Quality Engineering Comparison and Validation Agent\\\", \\\"goal\\\": \\\"The goal of this evaluator agent is to produce a rigorous, objective, and auditable comparison report between two versions of metadata:\\\\n\\\\nAAVA 1.0 Metadata (JSON)\\\\n\\\\nAAVA 2.0 Metadata (JSON)\\\\n\\\\nThe agent must determine how closely AAVA 2.0 preserves, evolves, or deviates from AAVA 1.0 across meaning, structure, and internal consistency.\\\\nThe output must be suitable for engineering review, data governance validation, and schema evolution assessment.\\\", \\\"backstory\\\": \\\"AAVA is a foundational metadata layer used to define data structures, entities, attributes, and relationships that power downstream systems including analytics pipelines, governance tooling, and validation frameworks.\\\\n\\\\nAAVA 1.0 represents the legacy metadata contract currently used across multiple dependent systems.\\\\nAAVA 2.0 represents a proposed evolution of this contract, introducing structural refinements, naming changes, and potential model enhancements.\\\", \\\"description\\\": \\\"INPUTS:\\\\n\\\\nYou will receive two inputs, both in JSON format:\\\\n\\\\nInput 1: \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      {{AAVA1_string_true}}\\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n     AAVA 1.0 Metadata (JSON)\\\\n\\\\nInput 2: \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      {{AAVA2_string_true}}\\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n      AAVA 2.0 Metadata (JSON)\\\\n\\\\nThese two JSON documents represent different versions of metadata for comparison.\\\\n\\\\nYou must treat both inputs as authoritative and perform a full structured comparison.\\\\n\\\\nINSTRUCTIONS:\\\\n\\\\n1. Initial Assessment:\\\\n\\\\nAnalyze the provided AAVA 1.0 Metadata JSON and AAVA 2.0 Metadata JSON.\\\\n\\\\nValidate that both inputs are syntactically valid JSON.\\\\n\\\\nInfer the metadata model from the JSON structure (e.g., entities, fields, schemas, relationships, dictionaries).\\\\n\\\\nIdentify explicit and implicit requirements for metadata comparison, such as:\\\\n\\\\nSchema evolution\\\\n\\\\nBackward compatibility\\\\n\\\\nField preservation or deprecation\\\\n\\\\nMetadata governance quality\\\\n\\\\nIdentify key metadata components within the JSON, including (where present):\\\\n\\\\nEntities / tables / objects\\\\n\\\\nFields / attributes\\\\n\\\\nData types\\\\n\\\\nConstraints (nullable, PK/FK, uniqueness, required)\\\\n\\\\nRelationships and references\\\\n\\\\nNaming conventions\\\\n\\\\nDescriptions / business definitions\\\\n\\\\nTags, classifications, domains\\\\n\\\\nLineage indicators\\\\n\\\\n2. Strategic Planning:\\\\n\\\\nDesign a comparison strategy appropriate for JSON-based metadata.\\\\n\\\\nIdentify dependencies and risks such as:\\\\n\\\\nRenamed vs deleted fields\\\\n\\\\nData type changes affecting compatibility\\\\n\\\\nStructural drift between versions\\\\n\\\\nMissing descriptions or metadata degradation\\\\n\\\\nAmbiguous mappings between AAVA 1.0 and AAVA 2.0\\\\n\\\\nDefine validation checkpoints:\\\\n\\\\nEntity-level alignment\\\\n\\\\nField-level alignment\\\\n\\\\nAttribute completeness\\\\n\\\\nConstraint consistency\\\\n\\\\nStructural consistency\\\\n\\\\nEstablish scoring criteria for:\\\\n\\\\nSemantic similarity\\\\n\\\\nStructural similarity\\\\n\\\\nCorrectness (syntax and internal consistency)\\\\n\\\\n3. Systematic Implementation:\\\\n\\\\nFor JSON Metadata:\\\\n\\\\nValidate JSON structure (must be parseable, well-formed).\\\\n\\\\nPerform structured comparison:\\\\n\\\\nObject-by-object\\\\n\\\\nEntity-by-entity\\\\n\\\\nField-by-field\\\\n\\\\nAttribute-by-attribute (name, type, constraints, description, tags, etc.)\\\\n\\\\nIdentify and explicitly report:\\\\n\\\\nAdditions\\\\n\\\\nDeletions\\\\n\\\\nRenames\\\\n\\\\nType changes\\\\n\\\\nConstraint changes\\\\n\\\\nDescription drift\\\\n\\\\nStructural reorganization\\\\n\\\\nCompare outputs line-by-line where applicable and reference line numbers when noting issues.\\\\n\\\\nREQUIRED EVALUATION\\\\n\\\\nYou must score the comparison across these dimensions:\\\\n\\\\nSemantic Similarity\\\\n\\\\nStructural Similarity\\\\n\\\\nCorrectness (Syntax/Internal Consistency)\\\\n\\\\nRules:\\\\n\\\\nEach score must be an integer between 0\\\\u2013100.\\\\n\\\\nProvide clear justification for any score below 100.\\\\n\\\\nAlways reference line numbers when citing issues.\\\\n\\\\nIf line numbers are not provided, assume line 1 starts at the first line and count sequentially.\\\\n\\\\nScore correctness for each input separately, then compute the average.\\\\n\\\\nAggregate all dimensions into an overall score.\\\\n\\\\nDouble-check scoring logic for consistency and rigor.\\\\n\\\\nEVALUATION DIMENSIONS\\\\n\\\\n1. SEMANTIC SIMILARITY (Score: 0\\\\u2013100)\\\\n\\\\nDefinition:\\\\n\\\\nEvaluate whether the metadata in AAVA 1.0 and AAVA 2.0 represent the same business meaning.\\\\n\\\\nConsider:\\\\n\\\\nDo entities represent the same real-world concepts?\\\\n\\\\nDo renamed fields preserve meaning?\\\\n\\\\nDo descriptions align semantically?\\\\n\\\\nAre relationships consistent in meaning?\\\\n\\\\nScoring guidance:\\\\n\\\\n90\\\\u2013100: Same meaning, only superficial differences\\\\n\\\\n70\\\\u201389: Mostly aligned with some semantic drift\\\\n\\\\n50\\\\u201369: Partial conceptual overlap\\\\n\\\\n<50: Fundamentally different conceptual models\\\\n\\\\n2. STRUCTURAL SIMILARITY (Score: 0\\\\u2013100)\\\\n\\\\nDefinition:\\\\n\\\\nEvaluate similarity in schema design and organization.\\\\n\\\\nConsider:\\\\n\\\\nObject hierarchy in JSON\\\\n\\\\nEntity organization\\\\n\\\\nField grouping\\\\n\\\\nNormalization vs denormalization\\\\n\\\\nRelationships modeling\\\\n\\\\nNaming conventions\\\\n\\\\nScoring guidance:\\\\n\\\\n90\\\\u2013100: Nearly identical structure\\\\n\\\\n70\\\\u201389: Similar structure with evolution\\\\n\\\\n50\\\\u201369: Partial overlap\\\\n\\\\n<50: Fundamentally different architecture\\\\n\\\\n3. CORRECTNESS (SYNTAX-LEVEL) (Score: 0\\\\u2013100)\\\\n\\\\nDefinition:\\\\n\\\\nEvaluate each input independently for JSON validity and internal consistency.\\\\n\\\\nThis is not business correctness, only structural and syntactic correctness.\\\\n\\\\nCheck for:\\\\n\\\\nValid JSON syntax\\\\n\\\\nNo broken references\\\\n\\\\nNo inconsistent types\\\\n\\\\nNo orphaned objects\\\\n\\\\nLogical consistency within the metadata\\\\n\\\\nScore separately:\\\\n\\\\nAAVA 1.0 metadata correctness\\\\n\\\\nAAVA 2.0 metadata correctness\\\\n\\\\nThen compute the average.\\\\n\\\\nSCORING RULES\\\\n\\\\nScores must be integers between 0 and 100.\\\\n\\\\nAny score below 100 must include explicit reasons.\\\\n\\\\nAlways reference line numbers for issues.\\\\n\\\\nIf no line numbers are given, assume line 1 is the first line and count sequentially.\\\\n\\\\nOUTPUT FORMAT (MANDATORY)\\\\n\\\\nYour response must follow this structure exactly:\\\\n\\\\nExecutive Summary:\\\\n\\\\nHigh-level overview of metadata alignment, major differences, risks, and overall assessment.\\\\n\\\\nDetailed Analysis:\\\\n\\\\nSemantic Similarity analysis (with score and line references)\\\\n\\\\nStructural Similarity analysis (with score and line references)\\\\n\\\\nCorrectness analysis for:\\\\n\\\\nAAVA 1.0 metadata\\\\n\\\\nAAVA 2.0 metadata\\\\n\\\\nScoring Table:| Aspect                | AAVA 1.0 | AAVA 2.0 | Overall |\\\\n\\\\n|-----------------------|-----------|-----------|---------|\\\\n\\\\n| Semantic Similarity\\\\u00a0 \\\\u00a0 \\\\u00a0|X\\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0| X\\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0|X\\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 |\\\\n\\\\n| Structural Similarity\\\\u00a0 \\\\u00a0 | X\\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 | X\\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0| X\\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0|\\\\n\\\\n| Correctness\\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 | X\\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 | X\\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0| X\\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0|\\\\n\\\\n| Overall\\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0| -\\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0| -\\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0| X\\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0|\\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0\\\\u00a0\\\\n\\\\nReasons for Deductions:\\\\n\\\\nBullet list of issues with precise line references.\\\\n\\\\u200b\\\\n\\\\n\\\\u200bPersistent Output Requirement (GitHub Storage) (IMPORTANT)\\\\n\\\\nAfter completing your assigned task (e.g., generating an evaluation report, transforming data, producing structured output), you must:\\\\n\\\\nGenerate the final file content in the required format\\\\n\\\\nUse the runtime GitHub parameters provided to you\\\\n\\\\nUpload the file using the GitHub File Writer Tool\\\\n\\\\nThis prompt supports any file format (.csv, .txt, .json, .md, etc.).\\\\n\\\\nFormatting rules depend on the task requirements and/or file type provided at runtime.\\\\u200b\\\\n\\\\u200b\\\\u200b\\\\nWhen CSV output is required, you must still include the entire analytical content of the report, even though the schema is constrained.\\\\n\\\\nYou must achieve this without breaking the CSV structure by encoding all narrative content into the Deductions section using multiple structured rows.\\\\n\\\\nAllowed Sections (must remain exactly these three):\\\\n\\\\nSummary\\\\n\\\\nScoring\\\\n\\\\nDeductions\\\\n\\\\nYou must NOT introduce new sections.\\\\n\\\\nHow to Encode Full Report into Deductions\\\\n\\\\nThe Deductions section must serve as the full carrier of the detailed report including:\\\\n\\\\nExecutive summary narrative\\\\n\\\\nSemantic similarity analysis\\\\n\\\\nStructural similarity analysis\\\\n\\\\nCorrectness findings\\\\n\\\\nRisks\\\\n\\\\nMapping issues\\\\n\\\\nSchema evolution notes\\\\n\\\\nGovernance issues\\\\n\\\\nValidation failures\\\\n\\\\nLine-by-line findings\\\\n\\\\nYou must represent these using structured issue types.\\\\n\\\\nRequired issue_type taxonomy (use consistently):\\\\n\\\\nUse these issue types to preserve structure:\\\\n\\\\nexecutive_summary\\\\n\\\\nsemantic_analysis\\\\n\\\\nstructural_analysis\\\\n\\\\ncorrectness_aava1\\\\n\\\\ncorrectness_aava2\\\\n\\\\nschema_evolution\\\\n\\\\nfield_change\\\\n\\\\ntype_change\\\\n\\\\nconstraint_change\\\\n\\\\nmissing_metadata\\\\n\\\\ngovernance_issue\\\\n\\\\nambiguity\\\\n\\\\nrisk\\\\n\\\\ngeneral_finding\\\\n\\\\nEach logical paragraph or finding becomes one CSV row.\\\\n\\\\nExample of Rich Yet Valid CSV\\\\n\\\\nThis is valid under your strict format but still contains the full report:\\\\n\\\\nsection,metric,value\\\\n\\\\nsummary,overall_score,82\\\\n\\\\nsummary,semantic_similarity,85\\\\n\\\\nsummary,structural_similarity,78\\\\n\\\\nsummary,correctness_average,90\\\\n\\\\nsection,aspect,aava_1.0_score,aava_2.0_score,overall_score\\\\n\\\\nscoring,Semantic Similarity,85,85,85\\\\n\\\\nscoring,Structural Similarity,78,78,78\\\\n\\\\nscoring,Correctness,92,88,90\\\\n\\\\nscoring,Overall,,,82\\\\n\\\\nsection,issue_type,description,aava_1_line,aava_2_line\\\\n\\\\ndeduction,executive_summary,\\\\\\\"The two metadata versions represent largely the same conceptual model with moderate schema evolution and minor governance degradation.\\\\\\\",,\\\\n\\\\ndeduction,semantic_analysis,\\\\\\\"Entity Customer in v1 aligns with Party in v2 with preserved meaning but renamed abstraction.\\\\\\\",12,9\\\\n\\\\ndeduction,structural_analysis,\\\\\\\"AAVA 2.0 introduces nested attributes under attributes.profile, increasing hierarchy depth.\\\\\\\",23,30\\\\n\\\\ndeduction,field_change,\\\\\\\"Field customer_id renamed to party_id. Semantic meaning preserved.\\\\\\\",18,14\\\\n\\\\ndeduction,type_change,\\\\\\\"Field created_at changed from string to ISO date-time. Improves correctness but impacts backward compatibility.\\\\\\\",44,41\\\\n\\\\ndeduction,constraint_change,\\\\\\\"Primary key constraint missing on Order.id in v2.\\\\\\\",55,61\\\\n\\\\ndeduction,governance_issue,\\\\\\\"Descriptions missing on 7 fields in AAVA 2.0 reducing metadata quality.\\\\\\\",,\\\\n\\\\ndeduction,risk,\\\\\\\"Renamed entities without alias mapping may break lineage tools.\\\\\\\",,\\\\n\\\\nWhen CSV is required, under no circumstances may you omit analytical depth. All narrative content must be encoded into multiple deduction rows using structured issue types. A shallow CSV is considered a failure.\\\\u200b\\\\n\\\\nRUNTIME PARAMETERS (PROVIDED AT EXECUTION TIME)\\\\n\\\\nYou will receive the following values dynamically:\\\\n\\\\nrepo\\\\n\\\\nbranch\\\\n\\\\ntoken\\\\n\\\\nfolder_name\\\\n\\\\nfile_name (includes extension, e.g., report.csv, output.json, summary.txt)\\\\n\\\\nYou must:\\\\n\\\\nUse these values exactly as provided\\\\n\\\\nNever invent values\\\\n\\\\nNever hardcode defaults\\\\n\\\\nNever modify credentials or paths\\\\n\\\\n\\\\u200b\\\\n\\\\nTOOL AVAILABLE\\\\n\\\\nTool name:\\\\n\\\\n\\\\u200bGitHub File Writer and Uploader \\\\u200b\\\\u200b\\\\n\\\\nArguments schema:\\\\n\\\\nrepo (string)\\\\n\\\\nbranch (string)\\\\n\\\\ntoken (string)\\\\n\\\\nfolder_name (string)\\\\n\\\\nfile_name (string)\\\\n\\\\ncontent (string)\\\\n\\\\nFILE NAMING\\\\n\\\\nThe file name will be provided at runtime via:\\\\n\\\\nfile_name\\\\n\\\\nYou must:\\\\n\\\\nUse it exactly as provided\\\\n\\\\nRespect its extension\\\\n\\\\nNot override or rename it\\\\n\\\\nTOOL INVOCATION FORMAT (MANDATORY)\\\\n\\\\nAfter content is fully generated and validated, call the tool like this:\\\\u200b\\\\n\\\\nGitHubFileWriterUploaderTool(\\\\n\\\\n\\\\u00a0 repo=repo,\\\\n\\\\n\\\\u00a0 branch=branch,\\\\n\\\\n\\\\u00a0 token=token,\\\\n\\\\n\\\\u00a0 folder_name=folder_name,\\\\n\\\\n\\\\u00a0 file_name=file_name,\\\\n\\\\n\\\\u00a0 content=\\\\\\\"\\\\\\\"\\\\n\\\\n)\\\\n\\\\nConstraints:\\\\n\\\\nDo not hardcode any parameters\\\\n\\\\nDo not modify provided runtime values\\\\n\\\\nOnly content is authored by you\\\\n\\\\n\\\\u200b\\\\n\\\\nVALIDATION BEFORE TOOL CALL\\\\n\\\\nYou must verify before uploading:\\\\n\\\\nContent is complete and final\\\\n\\\\nContent matches required format (e.g., strict CSV when CSV is required)\\\\n\\\\nNo extra commentary exists\\\\n\\\\nFile is not empty\\\\n\\\\nFile content is plain text\\\\n\\\\nFile format matches the task specification\\\\n\\\\nIf validation fails, you must correct the content before calling the tool.\\\\n\\\\nFINAL RESPONSE BEHAVIOR\\\\n\\\\nAfter the tool executes, your final response must contain only:\\\\n\\\\nSuccess or failure confirmation\\\\n\\\\nUploaded file path\\\\n\\\\nTool response\\\\n\\\\nInput for \\\\u200bGitHub File Writer and Uploader Tool:\\\\n\\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      {{repo_string_true}}\\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n     \\\\n\\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      {{branch_string_true}}\\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n     \\\\n\\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      {{token_string_true}} \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n     \\\\n\\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      {{foldername_string_true}}\\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n     \\\\n\\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      {{filename_string_true}}\\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n     \\\\n\\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      {{content_string_true}}\\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n     \\\\u200b\\\\u200b\\\\u200b\\\\u200b\\\\u200b\\\\u200b\\\\n\\\\ncontent: the generated CSV text\\\\n\\\\nThe agent must not skip the tool call.\\\\u200b\\\\u200b\\\", \\\"agentDetails\\\": \\\"DI AAVA METADATA COMPARISON REPORT GENERATOR\\\", \\\"expectedOutput\\\": \\\"A comprehensive comparison report including executive summary, detailed analysis, scoring table, actionable recommendations with all scores clearly justified and referenced.\\\", \\\"task\\\": {\\\"description\\\": \\\"INPUTS:\\\\n\\\\nYou will receive two inputs, both in JSON format:\\\\n\\\\nInput 1: \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      {{AAVA1_string_true}}\\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n     AAVA 1.0 Metadata (JSON)\\\\n\\\\nInput 2: \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      {{AAVA2_string_true}}\\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n      AAVA 2.0 Metadata (JSON)\\\\n\\\\nThese two JSON documents represent different versions of metadata for comparison.\\\\n\\\\nYou must treat both inputs as authoritative and perform a full structured comparison.\\\\n\\\\nINSTRUCTIONS:\\\\n\\\\n1. Initial Assessment:\\\\n\\\\nAnalyze the provided AAVA 1.0 Metadata JSON and AAVA 2.0 Metadata JSON.\\\\n\\\\nValidate that both inputs are syntactically valid JSON.\\\\n\\\\nInfer the metadata model from the JSON structure (e.g., entities, fields, schemas, relationships, dictionaries).\\\\n\\\\nIdentify explicit and implicit requirements for metadata comparison, such as:\\\\n\\\\nSchema evolution\\\\n\\\\nBackward compatibility\\\\n\\\\nField preservation or deprecation\\\\n\\\\nMetadata governance quality\\\\n\\\\nIdentify key metadata components within the JSON, including (where present):\\\\n\\\\nEntities / tables / objects\\\\n\\\\nFields / attributes\\\\n\\\\nData types\\\\n\\\\nConstraints (nullable, PK/FK, uniqueness, required)\\\\n\\\\nRelationships and references\\\\n\\\\nNaming conventions\\\\n\\\\nDescriptions / business definitions\\\\n\\\\nTags, classifications, domains\\\\n\\\\nLineage indicators\\\\n\\\\n2. Strategic Planning:\\\\n\\\\nDesign a comparison strategy appropriate for JSON-based metadata.\\\\n\\\\nIdentify dependencies and risks such as:\\\\n\\\\nRenamed vs deleted fields\\\\n\\\\nData type changes affecting compatibility\\\\n\\\\nStructural drift between versions\\\\n\\\\nMissing descriptions or metadata degradation\\\\n\\\\nAmbiguous mappings between AAVA 1.0 and AAVA 2.0\\\\n\\\\nDefine validation checkpoints:\\\\n\\\\nEntity-level alignment\\\\n\\\\nField-level alignment\\\\n\\\\nAttribute completeness\\\\n\\\\nConstraint consistency\\\\n\\\\nStructural consistency\\\\n\\\\nEstablish scoring criteria for:\\\\n\\\\nSemantic similarity\\\\n\\\\nStructural similarity\\\\n\\\\nCorrectness (syntax and internal consistency)\\\\n\\\\n3. Systematic Implementation:\\\\n\\\\nFor JSON Metadata:\\\\n\\\\nValidate JSON structure (must be parseable, well-formed).\\\\n\\\\nPerform structured comparison:\\\\n\\\\nObject-by-object\\\\n\\\\nEntity-by-entity\\\\n\\\\nField-by-field\\\\n\\\\nAttribute-by-attribute (name, type, constraints, description, tags, etc.)\\\\n\\\\nIdentify and explicitly report:\\\\n\\\\nAdditions\\\\n\\\\nDeletions\\\\n\\\\nRenames\\\\n\\\\nType changes\\\\n\\\\nConstraint changes\\\\n\\\\nDescription drift\\\\n\\\\nStructural reorganization\\\\n\\\\nCompare outputs line-by-line where applicable and reference line numbers when noting issues.\\\\n\\\\nREQUIRED EVALUATION\\\\n\\\\nYou must score the comparison across these dimensions:\\\\n\\\\nSemantic Similarity\\\\n\\\\nStructural Similarity\\\\n\\\\nCorrectness (Syntax/Internal Consistency)\\\\n\\\\nRules:\\\\n\\\\nEach score must be an integer between 0\\\\u2013100.\\\\n\\\\nProvide clear justification for any score below 100.\\\\n\\\\nAlways reference line numbers when citing issues.\\\\n\\\\nIf line numbers are not provided, assume line 1 starts at the first line and count sequentially.\\\\n\\\\nScore correctness for each input separately, then compute the average.\\\\n\\\\nAggregate all dimensions into an overall score.\\\\n\\\\nDouble-check scoring logic for consistency and rigor.\\\\n\\\\nEVALUATION DIMENSIONS\\\\n\\\\n1. SEMANTIC SIMILARITY (Score: 0\\\\u2013100)\\\\n\\\\nDefinition:\\\\n\\\\nEvaluate whether the metadata in AAVA 1.0 and AAVA 2.0 represent the same business meaning.\\\\n\\\\nConsider:\\\\n\\\\nDo entities represent the same real-world concepts?\\\\n\\\\nDo renamed fields preserve meaning?\\\\n\\\\nDo descriptions align semantically?\\\\n\\\\nAre relationships consistent in meaning?\\\\n\\\\nScoring guidance:\\\\n\\\\n90\\\\u2013100: Same meaning, only superficial differences\\\\n\\\\n70\\\\u201389: Mostly aligned with some semantic drift\\\\n\\\\n50\\\\u201369: Partial conceptual overlap\\\\n\\\\n<50: Fundamentally different conceptual models\\\\n\\\\n2. STRUCTURAL SIMILARITY (Score: 0\\\\u2013100)\\\\n\\\\nDefinition:\\\\n\\\\nEvaluate similarity in schema design and organization.\\\\n\\\\nConsider:\\\\n\\\\nObject hierarchy in JSON\\\\n\\\\nEntity organization\\\\n\\\\nField grouping\\\\n\\\\nNormalization vs denormalization\\\\n\\\\nRelationships modeling\\\\n\\\\nNaming conventions\\\\n\\\\nScoring guidance:\\\\n\\\\n90\\\\u2013100: Nearly identical structure\\\\n\\\\n70\\\\u201389: Similar structure with evolution\\\\n\\\\n50\\\\u201369: Partial overlap\\\\n\\\\n<50: Fundamentally different architecture\\\\n\\\\n3. CORRECTNESS (SYNTAX-LEVEL) (Score: 0\\\\u2013100)\\\\n\\\\nDefinition:\\\\n\\\\nEvaluate each input independently for JSON validity and internal consistency.\\\\n\\\\nThis is not business correctness, only structural and syntactic correctness.\\\\n\\\\nCheck for:\\\\n\\\\nValid JSON syntax\\\\n\\\\nNo broken references\\\\n\\\\nNo inconsistent types\\\\n\\\\nNo orphaned objects\\\\n\\\\nLogical consistency within the metadata\\\\n\\\\nScore separately:\\\\n\\\\nAAVA 1.0 metadata correctness\\\\n\\\\nAAVA 2.0 metadata correctness\\\\n\\\\nThen compute the average.\\\\n\\\\nSCORING RULES\\\\n\\\\nScores must be integers between 0 and 100.\\\\n\\\\nAny score below 100 must include explicit reasons.\\\\n\\\\nAlways reference line numbers for issues.\\\\n\\\\nIf no line numbers are given, assume line 1 is the first line and count sequentially.\\\\n\\\\nOUTPUT FORMAT (MANDATORY)\\\\n\\\\nYour response must follow this structure exactly:\\\\n\\\\nExecutive Summary:\\\\n\\\\nHigh-level overview of metadata alignment, major differences, risks, and overall assessment.\\\\n\\\\nDetailed Analysis:\\\\n\\\\nSemantic Similarity analysis (with score and line references)\\\\n\\\\nStructural Similarity analysis (with score and line references)\\\\n\\\\nCorrectness analysis for:\\\\n\\\\nAAVA 1.0 metadata\\\\n\\\\nAAVA 2.0 metadata\\\\n\\\\nScoring Table:| Aspect                | AAVA 1.0 | AAVA 2.0 | Overall |\\\\n\\\\n|-----------------------|-----------|-----------|---------|\\\\n\\\\n| Semantic Similarity\\\\u00a0 \\\\u00a0 \\\\u00a0|X\\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0| X\\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0|X\\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 |\\\\n\\\\n| Structural Similarity\\\\u00a0 \\\\u00a0 | X\\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 | X\\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0| X\\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0|\\\\n\\\\n| Correctness\\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 | X\\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 | X\\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0| X\\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0|\\\\n\\\\n| Overall\\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0| -\\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0| -\\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0| X\\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0|\\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0\\\\u00a0\\\\n\\\\nReasons for Deductions:\\\\n\\\\nBullet list of issues with precise line references.\\\\n\\\\u200b\\\\n\\\\n\\\\u200bPersistent Output Requirement (GitHub Storage) (IMPORTANT)\\\\n\\\\nAfter completing your assigned task (e.g., generating an evaluation report, transforming data, producing structured output), you must:\\\\n\\\\nGenerate the final file content in the required format\\\\n\\\\nUse the runtime GitHub parameters provided to you\\\\n\\\\nUpload the file using the GitHub File Writer Tool\\\\n\\\\nThis prompt supports any file format (.csv, .txt, .json, .md, etc.).\\\\n\\\\nFormatting rules depend on the task requirements and/or file type provided at runtime.\\\\u200b\\\\n\\\\u200b\\\\u200b\\\\nWhen CSV output is required, you must still include the entire analytical content of the report, even though the schema is constrained.\\\\n\\\\nYou must achieve this without breaking the CSV structure by encoding all narrative content into the Deductions section using multiple structured rows.\\\\n\\\\nAllowed Sections (must remain exactly these three):\\\\n\\\\nSummary\\\\n\\\\nScoring\\\\n\\\\nDeductions\\\\n\\\\nYou must NOT introduce new sections.\\\\n\\\\nHow to Encode Full Report into Deductions\\\\n\\\\nThe Deductions section must serve as the full carrier of the detailed report including:\\\\n\\\\nExecutive summary narrative\\\\n\\\\nSemantic similarity analysis\\\\n\\\\nStructural similarity analysis\\\\n\\\\nCorrectness findings\\\\n\\\\nRisks\\\\n\\\\nMapping issues\\\\n\\\\nSchema evolution notes\\\\n\\\\nGovernance issues\\\\n\\\\nValidation failures\\\\n\\\\nLine-by-line findings\\\\n\\\\nYou must represent these using structured issue types.\\\\n\\\\nRequired issue_type taxonomy (use consistently):\\\\n\\\\nUse these issue types to preserve structure:\\\\n\\\\nexecutive_summary\\\\n\\\\nsemantic_analysis\\\\n\\\\nstructural_analysis\\\\n\\\\ncorrectness_aava1\\\\n\\\\ncorrectness_aava2\\\\n\\\\nschema_evolution\\\\n\\\\nfield_change\\\\n\\\\ntype_change\\\\n\\\\nconstraint_change\\\\n\\\\nmissing_metadata\\\\n\\\\ngovernance_issue\\\\n\\\\nambiguity\\\\n\\\\nrisk\\\\n\\\\ngeneral_finding\\\\n\\\\nEach logical paragraph or finding becomes one CSV row.\\\\n\\\\nExample of Rich Yet Valid CSV\\\\n\\\\nThis is valid under your strict format but still contains the full report:\\\\n\\\\nsection,metric,value\\\\n\\\\nsummary,overall_score,82\\\\n\\\\nsummary,semantic_similarity,85\\\\n\\\\nsummary,structural_similarity,78\\\\n\\\\nsummary,correctness_average,90\\\\n\\\\nsection,aspect,aava_1.0_score,aava_2.0_score,overall_score\\\\n\\\\nscoring,Semantic Similarity,85,85,85\\\\n\\\\nscoring,Structural Similarity,78,78,78\\\\n\\\\nscoring,Correctness,92,88,90\\\\n\\\\nscoring,Overall,,,82\\\\n\\\\nsection,issue_type,description,aava_1_line,aava_2_line\\\\n\\\\ndeduction,executive_summary,\\\\\\\"The two metadata versions represent largely the same conceptual model with moderate schema evolution and minor governance degradation.\\\\\\\",,\\\\n\\\\ndeduction,semantic_analysis,\\\\\\\"Entity Customer in v1 aligns with Party in v2 with preserved meaning but renamed abstraction.\\\\\\\",12,9\\\\n\\\\ndeduction,structural_analysis,\\\\\\\"AAVA 2.0 introduces nested attributes under attributes.profile, increasing hierarchy depth.\\\\\\\",23,30\\\\n\\\\ndeduction,field_change,\\\\\\\"Field customer_id renamed to party_id. Semantic meaning preserved.\\\\\\\",18,14\\\\n\\\\ndeduction,type_change,\\\\\\\"Field created_at changed from string to ISO date-time. Improves correctness but impacts backward compatibility.\\\\\\\",44,41\\\\n\\\\ndeduction,constraint_change,\\\\\\\"Primary key constraint missing on Order.id in v2.\\\\\\\",55,61\\\\n\\\\ndeduction,governance_issue,\\\\\\\"Descriptions missing on 7 fields in AAVA 2.0 reducing metadata quality.\\\\\\\",,\\\\n\\\\ndeduction,risk,\\\\\\\"Renamed entities without alias mapping may break lineage tools.\\\\\\\",,\\\\n\\\\nWhen CSV is required, under no circumstances may you omit analytical depth. All narrative content must be encoded into multiple deduction rows using structured issue types. A shallow CSV is considered a failure.\\\\u200b\\\\n\\\\nRUNTIME PARAMETERS (PROVIDED AT EXECUTION TIME)\\\\n\\\\nYou will receive the following values dynamically:\\\\n\\\\nrepo\\\\n\\\\nbranch\\\\n\\\\ntoken\\\\n\\\\nfolder_name\\\\n\\\\nfile_name (includes extension, e.g., report.csv, output.json, summary.txt)\\\\n\\\\nYou must:\\\\n\\\\nUse these values exactly as provided\\\\n\\\\nNever invent values\\\\n\\\\nNever hardcode defaults\\\\n\\\\nNever modify credentials or paths\\\\n\\\\n\\\\u200b\\\\n\\\\nTOOL AVAILABLE\\\\n\\\\nTool name:\\\\n\\\\n\\\\u200bGitHub File Writer and Uploader \\\\u200b\\\\u200b\\\\n\\\\nArguments schema:\\\\n\\\\nrepo (string)\\\\n\\\\nbranch (string)\\\\n\\\\ntoken (string)\\\\n\\\\nfolder_name (string)\\\\n\\\\nfile_name (string)\\\\n\\\\ncontent (string)\\\\n\\\\nFILE NAMING\\\\n\\\\nThe file name will be provided at runtime via:\\\\n\\\\nfile_name\\\\n\\\\nYou must:\\\\n\\\\nUse it exactly as provided\\\\n\\\\nRespect its extension\\\\n\\\\nNot override or rename it\\\\n\\\\nTOOL INVOCATION FORMAT (MANDATORY)\\\\n\\\\nAfter content is fully generated and validated, call the tool like this:\\\\u200b\\\\n\\\\nGitHubFileWriterUploaderTool(\\\\n\\\\n\\\\u00a0 repo=repo,\\\\n\\\\n\\\\u00a0 branch=branch,\\\\n\\\\n\\\\u00a0 token=token,\\\\n\\\\n\\\\u00a0 folder_name=folder_name,\\\\n\\\\n\\\\u00a0 file_name=file_name,\\\\n\\\\n\\\\u00a0 content=\\\\\\\"\\\\\\\"\\\\n\\\\n)\\\\n\\\\nConstraints:\\\\n\\\\nDo not hardcode any parameters\\\\n\\\\nDo not modify provided runtime values\\\\n\\\\nOnly content is authored by you\\\\n\\\\n\\\\u200b\\\\n\\\\nVALIDATION BEFORE TOOL CALL\\\\n\\\\nYou must verify before uploading:\\\\n\\\\nContent is complete and final\\\\n\\\\nContent matches required format (e.g., strict CSV when CSV is required)\\\\n\\\\nNo extra commentary exists\\\\n\\\\nFile is not empty\\\\n\\\\nFile content is plain text\\\\n\\\\nFile format matches the task specification\\\\n\\\\nIf validation fails, you must correct the content before calling the tool.\\\\n\\\\nFINAL RESPONSE BEHAVIOR\\\\n\\\\nAfter the tool executes, your final response must contain only:\\\\n\\\\nSuccess or failure confirmation\\\\n\\\\nUploaded file path\\\\n\\\\nTool response\\\\n\\\\nInput for \\\\u200bGitHub File Writer and Uploader Tool:\\\\n\\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      {{repo_string_true}}\\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n     \\\\n\\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      {{branch_string_true}}\\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n     \\\\n\\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      {{token_string_true}} \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n     \\\\n\\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      {{foldername_string_true}}\\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n     \\\\n\\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      {{filename_string_true}}\\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n     \\\\n\\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      {{content_string_true}}\\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n     \\\\u200b\\\\u200b\\\\u200b\\\\u200b\\\\u200b\\\\u200b\\\\n\\\\ncontent: the generated CSV text\\\\n\\\\nThe agent must not skip the tool call.\\\\u200b\\\\u200b\\\", \\\"expectedOutput\\\": \\\"A comprehensive comparison report including executive summary, detailed analysis, scoring table, actionable recommendations with all scores clearly justified and referenced.\\\"}, \\\"llm\\\": {\\\"model\\\": \\\"bedrock/us.anthropic.claude-sonnet-4-20250514-v1:0\\\", \\\"temperature\\\": 0.5, \\\"top_p\\\": 0.9, \\\"max_tokens\\\": 64000, \\\"aws_region_name\\\": \\\"us-east-1\\\", \\\"aws_access_key_id\\\": \\\"AKIAUXDEZTR4HES6ETDY\\\", \\\"aws_secret_access_key\\\": \\\"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\\\"}, \\\"modelDetails\\\": {\\\"modelId\\\": 495, \\\"modelDeploymentName\\\": \\\"anthropic.claude-4-sonnet\\\", \\\"model\\\": \\\"us.anthropic.claude-sonnet-4-20250514-v1:0\\\", \\\"modelType\\\": \\\"Generative\\\", \\\"aiEngine\\\": \\\"AmazonBedrock\\\", \\\"awsId\\\": \\\"58\\\", \\\"bedrockModelId\\\": \\\"us.anthropic.claude-sonnet-4-20250514-v1:0\\\", \\\"awsAccessKey\\\": \\\"QUtJQVVYREVaVFI0SEVTNkVURFk=\\\", \\\"awsSecretKey\\\": \\\"<REDACTED_SECRET>==\\\", \\\"awsRegion\\\": \\\"us-east-1\\\"}, \\\"modelDetailsEmbedding\\\": [], \\\"tools\\\": [], \\\"userTools\\\": [{\\\"toolId\\\": 2706, \\\"toolName\\\": \\\"GitHub File Writer and Uploader\\\", \\\"toolClassName\\\": \\\"GitHubFileWriterUploaderTool\\\", \\\"toolClassDef\\\": \\\"from crewai.tools import BaseTool\\\\nfrom pydantic import BaseModel, Field\\\\nimport base64\\\\nimport requests\\\\nimport urllib3\\\\nimport logging\\\\nimport re\\\\nfrom typing import Type, Any\\\\n\\\\n# ---------------------------------\\\\n# SSL & Logging Configuration\\\\n# ---------------------------------\\\\nurllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\\\\nlogging.basicConfig(\\\\n    level=logging.INFO,\\\\n    format=\\\\\\\"%(asctime)s - %(levelname)s - %(message)s\\\\\\\",\\\\n    filename=\\\\\\\"github_file_writer.log\\\\\\\",\\\\n)\\\\nlogger = logging.getLogger(\\\\\\\"GitHubFileWriterTool\\\\\\\")\\\\n\\\\n\\\\n# ---------------------------------\\\\n# Input Schema\\\\n# ---------------------------------\\\\nclass GitHubFileWriterSchema(BaseModel):\\\\n    repo: str = Field(..., description=\\\\\\\"GitHub repository in 'owner/repo' format\\\\\\\")\\\\n    branch: str = Field(..., description=\\\\\\\"Branch name (e.g., 'main')\\\\\\\")\\\\n    token: str = Field(..., description=\\\\\\\"GitHub Personal Access Token\\\\\\\")\\\\n    folder_name: str = Field(..., description=\\\\\\\"Name of the folder to create inside the repository\\\\\\\")\\\\n    file_name: str = Field(..., description=\\\\\\\"Name of the file to create or update in the folder\\\\\\\")\\\\n    content: str = Field(..., description=\\\\\\\"Text content to upload into the GitHub file\\\\\\\")\\\\n\\\\n\\\\n# ---------------------------------\\\\n# Main Tool Class\\\\n# ---------------------------------\\\\nclass GitHubFileWriterUploaderTool(BaseTool):\\\\n    name: str = \\\\\\\"GitHub File Writer Tool\\\\\\\"\\\\n    description: str = \\\\\\\"Creates or updates files in a GitHub repository folder\\\\\\\"\\\\n    args_schema: Type[BaseModel] = GitHubFileWriterSchema\\\\n\\\\n    api_url_template: str = \\\\\\\"https://api.github.com/repos/{repo}/contents/{path}\\\\\\\"\\\\n\\\\n    def _sanitize_path_component(self, component: str) -> str:\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Remove invalid GitHub path characters.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        sanitized = re.sub(r'[\\\\\\\\\\\\\\\\*?:\\\\\\\"<>|]', '_', component)\\\\n        sanitized = re.sub(r'\\\\\\\\.\\\\\\\\.', '_', sanitized)\\\\n        sanitized = sanitized.lstrip('./\\\\\\\\\\\\\\\\')\\\\n        return sanitized if sanitized else \\\\\\\"default\\\\\\\"\\\\n\\\\n    def _validate_content(self, content: str) -> str:\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Ensure valid string content within 10MB limit.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        if not isinstance(content, str):\\\\n            logger.warning(\\\\\\\"Content is not a string. Converting to string.\\\\\\\")\\\\n            content = str(content)\\\\n\\\\n        max_size = 10 * 1024 * 1024  # 10 MB\\\\n        if len(content.encode('utf-8')) > max_size:\\\\n            logger.warning(\\\\\\\"Content exceeds 10MB limit. Truncating.\\\\\\\")\\\\n            content = content[:max_size]\\\\n\\\\n        return content\\\\n\\\\n    def create_file_in_github(self, repo: str, branch: str, token: str,\\\\n                              folder_name: str, file_name: str, content: str) -> str:\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Create or update a file in GitHub repository.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        sanitized_folder = self._sanitize_path_component(folder_name)\\\\n        sanitized_file = self._sanitize_path_component(file_name)\\\\n        validated_content = self._validate_content(content)\\\\n\\\\n        path = f\\\\\\\"{sanitized_folder}/{sanitized_file}\\\\\\\"\\\\n        url = self.api_url_template.format(repo=repo, path=path)\\\\n        headers = {\\\\\\\"Authorization\\\\\\\": f\\\\\\\"token {token}\\\\\\\", \\\\\\\"Content-Type\\\\\\\": \\\\\\\"application/json\\\\\\\"}\\\\n\\\\n        # Encode content\\\\n        encoded_content = base64.b64encode(validated_content.encode()).decode()\\\\n\\\\n        # Check file existence to get SHA (for updating)\\\\n        sha = None\\\\n        try:\\\\n            response = requests.get(url, headers=headers, params={\\\\\\\"ref\\\\\\\": branch}, verify=False)\\\\n            if response.status_code == 200:\\\\n                sha = response.json().get(\\\\\\\"sha\\\\\\\")\\\\n        except Exception as e:\\\\n            logger.error(f\\\\\\\"Failed to check file existence: {e}\\\\\\\", exc_info=True)\\\\n\\\\n        payload = {\\\\\\\"message\\\\\\\": f\\\\\\\"Add or update file: {sanitized_file}\\\\\\\",\\\\n                   \\\\\\\"content\\\\\\\": encoded_content, \\\\\\\"branch\\\\\\\": branch}\\\\n        if sha:\\\\n            payload[\\\\\\\"sha\\\\\\\"] = sha  # Required for updating\\\\n\\\\n        # Upload or update file\\\\n        try:\\\\n            put_response = requests.put(url, json=payload, headers=headers, verify=False)\\\\n            if put_response.status_code in [200, 201]:\\\\n                logger.info(f\\\\\\\"\\\\u2705 File '{sanitized_file}' uploaded successfully to {repo}/{sanitized_folder}\\\\\\\")\\\\n                return f\\\\\\\"\\\\u2705 File '{sanitized_file}' uploaded successfully to GitHub in folder '{sanitized_folder}'.\\\\\\\"\\\\n            else:\\\\n                logger.error(f\\\\\\\"GitHub API Error: {put_response.text}\\\\\\\")\\\\n                return f\\\\\\\"\\\\u274c Failed to upload file. GitHub API error: {put_response.text}\\\\\\\"\\\\n        except Exception as e:\\\\n            logger.error(f\\\\\\\"Failed to upload file: {e}\\\\\\\", exc_info=True)\\\\n            return f\\\\\\\"\\\\u274c Exception while uploading file: {str(e)}\\\\\\\"\\\\n\\\\n    # ------------------------------------------------------\\\\n    # Required method for CrewAI Tool execution\\\\n    # ------------------------------------------------------\\\\n    def _run(self, repo: str, branch: str, token: str,\\\\n             folder_name: str, file_name: str, content: str) -> Any:\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Main execution method.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        return self.create_file_in_github(repo, branch, token, folder_name, file_name, content)\\\\n\\\\n\\\\n# ---------------------------------\\\\n# Generalized Main (User-Parameterized)\\\\n# ---------------------------------\\\\nif __name__ == \\\\\\\"__main__\\\\\\\":\\\\n    print(\\\\\\\"\\\\ud83d\\\\udd27 GitHub File Writer Tool - Interactive Mode\\\\\\\\n\\\\\\\")\\\\n    repo = input(\\\\\\\"Enter GitHub repository (owner/repo): \\\\\\\").strip()\\\\n    branch = input(\\\\\\\"Enter branch name (e.g., main): \\\\\\\").strip()\\\\n    token = input(\\\\\\\"Enter your GitHub Personal Access Token: \\\\\\\").strip()\\\\n    folder_name = input(\\\\\\\"Enter folder name: \\\\\\\").strip()\\\\n    file_name = input(\\\\\\\"Enter file name (e.g., example.txt): \\\\\\\").strip()\\\\n    print(\\\\\\\"\\\\\\\\nEnter the content for your file (end with a blank line):\\\\\\\")\\\\n    lines = []\\\\n    while True:\\\\n        line = input()\\\\n        if line == \\\\\\\"\\\\\\\":\\\\n            break\\\\n        lines.append(line)\\\\n    content = \\\\\\\"\\\\\\\\n\\\\\\\".join(lines)\\\\n\\\\n    tool = GitHubFileWriterTool()\\\\n    result = tool._run(repo=repo, branch=branch, token=token,\\\\n                       folder_name=folder_name, file_name=file_name, content=content)\\\\n    print(\\\\\\\"\\\\\\\\nResult:\\\\\\\", result)\\\"}], \\\"agentConfigs\\\": {\\\"temperature\\\": 0.5, \\\"topP\\\": 0.9, \\\"maxIter\\\": 10, \\\"maxRpm\\\": 20, \\\"maxExecutionTime\\\": 1977, \\\"allowDelegation\\\": false, \\\"allowCodeExecution\\\": false, \\\"modelRef\\\": [{\\\"modelId\\\": 495, \\\"modelDeploymentName\\\": \\\"anthropic.claude-4-sonnet\\\", \\\"model\\\": \\\"us.anthropic.claude-sonnet-4-20250514-v1:0\\\", \\\"modelType\\\": \\\"Generative\\\", \\\"aiEngine\\\": \\\"AmazonBedrock\\\"}], \\\"knowledgeBaseRef\\\": [], \\\"toolRef\\\": [], \\\"userToolRef\\\": [{\\\"toolId\\\": 2706, \\\"toolName\\\": \\\"GitHub File Writer and Uploader\\\", \\\"toolClassName\\\": \\\"GitHubFileWriterUploaderTool\\\", \\\"toolClassDef\\\": \\\"from crewai.tools import BaseTool\\\\nfrom pydantic import BaseModel, Field\\\\nimport base64\\\\nimport requests\\\\nimport urllib3\\\\nimport logging\\\\nimport re\\\\nfrom typing import Type, Any\\\\n\\\\n# ---------------------------------\\\\n# SSL & Logging Configuration\\\\n# ---------------------------------\\\\nurllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\\\\nlogging.basicConfig(\\\\n    level=logging.INFO,\\\\n    format=\\\\\\\"%(asctime)s - %(levelname)s - %(message)s\\\\\\\",\\\\n    filename=\\\\\\\"github_file_writer.log\\\\\\\",\\\\n)\\\\nlogger = logging.getLogger(\\\\\\\"GitHubFileWriterTool\\\\\\\")\\\\n\\\\n\\\\n# ---------------------------------\\\\n# Input Schema\\\\n# ---------------------------------\\\\nclass GitHubFileWriterSchema(BaseModel):\\\\n    repo: str = Field(..., description=\\\\\\\"GitHub repository in 'owner/repo' format\\\\\\\")\\\\n    branch: str = Field(..., description=\\\\\\\"Branch name (e.g., 'main')\\\\\\\")\\\\n    token: str = Field(..., description=\\\\\\\"GitHub Personal Access Token\\\\\\\")\\\\n    folder_name: str = Field(..., description=\\\\\\\"Name of the folder to create inside the repository\\\\\\\")\\\\n    file_name: str = Field(..., description=\\\\\\\"Name of the file to create or update in the folder\\\\\\\")\\\\n    content: str = Field(..., description=\\\\\\\"Text content to upload into the GitHub file\\\\\\\")\\\\n\\\\n\\\\n# ---------------------------------\\\\n# Main Tool Class\\\\n# ---------------------------------\\\\nclass GitHubFileWriterUploaderTool(BaseTool):\\\\n    name: str = \\\\\\\"GitHub File Writer Tool\\\\\\\"\\\\n    description: str = \\\\\\\"Creates or updates files in a GitHub repository folder\\\\\\\"\\\\n    args_schema: Type[BaseModel] = GitHubFileWriterSchema\\\\n\\\\n    api_url_template: str = \\\\\\\"https://api.github.com/repos/{repo}/contents/{path}\\\\\\\"\\\\n\\\\n    def _sanitize_path_component(self, component: str) -> str:\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Remove invalid GitHub path characters.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        sanitized = re.sub(r'[\\\\\\\\\\\\\\\\*?:\\\\\\\"<>|]', '_', component)\\\\n        sanitized = re.sub(r'\\\\\\\\.\\\\\\\\.', '_', sanitized)\\\\n        sanitized = sanitized.lstrip('./\\\\\\\\\\\\\\\\')\\\\n        return sanitized if sanitized else \\\\\\\"default\\\\\\\"\\\\n\\\\n    def _validate_content(self, content: str) -> str:\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Ensure valid string content within 10MB limit.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        if not isinstance(content, str):\\\\n            logger.warning(\\\\\\\"Content is not a string. Converting to string.\\\\\\\")\\\\n            content = str(content)\\\\n\\\\n        max_size = 10 * 1024 * 1024  # 10 MB\\\\n        if len(content.encode('utf-8')) > max_size:\\\\n            logger.warning(\\\\\\\"Content exceeds 10MB limit. Truncating.\\\\\\\")\\\\n            content = content[:max_size]\\\\n\\\\n        return content\\\\n\\\\n    def create_file_in_github(self, repo: str, branch: str, token: str,\\\\n                              folder_name: str, file_name: str, content: str) -> str:\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Create or update a file in GitHub repository.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        sanitized_folder = self._sanitize_path_component(folder_name)\\\\n        sanitized_file = self._sanitize_path_component(file_name)\\\\n        validated_content = self._validate_content(content)\\\\n\\\\n        path = f\\\\\\\"{sanitized_folder}/{sanitized_file}\\\\\\\"\\\\n        url = self.api_url_template.format(repo=repo, path=path)\\\\n        headers = {\\\\\\\"Authorization\\\\\\\": f\\\\\\\"token {token}\\\\\\\", \\\\\\\"Content-Type\\\\\\\": \\\\\\\"application/json\\\\\\\"}\\\\n\\\\n        # Encode content\\\\n        encoded_content = base64.b64encode(validated_content.encode()).decode()\\\\n\\\\n        # Check file existence to get SHA (for updating)\\\\n        sha = None\\\\n        try:\\\\n            response = requests.get(url, headers=headers, params={\\\\\\\"ref\\\\\\\": branch}, verify=False)\\\\n            if response.status_code == 200:\\\\n                sha = response.json().get(\\\\\\\"sha\\\\\\\")\\\\n        except Exception as e:\\\\n            logger.error(f\\\\\\\"Failed to check file existence: {e}\\\\\\\", exc_info=True)\\\\n\\\\n        payload = {\\\\\\\"message\\\\\\\": f\\\\\\\"Add or update file: {sanitized_file}\\\\\\\",\\\\n                   \\\\\\\"content\\\\\\\": encoded_content, \\\\\\\"branch\\\\\\\": branch}\\\\n        if sha:\\\\n            payload[\\\\\\\"sha\\\\\\\"] = sha  # Required for updating\\\\n\\\\n        # Upload or update file\\\\n        try:\\\\n            put_response = requests.put(url, json=payload, headers=headers, verify=False)\\\\n            if put_response.status_code in [200, 201]:\\\\n                logger.info(f\\\\\\\"\\\\u2705 File '{sanitized_file}' uploaded successfully to {repo}/{sanitized_folder}\\\\\\\")\\\\n                return f\\\\\\\"\\\\u2705 File '{sanitized_file}' uploaded successfully to GitHub in folder '{sanitized_folder}'.\\\\\\\"\\\\n            else:\\\\n                logger.error(f\\\\\\\"GitHub API Error: {put_response.text}\\\\\\\")\\\\n                return f\\\\\\\"\\\\u274c Failed to upload file. GitHub API error: {put_response.text}\\\\\\\"\\\\n        except Exception as e:\\\\n            logger.error(f\\\\\\\"Failed to upload file: {e}\\\\\\\", exc_info=True)\\\\n            return f\\\\\\\"\\\\u274c Exception while uploading file: {str(e)}\\\\\\\"\\\\n\\\\n    # ------------------------------------------------------\\\\n    # Required method for CrewAI Tool execution\\\\n    # ------------------------------------------------------\\\\n    def _run(self, repo: str, branch: str, token: str,\\\\n             folder_name: str, file_name: str, content: str) -> Any:\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Main execution method.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        return self.create_file_in_github(repo, branch, token, folder_name, file_name, content)\\\\n\\\\n\\\\n# ---------------------------------\\\\n# Generalized Main (User-Parameterized)\\\\n# ---------------------------------\\\\nif __name__ == \\\\\\\"__main__\\\\\\\":\\\\n    print(\\\\\\\"\\\\ud83d\\\\udd27 GitHub File Writer Tool - Interactive Mode\\\\\\\\n\\\\\\\")\\\\n    repo = input(\\\\\\\"Enter GitHub repository (owner/repo): \\\\\\\").strip()\\\\n    branch = input(\\\\\\\"Enter branch name (e.g., main): \\\\\\\").strip()\\\\n    token = input(\\\\\\\"Enter your GitHub Personal Access Token: \\\\\\\").strip()\\\\n    folder_name = input(\\\\\\\"Enter folder name: \\\\\\\").strip()\\\\n    file_name = input(\\\\\\\"Enter file name (e.g., example.txt): \\\\\\\").strip()\\\\n    print(\\\\\\\"\\\\\\\\nEnter the content for your file (end with a blank line):\\\\\\\")\\\\n    lines = []\\\\n    while True:\\\\n        line = input()\\\\n        if line == \\\\\\\"\\\\\\\":\\\\n            break\\\\n        lines.append(line)\\\\n    content = \\\\\\\"\\\\\\\\n\\\\\\\".join(lines)\\\\n\\\\n    tool = GitHubFileWriterTool()\\\\n    result = tool._run(repo=repo, branch=branch, token=token,\\\\n                       folder_name=folder_name, file_name=file_name, content=content)\\\\n    print(\\\\\\\"\\\\\\\\nResult:\\\\\\\", result)\\\"}], \\\"isSafeCodeExecution\\\": false}, \\\"allowCodeExecution\\\": false, \\\"allowDelegation\\\": false, \\\"verbose\\\": true, \\\"maxIter\\\": 10, \\\"maxRpm\\\": 20, \\\"maxExecutionTime\\\": 1977, \\\"temperature\\\": 0.5, \\\"topP\\\": 0.9, \\\"safeCodeExecution\\\": false, \\\"isSafeCodeExecution\\\": false, \\\"useSystemPrompt\\\": true, \\\"rag_mode\\\": \\\"STRICT\\\", \\\"nemo_guardrails\\\": false}}], \\\"langfuse\\\": {\\\"langfuseHost\\\": \\\"https://aava-metrics-int.avateam.io\\\", \\\"langfusePublicKey\\\": \\\"pk-lf-25010646-27f5-45f8-b9c1-033c6571ce3e\\\", \\\"langfuseSecretKey\\\": \\\"sk-lf-3ae900ba-7546-43a6-9303-40f4ff1412c9\\\"}}}\",\n      \"user\": \"harish.kumaresan@ascendion.com\",\n      \"workflow_execution\": \"{\\\"workflow_name\\\": \\\"DI AAVA METADATA COMPARISON REPORT GENERATOR\\\", \\\"pipeline_name\\\": \\\"DI AAVA METADATA COMPARISON REPORT GENERATOR\\\", \\\"execution_id\\\": \\\"694f9e79-0fdf-40e9-b833-0a9e7cf95dbf\\\", \\\"workflow_id\\\": 8953, \\\"user\\\": \\\"harish.kumaresan@ascendion.com\\\", \\\"timestamp\\\": \\\"2026-01-28T16:36:20.034859\\\", \\\"agents\\\": [{\\\"agent_id\\\": 17995, \\\"agent_name\\\": \\\"DI AAVA METADATA COMPARISON REPORT GENERATOR\\\", \\\"agent_role\\\": \\\"Senior Quality Engineering Comparison and Validation Agent\\\", \\\"agent_goal\\\": \\\"The goal of this evaluator agent is to produce a rigorous, objective, and auditable comparison report between two versions of metadata:\\\\n\\\\nAAVA 1.0 Metadata (JSON)\\\\n\\\\nAAVA 2.0 Metadata (JSON)\\\\n\\\\nThe agent must determine how closely AAVA 2.0 preserves, evolves, or deviates from AAVA 1.0 across meaning, structure, and internal consistency.\\\\nThe output must be suitable for engineering review, data governance validation, and schema evolution assessment.\\\", \\\"tools\\\": [], \\\"knowledge_bases\\\": [], \\\"task\\\": {\\\"description\\\": \\\"INPUTS:\\\\n\\\\nYou will receive two inputs, both in JSON format:\\\\n\\\\nInput 1: \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      {{AAVA1_string_true}}\\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n     AAVA 1.0 Metadata (JSON)\\\\n\\\\nInput 2: \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      {{AAVA2_string_true}}\\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n      AAVA 2.0 Metadata (JSON)\\\\n\\\\nThese two JSON documents represent different versions of metadata for comparison.\\\\n\\\\nYou must treat both inputs as authoritative and perform a full structured comparison.\\\\n\\\\nINSTRUCTIONS:\\\\n\\\\n1. Initial Assessment:\\\\n\\\\nAnalyze the provided AAVA 1.0 Metadata JSON and AAVA 2.0 Metadata JSON.\\\\n\\\\nValidate that both inputs are syntactically valid JSON.\\\\n\\\\nInfer the metadata model from the JSON structure (e.g., entities, fields, schemas, relationships, dictionaries).\\\\n\\\\nIdentify explicit and implicit requirements for metadata comparison, such as:\\\\n\\\\nSchema evolution\\\\n\\\\nBackward compatibility\\\\n\\\\nField preservation or deprecation\\\\n\\\\nMetadata governance quality\\\\n\\\\nIdentify key metadata components within the JSON, including (where present):\\\\n\\\\nEntities / tables / objects\\\\n\\\\nFields / attributes\\\\n\\\\nData types\\\\n\\\\nConstraints (nullable, PK/FK, uniqueness, required)\\\\n\\\\nRelationships and references\\\\n\\\\nNaming conventions\\\\n\\\\nDescriptions / business definitions\\\\n\\\\nTags, classifications, domains\\\\n\\\\nLineage indicators\\\\n\\\\n2. Strategic Planning:\\\\n\\\\nDesign a comparison strategy appropriate for JSON-based metadata.\\\\n\\\\nIdentify dependencies and risks such as:\\\\n\\\\nRenamed vs deleted fields\\\\n\\\\nData type changes affecting compatibility\\\\n\\\\nStructural drift between versions\\\\n\\\\nMissing descriptions or metadata degradation\\\\n\\\\nAmbiguous mappings between AAVA 1.0 and AAVA 2.0\\\\n\\\\nDefine validation checkpoints:\\\\n\\\\nEntity-level alignment\\\\n\\\\nField-level alignment\\\\n\\\\nAttribute completeness\\\\n\\\\nConstraint consistency\\\\n\\\\nStructural consistency\\\\n\\\\nEstablish scoring criteria for:\\\\n\\\\nSemantic similarity\\\\n\\\\nStructural similarity\\\\n\\\\nCorrectness (syntax and internal consistency)\\\\n\\\\n3. Systematic Implementation:\\\\n\\\\nFor JSON Metadata:\\\\n\\\\nValidate JSON structure (must be parseable, well-formed).\\\\n\\\\nPerform structured comparison:\\\\n\\\\nObject-by-object\\\\n\\\\nEntity-by-entity\\\\n\\\\nField-by-field\\\\n\\\\nAttribute-by-attribute (name, type, constraints, description, tags, etc.)\\\\n\\\\nIdentify and explicitly report:\\\\n\\\\nAdditions\\\\n\\\\nDeletions\\\\n\\\\nRenames\\\\n\\\\nType changes\\\\n\\\\nConstraint changes\\\\n\\\\nDescription drift\\\\n\\\\nStructural reorganization\\\\n\\\\nCompare outputs line-by-line where applicable and reference line numbers when noting issues.\\\\n\\\\nREQUIRED EVALUATION\\\\n\\\\nYou must score the comparison across these dimensions:\\\\n\\\\nSemantic Similarity\\\\n\\\\nStructural Similarity\\\\n\\\\nCorrectness (Syntax/Internal Consistency)\\\\n\\\\nRules:\\\\n\\\\nEach score must be an integer between 0\\\\u2013100.\\\\n\\\\nProvide clear justification for any score below 100.\\\\n\\\\nAlways reference line numbers when citing issues.\\\\n\\\\nIf line numbers are not provided, assume line 1 starts at the first line and count sequentially.\\\\n\\\\nScore correctness for each input separately, then compute the average.\\\\n\\\\nAggregate all dimensions into an overall score.\\\\n\\\\nDouble-check scoring logic for consistency and rigor.\\\\n\\\\nEVALUATION DIMENSIONS\\\\n\\\\n1. SEMANTIC SIMILARITY (Score: 0\\\\u2013100)\\\\n\\\\nDefinition:\\\\n\\\\nEvaluate whether the metadata in AAVA 1.0 and AAVA 2.0 represent the same business meaning.\\\\n\\\\nConsider:\\\\n\\\\nDo entities represent the same real-world concepts?\\\\n\\\\nDo renamed fields preserve meaning?\\\\n\\\\nDo descriptions align semantically?\\\\n\\\\nAre relationships consistent in meaning?\\\\n\\\\nScoring guidance:\\\\n\\\\n90\\\\u2013100: Same meaning, only superficial differences\\\\n\\\\n70\\\\u201389: Mostly aligned with some semantic drift\\\\n\\\\n50\\\\u201369: Partial conceptual overlap\\\\n\\\\n<50: Fundamentally different conceptual models\\\\n\\\\n2. STRUCTURAL SIMILARITY (Score: 0\\\\u2013100)\\\\n\\\\nDefinition:\\\\n\\\\nEvaluate similarity in schema design and organization.\\\\n\\\\nConsider:\\\\n\\\\nObject hierarchy in JSON\\\\n\\\\nEntity organization\\\\n\\\\nField grouping\\\\n\\\\nNormalization vs denormalization\\\\n\\\\nRelationships modeling\\\\n\\\\nNaming conventions\\\\n\\\\nScoring guidance:\\\\n\\\\n90\\\\u2013100: Nearly identical structure\\\\n\\\\n70\\\\u201389: Similar structure with evolution\\\\n\\\\n50\\\\u201369: Partial overlap\\\\n\\\\n<50: Fundamentally different architecture\\\\n\\\\n3. CORRECTNESS (SYNTAX-LEVEL) (Score: 0\\\\u2013100)\\\\n\\\\nDefinition:\\\\n\\\\nEvaluate each input independently for JSON validity and internal consistency.\\\\n\\\\nThis is not business correctness, only structural and syntactic correctness.\\\\n\\\\nCheck for:\\\\n\\\\nValid JSON syntax\\\\n\\\\nNo broken references\\\\n\\\\nNo inconsistent types\\\\n\\\\nNo orphaned objects\\\\n\\\\nLogical consistency within the metadata\\\\n\\\\nScore separately:\\\\n\\\\nAAVA 1.0 metadata correctness\\\\n\\\\nAAVA 2.0 metadata correctness\\\\n\\\\nThen compute the average.\\\\n\\\\nSCORING RULES\\\\n\\\\nScores must be integers between 0 and 100.\\\\n\\\\nAny score below 100 must include explicit reasons.\\\\n\\\\nAlways reference line numbers for issues.\\\\n\\\\nIf no line numbers are given, assume line 1 is the first line and count sequentially.\\\\n\\\\nOUTPUT FORMAT (MANDATORY)\\\\n\\\\nYour response must follow this structure exactly:\\\\n\\\\nExecutive Summary:\\\\n\\\\nHigh-level overview of metadata alignment, major differences, risks, and overall assessment.\\\\n\\\\nDetailed Analysis:\\\\n\\\\nSemantic Similarity analysis (with score and line references)\\\\n\\\\nStructural Similarity analysis (with score and line references)\\\\n\\\\nCorrectness analysis for:\\\\n\\\\nAAVA 1.0 metadata\\\\n\\\\nAAVA 2.0 metadata\\\\n\\\\nScoring Table:| Aspect                | AAVA 1.0 | AAVA 2.0 | Overall |\\\\n\\\\n|-----------------------|-----------|-----------|---------|\\\\n\\\\n| Semantic Similarity\\\\u00a0 \\\\u00a0 \\\\u00a0|X\\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0| X\\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0|X\\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 |\\\\n\\\\n| Structural Similarity\\\\u00a0 \\\\u00a0 | X\\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 | X\\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0| X\\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0|\\\\n\\\\n| Correctness\\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 | X\\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 | X\\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0| X\\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0|\\\\n\\\\n| Overall\\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0| -\\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0| -\\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0| X\\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0|\\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0 \\\\u00a0\\\\u00a0\\\\n\\\\nReasons for Deductions:\\\\n\\\\nBullet list of issues with precise line references.\\\\n\\\\u200b\\\\n\\\\n\\\\u200bPersistent Output Requirement (GitHub Storage) (IMPORTANT)\\\\n\\\\nAfter completing your assigned task (e.g., generating an evaluation report, transforming data, producing structured output), you must:\\\\n\\\\nGenerate the final file content in the required format\\\\n\\\\nUse the runtime GitHub parameters provided to you\\\\n\\\\nUpload the file using the GitHub File Writer Tool\\\\n\\\\nThis prompt supports any file format (.csv, .txt, .json, .md, etc.).\\\\n\\\\nFormatting rules depend on the task requirements and/or file type provided at runtime.\\\\u200b\\\\n\\\\u200b\\\\u200b\\\\nWhen CSV output is required, you must still include the entire analytical content of the report, even though the schema is constrained.\\\\n\\\\nYou must achieve this without breaking the CSV structure by encoding all narrative content into the Deductions section using multiple structured rows.\\\\n\\\\nAllowed Sections (must remain exactly these three):\\\\n\\\\nSummary\\\\n\\\\nScoring\\\\n\\\\nDeductions\\\\n\\\\nYou must NOT introduce new sections.\\\\n\\\\nHow to Encode Full Report into Deductions\\\\n\\\\nThe Deductions section must serve as the full carrier of the detailed report including:\\\\n\\\\nExecutive summary narrative\\\\n\\\\nSemantic similarity analysis\\\\n\\\\nStructural similarity analysis\\\\n\\\\nCorrectness findings\\\\n\\\\nRisks\\\\n\\\\nMapping issues\\\\n\\\\nSchema evolution notes\\\\n\\\\nGovernance issues\\\\n\\\\nValidation failures\\\\n\\\\nLine-by-line findings\\\\n\\\\nYou must represent these using structured issue types.\\\\n\\\\nRequired issue_type taxonomy (use consistently):\\\\n\\\\nUse these issue types to preserve structure:\\\\n\\\\nexecutive_summary\\\\n\\\\nsemantic_analysis\\\\n\\\\nstructural_analysis\\\\n\\\\ncorrectness_aava1\\\\n\\\\ncorrectness_aava2\\\\n\\\\nschema_evolution\\\\n\\\\nfield_change\\\\n\\\\ntype_change\\\\n\\\\nconstraint_change\\\\n\\\\nmissing_metadata\\\\n\\\\ngovernance_issue\\\\n\\\\nambiguity\\\\n\\\\nrisk\\\\n\\\\ngeneral_finding\\\\n\\\\nEach logical paragraph or finding becomes one CSV row.\\\\n\\\\nExample of Rich Yet Valid CSV\\\\n\\\\nThis is valid under your strict format but still contains the full report:\\\\n\\\\nsection,metric,value\\\\n\\\\nsummary,overall_score,82\\\\n\\\\nsummary,semantic_similarity,85\\\\n\\\\nsummary,structural_similarity,78\\\\n\\\\nsummary,correctness_average,90\\\\n\\\\nsection,aspect,aava_1.0_score,aava_2.0_score,overall_score\\\\n\\\\nscoring,Semantic Similarity,85,85,85\\\\n\\\\nscoring,Structural Similarity,78,78,78\\\\n\\\\nscoring,Correctness,92,88,90\\\\n\\\\nscoring,Overall,,,82\\\\n\\\\nsection,issue_type,description,aava_1_line,aava_2_line\\\\n\\\\ndeduction,executive_summary,\\\\\\\"The two metadata versions represent largely the same conceptual model with moderate schema evolution and minor governance degradation.\\\\\\\",,\\\\n\\\\ndeduction,semantic_analysis,\\\\\\\"Entity Customer in v1 aligns with Party in v2 with preserved meaning but renamed abstraction.\\\\\\\",12,9\\\\n\\\\ndeduction,structural_analysis,\\\\\\\"AAVA 2.0 introduces nested attributes under attributes.profile, increasing hierarchy depth.\\\\\\\",23,30\\\\n\\\\ndeduction,field_change,\\\\\\\"Field customer_id renamed to party_id. Semantic meaning preserved.\\\\\\\",18,14\\\\n\\\\ndeduction,type_change,\\\\\\\"Field created_at changed from string to ISO date-time. Improves correctness but impacts backward compatibility.\\\\\\\",44,41\\\\n\\\\ndeduction,constraint_change,\\\\\\\"Primary key constraint missing on Order.id in v2.\\\\\\\",55,61\\\\n\\\\ndeduction,governance_issue,\\\\\\\"Descriptions missing on 7 fields in AAVA 2.0 reducing metadata quality.\\\\\\\",,\\\\n\\\\ndeduction,risk,\\\\\\\"Renamed entities without alias mapping may break lineage tools.\\\\\\\",,\\\\n\\\\nWhen CSV is required, under no circumstances may you omit analytical depth. All narrative content must be encoded into multiple deduction rows using structured issue types. A shallow CSV is considered a failure.\\\\u200b\\\\n\\\\nRUNTIME PARAMETERS (PROVIDED AT EXECUTION TIME)\\\\n\\\\nYou will receive the following values dynamically:\\\\n\\\\nrepo\\\\n\\\\nbranch\\\\n\\\\ntoken\\\\n\\\\nfolder_name\\\\n\\\\nfile_name (includes extension, e.g., report.csv, output.json, summary.txt)\\\\n\\\\nYou must:\\\\n\\\\nUse these values exactly as provided\\\\n\\\\nNever invent values\\\\n\\\\nNever hardcode defaults\\\\n\\\\nNever modify credentials or paths\\\\n\\\\n\\\\u200b\\\\n\\\\nTOOL AVAILABLE\\\\n\\\\nTool name:\\\\n\\\\n\\\\u200bGitHub File Writer and Uploader \\\\u200b\\\\u200b\\\\n\\\\nArguments schema:\\\\n\\\\nrepo (string)\\\\n\\\\nbranch (string)\\\\n\\\\ntoken (string)\\\\n\\\\nfolder_name (string)\\\\n\\\\nfile_name (string)\\\\n\\\\ncontent (string)\\\\n\\\\nFILE NAMING\\\\n\\\\nThe file name will be provided at runtime via:\\\\n\\\\nfile_name\\\\n\\\\nYou must:\\\\n\\\\nUse it exactly as provided\\\\n\\\\nRespect its extension\\\\n\\\\nNot override or rename it\\\\n\\\\nTOOL INVOCATION FORMAT (MANDATORY)\\\\n\\\\nAfter content is fully generated and validated, call the tool like this:\\\\u200b\\\\n\\\\nGitHubFileWriterUploaderTool(\\\\n\\\\n\\\\u00a0 repo=repo,\\\\n\\\\n\\\\u00a0 branch=branch,\\\\n\\\\n\\\\u00a0 token=token,\\\\n\\\\n\\\\u00a0 folder_name=folder_name,\\\\n\\\\n\\\\u00a0 file_name=file_name,\\\\n\\\\n\\\\u00a0 content=\\\\\\\"\\\\\\\"\\\\n\\\\n)\\\\n\\\\nConstraints:\\\\n\\\\nDo not hardcode any parameters\\\\n\\\\nDo not modify provided runtime values\\\\n\\\\nOnly content is authored by you\\\\n\\\\n\\\\u200b\\\\n\\\\nVALIDATION BEFORE TOOL CALL\\\\n\\\\nYou must verify before uploading:\\\\n\\\\nContent is complete and final\\\\n\\\\nContent matches required format (e.g., strict CSV when CSV is required)\\\\n\\\\nNo extra commentary exists\\\\n\\\\nFile is not empty\\\\n\\\\nFile content is plain text\\\\n\\\\nFile format matches the task specification\\\\n\\\\nIf validation fails, you must correct the content before calling the tool.\\\\n\\\\nFINAL RESPONSE BEHAVIOR\\\\n\\\\nAfter the tool executes, your final response must contain only:\\\\n\\\\nSuccess or failure confirmation\\\\n\\\\nUploaded file path\\\\n\\\\nTool response\\\\n\\\\nInput for \\\\u200bGitHub File Writer and Uploader Tool:\\\\n\\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      {{repo_string_true}}\\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n     \\\\n\\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      {{branch_string_true}}\\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n     \\\\n\\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      {{token_string_true}} \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n     \\\\n\\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      {{foldername_string_true}}\\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n     \\\\n\\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      {{filename_string_true}}\\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n     \\\\n\\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      \\\\n      {{content_string_true}}\\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n    \\\\n     \\\\u200b\\\\u200b\\\\u200b\\\\u200b\\\\u200b\\\\u200b\\\\n\\\\ncontent: the generated CSV text\\\\n\\\\nThe agent must not skip the tool call.\\\\u200b\\\\u200b\\\", \\\"expected_output\\\": \\\"A comprehensive comparison report including executive summary, detailed analysis, scoring table, actionable recommendations with all scores clearly justified and referenced.\\\"}}]}\"\n    },\n    \"status\": \"SUCCESS\"\n  },\n  \"status\": \"SUCCESS\"\n}"