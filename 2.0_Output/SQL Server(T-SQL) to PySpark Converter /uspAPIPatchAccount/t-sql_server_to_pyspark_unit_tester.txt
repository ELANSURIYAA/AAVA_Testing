1. **Test Case List:**

| Test Case ID | Description | Expected Outcome |
|--------------|-------------|-----------------|
| TC01 | Happy path: All required fields present, all joins succeed, all extension fields populated | Output DataFrame contains correct AccountID, ContactNumber, SubmissionFlag, LoopInstance, and a valid JSON_Message with all fields and extension fields present |
| TC02 | Edge: Some extension fields are NULL | Output JSON_Message omits extension fields with NULL values |
| TC03 | Edge: Account row missing in AccountID (AccountID is NULL, RCT_ID present) | Output AccountID uses RCT_ID value |
| TC04 | Edge: Account row missing in IdOverride (no override) | Output AccountID uses AccountID, UnderwriterId is set as per logic |
| TC05 | Edge: NationalAccountFlag = 1, ExpirationDate < yesterday (should not join NationalAccts) | UnderwriterId is not set to NULL (i.e., is preserved) |
| TC06 | Edge: NationalAccountFlag = 1, ExpirationDate > yesterday (should join NationalAccts) | UnderwriterId is set to NULL |
| TC07 | Edge: AccountStatus and Brand not in lookup tables | ItemID fields for InForceListCode and BrandCode are NULL in extension fields |
| TC08 | Edge: MailingAddress fields are NULL | JSON_Message contains empty string for those fields |
| TC09 | Edge: Input DataFrames are empty | Output DataFrame is empty |
| TC10 | Error: Schema mismatch (missing required column in Account_df) | Function raises an Exception |
| TC11 | Error: Invalid data type in extension field (e.g., int instead of string) | Function handles type conversion gracefully, output is string in JSON |
| TC12 | Filtering: PostPatch != 'Patch', Validated not NULL, DateSent not NULL, SubmissionFlag != 0 | No rows returned (filtered out) |
| TC13 | LoopInstance partitioning: More than 250 records, correct LoopInstance assignment | Only records with given LoopInstance are returned |

---

2. **Pytest Script:**

```python
import pytest
from pyspark.sql import SparkSession
from pyspark.sql import Row
from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DoubleType, FloatType, LongType, BooleanType, DateType, TimestampType
import json

# Import the function to test
from uspAPIPatchAccount import uspAPIPatchAccount

@pytest.fixture(scope="session")
def spark():
    return SparkSession.builder.master("local[2]").appName("pytest-pyspark").getOrCreate()

def make_account_df(spark, rows):
    schema = StructType([
        StructField("AccountID", StringType(), True),
        StructField("ContactNumber", StringType(), True),
        StructField("ExternalUniqueId", StringType(), True),
        StructField("UnderwriterId", StringType(), True),
        StructField("AccountStatus", StringType(), True),
        StructField("Brand", StringType(), True),
        StructField("PostPatch", StringType(), True),
        StructField("Validated", StringType(), True),
        StructField("DateSent", StringType(), True),
        StructField("SubmissionFlag", IntegerType(), True),
        StructField("Premium1", DoubleType(), True),
        StructField("MailingAddress.ProvinceID", StringType(), True),
        StructField("MailingAddress.AddressLine", StringType(), True),
        StructField("MailingAddress.City", StringType(), True),
        StructField("MailingAddress.PostalCode", StringType(), True),
        StructField("MailingAddress.Longitude", StringType(), True),
        StructField("MailingAddress.Latitude", StringType(), True),
        StructField("MailingAddress.County", StringType(), True),
        StructField("Name", StringType(), True),
        StructField("Phone", StringType(), True),
        StructField("Fax", StringType(), True),
        StructField("Email", StringType(), True),
        StructField("Notes", StringType(), True),
        # Add extension fields as needed for tests
        StructField("11", StringType(), True),
        StructField("37", StringType(), True),
        StructField("ContactNumber", StringType(), True),
        StructField("RCT_ID", StringType(), True),
        # ... add all other extension fields as needed
    ])
    return spark.createDataFrame([Row(**r) for r in rows], schema=schema)

def make_accountid_df(spark, rows):
    schema = StructType([
        StructField("ContactNumber", StringType(), True),
        StructField("AccountID", StringType(), True),
        StructField("RCT_ID", StringType(), True),
    ])
    return spark.createDataFrame([Row(**r) for r in rows], schema=schema)

def make_idoverride_df(spark, rows):
    schema = StructType([
        StructField("ExternalUniqueID", StringType(), True),
        StructField("ObjectType", StringType(), True),
        StructField("RCT_ID", StringType(), True),
    ])
    return spark.createDataFrame([Row(**r) for r in rows], schema=schema)

def make_policy_descriptors_df(spark, rows):
    schema = StructType([
        StructField("AccountNumber", StringType(), True),
        StructField("NationalAccountFlag", IntegerType(), True),
        StructField("ExpirationDate", StringType(), True),
    ])
    return spark.createDataFrame([Row(**r) for r in rows], schema=schema)

def extract_json(json_str):
    try:
        return json.loads(json_str)
    except Exception:
        return None

@pytest.mark.parametrize("test_case, rows, expected", [
    # TC01: Happy path
    ("TC01",
     [
         {
             "AccountID": "A1",
             "ContactNumber": "C1",
             "ExternalUniqueId": "EU1",
             "UnderwriterId": "U1",
             "AccountStatus": "inforce",
             "Brand": "Accident Fund",
             "PostPatch": "Patch",
             "Validated": None,
             "DateSent": None,
             "SubmissionFlag": 0,
             "Premium1": 1000.0,
             "MailingAddress.ProvinceID": "MI",
             "MailingAddress.AddressLine": "123 Main",
             "MailingAddress.City": "Lansing",
             "MailingAddress.PostalCode": "48910",
             "MailingAddress.Longitude": "42.7325",
             "MailingAddress.Latitude": "-84.5555",
             "MailingAddress.County": "Ingham",
             "Name": "Test Account",
             "Phone": "555-1234",
             "Fax": "555-5678",
             "Email": "test@company.com",
             "Notes": "Important",
             "11": "val11",
             "37": "val37",
             "RCT_ID": "R1"
         }
     ],
     {
         "AccountID": "A1",
         "ContactNumber": "C1",
         "SubmissionFlag": 0,
         "LoopInstance": 0,
         "UnderwriterId": "U1",
         "MailingAddress.ProvinceID": "MI",
         "MailingAddress.AddressLine": "123 Main",
         "MailingAddress.City": "Lansing",
         "MailingAddress.PostalCode": "48910",
         "MailingAddress.Longitude": "42.7325",
         "MailingAddress.Latitude": "-84.5555",
         "MailingAddress.County": "Ingham",
         "Name": "Test Account",
         "Phone": "555-1234",
         "Fax": "555-5678",
         "Email": "test@company.com",
         "Notes": "Important",
         "ExtensionFields": [{"Id": 11, "value": "val11"}, {"Id": 37, "value": "val37"}]
     }
    ),
    # TC02: Extension field NULL
    ("TC02",
     [
         {
             "AccountID": "A2",
             "ContactNumber": "C2",
             "ExternalUniqueId": "EU2",
             "UnderwriterId": "U2",
             "AccountStatus": "inforce",
             "Brand": "Accident Fund",
             "PostPatch": "Patch",
             "Validated": None,
             "DateSent": None,
             "SubmissionFlag": 0,
             "Premium1": 1000.0,
             "MailingAddress.ProvinceID": "MI",
             "MailingAddress.AddressLine": "456 Main",
             "MailingAddress.City": "Lansing",
             "MailingAddress.PostalCode": "48910",
             "MailingAddress.Longitude": "42.7325",
             "MailingAddress.Latitude": "-84.5555",
             "MailingAddress.County": "Ingham",
             "Name": "Test Account 2",
             "Phone": "555-4321",
             "Fax": "555-8765",
             "Email": "test2@company.com",
             "Notes": "Important2",
             "11": None,
             "37": "val37",
             "RCT_ID": "R2"
         }
     ],
     {
         "AccountID": "A2",
         "ContactNumber": "C2",
         "SubmissionFlag": 0,
         "LoopInstance": 0,
         "UnderwriterId": "U2",
         "ExtensionFields": [{"Id": 37, "value": "val37"}]
     }
    ),
    # TC09: Empty input
    ("TC09", [], None)
])
def test_uspAPIPatchAccount_happy_and_edge(spark, test_case, rows, expected):
    Account_df = make_account_df(spark, rows)
    AccountID_df = make_accountid_df(spark, [{"ContactNumber": r["ContactNumber"], "AccountID": r.get("AccountID", None), "RCT_ID": r.get("RCT_ID", None)} for r in rows]) if rows else make_accountid_df(spark, [])
    IdOverride_df = make_idoverride_df(spark, [{"ExternalUniqueID": r["ExternalUniqueId"], "ObjectType": "Account", "RCT_ID": r.get("RCT_ID", None)} for r in rows]) if rows else make_idoverride_df(spark, [])
    PolicyDescriptors_df = make_policy_descriptors_df(spark, [{"AccountNumber": r["ContactNumber"], "NationalAccountFlag": 1, "ExpirationDate": "2099-12-31 00:00:00"} for r in rows]) if rows else make_policy_descriptors_df(spark, [])
    result = uspAPIPatchAccount(Account_df, AccountID_df, IdOverride_df, PolicyDescriptors_df, loop_instance=0, spark=spark)
    data = result.collect()
    if test_case == "TC09":
        assert len(data) == 0
    else:
        assert len(data) == 1
        row = data[0]
        assert row.AccountID == expected["AccountID"]
        assert row.ContactNumber == expected["ContactNumber"]
        assert row.SubmissionFlag == expected["SubmissionFlag"]
        assert row.LoopInstance == expected.get("LoopInstance", 0)
        # Check JSON_Message
        json_msg = extract_json(row.JSON_Message)
        assert json_msg is not None
        # Check extension fields
        ext_fields = [op for op in json_msg if op.get("path") == "/ExtensionFields"]
        if "ExtensionFields" in expected:
            assert ext_fields, "ExtensionFields missing"
            ext_val = ext_fields[0]["value"]
            for ef in expected["ExtensionFields"]:
                assert ef in ext_val

def test_uspAPIPatchAccount_schema_mismatch(spark):
    # TC10: Schema mismatch
    Account_df = spark.createDataFrame([], StructType([StructField("WrongCol", StringType(), True)]))
    AccountID_df = make_accountid_df(spark, [])
    IdOverride_df = make_idoverride_df(spark, [])
    PolicyDescriptors_df = make_policy_descriptors_df(spark, [])
    with pytest.raises(Exception):
        uspAPIPatchAccount(Account_df, AccountID_df, IdOverride_df, PolicyDescriptors_df, loop_instance=0, spark=spark)

def test_uspAPIPatchAccount_type_conversion(spark):
    # TC11: Extension field is int, should be string in JSON
    rows = [{
        "AccountID": "A3",
        "ContactNumber": "C3",
        "ExternalUniqueId": "EU3",
        "UnderwriterId": "U3",
        "AccountStatus": "inforce",
        "Brand": "Accident Fund",
        "PostPatch": "Patch",
        "Validated": None,
        "DateSent": None,
        "SubmissionFlag": 0,
        "Premium1": 1000.0,
        "MailingAddress.ProvinceID": "MI",
        "MailingAddress.AddressLine": "789 Main",
        "MailingAddress.City": "Lansing",
        "MailingAddress.PostalCode": "48910",
        "MailingAddress.Longitude": "42.7325",
        "MailingAddress.Latitude": "-84.5555",
        "MailingAddress.County": "Ingham",
        "Name": "Test Account 3",
        "Phone": "555-0000",
        "Fax": "555-9999",
        "Email": "test3@company.com",
        "Notes": "Important3",
        "11": 123,  # int, should be string in JSON
        "37": None,
        "RCT_ID": "R3"
    }]
    Account_df = make_account_df(spark, rows)
    AccountID_df = make_accountid_df(spark, [{"ContactNumber": "C3", "AccountID": "A3", "RCT_ID": "R3"}])
    IdOverride_df = make_idoverride_df(spark, [{"ExternalUniqueID": "EU3", "ObjectType": "Account", "RCT_ID": "R3"}])
    PolicyDescriptors_df = make_policy_descriptors_df(spark, [{"AccountNumber": "C3", "NationalAccountFlag": 1, "ExpirationDate": "2099-12-31 00:00:00"}])
    result = uspAPIPatchAccount(Account_df, AccountID_df, IdOverride_df, PolicyDescriptors_df, loop_instance=0, spark=spark)
    data = result.collect()
    assert len(data) == 1
    json_msg = extract_json(data[0].JSON_Message)
    ext_fields = [op for op in json_msg if op.get("path") == "/ExtensionFields"]
    assert ext_fields
    ext_val = ext_fields[0]["value"]
    assert {"Id": 11, "value": "123"} in ext_val

# Additional tests for filtering, partitioning, and join logic can be added similarly.

```

3. **API Cost:**
- List files in directory: $0.0001
- Read a file's content: $0.0002
- **apiCost:** 0.0003 USD