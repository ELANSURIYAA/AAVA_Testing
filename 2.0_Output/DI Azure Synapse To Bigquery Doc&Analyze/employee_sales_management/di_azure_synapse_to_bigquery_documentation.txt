=============================================
Author:        Ascendion AVA
Created on:    
Description:   Loads cleaned and validated sales transactions from staging to the sales fact table, with audit logging and data quality checks.
=============================================

Procedure Overview:
This stored procedure, `dw.sp_load_sales_fact`, is designed to automate the ETL process for loading sales transaction data from the staging table (`stg.Sales_Transactions`) into the data warehouse fact table (`dw.Fact_Sales`). It performs data quality checks, logs the ETL process for auditing, and ensures only valid and clean data is loaded. The procedure supports the business need for reliable, accurate, and auditable sales data, which is critical for downstream reporting, analytics, and decision-making.

Logic Details:
- The procedure begins by logging the start of the ETL run in an audit table.
- It declares variables for batch tracking, timing, and error handling.
- It creates a temporary table to capture invalid rows based on business rules (e.g., missing Customer_ID, invalid Quantity).
- Invalid records are removed from the staging table and counted.
- Cleaned data is transformed and loaded into the `dw.Fact_Sales` table, joining with dimension tables for enrichment.
- The staging table is truncated after successful load.
- Data quality failures are logged for review.
- The audit log is updated with the outcome, including counts of inserted and rejected rows.
- Errors are caught, logged, and rethrown for pipeline monitoring.
- Temporary resources are cleaned up at the end.

Data Flow Details:
1. The procedure starts by inserting a new record into `dw.Audit_Log` to track the ETL batch.
2. A temporary table `#InvalidRows` is created to store failed data quality checks.
3. Data quality checks are performed on `stg.Sales_Transactions`:
   - Records with NULL `Customer_ID` or non-positive `Quantity` are flagged as invalid.
4. Invalid rows are deleted from the staging table and counted.
5. The remaining valid records are joined with `dw.Dim_Customer` and `dw.Dim_Date` to enrich the data.
6. The transformed data is inserted into `dw.Fact_Sales`.
7. The staging table is truncated to prepare for the next batch.
8. Invalid records are logged in `dw.DQ_Failures` for traceability.
9. The audit log is updated with results and status.
10. Any errors are logged and the process is cleaned up.

Data Transformations:
- Calculates `Total_Sales_Amount` as `Quantity * Unit_Price`.
- Enriches each transaction with `Region_ID` from `dw.Dim_Date` and `Customer_Segment` from `dw.Dim_Customer`.
- Adds ETL metadata: `Load_Timestamp` and `Batch_ID`.
- Filters out records with missing or invalid data according to business rules.
- All transformations ensure that only high-quality, business-ready data is loaded into the fact table.

Data Mapping:

| Target Table Name | Target Column Name    | Source Table Name     | Source Column Name    | Remarks (1 to 1 mapping, Transformation, Validation)         |
|-------------------|----------------------|-----------------------|----------------------|--------------------------------------------------------------|
| dw.Fact_Sales     | Transaction_ID       | stg.Sales_Transactions| Transaction_ID       | 1 to 1 mapping                                               |
| dw.Fact_Sales     | Customer_ID          | stg.Sales_Transactions| Customer_ID          | 1 to 1 mapping; validated for NOT NULL                       |
| dw.Fact_Sales     | Product_ID           | stg.Sales_Transactions| Product_ID           | 1 to 1 mapping                                               |
| dw.Fact_Sales     | Sales_Date           | stg.Sales_Transactions| Sales_Date           | 1 to 1 mapping; joined to dw.Dim_Date for enrichment         |
| dw.Fact_Sales     | Quantity             | stg.Sales_Transactions| Quantity             | 1 to 1 mapping; validated for > 0                            |
| dw.Fact_Sales     | Unit_Price           | stg.Sales_Transactions| Unit_Price           | 1 to 1 mapping                                               |
| dw.Fact_Sales     | Total_Sales_Amount   | (calculated)          | Quantity, Unit_Price | Transformation: Quantity * Unit_Price                        |
| dw.Fact_Sales     | Region_ID            | dw.Dim_Date           | Region_ID            | Enriched via join on Sales_Date = Date_Value                 |
| dw.Fact_Sales     | Customer_Segment     | dw.Dim_Customer       | Customer_Segment     | Enriched via join on Customer_ID                             |
| dw.Fact_Sales     | Load_Timestamp       | (system)              | SYSDATETIME()        | Transformation: load timestamp                               |
| dw.Fact_Sales     | Batch_ID             | (variable)            | @batch_id            | Transformation: ETL batch tracking                           |

Technical Complexity:

| Parameter            | Value      |
|----------------------|-----------|
| Procedure Name       | dw.sp_load_sales_fact |
| Source Tables        | 3         |
| Target Tables        | 2         |
| Data Flows           | 4         |
| Transformations      | 5         |
| Joins and Filters    | 4         |
| Variables            | 7         |
| Parameters           | 0         |
| Dependencies         | 0         |
| Complexity Score     | 65        |

Key Outputs:
- The main output is a cleaned, validated, and enriched dataset loaded into `dw.Fact_Sales`, ready for analytics and reporting.
- Invalid records are logged in `dw.DQ_Failures` for data quality monitoring.
- Audit logs in `dw.Audit_Log` provide traceability and operational transparency for each ETL run.
- These outputs ensure business users have access to trustworthy sales data for decision-making and compliance.

apiCost: 0.0125 USD