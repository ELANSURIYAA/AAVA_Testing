=============================================
Author:        Ascendion AVA
Created on:    
Description:   Loads cleaned and validated sales transactions from staging into the sales fact table, applying business rules, audit logging, and data quality checks.
=============================================

Procedure Overview:
This stored procedure, `dw.sp_load_sales_fact`, is designed to automate the ETL (Extract, Transform, Load) process for sales transactions. It extracts data from the staging table (`stg.Sales_Transactions`), applies data quality checks and business transformations, and loads the cleaned data into the fact table (`dw.Fact_Sales`). The procedure also logs audit information, handles errors, and tracks data quality failures. This process ensures only valid and high-quality sales data is loaded into the data warehouse, supporting accurate reporting and analytics for business decision-making.

Logic Details:
- The procedure begins by initializing audit logging and capturing metadata such as batch ID and timestamps.
- It creates a temporary table to capture invalid rows based on business rules (e.g., missing Customer_ID, invalid Quantity).
- Invalid records are removed from the staging table and logged for data quality analysis.
- Valid, transformed records are loaded into the `dw.Fact_Sales` table, with additional fields such as calculated sales amount, region, and customer segment.
- The staging table is truncated after processing.
- Data quality failures are logged in a dedicated table (`dw.DQ_Failures`).
- The audit log is updated with the outcome, and errors are handled gracefully with logging and optional rethrowing for monitoring.

Data Flow Details:
1. The process starts by logging the initiation in the `dw.Audit_Log` table.
2. A temporary table `#InvalidRows` is created to capture validation failures.
3. Data quality checks are performed on `stg.Sales_Transactions`:
   - Transactions with missing `Customer_ID` or non-positive `Quantity` are flagged as invalid.
4. Invalid rows are deleted from the staging table and counted.
5. Valid rows are joined with dimension tables (`dw.Dim_Customer`, `dw.Dim_Date`) to enrich the data.
6. Transformed and enriched data is inserted into `dw.Fact_Sales`.
7. The staging table is truncated to prepare for the next batch.
8. Invalid rows are logged in `dw.DQ_Failures`.
9. The audit log is updated with results and status.
10. Any errors encountered are logged, and the process is cleaned up.

Data Transformations:
- Calculation of `Total_Sales_Amount` as `Quantity * Unit_Price`.
- Enrichment with `Region_ID` from `dw.Dim_Date` and `Customer_Segment` from `dw.Dim_Customer`.
- Addition of technical metadata fields: `Load_Timestamp` and `Batch_ID`.
- Data validation rules:
  - Reject transactions with missing `Customer_ID`.
  - Reject transactions with `Quantity <= 0`.
- Only validated and enriched records are loaded into the fact table.

Data Mapping:

| Target Table Name | Target Column Name    | Source Table Name      | Source Column Name    | Remarks                                      |
|-------------------|----------------------|------------------------|----------------------|----------------------------------------------|
| dw.Fact_Sales     | Transaction_ID       | stg.Sales_Transactions | Transaction_ID       | 1 to 1 mapping                              |
| dw.Fact_Sales     | Customer_ID          | stg.Sales_Transactions | Customer_ID          | 1 to 1 mapping (after validation)            |
| dw.Fact_Sales     | Product_ID           | stg.Sales_Transactions | Product_ID           | 1 to 1 mapping                              |
| dw.Fact_Sales     | Sales_Date           | stg.Sales_Transactions | Sales_Date           | 1 to 1 mapping                              |
| dw.Fact_Sales     | Quantity             | stg.Sales_Transactions | Quantity             | 1 to 1 mapping (after validation)            |
| dw.Fact_Sales     | Unit_Price           | stg.Sales_Transactions | Unit_Price           | 1 to 1 mapping                              |
| dw.Fact_Sales     | Total_Sales_Amount   | (calculated)           | Quantity, Unit_Price | Transformation: Quantity * Unit_Price        |
| dw.Fact_Sales     | Region_ID            | dw.Dim_Date            | Region_ID            | Joined on Sales_Date = Date_Value            |
| dw.Fact_Sales     | Customer_Segment     | dw.Dim_Customer        | Customer_Segment     | Joined on Customer_ID                        |
| dw.Fact_Sales     | Load_Timestamp       | (system)               | SYSDATETIME()        | Transformation: Load timestamp at insert     |
| dw.Fact_Sales     | Batch_ID             | (system)               | @batch_id            | Transformation: Unique batch identifier      |

Technical Complexity:

| Parameter         | Value    |
|-------------------|----------|
| Procedure Name    | dw.sp_load_sales_fact |
| Source Tables     | 3        |
| Target Tables     | 3        |
| Data Flows        | 4        |
| Transformations   | 4        |
| Joins and Filters | 4        |
| Variables         | 7        |
| Parameters        | 0        |
| Dependencies      | 0        |
| Complexity Score  | 65       |

Key Outputs:
- The main output is the populated `dw.Fact_Sales` table, containing only validated, enriched, and transformed sales transactions.
- Data quality failures are logged in `dw.DQ_Failures` for further analysis.
- Audit logs in `dw.Audit_Log` provide traceability and operational transparency.
- These outputs support downstream reporting, analytics, and business intelligence, ensuring only high-quality data is used for decision-making.

apiCost: 0.0125 USD