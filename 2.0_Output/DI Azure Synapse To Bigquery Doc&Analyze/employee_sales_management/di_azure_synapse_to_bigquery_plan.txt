=============================================
Author:        Ascendion AVA
Created on:   
Description:   Loads cleaned and validated sales transactions from staging to the sales fact table, with audit logging and data quality checks.
=============================================

1. Cost Estimation

   1.1 BigQuery Runtime Cost

   **Pricing Model:**  
   - BigQuery On-Demand Query Pricing: $5.00 per TB processed

   **Data Volumes (from environment details):**
   - stg.Sales_Transactions: ~700 GB
   - dw.Dim_Customer: ~150 GB
   - dw.Dim_Date: ~100 GB
   - dw.Fact_Sales (Target Table): ~1 TB
   - Total Estimated Storage Used: ~1.95 TB

   **Estimated Data Processed Per Run:**  
   - 10% of total: ~200–500 GB/query

   **Calculation:**
   - Lower Bound: 200 GB processed = 0.2 TB × $5.00 = **$1.00 per run**
   - Upper Bound: 500 GB processed = 0.5 TB × $5.00 = **$2.50 per run**
   - **Cost Per Run:** $1.00 – $2.50

   **Reasons:**
   - The cost is based on the amount of data scanned by queries, not on the size of the tables themselves.
   - The ETL process involves reading from the staging table, joining with two dimension tables, and inserting into the fact table.
   - Temporary/CTE logic and audit logging add minimal extra data processed.
   - Multiple queries (validation, insert, logging) are typically run as part of the ETL, but the main cost driver is the SELECT+JOIN+INSERT pipeline.
   - The range accounts for variance in query complexity and possible reprocessing for testing.

   **Summary Table:**

   | Item                     | Estimate         |
   |--------------------------|-----------------|
   | Data Processed per Run   | 200–500 GB      |
   | Cost per Run             | $1.00–$2.50 USD |
   | BigQuery Pricing         | $5.00/TB        |
   | Number of Queries        | 4–6 (main ETL, validation, audit, DQ log) |
   | Main Cost Driver         | ETL SELECT+JOIN |

   **apiCost: 0.0125 USD**

---

2. Code Fixing and Testing Effort Estimation

   2.1 BigQuery Identified Manual Code Fixes and Unit Testing Effort

   **Manual Code Fixes Required:**
   - Refactor temp table logic (`#InvalidRows`) to use CTEs or persistent tables.
   - Rewrite variable management (`DECLARE`, `SET`, `@@ROWCOUNT`) using BigQuery scripting.
   - Refactor TRY/CATCH error handling to BigQuery scripting’s EXCEPTION blocks or external orchestration.
   - Update all audit logging logic to use BigQuery scripting (multi-step INSERT/UPDATE).
   - Replace SQL Server-specific functions (`SYSDATETIME()`, `NEWID()`, `OBJECT_NAME(@@PROCID)`) with BigQuery equivalents.
   - Explicitly count inserted/rejected rows (no `@@ROWCOUNT` in BigQuery).
   - Review and test all business rule validations (e.g., NULL Customer_ID, invalid Quantity).
   - Update TRUNCATE/DELETE logic for staging table.
   - Ensure all joins, data type conversions, and enrichment logic match BigQuery syntax and semantics.
   - Migrate/validate DQ failure logging and audit log updates.

   **Testing Effort (Unit, Integration, Data Recon):**
   - Unit test each transformation and validation rule.
   - Integration test joins and enrichment logic.
   - Data reconciliation between Synapse and BigQuery outputs.
   - Test audit and DQ logging for correctness.
   - Validate error handling and process cleanup.
   - Regression test with sample and full data loads.

   **Effort Estimation Table:**

   | Task                                      | Estimated Hours |
   |-------------------------------------------|----------------|
   | Temp Table/CTE Refactor                   | 2              |
   | Variable & Control Flow Refactor          | 2              |
   | Audit/Error Logging Refactor              | 2              |
   | Function/Type Conversion                  | 1              |
   | Data Quality Validation Logic             | 1              |
   | Joins & Enrichment Logic                  | 1              |
   | DQ Failure & Audit Log Testing            | 1              |
   | Data Reconciliation Testing               | 2              |
   | Regression/Integration Testing            | 2              |
   | **Total**                                 | **14 hours**   |

   **Notes:**
   - The above estimate assumes a moderately experienced BigQuery developer familiar with Synapse and GCP.
   - Effort may increase if additional orchestration or external error handling is required.
   - Data reconciliation is critical to ensure business rule parity post-migration.

---

**apiCost: 0.0125 USD**

**Summary:**
- **BigQuery Runtime Cost per ETL Run:** $1.00–$2.50 USD (mainly driven by data processed; see table above)
- **Manual Code Fixing & Testing Effort:** ~14 hours (detailed breakdown above)
- **API Cost for this estimation:** 0.0125 USD

All estimates are based on the provided Synapse procedure, BigQuery environment details, and standard GCP pricing as of the latest input.