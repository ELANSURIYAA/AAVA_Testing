=============================================
Author:        AAVA
Created on:   
Description:   Loads sales fact table from staging, performs data quality validation, audit logging, and error handling in BigQuery.
=============================================

-- BigQuery SQL Script: Sales Fact Table Loading with Data Quality Validation and Audit Logging

-- This script replicates the logic of the Azure Synapse stored procedure for loading sales fact data,
-- including data quality checks, audit logging, error handling, and cleanup.

-- To execute: Use BigQuery scripting (DECLARE, BEGIN ... EXCEPTION, etc.)

CREATE OR REPLACE PROCEDURE dw_sp_load_sales_fact()
BEGIN
  -- 1. Variable Declarations
  DECLARE batch_id STRING DEFAULT GENERATE_UUID();
  DECLARE start_time DATETIME DEFAULT CURRENT_DATETIME();
  DECLARE end_time DATETIME;
  DECLARE rows_inserted INT64 DEFAULT 0;
  DECLARE rows_rejected INT64 DEFAULT 0;
  DECLARE error_message STRING;
  DECLARE proc_name STRING DEFAULT 'dw_sp_load_sales_fact';

  -- 2. Start Audit Logging
  INSERT INTO dw.Audit_Log (
    Batch_ID,
    Procedure_Name,
    Start_Time,
    Status,
    Message
  )
  VALUES (
    batch_id,
    proc_name,
    start_time,
    'STARTED',
    'Sales Fact Load Initiated'
  );

  -- 3. Data Quality Checks (as CTEs)
  WITH
    InvalidRows_MissingCustomer AS (
      SELECT Transaction_ID, 'Missing CustomerID' AS Reason
      FROM stg.Sales_Transactions
      WHERE Customer_ID IS NULL
    ),
    InvalidRows_InvalidQuantity AS (
      SELECT Transaction_ID, 'Invalid Quantity' AS Reason
      FROM stg.Sales_Transactions
      WHERE Quantity <= 0
    ),
    InvalidRows AS (
      SELECT * FROM InvalidRows_MissingCustomer
      UNION ALL
      SELECT * FROM InvalidRows_InvalidQuantity
    ),
    -- 4. Cleaned Transactions (exclude invalids)
    Cleaned_Transactions AS (
      SELECT s.*
      FROM stg.Sales_Transactions s
      LEFT JOIN InvalidRows i
        ON s.Transaction_ID = i.Transaction_ID
      WHERE i.Transaction_ID IS NULL
    ),
    -- 5. Transformed Data for Fact Table
    Transformed AS (
      SELECT
        s.Transaction_ID,
        s.Customer_ID,
        s.Product_ID,
        s.Sales_Date,
        s.Quantity,
        s.Unit_Price,
        s.Quantity * s.Unit_Price AS Total_Sales_Amount,
        d.Region_ID,
        c.Customer_Segment,
        CURRENT_DATETIME() AS Load_Timestamp,
        batch_id AS Batch_ID
      FROM Cleaned_Transactions s
      INNER JOIN dw.Dim_Customer c
        ON s.Customer_ID = c.Customer_ID
      INNER JOIN dw.Dim_Date d
        ON DATE(s.Sales_Date) = d.Date_Value
    )

  -- 6. Insert Cleaned Data into Fact Table
  INSERT INTO dw.Fact_Sales (
    Transaction_ID,
    Customer_ID,
    Product_ID,
    Sales_Date,
    Quantity,
    Unit_Price,
    Total_Sales_Amount,
    Region_ID,
    Customer_Segment,
    Load_Timestamp,
    Batch_ID
  )
  SELECT *
  FROM Transformed;

  -- 7. Count Inserted Rows
  SET rows_inserted = (SELECT COUNT(*) FROM Transformed);

  -- 8. Delete All Rows from Staging Table (truncate equivalent)
  DELETE FROM stg.Sales_Transactions WHERE TRUE;

  -- 9. Log Validation Failures
  INSERT INTO dw.DQ_Failures (
    Transaction_ID,
    Failure_Reason,
    Logged_Timestamp,
    Batch_ID
  )
  SELECT
    Transaction_ID,
    Reason,
    CURRENT_DATETIME(),
    batch_id
  FROM InvalidRows;

  -- 10. Count Rejected Rows
  SET rows_rejected = (SELECT COUNT(*) FROM InvalidRows);

  -- 11. End Audit Logging
  SET end_time = CURRENT_DATETIME();
  UPDATE dw.Audit_Log
  SET
    End_Time = end_time,
    Rows_Inserted = rows_inserted,
    Rows_Rejected = rows_rejected,
    Status = 'COMPLETED',
    Message = CONCAT('Inserted ', CAST(rows_inserted AS STRING), ' rows; Rejected ', CAST(rows_rejected AS STRING), ' rows.')
  WHERE Batch_ID = batch_id;

EXCEPTION WHEN ERROR THEN
  -- 12. Error Handling & Audit Logging
  SET end_time = CURRENT_DATETIME();
  SET error_message = @@error.message;
  UPDATE dw.Audit_Log
  SET
    End_Time = end_time,
    Status = 'FAILED',
    Message = error_message
  WHERE Batch_ID = batch_id;
END;

-- Notes:
-- - All table references are generic, not dataset-specific.
-- - Data quality checks use CTEs for modularity and performance.
-- - Temporary table logic is replaced by CTEs.
-- - Error handling uses BigQuery scripting EXCEPTION block.
-- - All date/time and UUID functions use BigQuery equivalents.
-- - Audit logging and DQ failure logging are implemented as per original logic.
-- - For large tables, consider partitioning and clustering for performance.

-- End of BigQuery SQL Script

API Cost Consumed in dollars: 0.0040 USD