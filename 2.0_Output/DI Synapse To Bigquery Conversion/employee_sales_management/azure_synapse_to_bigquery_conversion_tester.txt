=============================================
Author:    AAVA
Created on:    
Description:   Loads sales fact table from staging, performs data quality validation, audit logging, and error handling in BigQuery.
=============================================

Test Case List:
| Test Case ID | Test Case Description | Expected Outcome |
|--------------|--------------------|----------------|
| TC01 | Happy path: All staging rows valid, all dimension lookups succeed | All rows inserted into dw.Fact_Sales, none in dw.DQ_Failures, Audit_Log shows correct counts |
| TC02 | Data quality: Some rows with NULL Customer_ID | Rows with NULL Customer_ID rejected, logged in DQ_Failures, not in Fact_Sales, Audit_Log reflects counts |
| TC03 | Data quality: Some rows with Quantity <= 0 | Rows with Quantity <= 0 rejected, logged in DQ_Failures, not in Fact_Sales, Audit_Log reflects counts |
| TC04 | Edge: All rows invalid (all fail DQ checks) | No rows inserted into Fact_Sales, all in DQ_Failures, Audit_Log shows 0 inserted, all rejected |
| TC05 | Edge: Empty staging table | No rows inserted or rejected, Audit_Log shows 0 for both, no DQ_Failures |
| TC06 | Edge: Customer_ID not found in Dim_Customer | Rows with missing Customer_ID in Dim_Customer not inserted, not rejected as DQ failure, not in Fact_Sales |
| TC07 | Edge: Sales_Date not found in Dim_Date | Rows with missing date in Dim_Date not inserted, not rejected as DQ failure, not in Fact_Sales |
| TC08 | Error handling: Simulate error during insert | Audit_Log status set to 'FAILED', error message captured |
| TC09 | Data type: Unexpected data format (e.g., string in Quantity) | Procedure fails, error logged in Audit_Log |
| TC10 | Missing columns in staging | Procedure fails, error logged in Audit_Log |

---

Pytest Script for Each Test Case

```python
================================
Author: AAVA
Created on: 
Description: Pytest script for validating the BigQuery sales fact loading procedure, covering data quality, transformation, audit logging, and error handling.
================================

import pytest
import pandas as pd
from sqlalchemy import create_engine, text
from datetime import datetime
import uuid

# Helper functions and fixtures

@pytest.fixture(scope="function")
def bq_engine():
    # Replace with your BigQuery SQLAlchemy connection string
    # Example: "bigquery://project_id/dataset"
    engine = create_engine("bigquery://your_project/your_dataset")
    yield engine
    engine.dispose()

@pytest.fixture(scope="function")
def setup_dim_tables(bq_engine):
    # Insert minimal dimension data for lookups
    customer_df = pd.DataFrame([
        {"Customer_ID": 1, "Customer_Segment": "Retail"},
        {"Customer_ID": 2, "Customer_Segment": "Wholesale"},
    ])
    date_df = pd.DataFrame([
        {"Date_Value": datetime(2023, 1, 1), "Region_ID": 10},
        {"Date_Value": datetime(2023, 1, 2), "Region_ID": 20},
    ])
    customer_df.to_sql("Dim_Customer", bq_engine, schema="dw", if_exists="replace", index=False)
    date_df.to_sql("Dim_Date", bq_engine, schema="dw", if_exists="replace", index=False)
    yield
    bq_engine.execute(text("DELETE FROM dw.Dim_Customer WHERE TRUE"))
    bq_engine.execute(text("DELETE FROM dw.Dim_Date WHERE TRUE"))

@pytest.fixture(scope="function")
def cleanup_tables(bq_engine):
    # Clean all target tables before and after each test
    for table in [
        "Fact_Sales",
        "Audit_Log",
        "DQ_Failures",
        "Sales_Transactions"
    ]:
        bq_engine.execute(text(f"DELETE FROM dw.{table} WHERE TRUE"))
        bq_engine.execute(text(f"DELETE FROM stg.{table} WHERE TRUE"))
    yield
    for table in [
        "Fact_Sales",
        "Audit_Log",
        "DQ_Failures",
        "Sales_Transactions"
    ]:
        bq_engine.execute(text(f"DELETE FROM dw.{table} WHERE TRUE"))
        bq_engine.execute(text(f"DELETE FROM stg.{table} WHERE TRUE"))

def insert_staging_data(bq_engine, data):
    df = pd.DataFrame(data)
    df.to_sql("Sales_Transactions", bq_engine, schema="stg", if_exists="replace", index=False)

def get_table_df(bq_engine, table, schema="dw"):
    return pd.read_sql(f"SELECT * FROM {schema}.{table}", bq_engine)

def run_procedure(bq_engine):
    # Run the BigQuery procedure
    bq_engine.execute(text("CALL dw_sp_load_sales_fact()"))

# Test Cases

def test_TC01_happy_path(bq_engine, setup_dim_tables, cleanup_tables):
    # All valid rows
    data = [
        {
            "Transaction_ID": 1001,
            "Customer_ID": 1,
            "Product_ID": 101,
            "Sales_Date": "2023-01-01",
            "Quantity": 2,
            "Unit_Price": 50.0
        },
        {
            "Transaction_ID": 1002,
            "Customer_ID": 2,
            "Product_ID": 102,
            "Sales_Date": "2023-01-02",
            "Quantity": 1,
            "Unit_Price": 100.0
        }
    ]
    insert_staging_data(bq_engine, data)
    run_procedure(bq_engine)
    fact = get_table_df(bq_engine, "Fact_Sales")
    dq = get_table_df(bq_engine, "DQ_Failures")
    audit = get_table_df(bq_engine, "Audit_Log")
    assert len(fact) == 2
    assert len(dq) == 0
    assert audit.iloc[-1]["Rows_Inserted"] == 2
    assert audit.iloc[-1]["Rows_Rejected"] == 0
    assert audit.iloc[-1]["Status"] == "COMPLETED"

def test_TC02_null_customer_id(bq_engine, setup_dim_tables, cleanup_tables):
    # One row with NULL Customer_ID
    data = [
        {
            "Transaction_ID": 1003,
            "Customer_ID": None,
            "Product_ID": 103,
            "Sales_Date": "2023-01-01",
            "Quantity": 2,
            "Unit_Price": 30.0
        }
    ]
    insert_staging_data(bq_engine, data)
    run_procedure(bq_engine)
    fact = get_table_df(bq_engine, "Fact_Sales")
    dq = get_table_df(bq_engine, "DQ_Failures")
    assert len(fact) == 0
    assert len(dq) == 1
    assert dq.iloc[0]["Failure_Reason"] == "Missing CustomerID"

def test_TC03_invalid_quantity(bq_engine, setup_dim_tables, cleanup_tables):
    # One row with Quantity <= 0
    data = [
        {
            "Transaction_ID": 1004,
            "Customer_ID": 1,
            "Product_ID": 104,
            "Sales_Date": "2023-01-01",
            "Quantity": 0,
            "Unit_Price": 25.0
        }
    ]
    insert_staging_data(bq_engine, data)
    run_procedure(bq_engine)
    fact = get_table_df(bq_engine, "Fact_Sales")
    dq = get_table_df(bq_engine, "DQ_Failures")
    assert len(fact) == 0
    assert len(dq) == 1
    assert dq.iloc[0]["Failure_Reason"] == "Invalid Quantity"

def test_TC04_all_invalid(bq_engine, setup_dim_tables, cleanup_tables):
    # All rows invalid
    data = [
        {
            "Transaction_ID": 1005,
            "Customer_ID": None,
            "Product_ID": 105,
            "Sales_Date": "2023-01-01",
            "Quantity": 0,
            "Unit_Price": 10.0
        }
    ]
    insert_staging_data(bq_engine, data)
    run_procedure(bq_engine)
    fact = get_table_df(bq_engine, "Fact_Sales")
    dq = get_table_df(bq_engine, "DQ_Failures")
    audit = get_table_df(bq_engine, "Audit_Log")
    assert len(fact) == 0
    assert len(dq) == 1
    assert audit.iloc[-1]["Rows_Inserted"] == 0
    assert audit.iloc[-1]["Rows_Rejected"] == 1

def test_TC05_empty_staging(bq_engine, setup_dim_tables, cleanup_tables):
    # No data in staging
    insert_staging_data(bq_engine, [])
    run_procedure(bq_engine)
    fact = get_table_df(bq_engine, "Fact_Sales")
    dq = get_table_df(bq_engine, "DQ_Failures")
    audit = get_table_df(bq_engine, "Audit_Log")
    assert len(fact) == 0
    assert len(dq) == 0
    assert audit.iloc[-1]["Rows_Inserted"] == 0
    assert audit.iloc[-1]["Rows_Rejected"] == 0

def test_TC06_missing_customer_in_dim(bq_engine, setup_dim_tables, cleanup_tables):
    # Customer_ID not in Dim_Customer
    data = [
        {
            "Transaction_ID": 1006,
            "Customer_ID": 999,
            "Product_ID": 106,
            "Sales_Date": "2023-01-01",
            "Quantity": 1,
            "Unit_Price": 20.0
        }
    ]
    insert_staging_data(bq_engine, data)
    run_procedure(bq_engine)
    fact = get_table_df(bq_engine, "Fact_Sales")
    dq = get_table_df(bq_engine, "DQ_Failures")
    # Not in DQ_Failures (not a DQ rule), not in Fact_Sales (lookup fails)
    assert len(fact) == 0
    assert len(dq) == 0

def test_TC07_missing_date_in_dim(bq_engine, setup_dim_tables, cleanup_tables):
    # Sales_Date not in Dim_Date
    data = [
        {
            "Transaction_ID": 1007,
            "Customer_ID": 1,
            "Product_ID": 107,
            "Sales_Date": "2023-12-31",
            "Quantity": 1,
            "Unit_Price": 15.0
        }
    ]
    insert_staging_data(bq_engine, data)
    run_procedure(bq_engine)
    fact = get_table_df(bq_engine, "Fact_Sales")
    dq = get_table_df(bq_engine, "DQ_Failures")
    assert len(fact) == 0
    assert len(dq) == 0

def test_TC08_error_handling(bq_engine, setup_dim_tables, cleanup_tables, monkeypatch):
    # Simulate error by patching procedure call to raise exception
    def error_run(*args, **kwargs):
        raise Exception("Simulated failure")
    monkeypatch.setattr(bq_engine, "execute", error_run)
    with pytest.raises(Exception):
        run_procedure(bq_engine)
    # Check Audit_Log for 'FAILED' status (if partial insert occurred before error)
    # This is a simulation; in real BQ, error handling must be validated via logs

def test_TC09_unexpected_data_format(bq_engine, setup_dim_tables, cleanup_tables):
    # Insert string in Quantity
    data = [
        {
            "Transaction_ID": 1008,
            "Customer_ID": 1,
            "Product_ID": 108,
            "Sales_Date": "2023-01-01",
            "Quantity": "bad_data",
            "Unit_Price": 10.0
        }
    ]
    insert_staging_data(bq_engine, data)
    with pytest.raises(Exception):
        run_procedure(bq_engine)
    audit = get_table_df(bq_engine, "Audit_Log")
    assert audit.iloc[-1]["Status"] == "FAILED"

def test_TC10_missing_columns(bq_engine, setup_dim_tables, cleanup_tables):
    # Missing Quantity column
    data = [
        {
            "Transaction_ID": 1009,
            "Customer_ID": 1,
            "Product_ID": 109,
            "Sales_Date": "2023-01-01",
            "Unit_Price": 10.0
        }
    ]
    df = pd.DataFrame(data)
    # Write with missing column
    df.to_sql("Sales_Transactions", bq_engine, schema="stg", if_exists="replace", index=False)
    with pytest.raises(Exception):
        run_procedure(bq_engine)
    audit = get_table_df(bq_engine, "Audit_Log")
    assert audit.iloc[-1]["Status"] == "FAILED"
```

---

API Cost Estimation

apiCost: 0.0040 USD