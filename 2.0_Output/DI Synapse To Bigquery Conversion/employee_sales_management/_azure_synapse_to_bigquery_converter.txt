=============================================
Author:        AAVA
Created on:   
Description:   Loads cleaned sales transactions from staging into the sales fact table, performs data quality checks, logs audit and DQ failures, and manages batch metadata.
=============================================

-- BigQuery SQL Script: Load Sales Fact Table with Data Quality Checks and Auditing

DECLARE batch_id STRING DEFAULT GENERATE_UUID();
DECLARE start_time TIMESTAMP DEFAULT CURRENT_TIMESTAMP();
DECLARE end_time TIMESTAMP;
DECLARE rows_inserted INT64 DEFAULT 0;
DECLARE rows_rejected INT64 DEFAULT 0;
DECLARE error_message STRING;
DECLARE proc_name STRING DEFAULT 'sp_load_sales_fact';

BEGIN

  -- 1. Start Audit Logging
  INSERT INTO `dw.Audit_Log`
  (
    Batch_ID,
    Procedure_Name,
    Start_Time,
    Status,
    Message
  )
  VALUES
  (
    batch_id,
    proc_name,
    start_time,
    'STARTED',
    'Sales Fact Load Initiated'
  );

  -- 2. Temporary Table for Validation Failures (using temp table via scripting)
  CREATE TEMP TABLE InvalidRows AS
  SELECT CAST(NULL AS INT64) AS Transaction_ID, CAST(NULL AS STRING) AS Reason
  WHERE FALSE;

  -- 3. Basic Data Quality Checks
  INSERT INTO InvalidRows (Transaction_ID, Reason)
  SELECT Transaction_ID, 'Missing CustomerID'
  FROM `stg.Sales_Transactions`
  WHERE Customer_ID IS NULL;

  INSERT INTO InvalidRows (Transaction_ID, Reason)
  SELECT Transaction_ID, 'Invalid Quantity'
  FROM `stg.Sales_Transactions`
  WHERE Quantity <= 0;

  -- 4. Delete Invalid Rows from Staging for This Batch
  -- BigQuery doesn't support DELETE with JOIN directly; use WHERE IN
  DELETE FROM `stg.Sales_Transactions`
  WHERE Transaction_ID IN (
    SELECT Transaction_ID FROM InvalidRows
  );

  SET rows_rejected = (SELECT COUNT(1) FROM InvalidRows);

  -- 5. Load Cleaned Data into Fact Table
  INSERT INTO `dw.Fact_Sales`
  (
    Transaction_ID,
    Customer_ID,
    Product_ID,
    Sales_Date,
    Quantity,
    Unit_Price,
    Total_Sales_Amount,
    Region_ID,
    Customer_Segment,
    Load_Timestamp,
    Batch_ID
  )
  WITH transformed AS (
    SELECT
      s.Transaction_ID,
      s.Customer_ID,
      s.Product_ID,
      s.Sales_Date,
      s.Quantity,
      s.Unit_Price,
      s.Quantity * s.Unit_Price AS Total_Sales_Amount,
      d.Region_ID,
      c.Customer_Segment,
      CURRENT_TIMESTAMP() AS Load_Timestamp,
      batch_id AS Batch_ID
    FROM `stg.Sales_Transactions` s
    INNER JOIN `dw.Dim_Customer` c
      ON s.Customer_ID = c.Customer_ID
    INNER JOIN `dw.Dim_Date` d
      ON DATE(s.Sales_Date) = d.Date_Value
  )
  SELECT * FROM transformed;

  SET rows_inserted = (SELECT COUNT(1) FROM transformed);

  -- 6. Archive or Truncate Staging Table (optional)
  TRUNCATE TABLE `stg.Sales_Transactions`;

  -- 7. Log Validation Failures
  INSERT INTO `dw.DQ_Failures`
  (
    Transaction_ID,
    Failure_Reason,
    Logged_Timestamp,
    Batch_ID
  )
  SELECT 
    Transaction_ID,
    Reason,
    CURRENT_TIMESTAMP(),
    batch_id
  FROM InvalidRows;

  -- 8. End Audit Log
  SET end_time = CURRENT_TIMESTAMP();

  UPDATE `dw.Audit_Log`
  SET 
    End_Time = end_time,
    Rows_Inserted = rows_inserted,
    Rows_Rejected = rows_rejected,
    Status = 'COMPLETED',
    Message = CONCAT('Inserted ', CAST(rows_inserted AS STRING), ' rows; Rejected ', CAST(rows_rejected AS STRING), ' rows.')
  WHERE Batch_ID = batch_id;

EXCEPTION WHEN ERROR THEN
  -- 9. Error Handling
  SET end_time = CURRENT_TIMESTAMP();
  SET error_message = ERROR_MESSAGE();

  UPDATE `dw.Audit_Log`
  SET 
    End_Time = end_time,
    Status = 'FAILED',
    Message = error_message
  WHERE Batch_ID = batch_id;

  -- Optionally re-raise error for pipeline monitoring
  RAISE USING MESSAGE = error_message;

END;

-- Notes:
-- - Uses BigQuery scripting for procedural logic.
-- - Temporary tables are implemented as script-scoped temp tables.
-- - All table references are generic; adjust dataset names as needed.
-- - Error handling and audit logging are implemented using BigQuery scripting constructs.

API Cost Consumed in dollars: 0.0047 USD