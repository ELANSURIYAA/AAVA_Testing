================================
Author: AAVA
Created on: 
Description: Unit test cases and Pytest script for validating BigQuery sales fact loading procedure, covering data quality, transformation, audit logging, and error handling.
================================

Test Case List:

| Test Case ID | Description                                                                                     | Expected Outcome                                                                                  |
|--------------|------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------|
| TC01         | Happy path: All sales transactions valid, correct dimension lookups                             | All rows inserted into Fact_Sales, Audit_Log status COMPLETED, no DQ_Failures                    |
| TC02         | Data quality: Transactions with NULL Customer_ID                                                | Those rows rejected, logged in DQ_Failures, not inserted into Fact_Sales                         |
| TC03         | Data quality: Transactions with Quantity <= 0                                                   | Those rows rejected, logged in DQ_Failures, not inserted into Fact_Sales                         |
| TC04         | Edge case: Empty staging table                                                                 | No rows inserted, Audit_Log shows 0 inserted/rejected, no DQ_Failures                            |
| TC05         | Edge case: All transactions invalid                                                            | All rows rejected, logged in DQ_Failures, Fact_Sales unchanged                                   |
| TC06         | Edge case: Missing dimension table row (Customer_ID not found in Dim_Customer)                 | Row not inserted into Fact_Sales, not logged as DQ_Failure (only staging validation is logged)    |
| TC07         | Error handling: Simulate error during insert (e.g., missing column in Fact_Sales)              | Audit_Log status FAILED, error message logged                                                    |
| TC08         | Boundary: Large batch with mixed valid/invalid transactions                                    | Only valid rows inserted, invalid rows logged, Audit_Log reflects correct counts                  |
| TC09         | Data transformation: Validate Total_Sales_Amount calculation accuracy                          | Inserted rows have correct Total_Sales_Amount                                                    |
| TC10         | Audit logging: Ensure Batch_ID, timestamps, and status are correctly recorded                  | Audit_Log and Fact_Sales have correct Batch_ID, timestamps, and status                           |

Pytest Script:

```python
================================
Author: AAVA
Created on: 
Description: Pytest script for validating BigQuery sales fact ETL procedure, including data quality, transformation, audit logging, and error handling.
================================

import pytest
import pandas as pd
from sqlalchemy import create_engine, text
from datetime import datetime
import uuid

# Helper functions for test setup/teardown
def setup_test_tables(engine):
    # Create all necessary tables with minimal schema for testing
    with engine.begin() as conn:
        conn.execute(text("""
            CREATE OR REPLACE TABLE stg_Sales_Transactions (
                Transaction_ID INT64,
                Customer_ID INT64,
                Product_ID INT64,
                Sales_Date DATETIME,
                Quantity INT64,
                Unit_Price FLOAT64
            );
        """))
        conn.execute(text("""
            CREATE OR REPLACE TABLE dw_Dim_Customer (
                Customer_ID INT64,
                Customer_Segment STRING
            );
        """))
        conn.execute(text("""
            CREATE OR REPLACE TABLE dw_Dim_Date (
                Date_Value DATE,
                Region_ID STRING
            );
        """))
        conn.execute(text("""
            CREATE OR REPLACE TABLE dw_Fact_Sales (
                Transaction_ID INT64,
                Customer_ID INT64,
                Product_ID INT64,
                Sales_Date DATETIME,
                Quantity INT64,
                Unit_Price FLOAT64,
                Total_Sales_Amount FLOAT64,
                Region_ID STRING,
                Customer_Segment STRING,
                Load_Timestamp DATETIME,
                Batch_ID STRING
            );
        """))
        conn.execute(text("""
            CREATE OR REPLACE TABLE dw_Audit_Log (
                Batch_ID STRING,
                Procedure_Name STRING,
                Start_Time DATETIME,
                End_Time DATETIME,
                Rows_Inserted INT64,
                Rows_Rejected INT64,
                Status STRING,
                Message STRING
            );
        """))
        conn.execute(text("""
            CREATE OR REPLACE TABLE dw_DQ_Failures (
                Transaction_ID INT64,
                Failure_Reason STRING,
                Logged_Timestamp DATETIME,
                Batch_ID STRING
            );
        """))

def teardown_test_tables(engine):
    # Drop all test tables
    with engine.begin() as conn:
        conn.execute(text("DROP TABLE IF EXISTS stg_Sales_Transactions;"))
        conn.execute(text("DROP TABLE IF EXISTS dw_Dim_Customer;"))
        conn.execute(text("DROP TABLE IF EXISTS dw_Dim_Date;"))
        conn.execute(text("DROP TABLE IF EXISTS dw_Fact_Sales;"))
        conn.execute(text("DROP TABLE IF EXISTS dw_Audit_Log;"))
        conn.execute(text("DROP TABLE IF EXISTS dw_DQ_Failures;"))

def insert_dataframe(engine, table_name, df):
    # Insert a pandas DataFrame into a BigQuery table using SQLAlchemy
    if df.empty:
        return
    cols = ', '.join(df.columns)
    values = ', '.join([':' + col for col in df.columns])
    sql = f"INSERT INTO {table_name} ({cols}) VALUES ({values})"
    with engine.begin() as conn:
        for _, row in df.iterrows():
            conn.execute(text(sql), **row.to_dict())

@pytest.fixture(scope="function")
def bq_engine():
    # Replace with your BigQuery SQLAlchemy connection string
    engine = create_engine("bigquery://project_id")
    setup_test_tables(engine)
    yield engine
    teardown_test_tables(engine)

def run_procedure(engine):
    # Simulate running the BigQuery stored procedure
    # For test purposes, we will execute the SQL logic step by step
    # (In production, you would call the procedure directly)
    batch_id = str(uuid.uuid4())
    start_time = datetime.now()
    proc_name = "dw.sp_load_sales_fact"
    # 1. Start Audit Log
    with engine.begin() as conn:
        conn.execute(text("""
            INSERT INTO dw_Audit_Log (Batch_ID, Procedure_Name, Start_Time, Status, Message)
            VALUES (:batch_id, :proc_name, :start_time, 'STARTED', 'Sales Fact Load Initiated')
        """), batch_id=batch_id, proc_name=proc_name, start_time=start_time)
    # 2. Data Quality Validation
    invalid_rows = []
    with engine.begin() as conn:
        result = conn.execute(text("""
            SELECT Transaction_ID FROM stg_Sales_Transactions WHERE Customer_ID IS NULL
        """))
        for row in result:
            invalid_rows.append({'Transaction_ID': row.Transaction_ID, 'Reason': 'Missing CustomerID'})
        result = conn.execute(text("""
            SELECT Transaction_ID FROM stg_Sales_Transactions WHERE Quantity <= 0
        """))
        for row in result:
            invalid_rows.append({'Transaction_ID': row.Transaction_ID, 'Reason': 'Invalid Quantity'})
    # 3. Cleaned Transactions
    cleaned_ids = set()
    with engine.begin() as conn:
        result = conn.execute(text("""
            SELECT Transaction_ID FROM stg_Sales_Transactions
        """))
        all_ids = set(row.Transaction_ID for row in result)
        invalid_ids = set(row['Transaction_ID'] for row in invalid_rows)
        cleaned_ids = all_ids - invalid_ids
    # 4. Transformed Data
    rows_inserted = 0
    transformed_rows = []
    with engine.begin() as conn:
        for tid in cleaned_ids:
            result = conn.execute(text("""
                SELECT s.Transaction_ID, s.Customer_ID, s.Product_ID, s.Sales_Date, s.Quantity, s.Unit_Price,
                       s.Quantity * s.Unit_Price AS Total_Sales_Amount,
                       d.Region_ID, c.Customer_Segment
                FROM stg_Sales_Transactions s
                INNER JOIN dw_Dim_Customer c ON s.Customer_ID = c.Customer_ID
                INNER JOIN dw_Dim_Date d ON DATE(s.Sales_Date) = d.Date_Value
                WHERE s.Transaction_ID = :tid
            """), tid=tid)
            for row in result:
                transformed_rows.append({
                    'Transaction_ID': row.Transaction_ID,
                    'Customer_ID': row.Customer_ID,
                    'Product_ID': row.Product_ID,
                    'Sales_Date': row.Sales_Date,
                    'Quantity': row.Quantity,
                    'Unit_Price': row.Unit_Price,
                    'Total_Sales_Amount': row.Total_Sales_Amount,
                    'Region_ID': row.Region_ID,
                    'Customer_Segment': row.Customer_Segment,
                    'Load_Timestamp': datetime.now(),
                    'Batch_ID': batch_id
                })
    # 5. Insert Valid Data
    df_transformed = pd.DataFrame(transformed_rows)
    insert_dataframe(engine, "dw_Fact_Sales", df_transformed)
    rows_inserted = len(df_transformed)
    # 6. Delete All Rows from Staging
    with engine.begin() as conn:
        conn.execute(text("DELETE FROM stg_Sales_Transactions WHERE TRUE"))
    # 7. Log Validation Failures
    df_invalid = pd.DataFrame(invalid_rows)
    if not df_invalid.empty:
        df_invalid['Logged_Timestamp'] = datetime.now()
        df_invalid['Batch_ID'] = batch_id
        insert_dataframe(engine, "dw_DQ_Failures", df_invalid)
    rows_rejected = len(df_invalid)
    # 8. End Audit Log
    end_time = datetime.now()
    with engine.begin() as conn:
        conn.execute(text("""
            UPDATE dw_Audit_Log
            SET End_Time = :end_time,
                Rows_Inserted = :rows_inserted,
                Rows_Rejected = :rows_rejected,
                Status = 'COMPLETED',
                Message = :msg
            WHERE Batch_ID = :batch_id
        """), end_time=end_time, rows_inserted=rows_inserted, rows_rejected=rows_rejected,
           msg=f"Inserted {rows_inserted} rows; Rejected {rows_rejected} rows.", batch_id=batch_id)
    return batch_id

# Test Cases

def test_TC01_happy_path(bq_engine):
    # All valid transactions
    stg_df = pd.DataFrame([
        {'Transaction_ID': 1, 'Customer_ID': 10, 'Product_ID': 100, 'Sales_Date': datetime(2023,1,1,10), 'Quantity': 2, 'Unit_Price': 50.0},
        {'Transaction_ID': 2, 'Customer_ID': 11, 'Product_ID': 101, 'Sales_Date': datetime(2023,1,2,11), 'Quantity': 5, 'Unit_Price': 20.0}
    ])
    dim_customer_df = pd.DataFrame([
        {'Customer_ID': 10, 'Customer_Segment': 'Retail'},
        {'Customer_ID': 11, 'Customer_Segment': 'Wholesale'}
    ])
    dim_date_df = pd.DataFrame([
        {'Date_Value': datetime(2023,1,1).date(), 'Region_ID': 'East'},
        {'Date_Value': datetime(2023,1,2).date(), 'Region_ID': 'West'}
    ])
    insert_dataframe(bq_engine, "stg_Sales_Transactions", stg_df)
    insert_dataframe(bq_engine, "dw_Dim_Customer", dim_customer_df)
    insert_dataframe(bq_engine, "dw_Dim_Date", dim_date_df)
    batch_id = run_procedure(bq_engine)
    # Validate Fact_Sales
    with bq_engine.begin() as conn:
        result = conn.execute(text("SELECT * FROM dw_Fact_Sales"))
        rows = result.fetchall()
        assert len(rows) == 2
        assert all(row.Total_Sales_Amount == row.Quantity * row.Unit_Price for row in rows)
    # Validate Audit_Log
    with bq_engine.begin() as conn:
        result = conn.execute(text("SELECT * FROM dw_Audit_Log WHERE Batch_ID = :batch_id"), batch_id=batch_id)
        row = result.fetchone()
        assert row.Status == 'COMPLETED'
        assert row.Rows_Inserted == 2
        assert row.Rows_Rejected == 0
    # Validate DQ_Failures
    with bq_engine.begin() as conn:
        result = conn.execute(text("SELECT * FROM dw_DQ_Failures"))
        assert result.rowcount == 0

def test_TC02_null_customer_id(bq_engine):
    # Transaction with NULL Customer_ID
    stg_df = pd.DataFrame([
        {'Transaction_ID': 3, 'Customer_ID': None, 'Product_ID': 102, 'Sales_Date': datetime(2023,1,3,12), 'Quantity': 3, 'Unit_Price': 30.0}
    ])
    dim_customer_df = pd.DataFrame([
        {'Customer_ID': 12, 'Customer_Segment': 'Retail'}
    ])
    dim_date_df = pd.DataFrame([
        {'Date_Value': datetime(2023,1,3).date(), 'Region_ID': 'North'}
    ])
    insert_dataframe(bq_engine, "stg_Sales_Transactions", stg_df)
    insert_dataframe(bq_engine, "dw_Dim_Customer", dim_customer_df)
    insert_dataframe(bq_engine, "dw_Dim_Date", dim_date_df)
    batch_id = run_procedure(bq_engine)
    # Validate Fact_Sales
    with bq_engine.begin() as conn:
        result = conn.execute(text("SELECT * FROM dw_Fact_Sales"))
        assert result.rowcount == 0
    # Validate DQ_Failures
    with bq_engine.begin() as conn:
        result = conn.execute(text("SELECT * FROM dw_DQ_Failures WHERE Batch_ID = :batch_id"), batch_id=batch_id)
        rows = result.fetchall()
        assert len(rows) == 1
        assert rows[0].Failure_Reason == 'Missing CustomerID'

def test_TC03_invalid_quantity(bq_engine):
    # Transaction with Quantity <= 0
    stg_df = pd.DataFrame([
        {'Transaction_ID': 4, 'Customer_ID': 13, 'Product_ID': 103, 'Sales_Date': datetime(2023,1,4,13), 'Quantity': 0, 'Unit_Price': 40.0}
    ])
    dim_customer_df = pd.DataFrame([
        {'Customer_ID': 13, 'Customer_Segment': 'Retail'}
    ])
    dim_date_df = pd.DataFrame([
        {'Date_Value': datetime(2023,1,4).date(), 'Region_ID': 'South'}
    ])
    insert_dataframe(bq_engine, "stg_Sales_Transactions", stg_df)
    insert_dataframe(bq_engine, "dw_Dim_Customer", dim_customer_df)
    insert_dataframe(bq_engine, "dw_Dim_Date", dim_date_df)
    batch_id = run_procedure(bq_engine)
    # Validate Fact_Sales
    with bq_engine.begin() as conn:
        result = conn.execute(text("SELECT * FROM dw_Fact_Sales"))
        assert result.rowcount == 0
    # Validate DQ_Failures
    with bq_engine.begin() as conn:
        result = conn.execute(text("SELECT * FROM dw_DQ_Failures WHERE Batch_ID = :batch_id"), batch_id=batch_id)
        rows = result.fetchall()
        assert len(rows) == 1
        assert rows[0].Failure_Reason == 'Invalid Quantity'

def test_TC04_empty_staging(bq_engine):
    # Empty staging table
    batch_id = run_procedure(bq_engine)
    with bq_engine.begin() as conn:
        result = conn.execute(text("SELECT * FROM dw_Fact_Sales"))
        assert result.rowcount == 0
        result = conn.execute(text("SELECT * FROM dw_DQ_Failures"))
        assert result.rowcount == 0
        result = conn.execute(text("SELECT * FROM dw_Audit_Log WHERE Batch_ID = :batch_id"), batch_id=batch_id)
        row = result.fetchone()
        assert row.Rows_Inserted == 0
        assert row.Rows_Rejected == 0

def test_TC05_all_invalid(bq_engine):
    # All transactions invalid
    stg_df = pd.DataFrame([
        {'Transaction_ID': 5, 'Customer_ID': None, 'Product_ID': 104, 'Sales_Date': datetime(2023,1,5,14), 'Quantity': 0, 'Unit_Price': 50.0}
    ])
    dim_customer_df = pd.DataFrame([
        {'Customer_ID': 14, 'Customer_Segment': 'Retail'}
    ])
    dim_date_df = pd.DataFrame([
        {'Date_Value': datetime(2023,1,5).date(), 'Region_ID': 'West'}
    ])
    insert_dataframe(bq_engine, "stg_Sales_Transactions", stg_df)
    insert_dataframe(bq_engine, "dw_Dim_Customer", dim_customer_df)
    insert_dataframe(bq_engine, "dw_Dim_Date", dim_date_df)
    batch_id = run_procedure(bq_engine)
    with bq_engine.begin() as conn:
        result = conn.execute(text("SELECT * FROM dw_Fact_Sales"))
        assert result.rowcount == 0
        result = conn.execute(text("SELECT * FROM dw_DQ_Failures WHERE Batch_ID = :batch_id"), batch_id=batch_id)
        rows = result.fetchall()
        assert len(rows) == 2  # Both reasons should be logged

def test_TC06_missing_dim_customer(bq_engine):
    # Customer_ID not found in Dim_Customer
    stg_df = pd.DataFrame([
        {'Transaction_ID': 6, 'Customer_ID': 99, 'Product_ID': 105, 'Sales_Date': datetime(2023,1,6,15), 'Quantity': 1, 'Unit_Price': 60.0}
    ])
    dim_customer_df = pd.DataFrame([
        {'Customer_ID': 15, 'Customer_Segment': 'Retail'}
    ])
    dim_date_df = pd.DataFrame([
        {'Date_Value': datetime(2023,1,6).date(), 'Region_ID': 'Central'}
    ])
    insert_dataframe(bq_engine, "stg_Sales_Transactions", stg_df)
    insert_dataframe(bq_engine, "dw_Dim_Customer", dim_customer_df)
    insert_dataframe(bq_engine, "dw_Dim_Date", dim_date_df)
    batch_id = run_procedure(bq_engine)
    with bq_engine.begin() as conn:
        result = conn.execute(text("SELECT * FROM dw_Fact_Sales"))
        assert result.rowcount == 0
        result = conn.execute(text("SELECT * FROM dw_DQ_Failures"))
        assert result.rowcount == 0  # Not a DQ failure, just not inserted

def test_TC07_error_handling(bq_engine):
    # Simulate error: remove a column from Fact_Sales
    with bq_engine.begin() as conn:
        conn.execute(text("ALTER TABLE dw_Fact_Sales DROP COLUMN Customer_Segment"))
    stg_df = pd.DataFrame([
        {'Transaction_ID': 7, 'Customer_ID': 16, 'Product_ID': 106, 'Sales_Date': datetime(2023,1,7,16), 'Quantity': 2, 'Unit_Price': 70.0}
    ])
    dim_customer_df = pd.DataFrame([
        {'Customer_ID': 16, 'Customer_Segment': 'Retail'}
    ])
    dim_date_df = pd.DataFrame([
        {'Date_Value': datetime(2023,1,7).date(), 'Region_ID': 'East'}
    ])
    insert_dataframe(bq_engine, "stg_Sales_Transactions", stg_df)
    insert_dataframe(bq_engine, "dw_Dim_Customer", dim_customer_df)
    insert_dataframe(bq_engine, "dw_Dim_Date", dim_date_df)
    try:
        batch_id = run_procedure(bq_engine)
    except Exception:
        # Validate Audit_Log status is FAILED
        with bq_engine.begin() as conn:
            result = conn.execute(text("SELECT * FROM dw_Audit_Log ORDER BY Start_Time DESC LIMIT 1"))
            row = result.fetchone()
            assert row.Status == 'FAILED'
            assert 'Customer_Segment' in row.Message

def test_TC08_large_batch_mixed(bq_engine):
    # Large batch with mixed valid/invalid
    stg_df = pd.DataFrame([
        {'Transaction_ID': 8, 'Customer_ID': 17, 'Product_ID': 107, 'Sales_Date': datetime(2023,1,8,17), 'Quantity': 3, 'Unit_Price': 80.0},
        {'Transaction_ID': 9, 'Customer_ID': None, 'Product_ID': 108, 'Sales_Date': datetime(2023,1,8,17), 'Quantity': 1, 'Unit_Price': 90.0},
        {'Transaction_ID': 10, 'Customer_ID': 18, 'Product_ID': 109, 'Sales_Date': datetime(2023,1,8,17), 'Quantity': -1, 'Unit_Price': 100.0}
    ])
    dim_customer_df = pd.DataFrame([
        {'Customer_ID': 17, 'Customer_Segment': 'Retail'},
        {'Customer_ID': 18, 'Customer_Segment': 'Wholesale'}
    ])
    dim_date_df = pd.DataFrame([
        {'Date_Value': datetime(2023,1,8).date(), 'Region_ID': 'North'}
    ])
    insert_dataframe(bq_engine, "stg_Sales_Transactions", stg_df)
    insert_dataframe(bq_engine, "dw_Dim_Customer", dim_customer_df)
    insert_dataframe(bq_engine, "dw_Dim_Date", dim_date_df)
    batch_id = run_procedure(bq_engine)
    with bq_engine.begin() as conn:
        result = conn.execute(text("SELECT * FROM dw_Fact_Sales"))
        rows = result.fetchall()
        assert len(rows) == 1
        assert rows[0].Transaction_ID == 8
        result = conn.execute(text("SELECT * FROM dw_DQ_Failures WHERE Batch_ID = :batch_id"), batch_id=batch_id)
        rows = result.fetchall()
        assert len(rows) == 2
        failure_reasons = set(row.Failure_Reason for row in rows)
        assert 'Missing CustomerID' in failure_reasons
        assert 'Invalid Quantity' in failure_reasons
        result = conn.execute(text("SELECT * FROM dw_Audit_Log WHERE Batch_ID = :batch_id"), batch_id=batch_id)
        row = result.fetchone()
        assert row.Rows_Inserted == 1
        assert row.Rows_Rejected == 2

def test_TC09_total_sales_amount_accuracy(bq_engine):
    # Validate Total_Sales_Amount calculation
    stg_df = pd.DataFrame([
        {'Transaction_ID': 11, 'Customer_ID': 19, 'Product_ID': 110, 'Sales_Date': datetime(2023,1,9,18), 'Quantity': 4, 'Unit_Price': 25.5}
    ])
    dim_customer_df = pd.DataFrame([
        {'Customer_ID': 19, 'Customer_Segment': 'Retail'}
    ])
    dim_date_df = pd.DataFrame([
        {'Date_Value': datetime(2023,1,9).date(), 'Region_ID': 'South'}
    ])
    insert_dataframe(bq_engine, "stg_Sales_Transactions", stg_df)
    insert_dataframe(bq_engine, "dw_Dim_Customer", dim_customer_df)
    insert_dataframe(bq_engine, "dw_Dim_Date", dim_date_df)
    batch_id = run_procedure(bq_engine)
    with bq_engine.begin() as conn:
        result = conn.execute(text("SELECT * FROM dw_Fact_Sales WHERE Transaction_ID = 11"))
        row = result.fetchone()
        assert row.Total_Sales_Amount == 4 * 25.5

def test_TC10_audit_logging_fields(bq_engine):
    # Ensure audit logging fields are correct
    stg_df = pd.DataFrame([
        {'Transaction_ID': 12, 'Customer_ID': 20, 'Product_ID': 111, 'Sales_Date': datetime(2023,1,10,19), 'Quantity': 2, 'Unit_Price': 60.0}
    ])
    dim_customer_df = pd.DataFrame([
        {'Customer_ID': 20, 'Customer_Segment': 'Retail'}
    ])
    dim_date_df = pd.DataFrame([
        {'Date_Value': datetime(2023,1,10).date(), 'Region_ID': 'West'}
    ])
    insert_dataframe(bq_engine, "stg_Sales_Transactions", stg_df)
    insert_dataframe(bq_engine, "dw_Dim_Customer", dim_customer_df)
    insert_dataframe(bq_engine, "dw_Dim_Date", dim_date_df)
    batch_id = run_procedure(bq_engine)
    with bq_engine.begin() as conn:
        result = conn.execute(text("SELECT * FROM dw_Audit_Log WHERE Batch_ID = :batch_id"), batch_id=batch_id)
        row = result.fetchone()
        assert row.Batch_ID == batch_id
        assert row.Procedure_Name == "dw.sp_load_sales_fact"
        assert row.Status == "COMPLETED"
        assert row.Rows_Inserted == 1
        assert row.Rows_Rejected == 0
        assert row.Start_Time is not None
        assert row.End_Time is not None

```

API Cost Consumed in dollars: 0.0080 USD