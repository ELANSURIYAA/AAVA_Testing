=============================================
Author:   AAVA
Created on:   
Description:   Loads the FACT_EXECUTIVE_SUMMARY table with summarized holding metrics from staging, performing data quality validation, business rule checks, and ensuring referential integrity via dimension joins.
=============================================

**1. Workflow Overview**

The stored procedure `dbo.LOAD_FACT_EXECUTIVE_SUMMARY` is designed to load the `FACT_EXECUTIVE_SUMMARY` fact table from the `STG_HOLDING_METRICS` staging table. It performs data quality validation and applies business rules, such as handling null or negative income amounts, and ensures referential integrity by joining with dimension tables (`DIM_DATE`, `DIM_INSTITUTION`, `DIM_CORPORATION`, `DIM_PRODUCT`). The process includes staging data preparation, insertion into the fact table, audit logging, and cleanup. The main business objective is data integration and transformation for executive-level reporting.

**2. Complexity Metrics**

| Metric                              | Description                                                                 | Value / Assessment                 |
|--------------------------------------|-----------------------------------------------------------------------------|------------------------------------|
| Number of Input Tables               | Count of distinct source tables used in the procedure.                      | 5 (`STG_HOLDING_METRICS`, `DIM_DATE`, `DIM_INSTITUTION`, `DIM_CORPORATION`, `DIM_PRODUCT`) |
| Number of Output Tables              | Count of target or intermediate tables modified or populated.                | 1 (`FACT_EXECUTIVE_SUMMARY`)       |
| Variable Declarations                | Number of declared variables and their usage complexity.                     | 2 (`@v_row_count`, `@error_message`) - simple usage for row count and error message |
| Conditional Logic                    | Number of IF, CASE, or nested conditional blocks.                            | 3 (IF for temp table existence, CASE for income_amount, IF for cleanup) |
| Loop Constructs                      | Number of WHILE or FOR loops, if present.                                   | 0                                  |
| Join Conditions                      | Count and types of joins (INNER, LEFT, RIGHT, FULL).                        | 4 INNER JOINs                      |
| Aggregations                         | Number of aggregation operations (SUM, COUNT, AVG, etc.).                   | 0 (no explicit aggregation)        |
| Subqueries / CTEs                    | Number of subqueries or Common Table Expressions used.                      | 0                                  |
| Procedural Calls                     | Number of stored procedure or function invocations.                         | 0                                  |
| DML Operations                       | Frequency of INSERT, UPDATE, DELETE, MERGE operations.                      | 1 INSERT, 2 DROP TABLE (temp)      |
| Temporary Tables / Table Variables   | Number of temp tables or table variables created and used.                   | 1 temp table (`#staging_metrics`)  |
| Transaction Handling                 | Count of BEGIN TRAN, COMMIT, ROLLBACK statements.                           | 0                                  |
| Error Handling Blocks                | Presence and count of TRY...CATCH logic.                                    | 0                                  |
| Complexity Score (0â€“100)             | Based on nested logic, control flow, DML count, and procedural depth.        | 25 (Low to moderate complexity)    |

**High-Complexity Areas:**
- Use of temp table for staging and cleanup
- Multiple joins to dimension tables for referential integrity
- Conditional logic for data quality (CASE for income_amount)
- No dynamic SQL or procedural control flow

**3. Syntax Differences**

- **Variable Declarations:** T-SQL `DECLARE` statements (`@v_row_count`, `@error_message`) do not have direct equivalents in Fabric code and should be replaced by CTEs or derived columns.
- **Temp Tables:** Creation and dropping of temp tables (`#staging_metrics`) must be replaced with CTEs or view-based logic in Fabric code, as temp tables are not natively supported.
- **Control Flow:** T-SQL procedural blocks (IF, PRINT, SET) must be replaced with declarative SQL or Fabric pipeline steps. Logging via `PRINT` should be handled by Fabric pipeline logging or monitoring.
- **CASE Statements:** Supported in Fabric SQL, but ensure compatibility with Fabric syntax.
- **Transaction Handling:** Not present in this procedure, but if needed, Fabric handles transactions differently and typically relies on atomic operations.
- **Data Types:** Ensure conversion of T-SQL types (e.g., INT, NVARCHAR) to Fabric-supported types. `DATETIME` should be mapped to `TIMESTAMP` if present.
- **Error Handling:** No TRY...CATCH blocks are used, but if present, would need to be replaced with Fabric error handling mechanisms.

**4. Manual Adjustments**

- **Audit Logging:** The row count and print statements for audit need to be implemented using Fabric pipeline logging or monitoring features.
- **Temp Table Usage:** Replace temp table logic with CTEs or intermediate views.
- **Business Rule Validation:** The CASE logic for `income_amount` should be validated post-conversion to ensure parity.
- **External Dependencies:** None detected in this procedure, but ensure any pre/post job scripts or triggers are migrated to Fabric orchestration.
- **Cleanup Logic:** Explicit temp table drops are not needed in Fabric; cleanup should be handled by pipeline design.

**5. Optimization Techniques**

- **Sequential CTEs:** Replace temp table staging with sequential CTEs to streamline data flow.
- **Modular Queries:** Break down complex joins into modular, readable queries for maintainability.
- **Predicate Pushdown:** Ensure join and filter conditions are pushed down to minimize data movement and optimize performance.
- **Reduce Materializations:** Avoid unnecessary intermediate tables; use views or CTEs where possible.
- **Refactor vs. Rebuild:** Refactor is sufficient for this procedure due to moderate complexity and clear logic. Rebuild only if performance profiling in Fabric reveals bottlenecks.

**6. API Cost Consumption**

```
apiCost: 0.0523 USD
```