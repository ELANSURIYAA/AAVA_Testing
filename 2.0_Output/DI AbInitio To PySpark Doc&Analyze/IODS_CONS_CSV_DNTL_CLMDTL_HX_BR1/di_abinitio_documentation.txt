```
====================================================
Author:        Ascendion AVA+
Date:          
Description:   Ab Initio graph for dental claim detail history consolidation, enrichment, and load to BigQuery staging.
====================================================

# Ab Initio Graph Documentation

## 1. Overview of Graph/Component

This Ab Initio graph orchestrates the extraction, enrichment, deduplication, and transformation of dental claim detail history data from BigQuery sources, culminating in the loading of consolidated records into a BigQuery staging table. The process ensures data quality via deduplication, field enrichment, and robust error handling, supporting downstream analytics and regulatory reporting.

**Business Logic:**  
- Extracts service line and provider data, joins with claim history, enriches and deduplicates records, and loads the result into a staging table for further processing.

---

## 2. Component Structure and Design

**Key Components:**
- **Input Table:** Reads from BigQuery using a complex SQL join (service line, provider, and claim history tables).
- **Reformat (Adaptor):** Applies initial field mapping and type adaptation.
- **Sort:** Orders records by key fields to prepare for deduplication.
- **Dedup Sorted:** Removes duplicate records based on composite business keys.
- **Reformat (Join/Enrichment):** Applies business logic, field enrichment, and mapping using `.xfr` files.
- **Partition by Key:** Ensures parallel processing by partitioning on key fields.
- **Reformat (Final Mapping):** Prepares records for output, including staging-specific adaptations.
- **Output Table:** Loads the final records into the BigQuery staging table.
- **Output File:** Optionally writes to a temporary file for audit or backup.
- **Error/Reject/Log Ports:** Present on all major components for robust error handling.

**Connection Flow:**  
Input Table → Reformat (Adaptor) → Sort → Dedup Sorted → Reformat (Join/Enrichment) → Partition by Key → Reformat (Final Mapping) → Output Table

Parameters and variables are used for environment-specific paths, DMLs, and date filtering.

---

## 3. Data Flow and Processing Logic

### Processed Datasets:
- **Input:**  
  - BigQuery tables: `CSV_5010_DENTAL_SERVICE_LINE_HX`, `CSV_5010_DENTAL_SERVICE_LINE_PROVIDER_HX`, `CONS_CSV_DENTAL_CLM_HX`
- **Intermediate:**  
  - Temporary multifile system (MFS) files
  - Deduplicated and reformatted datasets
- **Output:**  
  - BigQuery table: `STG_CONS_CSV_DENTAL_CLM_DTL_HX`
  - Optional: Output file in GCS bucket

### Data Flow:
1. **Extraction:**  
   - SQL join pulls service line, provider, and claim history data for a date range.
2. **Adaptation:**  
   - Reformat adapts fields to internal DML.
3. **Sorting & Deduplication:**  
   - Sorts by composite key; deduplication retains the first record per key.
4. **Enrichment & Mapping:**  
   - Reformat applies business rules and field enrichment using `.xfr` logic.
5. **Partitioning:**  
   - Data is partitioned for parallel processing.
6. **Final Mapping:**  
   - Reformat prepares records for staging table structure.
7. **Load:**  
   - Output Table loads records into BigQuery staging; Output File writes to GCS if configured.
8. **Error/Reject Handling:**  
   - All steps route errors/rejects to dedicated ports/files.

---

## 4. Data Mapping (Lineage)

```
Target Table Name : STG_CONS_CSV_DENTAL_CLM_DTL_HX
Target Column Name : <see DML, e.g., AK_UCK_ID, AK_UCK_ID_PREFIX_CD, ...>
Source Table Name : CSV_5010_DENTAL_SERVICE_LINE_HX, CSV_5010_DENTAL_SERVICE_LINE_PROVIDER_HX, CONS_CSV_DENTAL_CLM_HX
Source Column Name : <see SQL select list>
Remarks : 1:1 Mapping for most fields; some fields use COALESCE for enrichment; deduplication on composite key; date filtering applied.
```

- Example:
```
Target Table Name : STG_CONS_CSV_DENTAL_CLM_DTL_HX
Target Column Name : AK_UCK_ID
Source Table Name : CSV_5010_DENTAL_SERVICE_LINE_HX
Source Column Name : UCK_ID
Remarks : 1:1 Mapping
```
- For enriched fields:
```
Target Table Name : STG_CONS_CSV_DENTAL_CLM_DTL_HX
Target Column Name : ASRG_FST_NM
Source Table Name : CSV_5010_DENTAL_SERVICE_LINE_PROVIDER_HX
Source Column Name : ASRG_FST_NM
Remarks : Transformation - COALESCE(B.ASRG_FST_NM,'')
```

---

## 5. Transformation Logic

- **.xfr Functions Used:**
  - `$AI_XFR/table_adaptor.xfr`: Adapts input fields to internal DML.
  - `$AI_XFR/GEN_CSV_FIRST_DEFINED.xfr`: Applies "first defined" logic for field selection.
  - `$AI_XFR/IODS_CONS_CSV_DNTL_CLMDTL_HX_BR1_V353S6P2.xfr` and `$AI_XFR/IODS_CONS_CSV_DNTL_CLMDTL_HX_BR1_V353S6P3.xfr`: Custom business logic for field mapping and enrichment.
  - Inline reformat: `out.* :: in.*;` for direct field pass-through.

- **Field Involvement:**  
  - All fields listed in the DMLs are mapped, with enrichment for provider and claim fields.
  - Deduplication uses composite keys: `AK_UCK_ID`, `AK_UCK_ID_PREFIX_CD`, `AK_UCK_ID_SEGMENT_NO`, `AK_SUBMT_SVC_LN_NO`.

- **Reusable Components:**  
  - Standard Ab Initio components for Sort, Dedup, Partitioning, and Reformat.

---

## 6. Complexity Analysis

- **Number of Graph Components:** 15+ (Input Table, Reformat x5, Sort, Dedup, Partition by Key, Output Table, Output File, etc.)
- **Number of Lines of Code (in .xfr or .plan):** ~1000+ (including SQL, DML, and XFR logic)
- **Transform Functions Used:** 5+ (including custom and standard .xfrs)
- **Joins Used:**  
  - SQL Join: 1 LEFT OUTER JOIN, 1 INNER JOIN
- **Lookup Files or Datasets:** None (all joins are in SQL)
- **Parameter Sets (.pset) or Plan Files Used:** 1+ (parameter set for environment/config)
- **Number of Output Datasets:** 2 (BigQuery table, optional output file)
- **Conditional Logic or `if-else` flows:** 2+ (COALESCE, CASE WHEN in SQL and XFR)
- **External Dependencies:**  
  - JDBC/BigQuery connections (`bigquery_impersonate.dbc`)
  - Shell environment variables for GCS paths
  - DML and XFR libraries
- **Overall Complexity Score:** 85/100  
  (High due to multi-table joins, deduplication, enrichment, and robust error handling)

---

## 7. Key Outputs

- **BigQuery Table:**  
  - `STG_CONS_CSV_DENTAL_CLM_DTL_HX`  
  - Format: Variable-width, UTF-8, as per DML
  - Use: Downstream analytics, reporting, and further ETL

- **Optional Output File:**  
  - GCS bucket path (MFS)
  - Format: As per DML, for backup/audit

---

## 8. Error Handling and Logging

- **Reject/Error/Log Ports:**  
  - All major components (Reformat, Dedup, Output Table) have reject, error, and log ports.
- **Error Tagging:**  
  - `.xfr` logic and Ab Initio built-in error types
- **Reject Thresholds:**  
  - Typically set to "Abort on first reject" or configurable via parameter
- **Control Files:**  
  - Not explicitly used, but logging and reject files are generated per component
- **Error Routing:**  
  - Errors are routed to reject files or error logs; logs can be monitored for alerts

---

## 9. API Cost (Cloud Ab Initio Deployments)

**Estimate:**  
- **BigQuery Read:** Cost based on bytes read by the SQL extraction (can be millions of rows, several GB).
- **BigQuery Write:** Cost based on bytes written to the staging table.
- **Ab Initio Compute:** Cost based on number of records processed, parallelism (PROC_DEPTH), and temporary storage (MFS).

**Formula Example:**  
```
Total Cost = (Input Bytes Read * BigQuery Read Rate) + (Output Bytes Written * BigQuery Write Rate) + (Compute Time * VM Rate)
```
- For 10GB input, 5GB output, 1 hour compute:
  - BigQuery Read: 10GB * $5/TB = $0.05
  - BigQuery Write: 5GB * $1/TB = $0.005
  - Compute: 1hr * $0.50/hr = $0.50
  - **Total: ~$0.56 per run (estimate)**
```

---

**End of Documentation**