Test Case List:

| Test Case ID | Description | Expected Outcome |
|--------------|-------------|-----------------|
| TC01 | Happy Path: Valid sales data for 2023, discount applied, USA country, all fields populated | Top 5 customers per region returned with correct aggregations, product lists, sale categories, and sources |
| TC02 | Edge Case: Customer with no sales in 2023 | Customer appears with zero sales, zero orders, empty product list, no sales_performance rows |
| TC03 | Edge Case: Sales with NULL sale_amount | Aggregations ignore NULL sale_amounts, sale_category assigned as 'Low Value' |
| TC04 | Edge Case: Sales with sale_metadata missing 'discount_applied' or 'country' | Rows excluded from aggregations and sales_performance as per WHERE filters |
| TC05 | Edge Case: Customer with multiple regions (data anomaly) | Customer appears in each region, ranked appropriately |
| TC06 | Edge Case: Sales with discount_applied FALSE | Sales excluded from aggregations and product_list |
| TC07 | Edge Case: Product with NULL name | sale_performance row included, product_name is NULL |
| TC08 | Edge Case: sale_metadata:source is NULL | source field in output is NULL |
| TC09 | Boundary: sale_amount exactly 1000 and 500 | sale_category assigned as 'Medium Value' for 1000, 'Low Value' for 500 |
| TC10 | Error: Invalid data types in metadata fields | Query fails gracefully or ignores invalid rows (depends on BigQuery behavior) |
| TC11 | Empty Dataset: No customers, sales, or products | Output is empty, no errors |
| TC12 | Large Dataset: Performance/Scalability | Query completes without timeout, returns correct top 5 per region |

Pytest Script (PEP 8, with setup/teardown, mock data, assertions):

```python
import pytest
from google.cloud import bigquery

# Helper functions for setup/teardown
def setup_test_data(client, dataset_id):
    # Create mock tables and insert test data for each test case
    # Customers
    client.query(f"""
        CREATE OR REPLACE TABLE `{dataset_id}.Customers` (
            customer_id INT64,
            customer_name STRING,
            region STRING,
            metadata JSON
        );
    """).result()
    # Sales
    client.query(f"""
        CREATE OR REPLACE TABLE `{dataset_id}.Sales` (
            sale_id INT64,
            sale_date DATE,
            sale_amount FLOAT64,
            discount_percentage FLOAT64,
            sale_metadata JSON,
            product_id INT64,
            customer_id INT64
        );
    """).result()
    # Products
    client.query(f"""
        CREATE OR REPLACE TABLE `{dataset_id}.Products` (
            product_id INT64,
            product_name STRING
        );
    """).result()

def teardown_test_data(client, dataset_id):
    client.query(f"DROP TABLE IF EXISTS `{dataset_id}.Customers`;").result()
    client.query(f"DROP TABLE IF EXISTS `{dataset_id}.Sales`;").result()
    client.query(f"DROP TABLE IF EXISTS `{dataset_id}.Products`;").result()

@pytest.fixture(scope="function")
def bq_client():
    client = bigquery.Client()
    dataset_id = "test_total_sales"
    # Create dataset if not exists
    client.query(f"CREATE SCHEMA IF NOT EXISTS `{dataset_id}`;").result()
    setup_test_data(client, dataset_id)
    yield client, dataset_id
    teardown_test_data(client, dataset_id)

def run_total_sales_query(client, dataset_id):
    # The converted BigQuery SQL (adapted from Snowflake)
    query = f"""
    WITH customer_sales AS (
        SELECT 
            c.customer_id,
            c.customer_name,
            c.region,
            CAST(JSON_VALUE(c.metadata, '$.loyalty_level') AS STRING) AS loyalty_level,
            SUM(s.sale_amount) AS total_sales,
            COUNT(s.sale_id) AS total_orders,
            ARRAY_AGG(DISTINCT s.product_id) AS product_list
        FROM `{dataset_id}.Customers` c
        LEFT JOIN `{dataset_id}.Sales` s ON c.customer_id = s.customer_id
        WHERE s.sale_date >= '2023-01-01'
            AND s.sale_date < '2024-01-01'
            AND CAST(JSON_VALUE(s.sale_metadata, '$.discount_applied') AS BOOL) = TRUE
        GROUP BY c.customer_id, c.customer_name, c.region, c.metadata
    ),
    top_customers AS (
        SELECT 
            customer_id,
            customer_name,
            region,
            loyalty_level,
            total_sales,
            total_orders,
            product_list,
            RANK() OVER (PARTITION BY region ORDER BY total_sales DESC) AS region_rank
        FROM customer_sales
    ),
    sales_performance AS (
        SELECT
            s.sale_id,
            s.sale_date,
            s.sale_amount,
            s.discount_percentage,
            CAST(JSON_VALUE(s.sale_metadata, '$.source') AS STRING) AS source,
            p.product_name,
            CASE
                WHEN s.sale_amount > 1000 THEN 'High Value'
                WHEN s.sale_amount > 500 THEN 'Medium Value'
                ELSE 'Low Value'
            END AS sale_category
        FROM `{dataset_id}.Sales` s
        INNER JOIN `{dataset_id}.Products` p ON s.product_id = p.product_id
        WHERE s.sale_date >= '2023-01-01'
            AND CAST(JSON_VALUE(s.sale_metadata, '$.country') AS STRING) = 'USA'
    )
    SELECT 
        tc.customer_name,
        tc.region,
        tc.loyalty_level,
        tc.total_sales,
        tc.total_orders,
        sp.sale_id,
        sp.sale_date,
        sp.product_name,
        sp.sale_category,
        sp.source
    FROM top_customers tc
    LEFT JOIN sales_performance sp ON tc.customer_id = sp.customer_id
    WHERE tc.region_rank <= 5
    ORDER BY tc.region, tc.region_rank, sp.sale_date
    """
    return list(client.query(query).result())

# Test Cases

def test_TC01_happy_path(bq_client):
    client, dataset_id = bq_client
    # Insert mock data for happy path
    client.query(f"""
        INSERT INTO `{dataset_id}.Customers` VALUES
        (1, 'Alice', 'East', '{{"loyalty_level": "Gold"}}'),
        (2, 'Bob', 'West', '{{"loyalty_level": "Silver"}}');
        INSERT INTO `{dataset_id}.Sales` VALUES
        (101, '2023-02-01', 1200, 10, '{{"discount_applied": true, "country": "USA", "source": "Online"}}', 201, 1),
        (102, '2023-03-01', 800, 5, '{{"discount_applied": true, "country": "USA", "source": "Store"}}', 202, 2);
        INSERT INTO `{dataset_id}.Products` VALUES
        (201, 'Laptop'),
        (202, 'Tablet');
    """).result()
    results = run_total_sales_query(client, dataset_id)
    assert len(results) == 2
    assert results[0].customer_name == 'Alice'
    assert results[0].total_sales == 1200
    assert results[0].sale_category == 'High Value'
    assert results[1].customer_name == 'Bob'
    assert results[1].sale_category == 'Medium Value'

def test_TC02_customer_no_sales(bq_client):
    client, dataset_id = bq_client
    client.query(f"""
        INSERT INTO `{dataset_id}.Customers` VALUES
        (3, 'Charlie', 'North', '{{"loyalty_level": "Bronze"}}');
    """).result()
    results = run_total_sales_query(client, dataset_id)
    # Charlie should appear with zero sales/orders, product_list empty, no sales_performance
    assert any(r.customer_name == 'Charlie' and r.total_sales is None for r in results) or len(results) == 0

def test_TC03_null_sale_amount(bq_client):
    client, dataset_id = bq_client
    client.query(f"""
        INSERT INTO `{dataset_id}.Customers` VALUES
        (4, 'Dana', 'South', '{{"loyalty_level": "Gold"}}');
        INSERT INTO `{dataset_id}.Sales` VALUES
        (103, '2023-04-01', NULL, 15, '{{"discount_applied": true, "country": "USA", "source": "App"}}', 203, 4);
        INSERT INTO `{dataset_id}.Products` VALUES
        (203, 'Phone');
    """).result()
    results = run_total_sales_query(client, dataset_id)
    # Sale amount NULL should be ignored in SUM, sale_category should be 'Low Value'
    assert any(r.customer_name == 'Dana' and (r.sale_category == 'Low Value' or r.sale_category is None) for r in results)

def test_TC04_missing_discount_applied_or_country(bq_client):
    client, dataset_id = bq_client
    client.query(f"""
        INSERT INTO `{dataset_id}.Customers` VALUES
        (5, 'Eve', 'East', '{{"loyalty_level": "Silver"}}');
        INSERT INTO `{dataset_id}.Sales` VALUES
        (104, '2023-05-01', 900, 20, '{{"country": "USA", "source": "Online"}}', 204, 5),
        (105, '2023-06-01', 700, 5, '{{"discount_applied": true, "source": "Online"}}', 204, 5);
        INSERT INTO `{dataset_id}.Products` VALUES
        (204, 'Monitor');
    """).result()
    results = run_total_sales_query(client, dataset_id)
    # Only sales with both discount_applied TRUE and country 'USA' should be included
    assert all(r.customer_name == 'Eve' and r.sale_id == 105 for r in results)

def test_TC05_multiple_regions(bq_client):
    client, dataset_id = bq_client
    client.query(f"""
        INSERT INTO `{dataset_id}.Customers` VALUES
        (6, 'Frank', 'East', '{{"loyalty_level": "Gold"}}'),
        (6, 'Frank', 'West', '{{"loyalty_level": "Gold"}}');
        INSERT INTO `{dataset_id}.Sales` VALUES
        (106, '2023-07-01', 1100, 10, '{{"discount_applied": true, "country": "USA", "source": "App"}}', 205, 6);
        INSERT INTO `{dataset_id}.Products` VALUES
        (205, 'Keyboard');
    """).result()
    results = run_total_sales_query(client, dataset_id)
    # Frank should appear in both regions, ranked appropriately
    assert any(r.customer_name == 'Frank' and r.region == 'East' for r in results)
    assert any(r.customer_name == 'Frank' and r.region == 'West' for r in results)

def test_TC06_discount_applied_false(bq_client):
    client, dataset_id = bq_client
    client.query(f"""
        INSERT INTO `{dataset_id}.Customers` VALUES
        (7, 'Grace', 'North', '{{"loyalty_level": "Bronze"}}');
        INSERT INTO `{dataset_id}.Sales` VALUES
        (107, '2023-08-01', 950, 10, '{{"discount_applied": false, "country": "USA", "source": "Online"}}', 206, 7);
        INSERT INTO `{dataset_id}.Products` VALUES
        (206, 'Mouse');
    """).result()
    results = run_total_sales_query(client, dataset_id)
    # Sale should be excluded from aggregations
    assert all(r.customer_name != 'Grace' for r in results) or len(results) == 0

def test_TC07_null_product_name(bq_client):
    client, dataset_id = bq_client
    client.query(f"""
        INSERT INTO `{dataset_id}.Customers` VALUES
        (8, 'Hank', 'South', '{{"loyalty_level": "Silver"}}');
        INSERT INTO `{dataset_id}.Sales` VALUES
        (108, '2023-09-01', 600, 5, '{{"discount_applied": true, "country": "USA", "source": "Online"}}', 207, 8);
        INSERT INTO `{dataset_id}.Products` VALUES
        (207, NULL);
    """).result()
    results = run_total_sales_query(client, dataset_id)
    # Product name should be NULL in output
    assert any(r.customer_name == 'Hank' and r.product_name is None for r in results)

def test_TC08_null_source_field(bq_client):
    client, dataset_id = bq_client
    client.query(f"""
        INSERT INTO `{dataset_id}.Customers` VALUES
        (9, 'Ivy', 'East', '{{"loyalty_level": "Gold"}}');
        INSERT INTO `{dataset_id}.Sales` VALUES
        (109, '2023-10-01', 700, 10, '{{"discount_applied": true, "country": "USA"}}', 208, 9);
        INSERT INTO `{dataset_id}.Products` VALUES
        (208, 'Speaker');
    """).result()
    results = run_total_sales_query(client, dataset_id)
    # Source should be NULL in output
    assert any(r.customer_name == 'Ivy' and r.source is None for r in results)

def test_TC09_sale_amount_boundaries(bq_client):
    client, dataset_id = bq_client
    client.query(f"""
        INSERT INTO `{dataset_id}.Customers` VALUES
        (10, 'Jack', 'West', '{{"loyalty_level": "Silver"}}');
        INSERT INTO `{dataset_id}.Sales` VALUES
        (110, '2023-11-01', 1000, 5, '{{"discount_applied": true, "country": "USA", "source": "Online"}}', 209, 10),
        (111, '2023-12-01', 500, 5, '{{"discount_applied": true, "country": "USA", "source": "Online"}}', 209, 10);
        INSERT INTO `{dataset_id}.Products` VALUES
        (209, 'Camera');
    """).result()
    results = run_total_sales_query(client, dataset_id)
    # 1000 should be 'Medium Value', 500 should be 'Low Value'
    assert any(r.sale_amount == 1000 and r.sale_category == 'Medium Value' for r in results)
    assert any(r.sale_amount == 500 and r.sale_category == 'Low Value' for r in results)

def test_TC10_invalid_metadata_types(bq_client):
    client, dataset_id = bq_client
    client.query(f"""
        INSERT INTO `{dataset_id}.Customers` VALUES
        (11, 'Kim', 'North', '{{"loyalty_level": 123}}');
        INSERT INTO `{dataset_id}.Sales` VALUES
        (112, '2023-01-01', 800, 5, '{{"discount_applied": "notabool", "country": "USA", "source": "Online"}}', 210, 11);
        INSERT INTO `{dataset_id}.Products` VALUES
        (210, 'Printer');
    """).result()
    try:
        results = run_total_sales_query(client, dataset_id)
        # Invalid types should be ignored or cause no output
        assert all(r.customer_name != 'Kim' for r in results) or len(results) == 0
    except Exception:
        # Acceptable if BigQuery throws error on invalid type cast
        assert True

def test_TC11_empty_dataset(bq_client):
    client, dataset_id = bq_client
    # No data inserted
    results = run_total_sales_query(client, dataset_id)
    assert len(results) == 0

def test_TC12_large_dataset_performance(bq_client):
    client, dataset_id = bq_client
    # Insert a large number of customers/sales/products
    for i in range(1, 101):
        client.query(f"""
            INSERT INTO `{dataset_id}.Customers` VALUES
            ({i}, 'Customer{i}', 'Region{i%5}', '{{"loyalty_level": "Level{i%3}"}}');
            INSERT INTO `{dataset_id}.Sales` VALUES
            ({1000+i}, '2023-01-15', {500+i*10}, 5, '{{"discount_applied": true, "country": "USA", "source": "Online"}}', {2000+i}, {i});
            INSERT INTO `{dataset_id}.Products` VALUES
            ({2000+i}, 'Product{i}');
        """).result()
    results = run_total_sales_query(client, dataset_id)
    # Should return top 5 customers per region
    regions = set(r.region for r in results)
    for region in regions:
        assert sum(1 for r in results if r.region == region) <= 5

# Note: You may need to adapt the JSON extraction syntax for your BigQuery version.
# All tests use setup/teardown to isolate data.
```

apiCost: 0.0040 USD