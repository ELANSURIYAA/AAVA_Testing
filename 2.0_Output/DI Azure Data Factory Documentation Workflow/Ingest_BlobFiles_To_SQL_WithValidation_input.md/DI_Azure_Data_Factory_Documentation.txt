=============================================
Author:        Ascendion AVA+
Created on:    
Description:   Pipeline to ingest multiple blob files into SQL staging with validation and cleanup
=============================================

# Ingest_BlobFiles_To_SQL_WithValidation Pipeline Documentation

---

## 1. Overview of Pipeline

The **Ingest_BlobFiles_To_SQL_WithValidation** pipeline automates the ingestion of multiple files from Azure Blob Storage into a SQL staging table, ensuring that the target table is validated and cleaned prior to data load. This pipeline supports enterprise data integration and analytics by enabling reliable, repeatable ingestion of raw files for downstream processing, reporting, and compliance. It orchestrates the movement, validation, and transformation of data, bridging technical and business requirements for accurate, auditable data flows.

**Components:**
- **Pipelines:** Ingest_BlobFiles_To_SQL_WithValidation
- **Activities:** Lookup, IfCondition, Stored Procedure, ForEach, Copy
- **Datasets:** InputBlobDataset (Binary), OutputSqlDataset (AzureSqlTable)
- **Linked Services:** AzureBlobStorageLS, AzureSqlDatabaseLS
- **Triggers:** Not defined in JSON
- **Integration Runtimes:** Not explicitly defined

---

## 2. Pipeline Structure and Design

**Pipeline Parameters:**
- `SourceFileList` (Array): List of files to ingest (default: ["file1.csv", "file2.csv"])
- `RunDate` (String): Execution timestamp (default: current UTC)

**Variables:**
- `rowCount` (Int): Used for validation

**Pipeline Activities:**
1. **LookupRowCount:** Executes SQL query to count rows in `Sales_Staging`.
2. **IfHasData:** Conditional activity; if row count > 0, executes table truncation.
3. **TruncateTable:** Calls stored procedure `usp_Truncate_Staging` to clear staging.
4. **ForEachFiles:** Iterates over `SourceFileList`, running `CopyBlobToSQL` for each file.
5. **CopyBlobToSQL:** Copies each blob file to the SQL staging table.

**Dependencies:**
- `IfHasData` depends on `LookupRowCount`
- `ForEachFiles` depends on `IfHasData`
- `CopyBlobToSQL` runs inside `ForEachFiles`

**Performance/Optimization Notes:**
- Table truncation ensures clean staging for each run.
- Parallel file ingestion possible via `ForEach`.
- Binary copy assumes files are compatible with SQL staging schema.

---

## 3. Data Flow and Processing Logic

### Step-by-Step Data Movement

```markdown
[Start]
   |
   v
[LookupRowCount] --(rowCount > 0)--> [IfHasData]
   |                                   |
   |                                   v
   |                              [TruncateTable]
   |                                   |
   v                                   v
[ForEachFiles]------------------------>[CopyBlobToSQL]
   |
   v
[End]
```

**Detailed Steps:**
1. **LookupRowCount:** Runs `SELECT COUNT(*) as cnt FROM Sales_Staging` to determine existing data.
2. **IfHasData:** If count > 0, triggers `TruncateTable`; otherwise, skips.
3. **TruncateTable:** Executes `usp_Truncate_Staging` to clear the table.
4. **ForEachFiles:** Loops through each file in `SourceFileList`.
5. **CopyBlobToSQL:** For each file, copies from Blob Storage (`input/incoming/fileName`) to SQL table `Sales_Staging`.

---

## 4. Transformation Breakdown (Mandatory)

| Activity            | Input Source                  | Transformation Logic                                                      | Output Destination         |
|---------------------|------------------------------|--------------------------------------------------------------------------|---------------------------|
| LookupRowCount      | Sales_Staging (SQL Table)    | SQL: `SELECT COUNT(*) as cnt FROM Sales_Staging`                         | Row count (int)           |
| IfHasData           | LookupRowCount output        | Expression: `@greater(activity('LookupRowCount').output.firstRow.cnt,0)` | Conditional path           |
| TruncateTable       | Sales_Staging (SQL Table)    | Stored Procedure: `usp_Truncate_Staging`                                 | Empty Sales_Staging table |
| CopyBlobToSQL       | Azure Blob Storage (Binary)  | Binary copy to SQL staging (no explicit transformation in JSON)          | Sales_Staging (SQL Table) |

**Note:** No explicit transformations (joins, filters, aggregates) are defined in the JSON. All business logic is handled via stored procedure and SQL query.

---

## 5. Data Mapping

| Target Dataset   | Target Field | Source Dataset    | Source Field | Transformation / Rule          |
|------------------|--------------|-------------------|-------------|-------------------------------|
| Sales_Staging    | (all fields) | InputBlobDataset  | (all fields)| Direct binary copy per file    |

**Rule:** Each file from Blob Storage is copied as-is to the staging table. No field-level transformation is specified in the pipeline JSON.

---

## 6. Complexity Analysis

| Metric                | Count/Details         |
|-----------------------|----------------------|
| Pipelines             | 1                    |
| Activities            | 4 (Lookup, If, SP, ForEach/Copy) |
| Datasets              | 2 (Blob, SQL Table)  |
| Triggers              | 0                    |
| Parameters            | 2 (SourceFileList, RunDate) |
| Conditional Logic     | 1 (IfCondition)      |
| Transformations       | 1 (Stored Procedure) |
| Dependencies          | 3 (Lookup->If->ForEach) |

**Overall Complexity Score:** 35/100  
(Simple ingestion and validation pipeline; moderate use of conditional logic and iteration.)

---

## 7. Key Outputs

- **Final Output Table:** `Sales_Staging` in Azure SQL Database
- **Schema:** Not specified in JSON; assumed to match input file structure
- **Storage Format:** Azure SQL Table
- **Purpose:** Curated staging data for downstream analytics, reporting, and compliance
- **Alignment:** Ensures only fresh data is loaded, supporting business requirements for data accuracy and auditability

---

## 8. API Cost Calculations

**API Calls:**
- Lookup Activity: 1 SQL call
- Stored Procedure: 1 SQL call (conditional)
- Copy Activity: 1 per file (2 files default)
- Total: 4 API calls (assuming default SourceFileList)

**Cost Calculation:**  
Azure Data Factory pricing (as of 2024):  
- Lookup: $0.00025 per activity run  
- Stored Procedure: $0.00025 per activity run  
- Copy: $0.003 per activity run  

| Activity         | Count | Unit Cost (USD) | Total Cost (USD) |
|------------------|-------|-----------------|------------------|
| Lookup           | 1     | 0.00025         | 0.00025          |
| Stored Procedure | 1     | 0.00025         | 0.00025          |
| Copy             | 2     | 0.003           | 0.006            |
| **Total**        |       |                 | **0.0065**       |

**API Call Cost (USD):** $0.0065

---

**End of Documentation**