=============================================
Author:        AAVA
Created on:   
Description:   Loads the FACT_EXECUTIVE_SUMMARY table with validated, enriched holding metrics from staging, ensuring referential integrity and audit logging.
=============================================

## 1. Procedure Overview

The `LOAD_FACT_EXECUTIVE_SUMMARY` stored procedure ingests raw holding metrics from the staging table `STG_HOLDING_METRICS`, applies business rule validations (such as income normalization), ensures referential integrity by joining to dimension tables, and loads the cleansed, validated data into the `FACT_EXECUTIVE_SUMMARY` table. It supports enterprise reporting and analytics by providing a reliable, enriched fact table for downstream consumption. The procedure also performs audit logging and temporary resource cleanup.

**Key Business Objective:**  
Data integration, cleansing, enrichment, and transformation for executive summary reporting.

---

## 2. Complexity Metrics

| Metric                                 | Description                                                                 | Value/Details                                                                                 |
|-----------------------------------------|-----------------------------------------------------------------------------|----------------------------------------------------------------------------------------------|
| Number of Input Tables                  | Count of distinct source tables used in the procedure.                      | 5 (`STG_HOLDING_METRICS`, `DIM_DATE`, `DIM_INSTITUTION`, `DIM_CORPORATION`, `DIM_PRODUCT`)   |
| Number of Output Tables                 | Count of target or intermediate tables modified or populated.                | 2 (`FACT_EXECUTIVE_SUMMARY`, `#staging_metrics` temp table)                                  |
| Variable Declarations                   | Number of declared variables and their usage complexity.                     | 2 (`@v_row_count`, `@error_message`); simple assignment and usage                            |
| Conditional Logic                       | Number of IF, CASE, or nested conditional blocks.                           | 3 (2 IFs for temp table existence, 1 CASE for income_amount normalization)                   |
| Loop Constructs                         | Number of WHILE or FOR loops, if present.                                   | 0                                                                                            |
| Join Conditions                         | Count and types of joins (INNER, LEFT, RIGHT, FULL).                        | 4 INNER JOINs (to dimension tables)                                                          |
| Aggregations                            | Number of aggregation operations (SUM, COUNT, AVG, etc.).                   | 0 (no explicit aggregation functions)                                                        |
| Subqueries / CTEs                       | Number of subqueries or Common Table Expressions used.                       | 0                                                                                            |
| Procedural Calls                        | Number of stored procedure or function invocations.                          | 0                                                                                            |
| DML Operations                          | Frequency of INSERT, UPDATE, DELETE, MERGE operations.                      | 1 INSERT INTO target table, 1 SELECT INTO temp table, 2 DROP TABLEs                          |
| Temporary Tables / Table Variables      | Number of temp tables or table variables created and used.                   | 1 temp table (`#staging_metrics`)                                                            |
| Transaction Handling                    | Count of BEGIN TRAN, COMMIT, ROLLBACK statements.                           | 0                                                                                            |
| Error Handling Blocks                   | Presence and count of TRY...CATCH logic.                                    | 0                                                                                            |
| Complexity Score (0–100)                | Based on nested logic, control flow, DML count, and procedural depth.        | 25                                                                                           |

**High-Complexity Areas:**
- Use of temp table for staging (requires refactoring for Databricks).
- Referential integrity enforced via multiple joins.
- Business rule logic embedded in a CASE statement.
- No dynamic SQL, no procedural loops, and minimal nested logic.

---

## 3. Syntax Differences

- **Variable Declarations:**  
  - T-SQL uses `DECLARE @var` for variables. Databricks declarative SQL does not support procedural variable declarations; such logic must be handled in SELECT/CTE expressions or external orchestration.
- **Temp Tables:**  
  - T-SQL allows `SELECT ... INTO #temp_table`. Databricks declarative SQL does not support temp tables; use CTEs or views instead.
- **Control Flow:**  
  - T-SQL IF statements (e.g., checking for temp table existence) are not supported in Databricks declarative SQL. Logic must be handled in orchestration or replaced with idempotent SQL.
- **PRINT Statements:**  
  - T-SQL `PRINT` is not supported. Logging must be handled externally or via notebook markdown/comments.
- **Procedural Logic:**  
  - No BEGIN...END blocks, no TRY...CATCH, no explicit transactions present, but if they were, these would need to be refactored.
- **Data Types:**  
  - No explicit data type conversions in the code, but ensure mappings like `DATETIME` → `TIMESTAMP`, and check for numeric precision.
- **Row Count Retrieval:**  
  - T-SQL uses `@@ROWCOUNT` for audit logging. In Databricks, this must be handled via a separate SELECT COUNT or as part of orchestration.

---

## 4. Manual Adjustments

- **Temp Table Usage:**  
  - Refactor temp table logic (`#staging_metrics`) into a CTE or view.
- **Variable Logic:**  
  - Manual adjustment required for row count/audit logging; move to orchestration or as a post-insert SELECT COUNT.
- **Control Flow:**  
  - Remove or externalize IF EXISTS checks and PRINT statements.
- **Audit Logging:**  
  - Implement audit logging outside SQL or as a separate query.
- **Error Handling:**  
  - No TRY...CATCH blocks to convert, but if error handling is required, must be implemented externally.
- **External Dependencies:**  
  - Ensure dimension tables are available and up to date in Databricks.
- **Business Rule Validation:**  
  - Validate that the CASE logic for `income_amount` is preserved and tested post-migration.

---

## 5. Optimization Techniques

- **Replace Temp Tables:**  
  - Use sequential CTEs to stage and transform data instead of temp tables.
- **Modularize Joins:**  
  - Structure joins in CTEs for clarity and maintainability.
- **Predicate Pushdown:**  
  - Apply filters early in the CTE chain to reduce data volume before joins.
- **Combine Steps:**  
  - Where possible, combine staging and transformation into a single CTE or view to minimize intermediate materialization.
- **Audit Logging:**  
  - If audit is required, use a SELECT COUNT(*) after INSERT or as part of orchestration.
- **Simplify Logic:**  
  - Move all business rule logic into SELECT/CASE statements within CTEs.

---

## 6. API Cost Consumption

```
apiCost: 0.0050 USD
```