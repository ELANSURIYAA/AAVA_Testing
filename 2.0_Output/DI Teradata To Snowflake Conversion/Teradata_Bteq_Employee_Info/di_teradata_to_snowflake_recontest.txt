```
=============================================
Author:        Ascendion AVA+
Created on:   
Description:   Python script to automate Teradata-to-Snowflake migration validation for employee backup join, including execution, data transfer, comparison, and reporting.
=============================================

import os
import sys
import logging
import traceback
import pandas as pd
import pyarrow as pa
import pyarrow.parquet as pq
import teradatasql
import snowflake.connector
from datetime import datetime

# ------------------ CONFIGURATION ------------------
# Credentials and connection info should be set via environment variables for security
TERADATA_HOST = os.getenv('TERADATA_HOST')
TERADATA_USER = os.getenv('TERADATA_USER')
TERADATA_PASS = os.getenv('TERADATA_PASS')
TERADATA_DATABASE = os.getenv('TERADATA_DATABASE')

SNOWFLAKE_USER = os.getenv('SNOWFLAKE_USER')
SNOWFLAKE_PASS = os.getenv('SNOWFLAKE_PASS')
SNOWFLAKE_ACCOUNT = os.getenv('SNOWFLAKE_ACCOUNT')
SNOWFLAKE_WAREHOUSE = os.getenv('SNOWFLAKE_WAREHOUSE')
SNOWFLAKE_DATABASE = os.getenv('SNOWFLAKE_DATABASE')
SNOWFLAKE_SCHEMA = os.getenv('SNOWFLAKE_SCHEMA')
SNOWFLAKE_STAGE = os.getenv('SNOWFLAKE_STAGE', 'EMPLOYEE_STAGE')

EXPORT_DIR = os.getenv('EXPORT_DIR', '/tmp/td_sf_migration')
os.makedirs(EXPORT_DIR, exist_ok=True)

# ------------------ LOGGING SETUP ------------------
logging.basicConfig(
    filename=os.path.join(EXPORT_DIR, 'migration_validation.log'),
    level=logging.INFO,
    format='%(asctime)s %(levelname)s %(message)s'
)

def log_and_print(msg):
    print(msg)
    logging.info(msg)

def log_error(msg):
    print(msg, file=sys.stderr)
    logging.error(msg)

# ------------------ TERADATA EXECUTION ------------------
def run_teradata_sql(sql_script):
    try:
        log_and_print("Connecting to Teradata...")
        conn = teradatasql.connect(
            host=TERADATA_HOST,
            user=TERADATA_USER,
            password=TERADATA_PASS,
            database=TERADATA_DATABASE
        )
        cursor = conn.cursor()
        log_and_print("Executing Teradata SQL script...")
        for statement in sql_script.split(';'):
            stmt = statement.strip()
            if stmt:
                cursor.execute(stmt)
        log_and_print("Teradata SQL executed successfully.")
        return conn
    except Exception as e:
        log_error(f"Teradata execution failed: {e}")
        log_error(traceback.format_exc())
        raise

# ------------------ EXPORT TERADATA TABLES ------------------
def export_table_to_csv(conn, table_name):
    try:
        log_and_print(f"Exporting Teradata table '{table_name}' to CSV...")
        df = pd.read_sql(f"SELECT * FROM {table_name}", conn)
        csv_path = os.path.join(EXPORT_DIR, f"{table_name}_{datetime.now().strftime('%Y%m%d%H%M%S')}.csv")
        df.to_csv(csv_path, index=False)
        log_and_print(f"Exported to {csv_path}")
        return csv_path, df
    except Exception as e:
        log_error(f"Export failed for table {table_name}: {e}")
        log_error(traceback.format_exc())
        raise

def convert_csv_to_parquet(csv_path):
    try:
        log_and_print(f"Converting CSV '{csv_path}' to Parquet...")
        df = pd.read_csv(csv_path)
        table = pa.Table.from_pandas(df)
        parquet_path = csv_path.replace('.csv', '.parquet')
        pq.write_table(table, parquet_path)
        log_and_print(f"Converted to {parquet_path}")
        return parquet_path
    except Exception as e:
        log_error(f"CSV to Parquet conversion failed: {e}")
        log_error(traceback.format_exc())
        raise

# ------------------ SNOWFLAKE EXECUTION ------------------
def run_snowflake_sql(sql_script):
    try:
        log_and_print("Connecting to Snowflake...")
        conn = snowflake.connector.connect(
            user=SNOWFLAKE_USER,
            password=SNOWFLAKE_PASS,
            account=SNOWFLAKE_ACCOUNT,
            warehouse=SNOWFLAKE_WAREHOUSE,
            database=SNOWFLAKE_DATABASE,
            schema=SNOWFLAKE_SCHEMA
        )
        cursor = conn.cursor()
        log_and_print("Executing Snowflake SQL script...")
        for statement in sql_script.split(';'):
            stmt = statement.strip()
            if stmt:
                cursor.execute(stmt)
        log_and_print("Snowflake SQL executed successfully.")
        return conn
    except Exception as e:
        log_error(f"Snowflake execution failed: {e}")
        log_error(traceback.format_exc())
        raise

# ------------------ SNOWFLAKE FILE TRANSFER ------------------
def upload_parquet_to_stage(sf_conn, parquet_path, stage_name):
    try:
        log_and_print(f"Uploading Parquet '{parquet_path}' to Snowflake stage '{stage_name}'...")
        cursor = sf_conn.cursor()
        put_cmd = f"PUT file://{parquet_path} @{stage_name} AUTO_COMPRESS=FALSE OVERWRITE=TRUE"
        cursor.execute(put_cmd)
        res = cursor.fetchall()
        log_and_print(f"PUT command result: {res}")
        # Integrity check
        cursor.execute(f"LIST @{stage_name}")
        files = cursor.fetchall()
        file_name = os.path.basename(parquet_path)
        if not any(file_name in row[0] for row in files):
            raise Exception(f"File {file_name} not found in stage {stage_name} after upload.")
        log_and_print(f"File {file_name} successfully uploaded and verified in stage {stage_name}.")
    except Exception as e:
        log_error(f"File upload failed: {e}")
        log_error(traceback.format_exc())
        raise

# ------------------ SNOWFLAKE EXTERNAL TABLE CREATION ------------------
def create_external_table(sf_conn, table_name, parquet_path, schema_dict, stage_name):
    try:
        log_and_print(f"Creating external table '{table_name}_ext' in Snowflake...")
        columns = ', '.join([f"{col} {dtype}" for col, dtype in schema_dict.items()])
        file_name = os.path.basename(parquet_path)
        create_ext_sql = f"""
            CREATE OR REPLACE EXTERNAL TABLE {table_name}_ext (
                {columns}
            )
            LOCATION=@{stage_name}/{file_name}
            FILE_FORMAT=(TYPE=PARQUET)
            AUTO_REFRESH = FALSE;
        """
        cursor = sf_conn.cursor()
        cursor.execute(create_ext_sql)
        log_and_print(f"External table '{table_name}_ext' created.")
    except Exception as e:
        log_error(f"External table creation failed: {e}")
        log_error(traceback.format_exc())
        raise

# ------------------ DATA COMPARISON ------------------
def compare_tables(sf_conn, table1, table2, key_cols):
    try:
        log_and_print(f"Comparing tables '{table1}' and '{table2}'...")
        cursor = sf_conn.cursor()
        # Row count comparison
        cursor.execute(f"SELECT COUNT(*) FROM {table1}")
        count1 = cursor.fetchone()[0]
        cursor.execute(f"SELECT COUNT(*) FROM {table2}")
        count2 = cursor.fetchone()[0]
        match_status = "MATCH" if count1 == count2 else "NO MATCH"
        # Column-by-column comparison
        cursor.execute(f"SELECT * FROM {table1} ORDER BY {', '.join(key_cols)}")
        data1 = cursor.fetchall()
        cursor.execute(f"SELECT * FROM {table2} ORDER BY {', '.join(key_cols)}")
        data2 = cursor.fetchall()
        col_discrepancies = []
        sample_mismatches = []
        if data1 != data2:
            match_status = "PARTIAL MATCH" if count1 == count2 else "NO MATCH"
            for i, (row1, row2) in enumerate(zip(data1, data2)):
                if row1 != row2:
                    col_discrepancies.append((row1, row2))
                    if len(sample_mismatches) < 5:
                        sample_mismatches.append({"row1": row1, "row2": row2})
        match_percent = (sum(1 for i in range(min(len(data1), len(data2))) if data1[i] == data2[i]) / max(len(data1), len(data2)) * 100) if max(len(data1), len(data2)) > 0 else 100
        return {
            "table1": table1,
            "table2": table2,
            "row_count_1": count1,
            "row_count_2": count2,
            "match_status": match_status,
            "match_percent": match_percent,
            "col_discrepancies": col_discrepancies,
            "sample_mismatches": sample_mismatches
        }
    except Exception as e:
        log_error(f"Table comparison failed: {e}")
        log_error(traceback.format_exc())
        raise

# ------------------ REPORTING ------------------
def generate_report(comparison_results, output_path):
    try:
        log_and_print("Generating comparison report...")
        with open(output_path, 'w') as f:
            for result in comparison_results:
                f.write(f"Table Comparison: {result['table1']} vs {result['table2']}\n")
                f.write(f"Match Status: {result['match_status']}\n")
                f.write(f"Row Counts: {result['row_count_1']} vs {result['row_count_2']}\n")
                f.write(f"Match Percentage: {result['match_percent']:.2f}%\n")
                if result['col_discrepancies']:
                    f.write("Column Discrepancies:\n")
                    for row1, row2 in result['col_discrepancies']:
                        f.write(f"  {row1} != {row2}\n")
                if result['sample_mismatches']:
                    f.write("Sample Mismatches:\n")
                    for sm in result['sample_mismatches']:
                        f.write(f"  {sm}\n")
                f.write("\n")
        log_and_print(f"Report generated at {output_path}")
    except Exception as e:
        log_error(f"Report generation failed: {e}")
        log_error(traceback.format_exc())
        raise

# ------------------ MAIN ORCHESTRATION ------------------
def main(teradata_sql, snowflake_sql):
    try:
        # Step 1: Execute Teradata SQL
        td_conn = run_teradata_sql(teradata_sql)
        # Step 2: Export Teradata target table(s)
        td_table = 'employee_bkup'
        csv_path, td_df = export_table_to_csv(td_conn, td_table)
        parquet_path = convert_csv_to_parquet(csv_path)
        schema_dict = {
            "EmployeeNo": "INTEGER",
            "FirstName": "VARCHAR(30)",
            "LastName": "VARCHAR(30)",
            "DepartmentNo": "SMALLINT",
            "NetPay": "INTEGER"
        }
        # Step 3: Connect to Snowflake
        sf_conn = run_snowflake_sql("")  # Empty string to just connect
        # Step 4: Upload Parquet to Snowflake stage
        upload_parquet_to_stage(sf_conn, parquet_path, SNOWFLAKE_STAGE)
        # Step 5: Create external table in Snowflake
        create_external_table(sf_conn, td_table, parquet_path, schema_dict, SNOWFLAKE_STAGE)
        # Step 6: Execute Snowflake SQL
        run_snowflake_sql(snowflake_sql)
        # Step 7: Compare external table vs Snowflake output table
        comparison = compare_tables(sf_conn, f"{td_table}_ext", td_table, ["EmployeeNo"])
        # Step 8: Reporting
        report_path = os.path.join(EXPORT_DIR, 'comparison_report.txt')
        generate_report([comparison], report_path)
        log_and_print("Migration validation completed successfully.")
        return comparison
    except Exception as e:
        log_error(f"Migration validation failed: {e}")
        log_error(traceback.format_exc())
        sys.exit(1)

# ------------------ ENTRY POINT ------------------
if __name__ == "__main__":
    # Read Teradata and Snowflake SQL from files or arguments
    teradata_sql = """
.LOGON 192.168.1.102/dbc,dbc; 
DATABASE tduser;
CREATE TABLE employee_bkup (EmployeeNo INTEGER,FirstName CHAR(30),LastName CHAR(30),DepartmentNo SMALLINT,NetPay INTEGER) Unique Primary Index(EmployeeNo);
DROP TABLE employee_bkup;
INSERT INTO employee_bkup 
SELECT a.EmployeeNo, a.FirstName, a.LastName, a.DepartmentNo, b.NetPay 
FROM Employee a INNER JOIN Salary b ON (a.EmployeeNo = b.EmployeeNo);
.LOGOFF;
"""
    snowflake_sql = """
DROP TABLE IF EXISTS employee_bkup;
CREATE TABLE employee_bkup (
    EmployeeNo INTEGER,
    FirstName VARCHAR(30),
    LastName VARCHAR(30),
    DepartmentNo SMALLINT,
    NetPay INTEGER
);
INSERT INTO employee_bkup
SELECT
    a.EmployeeNo,
    a.FirstName,
    a.LastName,
    a.DepartmentNo,
    b.NetPay
FROM
    Employee a
    INNER JOIN Salary b
        ON a.EmployeeNo = b.EmployeeNo;
"""
    result = main(teradata_sql, snowflake_sql)
    print("Structured Result:", result)
```