=============================================
Author:        AAVA
Date:   
Description:   Unit tests and Pytest script for validating the Fabric implementation of the Load_HoldingsFact ETL process, ensuring correct data transformation, integrity, and error handling.
=============================================

Test Case List:

| Test Case ID | Test Case Description                                                      | Expected Outcome                                                                                              |
|--------------|---------------------------------------------------------------------------|---------------------------------------------------------------------------------------------------------------|
| TC01         | Happy path: All staging and dimension data present and valid               | All records correctly loaded into FACT_EXECUTIVE_SUMMARY with proper joins and transformation                 |
| TC02         | Edge case: NULL income_amount in staging                                   | income_amount in FACT_EXECUTIVE_SUMMARY set to 0                                                              |
| TC03         | Edge case: Negative income_amount in staging                               | income_amount in FACT_EXECUTIVE_SUMMARY set to 0                                                              |
| TC04         | Edge case: Missing dimension key in DIM_DATE                               | Record with missing date_key not loaded into FACT_EXECUTIVE_SUMMARY                                           |
| TC05         | Edge case: Missing dimension key in DIM_INSTITUTION                        | Record with missing institution_id not loaded into FACT_EXECUTIVE_SUMMARY                                     |
| TC06         | Edge case: Missing dimension key in DIM_CORPORATION                        | Record with missing corporation_id not loaded into FACT_EXECUTIVE_SUMMARY                                     |
| TC07         | Edge case: Missing dimension key in DIM_PRODUCT                            | Record with missing product_id not loaded into FACT_EXECUTIVE_SUMMARY                                         |
| TC08         | Edge case: Empty staging table                                             | No records loaded into FACT_EXECUTIVE_SUMMARY                                                                 |
| TC09         | Error case: Staging table missing required columns                         | ETL process raises error due to missing columns                                                               |
| TC10         | Error case: Unexpected data type in numeric column                         | ETL process raises error or skips malformed records                                                           |

Pytest Script for Each Test Case:

```python
=============================================
Author:        AAVA
Date:   
Description:   Pytest unit tests for Fabric Load_HoldingsFact ETL process: transformation, joins, and error handling
=============================================

import pytest
import pandas as pd
from sqlalchemy import create_engine
from pandas.testing import assert_frame_equal

# Helper function to simulate the ETL transformation logic
def load_holdings_fact(
    stg_holding_metrics: pd.DataFrame,
    dim_date: pd.DataFrame,
    dim_institution: pd.DataFrame,
    dim_corporation: pd.DataFrame,
    dim_product: pd.DataFrame
) -> pd.DataFrame:
    # Join staging with dimensions
    merged = stg_holding_metrics \
        .merge(dim_date, left_on='date_value', right_on='date_key', how='inner', suffixes=('', '_date')) \
        .merge(dim_institution, on='institution_id', how='inner', suffixes=('', '_inst')) \
        .merge(dim_corporation, on='corporation_id', how='inner', suffixes=('', '_corp')) \
        .merge(dim_product, on='product_id', how='inner', suffixes=('', '_prod'))
    
    # Apply business rule: income_amount NULL or <0 -> 0
    merged['income_amount'] = merged['income_amount'].apply(lambda x: 0 if pd.isnull(x) or x < 0 else x)
    
    # Select and rename columns for fact table
    fact_cols = [
        'date_key', 'institution_id', 'corporation_id', 'product_id',
        'a120_amount', 'a120_count', 'a30_to_59_amount', 'a30_to_59_count',
        'a60_to_89_amount', 'a60_to_89_count', 'a90_to_119_amount', 'a90_to_119_count',
        'charge_off_amount', 'charge_off_count', 'fraud_amount', 'fraud_count',
        'income_amount', 'number_of_accounts', 'purchases_amount', 'purchases_count'
    ]
    fact_df = merged[fact_cols].copy()
    return fact_df

# Fixtures for dimension tables
@pytest.fixture
def dim_date():
    return pd.DataFrame({'date_key': [20230101, 20230102]})

@pytest.fixture
def dim_institution():
    return pd.DataFrame({'institution_id': [1, 2]})

@pytest.fixture
def dim_corporation():
    return pd.DataFrame({'corporation_id': [10, 20]})

@pytest.fixture
def dim_product():
    return pd.DataFrame({'product_id': [100, 200]})

# TC01: Happy path
def test_happy_path(dim_date, dim_institution, dim_corporation, dim_product):
    stg = pd.DataFrame({
        'date_value': [20230101, 20230102],
        'institution_id': [1, 2],
        'corporation_id': [10, 20],
        'product_id': [100, 200],
        'a120_amount': [1000, 2000],
        'a120_count': [10, 20],
        'a30_to_59_amount': [300, 400],
        'a30_to_59_count': [3, 4],
        'a60_to_89_amount': [500, 600],
        'a60_to_89_count': [5, 6],
        'a90_to_119_amount': [700, 800],
        'a90_to_119_count': [7, 8],
        'charge_off_amount': [50, 60],
        'charge_off_count': [1, 2],
        'fraud_amount': [5, 6],
        'fraud_count': [0, 1],
        'income_amount': [100, 200],
        'number_of_accounts': [100, 200],
        'purchases_amount': [10000, 20000],
        'purchases_count': [100, 200]
    })
    result = load_holdings_fact(stg, dim_date, dim_institution, dim_corporation, dim_product)
    assert len(result) == 2
    assert (result['income_amount'] == [100, 200]).all()

# TC02: NULL income_amount
def test_null_income_amount(dim_date, dim_institution, dim_corporation, dim_product):
    stg = pd.DataFrame({
        'date_value': [20230101],
        'institution_id': [1],
        'corporation_id': [10],
        'product_id': [100],
        'a120_amount': [1000],
        'a120_count': [10],
        'a30_to_59_amount': [300],
        'a30_to_59_count': [3],
        'a60_to_89_amount': [500],
        'a60_to_89_count': [5],
        'a90_to_119_amount': [700],
        'a90_to_119_count': [7],
        'charge_off_amount': [50],
        'charge_off_count': [1],
        'fraud_amount': [5],
        'fraud_count': [0],
        'income_amount': [None],
        'number_of_accounts': [100],
        'purchases_amount': [10000],
        'purchases_count': [100]
    })
    result = load_holdings_fact(stg, dim_date, dim_institution, dim_corporation, dim_product)
    assert result.iloc[0]['income_amount'] == 0

# TC03: Negative income_amount
def test_negative_income_amount(dim_date, dim_institution, dim_corporation, dim_product):
    stg = pd.DataFrame({
        'date_value': [20230101],
        'institution_id': [1],
        'corporation_id': [10],
        'product_id': [100],
        'a120_amount': [1000],
        'a120_count': [10],
        'a30_to_59_amount': [300],
        'a30_to_59_count': [3],
        'a60_to_89_amount': [500],
        'a60_to_89_count': [5],
        'a90_to_119_amount': [700],
        'a90_to_119_count': [7],
        'charge_off_amount': [50],
        'charge_off_count': [1],
        'fraud_amount': [5],
        'fraud_count': [0],
        'income_amount': [-100],
        'number_of_accounts': [100],
        'purchases_amount': [10000],
        'purchases_count': [100]
    })
    result = load_holdings_fact(stg, dim_date, dim_institution, dim_corporation, dim_product)
    assert result.iloc[0]['income_amount'] == 0

# TC04: Missing DIM_DATE key
def test_missing_dim_date(dim_institution, dim_corporation, dim_product):
    dim_date = pd.DataFrame({'date_key': [20230102]})  # Only 20230102 present
    stg = pd.DataFrame({
        'date_value': [20230101],
        'institution_id': [1],
        'corporation_id': [10],
        'product_id': [100],
        'a120_amount': [1000],
        'a120_count': [10],
        'a30_to_59_amount': [300],
        'a30_to_59_count': [3],
        'a60_to_89_amount': [500],
        'a60_to_89_count': [5],
        'a90_to_119_amount': [700],
        'a90_to_119_count': [7],
        'charge_off_amount': [50],
        'charge_off_count': [1],
        'fraud_amount': [5],
        'fraud_count': [0],
        'income_amount': [100],
        'number_of_accounts': [100],
        'purchases_amount': [10000],
        'purchases_count': [100]
    })
    result = load_holdings_fact(stg, dim_date, dim_institution, dim_corporation, dim_product)
    assert result.empty

# TC05: Missing DIM_INSTITUTION key
def test_missing_dim_institution(dim_date, dim_corporation, dim_product):
    dim_institution = pd.DataFrame({'institution_id': [2]})  # Only institution_id 2 present
    stg = pd.DataFrame({
        'date_value': [20230101],
        'institution_id': [1],
        'corporation_id': [10],
        'product_id': [100],
        'a120_amount': [1000],
        'a120_count': [10],
        'a30_to_59_amount': [300],
        'a30_to_59_count': [3],
        'a60_to_89_amount': [500],
        'a60_to_89_count': [5],
        'a90_to_119_amount': [700],
        'a90_to_119_count': [7],
        'charge_off_amount': [50],
        'charge_off_count': [1],
        'fraud_amount': [5],
        'fraud_count': [0],
        'income_amount': [100],
        'number_of_accounts': [100],
        'purchases_amount': [10000],
        'purchases_count': [100]
    })
    result = load_holdings_fact(stg, dim_date, dim_institution, dim_corporation, dim_product)
    assert result.empty

# TC06: Missing DIM_CORPORATION key
def test_missing_dim_corporation(dim_date, dim_institution, dim_product):
    dim_corporation = pd.DataFrame({'corporation_id': [20]})  # Only corporation_id 20 present
    stg = pd.DataFrame({
        'date_value': [20230101],
        'institution_id': [1],
        'corporation_id': [10],
        'product_id': [100],
        'a120_amount': [1000],
        'a120_count': [10],
        'a30_to_59_amount': [300],
        'a30_to_59_count': [3],
        'a60_to_89_amount': [500],
        'a60_to_89_count': [5],
        'a90_to_119_amount': [700],
        'a90_to_119_count': [7],
        'charge_off_amount': [50],
        'charge_off_count': [1],
        'fraud_amount': [5],
        'fraud_count': [0],
        'income_amount': [100],
        'number_of_accounts': [100],
        'purchases_amount': [10000],
        'purchases_count': [100]
    })
    result = load_holdings_fact(stg, dim_date, dim_institution, dim_corporation, dim_product)
    assert result.empty

# TC07: Missing DIM_PRODUCT key
def test_missing_dim_product(dim_date, dim_institution, dim_corporation):
    dim_product = pd.DataFrame({'product_id': [200]})  # Only product_id 200 present
    stg = pd.DataFrame({
        'date_value': [20230101],
        'institution_id': [1],
        'corporation_id': [10],
        'product_id': [100],
        'a120_amount': [1000],
        'a120_count': [10],
        'a30_to_59_amount': [300],
        'a30_to_59_count': [3],
        'a60_to_89_amount': [500],
        'a60_to_89_count': [5],
        'a90_to_119_amount': [700],
        'a90_to_119_count': [7],
        'charge_off_amount': [50],
        'charge_off_count': [1],
        'fraud_amount': [5],
        'fraud_count': [0],
        'income_amount': [100],
        'number_of_accounts': [100],
        'purchases_amount': [10000],
        'purchases_count': [100]
    })
    result = load_holdings_fact(stg, dim_date, dim_institution, dim_corporation, dim_product)
    assert result.empty

# TC08: Empty staging table
def test_empty_staging(dim_date, dim_institution, dim_corporation, dim_product):
    stg = pd.DataFrame(columns=[
        'date_value', 'institution_id', 'corporation_id', 'product_id',
        'a120_amount', 'a120_count', 'a30_to_59_amount', 'a30_to_59_count',
        'a60_to_89_amount', 'a60_to_89_count', 'a90_to_119_amount', 'a90_to_119_count',
        'charge_off_amount', 'charge_off_count', 'fraud_amount', 'fraud_count',
        'income_amount', 'number_of_accounts', 'purchases_amount', 'purchases_count'
    ])
    result = load_holdings_fact(stg, dim_date, dim_institution, dim_corporation, dim_product)
    assert result.empty

# TC09: Missing required columns in staging
def test_missing_columns(dim_date, dim_institution, dim_corporation, dim_product):
    stg = pd.DataFrame({
        'date_value': [20230101],
        # Missing institution_id, corporation_id, product_id, etc.
        'a120_amount': [1000],
        'a120_count': [10],
        'income_amount': [100]
    })
    with pytest.raises(KeyError):
        load_holdings_fact(stg, dim_date, dim_institution, dim_corporation, dim_product)

# TC10: Unexpected data type in numeric column
def test_unexpected_data_type(dim_date, dim_institution, dim_corporation, dim_product):
    stg = pd.DataFrame({
        'date_value': [20230101],
        'institution_id': [1],
        'corporation_id': [10],
        'product_id': [100],
        'a120_amount': ['not_a_number'],
        'a120_count': [10],
        'a30_to_59_amount': [300],
        'a30_to_59_count': [3],
        'a60_to_89_amount': [500],
        'a60_to_89_count': [5],
        'a90_to_119_amount': [700],
        'a90_to_119_count': [7],
        'charge_off_amount': [50],
        'charge_off_count': [1],
        'fraud_amount': [5],
        'fraud_count': [0],
        'income_amount': [100],
        'number_of_accounts': [100],
        'purchases_amount': [10000],
        'purchases_count': [100]
    })
    with pytest.raises(ValueError):
        # Try to coerce to numeric, should fail
        stg['a120_amount'] = pd.to_numeric(stg['a120_amount'])
        load_holdings_fact(stg, dim_date, dim_institution, dim_corporation, dim_product)
```

API Cost Estimation:
apiCost: 0.0047 USD

Transformation Change Detection & Manual Interventions (Summary):

- Expression Transformation Mapping: CASE logic for `income_amount` mapped to vectorized DataFrame operation.
- Aggregator Transformations: No aggregations; direct field mapping.
- Join Strategies: 4 INNER JOINs mapped to DataFrame merges.
- Data Type Transformations: Direct mapping; ensure numeric columns are validated.
- Null Handling and Case Sensitivity: Explicit handling for NULL and negative values in `income_amount`.

Manual Interventions Recommended:
- Performance optimizations: Broadcast joins, partitioning on `date_key`, caching dimension tables.
- Edge case handling: NULL/negative values, missing dimension keys.
- Error handling: Raise exceptions for missing columns/data types.
- Data quality: Validate input schema and types before processing.

All required sections and code are provided above.