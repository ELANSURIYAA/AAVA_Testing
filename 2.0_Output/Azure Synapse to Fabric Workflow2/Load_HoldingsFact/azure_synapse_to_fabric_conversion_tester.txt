```
=============================================
Author:        AAVA
Date:   
Description:   Unit Testing and Pytest Script Design for Fabric Converted from Synapse Stored Procedures (Load_HoldingsFact)
=============================================

1. Transformation Change Detection

- **Expression Transformation Mapping**:  
  The Synapse CASE statement for `income_amount` (`CASE WHEN stg.income_amount IS NULL OR stg.income_amount < 0 THEN 0 ELSE stg.income_amount END`) is mapped to a vectorized operation in Fabric (e.g., using `.apply()` or `F.when().otherwise()` in Spark).
- **Aggregator Transformations**:  
  No aggregations in the original procedure; direct field mapping is preserved.
- **Join Strategies**:  
  Synapse uses INNER JOINs for referential integrity. Fabric code uses DataFrame `.merge()` or `.join()` with equivalent logic.
- **Data Type Transformations**:  
  Synapse numeric types (e.g., amounts) are mapped to Fabric's float/decimal types; date keys are mapped to integer or timestamp types as appropriate.
- **Null Handling and Case Sensitivity Adjustments**:  
  Explicit null handling for `income_amount` is preserved. Case sensitivity is managed by column naming conventions in Fabric.

2. Recommended Manual Interventions

- **Performance optimizations**:  
  - Implement broadcast joins for small dimension tables.  
  - Partition fact table by `date_key` for query performance.  
  - Cache dimension tables if reused.
- **Edge case handling**:  
  - Ensure all NULL and negative values for `income_amount` are set to 0.  
  - Handle missing dimension keys by excluding unmatched rows.
- **Complex transformations**:  
  - If additional business rules are added, consider UDFs for complex logic.
- **String manipulations and format conversions**:  
  - Ensure all IDs and keys are consistently typed (e.g., string vs. int).
- **Error handling**:  
  - Implement logging and exception handling for missing columns or data type mismatches.

3. Test Case List:

| Test Case ID | Test Case Description                                                                 | Expected Outcome                                                                                      |
|--------------|--------------------------------------------------------------------------------------|------------------------------------------------------------------------------------------------------|
| TC01         | Happy path: Valid staging data, all dimension keys present, positive income_amount    | Fact table is loaded with correct mappings and income_amount transformation                           |
| TC02         | Edge case: income_amount is NULL                                                     | income_amount in fact table is set to 0                                                              |
| TC03         | Edge case: income_amount is negative                                                 | income_amount in fact table is set to 0                                                              |
| TC04         | Edge case: Missing dimension key (e.g., institution_key not found)                   | Row is excluded from fact table load                                                                  |
| TC05         | Edge case: Empty staging table                                                       | No rows loaded into fact table                                                                        |
| TC06         | Error handling: Staging table missing required column                                | ETL process raises exception or logs error                                                            |
| TC07         | Error handling: Unexpected data type in income_amount                                | ETL process raises exception or logs error                                                            |
| TC08         | Boundary: Large numeric values for aging buckets                                     | Fact table correctly stores large values                                                              |
| TC09         | Boundary: All aging buckets are zero                                                 | Fact table stores zeros for all aging bucket columns                                                  |
| TC10         | Edge case: Duplicate records in staging table                                        | Fact table does not contain duplicate records (if deduplication logic is present)                     |

4. Pytest Script for Each Test Case

```python
=============================================
Author:        AAVA
Date:   
Description:   Pytest script for unit testing Fabric ETL logic for Load_HoldingsFact (converted from Synapse stored procedure)
=============================================

import pytest
import pandas as pd

# Helper function to simulate Fabric ETL logic
def load_holdings_fact(staging_df, dim_date_df, dim_institution_df, dim_corporation_df, dim_product_df):
    # Join staging with dimensions
    df = staging_df \
        .merge(dim_date_df, on='date_key', how='inner') \
        .merge(dim_institution_df, on='institution_key', how='inner') \
        .merge(dim_corporation_df, on='corporation_key', how='inner') \
        .merge(dim_product_df, on='product_key', how='inner')
    # Data quality transformation
    df['income_amount'] = df['income_amount'].apply(lambda x: 0 if pd.isnull(x) or x < 0 else x)
    # Select relevant columns for fact table
    fact_cols = [
        'date_key', 'institution_key', 'corporation_key', 'product_key',
        'aging_30_59', 'aging_60_89', 'aging_90_119', 'aging_120_plus', 'income_amount'
    ]
    return df[fact_cols]

@pytest.fixture
def dim_tables():
    dim_date = pd.DataFrame({'date_key': [20230101, 20230102]})
    dim_institution = pd.DataFrame({'institution_key': [1, 2]})
    dim_corporation = pd.DataFrame({'corporation_key': [100, 200]})
    dim_product = pd.DataFrame({'product_key': ['A', 'B']})
    return dim_date, dim_institution, dim_corporation, dim_product

def test_TC01_happy_path(dim_tables):
    dim_date, dim_institution, dim_corporation, dim_product = dim_tables
    staging = pd.DataFrame({
        'date_key': [20230101],
        'institution_key': [1],
        'corporation_key': [100],
        'product_key': ['A'],
        'aging_30_59': [10],
        'aging_60_89': [5],
        'aging_90_119': [0],
        'aging_120_plus': [1],
        'income_amount': [100.0]
    })
    result = load_holdings_fact(staging, dim_date, dim_institution, dim_corporation, dim_product)
    assert result.iloc[0]['income_amount'] == 100.0
    assert result.shape[0] == 1

def test_TC02_income_null(dim_tables):
    dim_date, dim_institution, dim_corporation, dim_product = dim_tables
    staging = pd.DataFrame({
        'date_key': [20230101],
        'institution_key': [1],
        'corporation_key': [100],
        'product_key': ['A'],
        'aging_30_59': [10],
        'aging_60_89': [5],
        'aging_90_119': [0],
        'aging_120_plus': [1],
        'income_amount': [None]
    })
    result = load_holdings_fact(staging, dim_date, dim_institution, dim_corporation, dim_product)
    assert result.iloc[0]['income_amount'] == 0

def test_TC03_income_negative(dim_tables):
    dim_date, dim_institution, dim_corporation, dim_product = dim_tables
    staging = pd.DataFrame({
        'date_key': [20230101],
        'institution_key': [1],
        'corporation_key': [100],
        'product_key': ['A'],
        'aging_30_59': [10],
        'aging_60_89': [5],
        'aging_90_119': [0],
        'aging_120_plus': [1],
        'income_amount': [-50.0]
    })
    result = load_holdings_fact(staging, dim_date, dim_institution, dim_corporation, dim_product)
    assert result.iloc[0]['income_amount'] == 0

def test_TC04_missing_dimension_key(dim_tables):
    dim_date, dim_institution, dim_corporation, dim_product = dim_tables
    staging = pd.DataFrame({
        'date_key': [20230101],
        'institution_key': [999],  # Not present in dim_institution
        'corporation_key': [100],
        'product_key': ['A'],
        'aging_30_59': [10],
        'aging_60_89': [5],
        'aging_90_119': [0],
        'aging_120_plus': [1],
        'income_amount': [100.0]
    })
    result = load_holdings_fact(staging, dim_date, dim_institution, dim_corporation, dim_product)
    assert result.shape[0] == 0  # Row excluded

def test_TC05_empty_staging(dim_tables):
    dim_date, dim_institution, dim_corporation, dim_product = dim_tables
    staging = pd.DataFrame(columns=[
        'date_key', 'institution_key', 'corporation_key', 'product_key',
        'aging_30_59', 'aging_60_89', 'aging_90_119', 'aging_120_plus', 'income_amount'
    ])
    result = load_holdings_fact(staging, dim_date, dim_institution, dim_corporation, dim_product)
    assert result.shape[0] == 0

def test_TC06_missing_column(dim_tables):
    dim_date, dim_institution, dim_corporation, dim_product = dim_tables
    staging = pd.DataFrame({
        'date_key': [20230101],
        # 'institution_key' column missing
        'corporation_key': [100],
        'product_key': ['A'],
        'aging_30_59': [10],
        'aging_60_89': [5],
        'aging_90_119': [0],
        'aging_120_plus': [1],
        'income_amount': [100.0]
    })
    with pytest.raises(KeyError):
        load_holdings_fact(staging, dim_date, dim_institution, dim_corporation, dim_product)

def test_TC07_unexpected_income_type(dim_tables):
    dim_date, dim_institution, dim_corporation, dim_product = dim_tables
    staging = pd.DataFrame({
        'date_key': [20230101],
        'institution_key': [1],
        'corporation_key': [100],
        'product_key': ['A'],
        'aging_30_59': [10],
        'aging_60_89': [5],
        'aging_90_119': [0],
        'aging_120_plus': [1],
        'income_amount': ['not_a_number']
    })
    with pytest.raises(TypeError):
        load_holdings_fact(staging, dim_date, dim_institution, dim_corporation, dim_product)

def test_TC08_large_aging_values(dim_tables):
    dim_date, dim_institution, dim_corporation, dim_product = dim_tables
    staging = pd.DataFrame({
        'date_key': [20230101],
        'institution_key': [1],
        'corporation_key': [100],
        'product_key': ['A'],
        'aging_30_59': [99999999],
        'aging_60_89': [88888888],
        'aging_90_119': [77777777],
        'aging_120_plus': [66666666],
        'income_amount': [100.0]
    })
    result = load_holdings_fact(staging, dim_date, dim_institution, dim_corporation, dim_product)
    assert result.iloc[0]['aging_30_59'] == 99999999
    assert result.iloc[0]['aging_120_plus'] == 66666666

def test_TC09_zero_aging_buckets(dim_tables):
    dim_date, dim_institution, dim_corporation, dim_product = dim_tables
    staging = pd.DataFrame({
        'date_key': [20230101],
        'institution_key': [1],
        'corporation_key': [100],
        'product_key': ['A'],
        'aging_30_59': [0],
        'aging_60_89': [0],
        'aging_90_119': [0],
        'aging_120_plus': [0],
        'income_amount': [100.0]
    })
    result = load_holdings_fact(staging, dim_date, dim_institution, dim_corporation, dim_product)
    assert all(result.iloc[0][['aging_30_59', 'aging_60_89', 'aging_90_119', 'aging_120_plus']] == 0)

def test_TC10_duplicate_records(dim_tables):
    dim_date, dim_institution, dim_corporation, dim_product = dim_tables
    staging = pd.DataFrame({
        'date_key': [20230101, 20230101],
        'institution_key': [1, 1],
        'corporation_key': [100, 100],
        'product_key': ['A', 'A'],
        'aging_30_59': [10, 10],
        'aging_60_89': [5, 5],
        'aging_90_119': [0, 0],
        'aging_120_plus': [1, 1],
        'income_amount': [100.0, 100.0]
    })
    result = load_holdings_fact(staging, dim_date, dim_institution, dim_corporation, dim_product)
    # If deduplication is required, change the assertion accordingly
    assert result.shape[0] == 2  # No deduplication in this logic

# Note: For actual Spark/Fabric implementation, replace Pandas with Spark DataFrames and use Spark SQL functions.

```

5. API Cost Estimation

```
apiCost: 0.0847 USD