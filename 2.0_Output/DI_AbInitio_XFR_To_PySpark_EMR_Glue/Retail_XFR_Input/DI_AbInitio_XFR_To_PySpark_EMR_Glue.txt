def cleanse_transform(df):
    from pyspark.sql.functions import col
    return df.withColumn("txn_id", col("txn_id").cast("decimal(10,0)")) \
             .withColumn("store_id", col("store_id")) \
             .withColumn("txn_date", col("txn_date_str").cast("date")) \
             .withColumn("total_amount", col("quantity_str").cast("decimal(10,2)") * col("unit_price_str").cast("decimal(10,2)")) \
             .withColumn("tax_amount", col("total_amount") * 0) \
             .withColumn("final_bill", col("total_amount") * 0) \
             .withColumn("loyalty_points", col("total_amount") * 0)

def pricing_logic(df):
    from pyspark.sql.functions import floor, col
    tax_rate = 0.085
    return df.withColumn("tax_amount", col("total_amount") * tax_rate) \
             .withColumn("final_bill", col("total_amount") + (col("total_amount") * tax_rate)) \
             .withColumn("loyalty_points", floor(col("total_amount") / 10))

def rollup_logic(df):
    from pyspark.sql import functions as F
    grouped = df.groupBy("store_id", "txn_date").agg(
        F.sum("final_bill").alias("total_gross_sales"),
        F.sum("tax_amount").alias("total_tax_collected"),
        F.count("*").alias("total_transaction_count")
    )
    return grouped.withColumn("report_date", col("txn_date")) \
                  .withColumn("newline", F.lit("\n")) \
                  .select("store_id", "report_date", "total_gross_sales", "total_tax_collected", "total_transaction_count", "newline")
