=============================================
Author:        AAVA
Created on : 
Description:   Loads the FACT_EXECUTIVE_SUMMARY table with summarized holding metrics from staging, applying business rules and data quality checks.
=============================================

Procedure Name: LOAD_FACT_EXECUTIVE_SUMMARY

Converted Databricks Procedure:

-- Create or replace the Databricks SQL procedure for loading FACT_EXECUTIVE_SUMMARY

CREATE OR REPLACE PROCEDURE LOAD_FACT_EXECUTIVE_SUMMARY()
RETURNS STRING
LANGUAGE SQL
AS
$$
-- Step 1: Prepare staging data as a temporary view
CREATE OR REPLACE TEMP VIEW staging_metrics AS
SELECT *
FROM STG_HOLDING_METRICS;

-- Step 2: Insert valid records into Fact table
INSERT INTO FACT_EXECUTIVE_SUMMARY (
    date_key,
    institution_id,
    corporation_id,
    product_id,
    a120_amount,
    a120_count,
    a30_to_59_amount,
    a30_to_59_count,
    a60_to_89_amount,
    a60_to_89_count,
    a90_to_119_amount,
    a90_to_119_count,
    charge_off_amount,
    charge_off_count,
    fraud_amount,
    fraud_count,
    income_amount,
    number_of_accounts,
    purchases_amount,
    purchases_count
)
SELECT 
    dt.date_key,
    inst.institution_id,
    corp.corporation_id,
    prod.product_id,
    stg.a120_amount,
    stg.a120_count,
    stg.a30_to_59_amount,
    stg.a30_to_59_count,
    stg.a60_to_89_amount,
    stg.a60_to_89_count,
    stg.a90_to_119_amount,
    stg.a90_to_119_count,
    stg.charge_off_amount,
    stg.charge_off_count,
    stg.fraud_amount,
    stg.fraud_count,
    CASE 
        WHEN stg.income_amount IS NULL OR stg.income_amount < 0 THEN 0
        ELSE stg.income_amount
    END AS income_amount,
    stg.number_of_accounts,
    stg.purchases_amount,
    stg.purchases_count
FROM staging_metrics stg
INNER JOIN DIM_DATE dt ON dt.date_key = stg.date_value
INNER JOIN DIM_INSTITUTION inst ON inst.institution_id = stg.institution_id
INNER JOIN DIM_CORPORATION corp ON corp.corporation_id = stg.corporation_id
INNER JOIN DIM_PRODUCT prod ON prod.product_id = stg.product_id;

-- Step 3: Audit logging (row count inserted)
-- Databricks SQL does not support PRINT, so return the row count as a string
RETURN (
  SELECT CONCAT(COUNT(*), ' records inserted into FACT_EXECUTIVE_SUMMARY.')
  FROM staging_metrics stg
  INNER JOIN DIM_DATE dt ON dt.date_key = stg.date_value
  INNER JOIN DIM_INSTITUTION inst ON inst.institution_id = stg.institution_id
  INNER JOIN DIM_CORPORATION corp ON corp.corporation_id = stg.corporation_id
  INNER JOIN DIM_PRODUCT prod ON prod.product_id = stg.product_id
);

-- Step 4: Cleanup
DROP VIEW IF EXISTS staging_metrics;
$$;

-- To execute the procedure and see the audit log:
-- CALL LOAD_FACT_EXECUTIVE_SUMMARY();

Instructions for Handling the Databricks Job Executor Tool

- Use the above Databricks SQL as “Code” in the Databricks SQL Editor or notebook.
- Create a SQL notebook in Databricks, paste the code, and run the notebook as a job.
- After execution, the procedure will return the number of records inserted as a string.
- Validate the output by comparing the row count and data in FACT_EXECUTIVE_SUMMARY with the expected results from the original Synapse procedure.

Job Output:
- The output will be a string indicating the number of records inserted, e.g., "1234 records inserted into FACT_EXECUTIVE_SUMMARY."

(Note: The metadata header is included only once at the top as required.)