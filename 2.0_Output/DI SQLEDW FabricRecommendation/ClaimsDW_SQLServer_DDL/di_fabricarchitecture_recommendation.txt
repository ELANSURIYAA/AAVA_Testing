```markdown
# Optimized Microsoft Fabric Architecture & Migration Recommendations

---

## Table of Contents
1. [Assessment of Existing Environment](#assessment-of-existing-environment)
    - Inventory Analysis
    - Package Complexity
    - Report Complexity
2. [Architecture Principles for Fabric](#architecture-principles-for-fabric)
    - Architecture Overview & Diagram
    - Data Lake-first Architecture
    - Delta Lake and Lakehouse Strategy
    - Semantic Model Usage
3. [SSIS Migration Strategy](#ssis-migration-strategy)
    - Retire / Refactor / Consolidate / Migrate Decision Framework
    - Low-code ETL with Dataflows Gen2
    - Notebooks and Spark for Advanced Logic
    - Migration Table
4. [SSRS Migration Strategy](#ssrs-migration-strategy)
    - Paginated Reports in Power BI Service
    - Analytical Dashboard Recommendation
    - Migration Table
5. [Integration and Connectivity](#integration-and-connectivity)
    - Source Data Connectors
    - DirectQuery/Import Modes
    - Data Gateway Considerations
6. [Security and Governance](#security-and-governance)
    - Role-based Access Control (RBAC)
    - Sensitivity Labels and Lineage
    - Auditability and Compliance
7. [Cost and Performance](#cost-and-performance)
    - Fabric Capacity Planning
    - Compute Cost Optimization
8. [Monitoring and Observability](#monitoring-and-observability)
    - Fabric Monitoring Capabilities
    - Pipeline and Report Monitoring
9. [Future Scalability and Roadmap](#future-scalability-and-roadmap)
    - Real-time and Streaming Scenarios
    - AI/ML Integration

---

## Assessment of Existing Environment

### Inventory Analysis

**SSIS Packages:**
- 6 ETL packages:  
    - EDW_CC_Load_DimClaim.dtsx  
    - EDW_CC_Load_DimCheck.dtsx  
    - EDW_CC_Load_DimClaimant.dtsx  
    - EDW_CC_Load_DimExposure.dtsx  
    - EDW_CC_Load_DimLossLocation.dtsx  
    - EDW_CC_Load_DimUser.dtsx  
    - EDW_CC_Load_FactClaimTransaction.dtsx  
    - EDW_CC_Load_LossBodyParts.dtsx  
- Target tables: DimClaim, DimCheck, DimClaimant, DimExposure, DimLossLocation, DimUser, FactClaimTransaction, LossBodyParts
- Lookup operations: PublicID, BeanVersion (SCD logic), ClaimID (LossBodyParts)
- Unused tables: dmproc.Audit, dmproc.AuditReference, dmproc.ErrorLog, dmproc.BatchIdentifier

**SSRS Reports:**
- 3 main reports: Claims Financial Performance, Claims Operational Efficiency, ClaimsStatusSummary
- Referenced tables: DimClaim, FactClaimTransaction, DimUser
- Unreferenced tables: DimCheck, DimClaimant, DimExposure, DimLossLocation, LossBodyParts, all dmproc.* tables

**Source and Target Systems:**
- Source: Legacy operational systems
- Target: SQL Server EDW

**Frequency and Schedule of Jobs/Reports:**
- ETL: Batch, scheduled nightly
- Reports: Daily/weekly/monthly

### Package Complexity

- SCD Type 1/2 update logic
- Custom business rules: IsActive calculation, batch handling, not null checks, type conversions, joins
- Use of BeanVersion for SCD
- Error handling: minimal, mostly batch-level
- Parameters: batch, date, source system

### Report Complexity

- Datasets: Joins between DimClaim, FactClaimTransaction, DimUser
- Parameters: Date ranges, claim status, user
- Expressions: KPI calculations, conditional aggregations
- Drillthrough navigation: Handler details, claim details

---

## Architecture Principles for Fabric

### Architecture Overview & Diagram

**Principles:**
- Data Lake-first: OneLake as central store
- ELT over ETL: Leverage Lakehouse, Delta Lake, and shortcuts
- Semantic Model: Power BI replaces SSRS datasets

**Fabric Architecture Diagram:**

```
+------------------+      +---------------------+      +---------------------+
|  Data Sources    | ---> | Ingestion Layer     | ---> | Storage Layer       |
| (Legacy Systems) |      | (Dataflows Gen2,    |      | (OneLake, Lakehouse |
|                  |      |  Pipelines)         |      |  Warehouse)         |
+------------------+      +---------------------+      +---------------------+
                                                        |
                                                        v
                                                +---------------------+
                                                | Processing Layer    |
                                                | (Notebooks, Spark,  |
                                                |  T-SQL Endpoints)   |
                                                +---------------------+
                                                        |
                                                        v
                                                +---------------------+
                                                | Semantic Model      |
                                                | (Power BI Dataset)  |
                                                +---------------------+
                                                        |
                                                        v
                                                +---------------------+
                                                | Reporting Layer     |
                                                | (Power BI Reports,  |
                                                |  Paginated Reports) |
                                                +---------------------+
                                                        |
                                                        v
                                                +---------------------+
                                                | Governance Layer    |
                                                | (Purview, RBAC)     |
                                                +---------------------+
```

**Data Flow:**
- Data Sources --> Ingestion Layer (Dataflows Gen2, Pipelines) --> Storage Layer (OneLake, Lakehouse, Warehouse)
- Storage Layer --> Processing Layer (Notebooks, Spark, T-SQL)
- Processing Layer --> Semantic Model (Power BI Dataset)
- Semantic Model --> Reporting Layer (Power BI Reports, Paginated Reports)
- Governance Layer overlays all for security, lineage, and compliance

### Data Lake-first Architecture

- OneLake centralizes all data, enables shortcutting and cross-workspace access
- Lakehouse stores raw and curated data, supports Delta Lake format for ACID transactions

### Delta Lake and Lakehouse Strategy

- ETL logic transitioned to ELT: Dataflows Gen2 for simple transformations, Spark/Notebooks for complex
- Use Delta Lake for incremental loads, SCD, and data versioning

### Semantic Model Usage

- Power BI semantic models replace SSRS datasets
- DAX for business logic and KPIs
- DirectQuery/Import modes for performance tuning

---

## SSIS Migration Strategy

### Decision Framework

| Package Name                        | Recommended Approach | Reason for the Recommendation |
|--------------------------------------|---------------------|------------------------------|
| EDW_CC_Load_DimClaim.dtsx           | Refactor            | SCD logic, batch, not null checks, can be implemented in Dataflows Gen2 or Spark Notebooks |
| EDW_CC_Load_DimCheck.dtsx           | Refactor            | SCD logic, batch, not null checks, Dataflows Gen2 or Spark Notebooks |
| EDW_CC_Load_DimClaimant.dtsx        | Refactor            | SCD logic, batch, not null checks, Dataflows Gen2 or Spark Notebooks |
| EDW_CC_Load_DimExposure.dtsx        | Refactor            | SCD logic, batch, not null checks, Dataflows Gen2 or Spark Notebooks |
| EDW_CC_Load_DimLossLocation.dtsx    | Refactor            | SCD logic, batch, not null checks, Dataflows Gen2 or Spark Notebooks |
| EDW_CC_Load_DimUser.dtsx            | Refactor            | SCD logic, batch, not null checks, Dataflows Gen2 or Spark Notebooks |
| EDW_CC_Load_FactClaimTransaction.dtsx | Refactor          | SCD logic, batch, financial calculations, Dataflows Gen2 or Spark Notebooks |
| EDW_CC_Load_LossBodyParts.dtsx      | Refactor            | SCD logic, batch, not null checks, Dataflows Gen2 or Spark Notebooks |
| dmproc.Audit                        | Retire              | Not used in SSIS or SSRS, candidate for archival/removal |
| dmproc.AuditReference               | Retire              | Not used in SSIS or SSRS, candidate for archival/removal |
| dmproc.ErrorLog                     | Retire              | Not used in SSIS or SSRS, candidate for archival/removal |
| dmproc.BatchIdentifier              | Retire              | Not used in SSIS or SSRS, candidate for archival/removal |

**Low-code ETL with Dataflows Gen2:**  
- Use for simple SCD, batch, and lookup logic  
**Notebooks and Spark for Advanced Logic:**  
- Use for script-heavy, transformation-intensive, or custom business rule logic

---

## SSRS Migration Strategy

| Report Name                   | Recommended Approach         | Reason for the Recommendation |
|-------------------------------|-----------------------------|------------------------------|
| Claims Financial Performance  | Power BI Dashboard + Paginated Report | KPIs, aggregations, improved interactivity, DAX for business logic |
| Claims Operational Efficiency | Power BI Dashboard          | Handler metrics, drillthrough, DAX for business logic |
| ClaimsStatusSummary           | Power BI Dashboard          | Claim status metrics, DAX, slicers, improved UX |

**Paginated Reports in Power BI Service:**  
- For pixel-perfect, printable reports  
**Analytical Dashboards:**  
- Enhanced interactivity, drillthrough, visualizations  
**Shift from SQL Server/Oracle queries to Fabric Lakehouse/SQL Endpoint models:**  
- Use Power BI semantic models for all reporting

---

## Integration and Connectivity

### Source Data Connectors

- Dataflows Gen2 supports wide range of connectors (SQL, Oracle, flat files, APIs)
- Existing SSIS sources can be mapped to Dataflows Gen2 connectors

### DirectQuery/Import Modes

- DirectQuery for real-time, Import for performance
- Hybrid for large datasets

### Data Gateway Considerations

- Use Data Gateway for on-prem sources during interim migration
- Plan for full cloud migration to remove dependency

---

## Security and Governance

- RBAC: Leverage Fabric workspace roles, granular access control
- Sensitivity Labels: Apply in Purview/Fabric for compliance
- Lineage: Use Fabric lineage features for traceability
- Auditability: Enable activity logs, monitor access and changes

---

## Cost and Performance

### Fabric Capacity Planning

- F SKU: Per user, suitable for small teams
- P SKU: Per capacity, scalable for enterprise workloads

### Compute Cost Optimization

- Optimize query patterns, use caching, schedule pipeline triggers during off-peak
- Monitor and tune Spark/SQL workloads

---

## Monitoring and Observability

- Fabric Monitoring: Activity logs, metrics, pipeline/report health
- Alerting: Set up alerts for failures, performance thresholds
- Usage analytics: Track report and dataset usage

---

## Future Scalability and Roadmap

- Real-time/Streaming: Use Fabric Real-Time Hub for streaming scenarios
- AI/ML Integration: Leverage Copilot, integrate notebooks for advanced analytics
- Plan for expansion: Modular architecture, scalable storage and compute

---

## Best Practices

- Archive/remove unused tables and columns (dmproc.* and unreferenced columns)
- Document data lineage and usage
- Consolidate ETL logic for shared targets
- Optimize SCD and lookup operations
- Refine report data sources and documentation
- Leverage Fabric governance and monitoring features

---

## Appendix

**EDW Table Usage Summary:**  
- Extensively used: DimClaim, FactClaimTransaction, DimUser  
- Exclusively SSIS: DimCheck, DimClaimant, DimExposure, DimLossLocation, LossBodyParts  
- Not used: dmproc.Audit, dmproc.AuditReference, dmproc.ErrorLog, dmproc.BatchIdentifier

---

# End of Report
```