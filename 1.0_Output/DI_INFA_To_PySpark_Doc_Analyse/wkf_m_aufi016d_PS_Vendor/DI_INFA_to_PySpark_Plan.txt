=============================================
Author:        Ascendion AVA+
Date:          
Description:   Cost and effort estimation for PySpark conversion
=============================================

# 1. Cost Estimation

## 1.1 PySpark Runtime Cost

**Estimated Data Volume:**  
- Input file: ~500 MB (PS_VENDOR_S4)
- Output table: ~500 MB (PS_VENDOR)

**Transformation Complexity:**  
- Simple linear ETL: flat file → expression (parameter assignment, timestamp) → Oracle table.
- No lookups, joins, or aggregations.
- Minimal transformation logic (parameter assignment, timestamp enrichment).

**PySpark Job Steps:**  
- Read flat file (delimiter: `||`, encoding: US-ASCII)
- Assign audit year (parameterized)
- Assign load timestamp (job start time)
- Write to Oracle via JDBC (truncate and load)
- Capture rejects/bad records (optional)

**GCP Dataproc Serverless Environment (using provided cost model as proxy):**  
- Typical cost: ~$0.60 per hour per node (Dataproc serverless or Databricks job cluster)
- Estimated job duration: 5–10 minutes (for 500 MB, minimal transformation, single target)
- Estimated cluster: 1 driver, 2 workers (standard nodes)

**Cost Calculation:**  
- Total runtime per job: 0.17 hour (10 minutes)
- Nodes used: 3 (1 driver + 2 workers)
- Total compute cost: 3 nodes x 0.17 hour x $0.60 = **$0.31 per run**
- Storage cost: Negligible for transient processing (data stored in Oracle, not in Spark storage)

**Performance Optimizations:**  
- No partitioning/caching needed due to small data volume and linear flow.
- Bulk JDBC write for Oracle target.
- Reject handling via DataFrame filters.

**Justification:**  
- The workflow is simple, with no expensive operations (joins, aggregations, or lookups).
- Data volume is moderate (~500 MB).
- Job is expected to complete quickly on a small cluster.

**Estimated PySpark Runtime Cost per Run:**  
**$0.31 USD**

---

# 2. Code Fixing and Testing Effort Estimation

## 2.1 PySpark Code Manual Fixes and Unit Testing Effort

**Manual Adjustments Required:**
- Replace Informatica parameter `$$Audit_Year` with PySpark job parameter/config.
- Replace `SESSSTARTTIME` with PySpark's `current_timestamp()` at job start.
- Implement reject/bad file logic (capture and log failed records).
- Parameterize input/output file paths and Oracle JDBC connection.
- Implement pre-load truncate for Oracle target.
- Map Informatica data types to Spark SQL types.

**Effort Breakdown:**
- Parameterization (audit year, file paths): 0.5 hour
- Timestamp assignment logic: 0.25 hour
- JDBC connection and truncate logic: 0.5 hour
- Error/reject handling: 0.5 hour
- Data type mapping and validation: 0.25 hour
- Unit test development (simple path): 0.5 hour

**Total Manual Code Fixes & Unit Testing Effort:**  
**2.5 hours**

## 2.2 Output Validation Effort

**Tasks:**
- Compare row counts and field-level data between Informatica and PySpark outputs.
- Validate audit year and load timestamp correctness.
- Validate reject/bad file logic (if any records are rejected).
- Document and resolve any discrepancies.

**Effort Estimate:**  
- Data extraction and comparison: 0.5 hour
- Validation of audit/timestamp: 0.25 hour
- Review and documentation: 0.25 hour

**Total Output Validation Effort:**  
**1.0 hour**

## 2.3 Total Estimated Effort in Hours

- Manual code fixes & unit testing: 2.5 hours
- Output validation: 1.0 hour

**Total Estimated Effort:**  
**3.5 hours**

**Justification:**  
- The mapping is linear and simple, with no complex transformations or dependencies.
- Manual effort is primarily in parameterization, JDBC setup, and basic validation.
- Validation is straightforward due to 1:1 field mapping and no branching logic.

---

# 3. API Cost Consumption

```
apiCost: 0.0523 USD
```

---

**Summary Table**

| Activity                      | Effort (hrs) |
|-------------------------------|--------------|
| Manual code fixes & unit test  | 2.5          |
| Output validation              | 1.0          |
| **Total**                     | **3.5**      |

**Estimated PySpark Runtime Cost per Run:** $0.31 USD  
**API Cost for this analysis:** 0.0523 USD

---

**Note:**  
- All estimates are based on the provided Informatica mapping, workflow, and environment details.
- No additional Informatica XML files were detected in the input; this output is for `wkf_m_aufi016d_PS_Vendor`.
- If additional XMLs are provided, repeat this analysis for each file.