# Azure Synapse Stored Procedure Documentation

=============================================
Author:        Ascendion AVA
Created on:    
Description:   ETL stored procedure for loading sales transaction data from staging to fact table with data quality validation and audit logging
=============================================

## dw.sp_load_sales_fact

### Procedure Overview
This stored procedure serves as the core ETL component for the sales data warehouse, responsible for transforming and loading sales transaction data from the staging layer into the dimensional fact table. The procedure ensures data quality through validation checks, maintains audit trails for compliance and monitoring, and provides robust error handling to maintain data integrity. It supports business intelligence and analytics requirements by delivering clean, validated sales data for reporting and analysis. The procedure solves the critical business problem of ensuring accurate, reliable sales data is available for decision-making while maintaining complete traceability and data quality standards.

### Logic Details
The procedure implements a comprehensive ETL pattern with the following key components:
- **Main Purpose:** Transform and load sales transaction data from staging to fact table with quality assurance
- **Structure:** Sequential processing with TRY-CATCH error handling and comprehensive audit logging
- **Key SQL Operations:** Data validation, dimensional lookups, calculated field generation, and batch processing
- **Input Parameters:** No external parameters (uses system-generated batch ID and timestamps)
- **Output:** Populated fact table with enriched sales data, audit logs, and data quality failure records

### Data Flow Details
**Step-by-Step Data Processing:**

1. **Initialization Phase:** Generate unique batch ID (@batch_id) and initialize audit variables for tracking execution metrics and performance monitoring
2. **Audit Logging Start:** Record procedure execution start in dw.Audit_Log with batch ID, procedure name, start timestamp, and initial status
3. **Validation Setup:** Create temporary table #InvalidRows to capture data quality validation failures for later processing and logging
4. **Data Quality Checks:** Execute business rule validations including missing Customer_ID checks and invalid quantity validations (<=0)
5. **Data Cleansing:** Remove invalid records from stg.Sales_Transactions table using INNER JOIN with #InvalidRows and count rejected rows
6. **Data Transformation:** Apply business logic transformations using CTE including calculated Total_Sales_Amount and dimensional lookups
7. **Dimensional Enrichment:** Join with dw.Dim_Customer for Customer_Segment and dw.Dim_Date for Region_ID to enrich fact data
8. **Fact Table Loading:** Insert transformed and validated data into dw.Fact_Sales with all required fields and audit information
9. **Staging Cleanup:** Truncate stg.Sales_Transactions table to prepare for next batch processing cycle
10. **Failure Logging:** Record all validation failures in dw.DQ_Failures table with transaction IDs, reasons, and batch tracking
11. **Audit Completion:** Update dw.Audit_Log with end time, row counts, completion status, and summary message
12. **Error Handling:** Capture runtime errors in CATCH block, update audit log with failure status, and re-throw for pipeline monitoring
13. **Resource Cleanup:** Drop temporary table #InvalidRows to free system resources and complete processing

### Data Transformations
**Specific Changes Applied to Data:**

- **Financial Calculations:** Total_Sales_Amount computed as Quantity Ã— Unit_Price to provide complete transaction value for financial reporting and analysis
- **Dimensional Enrichment:** Region_ID added through dw.Dim_Date lookup based on Sales_Date to enable geographical analysis and regional reporting
- **Customer Analytics:** Customer_Segment appended via dw.Dim_Customer lookup to support marketing analytics and customer behavior analysis
- **Audit Trail Creation:** Load_Timestamp (SYSDATETIME()) and Batch_ID added for complete data lineage tracking and operational monitoring
- **Data Type Standardization:** Sales_Date converted to DATE format using CAST function to ensure compatibility with dimension table joins
- **Data Quality Filtering:** Records with NULL Customer_ID or non-positive quantities systematically excluded to maintain data integrity
- **Business Rule Application:** Validation logic ensures only complete, valid transactions proceed to fact table loading

### Data Mapping

| Target Table Name | Target Column Name | Source Table Name | Source Column Name | Remarks |
|-------------------|-------------------|-------------------|-------------------|---------|
| dw.Fact_Sales | Transaction_ID | stg.Sales_Transactions | Transaction_ID | 1 to 1 mapping |
| dw.Fact_Sales | Customer_ID | stg.Sales_Transactions | Customer_ID | 1 to 1 mapping |
| dw.Fact_Sales | Product_ID | stg.Sales_Transactions | Product_ID | 1 to 1 mapping |
| dw.Fact_Sales | Sales_Date | stg.Sales_Transactions | Sales_Date | 1 to 1 mapping |
| dw.Fact_Sales | Quantity | stg.Sales_Transactions | Quantity | 1 to 1 mapping |
| dw.Fact_Sales | Unit_Price | stg.Sales_Transactions | Unit_Price | 1 to 1 mapping |
| dw.Fact_Sales | Total_Sales_Amount | stg.Sales_Transactions | Quantity * Unit_Price | Transformation |
| dw.Fact_Sales | Region_ID | dw.Dim_Date | Region_ID | Transformation |
| dw.Fact_Sales | Customer_Segment | dw.Dim_Customer | Customer_Segment | Transformation |
| dw.Fact_Sales | Load_Timestamp | System Generated | SYSDATETIME() | Transformation |
| dw.Fact_Sales | Batch_ID | System Generated | @batch_id | Transformation |

### Technical Complexity

| Parameter | Value |
|-----------|-------|
| Procedure Name | dw.sp_load_sales_fact |
| Source Tables | 3 |
| Target Tables | 3 |
| Data Flows | 8 |
| Transformations | 6 |
| Joins and Filters | 5 |
| Variables | 6 |
| Parameters | 0 |
| Dependencies | 3 |
| Complexity Score | 72 |

### Key Outputs
**Final Results Generated:**

- **Primary Fact Data:** Clean, validated sales fact records loaded into dw.Fact_Sales table with complete dimensional enrichment including customer segments and regional information for comprehensive business analysis
- **Comprehensive Audit Trail:** Complete execution log in dw.Audit_Log including batch ID, execution timing, row processing counts, and status information for operational monitoring and compliance reporting
- **Data Quality Intelligence:** Detailed validation failure records in dw.DQ_Failures table capturing transaction IDs, specific failure reasons, and timestamps for business review and data stewardship activities
- **Operational Metrics:** Performance indicators including rows inserted, rows rejected, and execution duration enabling SLA monitoring and capacity planning for data operations teams
- **Error Diagnostics:** Comprehensive error messages and execution context in audit logs for rapid troubleshooting and root cause analysis of failed processing cycles
- **Data Lineage Foundation:** Batch ID tracking system enabling end-to-end data lineage, impact analysis, and regulatory compliance for data governance requirements

**Business Alignment:** These outputs directly support business intelligence initiatives, regulatory compliance requirements, and operational excellence goals by providing reliable, traceable, and high-quality sales data for strategic decision-making and performance monitoring.

### apiCost: 0.0000 USD

*Note: This stored procedure executes within the existing Azure Synapse Analytics environment without external API calls. Processing costs are included in standard Synapse compute pricing based on DWU consumption and data volume processed.*