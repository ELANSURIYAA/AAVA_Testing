--------------------------------------------------
Test Case List:
----------------
Test Case ID: TC001
Description: Happy Path - Input DataFrame contains valid records with bukrs equal to '1000' and blart equal to 'SA'. The DataFrame should be correctly filtered and only the columns belnr and budat should be selected.
Expected Outcome: The resulting DataFrame contains only the records that satisfy both conditions and includes exactly the columns belnr and budat.

Test Case ID: TC002
Description: No Matching Bukrs - Input DataFrame does not contain any record with bukrs equal to '1000'.
Expected Outcome: The resulting DataFrame should be empty (no records returned).

Test Case ID: TC003
Description: No Matching Blart - Input DataFrame contains records with bukrs equal to '1000', but none with blart equal to 'SA'.
Expected Outcome: The resulting DataFrame should be empty (no records returned).

Test Case ID: TC004
Description: Null Values - Input DataFrame contains null values in the key fields (bukrs or blart). Only records that fully match bukrs = '1000' and blart = 'SA' should pass.
Expected Outcome: Only records with non-null bukrs equal to '1000' and non-null blart equal to 'SA' will be returned. In this case, if only one record qualifies, the resulting DataFrame returns that single record.

--------------------------------------------------
Pytest Script (test_zbw_load_gl_data.py):
--------------------------------------------------
#!/usr/bin/env python
import pytest
from pyspark.sql import SparkSession
from pyspark.sql.functions import col

# Helper function replicating the transformation logic from the main PySpark code.
def transform_bkpf_df(bkpf_df):
    """
    Applies the following transformation:
    1. Filters records where bukrs equals '1000'
    2. Further filters records where blart equals 'SA'
    3. Selects the columns belnr and budat
    """
    filtered_df = bkpf_df.filter(col("bukrs") == "1000")
    result_df = filtered_df.filter(col("blart") == "SA")
    selected_df = result_df.select("belnr", "budat")
    return selected_df

@pytest.fixture(scope="module")
def spark():
    """
    Fixture for creating a SparkSession for the tests.
    """
    spark_session = SparkSession.builder \
        .master("local[2]") \
        .appName("PyTest for ZBW_LOAD_GL_DATA") \
        .getOrCreate()
    yield spark_session
    spark_session.stop()

def assert_df_equality(df, expected_data):
    """
    Helper function to compare DataFrame content with expected rows.
    Converts rows to dictionaries and sorts them for order independence.
    """
    result = [row.asDict() for row in df.collect()]
    result_sorted = sorted(result, key=lambda x: (x.get("belnr", ""), x.get("budat", "")))
    expected_sorted = sorted(expected_data, key=lambda x: (x.get("belnr", ""), x.get("budat", "")))
    assert result_sorted == expected_sorted

def test_happy_path(spark):
    """
    TC001: Happy Path
    Given a DataFrame with valid records where:
      - bukrs = '1000'
      - blart = 'SA'
    Some records do not pass the filter.
    Expected: Only matching records are output with columns belnr and budat.
    """
    data = [
        {"bukrs": "1000", "blart": "SA", "belnr": "B001", "budat": "2023-01-01"},
        {"bukrs": "1000", "blart": "XX", "belnr": "B002", "budat": "2023-01-02"},
        {"bukrs": "2000", "blart": "SA", "belnr": "B003", "budat": "2023-01-03"},
        {"bukrs": "1000", "blart": "SA", "belnr": "B004", "budat": "2023-01-04"}
    ]
    bkpf_df = spark.createDataFrame(data)
    result_df = transform_bkpf_df(bkpf_df)
    expected = [
        {"belnr": "B001", "budat": "2023-01-01"},
        {"belnr": "B004", "budat": "2023-01-04"}
    ]
    assert_df_equality(result_df, expected)

def test_no_bukrs(spark):
    """
    TC002: No Matching Bukrs
    Given a DataFrame that does not include any record with bukrs equal to '1000'.
    Expected: The resulting DataFrame should be empty.
    """
    data = [
        {"bukrs": "2000", "blart": "SA", "belnr": "B005", "budat": "2023-02-01"},
        {"bukrs": "3000", "blart": "SA", "belnr": "B006", "budat": "2023-02-02"}
    ]
    bkpf_df = spark.createDataFrame(data)
    result_df = transform_bkpf_df(bkpf_df)
    assert result_df.count() == 0

def test_no_blart(spark):
    """
    TC003: No Matching Blart
    Given a DataFrame where records have bukrs equal to '1000' but none have blart equal to 'SA'.
    Expected: The resulting DataFrame should be empty.
    """
    data = [
        {"bukrs": "1000", "blart": "XX", "belnr": "B007", "budat": "2023-03-01"},
        {"bukrs": "1000", "blart": "YY", "belnr": "B008", "budat": "2023-03-02"}
    ]
    bkpf_df = spark.createDataFrame(data)
    result_df = transform_bkpf_df(bkpf_df)
    assert result_df.count() == 0

def test_null_values(spark):
    """
    TC004: Null Values
    Given a DataFrame where some records have null values in key fields (bukrs or blart).
    Expected: Only records with both bukrs = '1000' and blart = 'SA' (non-null values) are returned.
    """
    data = [
        {"bukrs": None, "blart": "SA", "belnr": "B009", "budat": "2023-04-01"},
        {"bukrs": "1000", "blart": None, "belnr": "B010", "budat": "2023-04-02"},
        {"bukrs": "1000", "blart": "SA", "belnr": "B011", "budat": "2023-04-03"}
    ]
    bkpf_df = spark.createDataFrame(data)
    result_df = transform_bkpf_df(bkpf_df)
    expected = [
        {"belnr": "B011", "budat": "2023-04-03"}
    ]
    assert_df_equality(result_df, expected)

# API Cost Consumed for this call: $0.01
--------------------------------------------------

This completes the required deliverable with the test case list and Pytest script, including detailed instructions and expected outcomes.