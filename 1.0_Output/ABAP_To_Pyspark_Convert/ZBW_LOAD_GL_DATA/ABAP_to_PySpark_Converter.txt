------------------------------------------------------------
# Converted PySpark Code for GL Data Processing
# API Cost Consumed: 0.005 USD (example cost)

from pyspark.sql import SparkSession, functions as F

def main():
    # Initialize the Spark session
    spark = SparkSession.builder \
        .appName('GL_Data_Load_and_Transformation') \
        .getOrCreate()

    # JDBC connection properties - replace with actual database connection details
    jdbc_url = "jdbc:your_database_url"
    connection_properties = {
        "user": "your_username",
        "password": "your_password",
        "driver": "your_jdbc_driver"
    }

    # Read data from the database table 'zgl_table' into a DataFrame.
    # This corresponds to the ABAP SELECT * FROM zgl_table.
    df = spark.read.jdbc(url=jdbc_url, table="zgl_table", properties=connection_properties)

    # Transform the data:
    # Add a new column 'status' based on the value of 'betrag'.
    # If 'betrag' > 1000 then assign 'HIGH', else assign 'LOW'.
    # This replaces the ABAP loop with an IF condition inside the LOOP.
    df_transformed = df.withColumn(
        "status",
        F.when(F.col("betrag") > 1000, F.lit("HIGH")).otherwise(F.lit("LOW"))
    )

    # Write the transformed DataFrame back to the database table.
    # This corresponds to updating the records and committing the work in ABAP.
    df_transformed.write.mode("overwrite") \
        .jdbc(url=jdbc_url, table="zgl_table", properties=connection_properties)

    # Stop the Spark session after completion.
    spark.stop()

if __name__ == "__main__":
    main()
------------------------------------------------------------