# Converted PySpark Code

from pyspark.sql import SparkSession
from pyspark.sql.types import StructType, StructField, StringType, FloatType
from pyspark.sql.functions import col, split, size

# Create a Spark session
spark = SparkSession.builder.appName("ZBW_LOAD_GL_DATA Conversion").getOrCreate()

# Define the file path as used in the ABAP code
file_path = "/usr/sap/interfaces/finance_data.csv"

# Read the file as a text file (each row is a line from the CSV)
raw_df = spark.read.text(file_path)

# Split each line by comma to simulate the SPLIT operation in ABAP
split_df = raw_df.withColumn("fields", split(col("value"), ","))

# Filter rows to ensure they have exactly 7 fields (as per the ABAP codeâ€™s check)
filtered_df = split_df.filter(size(col("fields")) == 7)

# Map the fields to the corresponding columns
# Note: In the ABAP code, the first field corresponds to company code (bukrs) and so on.
final_df = filtered_df.select(
    col("fields").getItem(0).alias("bukrs"),
    col("fields").getItem(1).alias("fiscyear"),
    col("fields").getItem(2).alias("costcenter"),
    col("fields").getItem(3).alias("gl_account"),
    col("fields").getItem(4).alias("amount"),
    col("fields").getItem(5).alias("currency"),
    col("fields").getItem(6).alias("posting_date")
)

# Optionally cast the amount column to float for correct numeric operations
final_df = final_df.withColumn("amount", col("amount").cast(FloatType()))

# The ABAP code then performs an insert into a GL data table.
# In PySpark, this can be achieved by writing to a target database using the dataframe write API.
# For example (uncomment and modify the options as per your database setup):
"""
final_df.write \
    .format("jdbc") \
    .option("url", "jdbc:your_database_url") \
    .option("dbtable", "zgl_finance_data") \
    .option("user", "your_username") \
    .option("password", "your_password") \
    .mode("append") \
    .save()
"""

# For demonstration purposes, we print the final dataframe
final_df.show()

# Stop the Spark session
spark.stop()

# API cost consumed for this call: 1 unit