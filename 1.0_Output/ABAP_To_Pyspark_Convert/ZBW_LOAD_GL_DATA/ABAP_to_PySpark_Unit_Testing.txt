Test Case List:
----------------
Test Case ID: TC001
Description: Happy Path - Input DataFrame contains valid records with bukrs equal to '1000' and blart equal to 'SA'. The DataFrame should be correctly filtered and only the columns belnr and budat should be selected.
Expected Outcome: The resulting DataFrame contains only the records that satisfy both conditions with exactly the columns belnr and budat.

Test Case ID: TC002
Description: No Matching Bukrs - Input DataFrame does not contain any record with bukrs equal to '1000'.
Expected Outcome: The resulting DataFrame should be empty (no records returned).

Test Case ID: TC003
Description: No Matching Blart - Input DataFrame contains records with bukrs equal to '1000', but none with blart equal to 'SA'.
Expected Outcome: The resulting DataFrame should be empty (no records returned).

Test Case ID: TC004
Description: Null Values - Input DataFrame contains null values in the fields bukrs or blart.
Expected Outcome: The resulting DataFrame should exclude records with null values in the filter columns and return an empty DataFrame if no record fully qualifies.

--------------------------------------------------
Pytest Script (test_zbw_load_gl_data.py):
--------------------------------------------------
#!/usr/bin/env python
import pytest
from pyspark.sql import SparkSession
from pyspark.sql.functions import col

# Helper function that replicates the transformation logic from the main code.
def transform_bkpf_df(bkpf_df):
    \"\"\" 
    Applies the following transformation:
    1. Filters records where bukrs equals '1000'
    2. Further filters records where blart equals 'SA'
    3. Selects the columns belnr and budat
    \"\"\"
    filtered_df = bkpf_df.filter(col("bukrs") == "1000")
    result_df = filtered_df.filter(col("blart") == "SA")
    selected_df = result_df.select("belnr", "budat")
    return selected_df

@pytest.fixture(scope="module")
def spark():
    \"\"\" Fixture for creating a SparkSession for the tests. \"\"\"
    spark = SparkSession.builder \
        .master("local[2]") \
        .appName("PyTest for ZBW_LOAD_GL_DATA") \
        .getOrCreate()
    yield spark
    spark.stop()

def assert_df_equality(df, expected_data):
    \"\"\" Helper function to compare DataFrame content with expected rows. \"\"\"
    result = [row.asDict() for row in df.collect()]
    # Sorting lists by keys to make the comparison order independent
    result = sorted(result, key=lambda x: (x.get("belnr", ""), x.get("budat", "")))
    expected = sorted(expected_data, key=lambda x: (x.get("belnr", ""), x.get("budat", "")))
    assert result == expected

def test_happy_path(spark):
    \"\"\" 
    TC001: Happy Path
    Given a DataFrame with valid records where:
      - bukrs = '1000'
      - blart = 'SA'
    Also includes some records that do not pass the filter.
    Expected: Only the records matching the filter are output with columns belnr and budat.
    \"\"\"
    data = [
        {"bukrs": "1000", "blart": "SA", "belnr": "B001", "budat": "2023-01-01"},
        {"bukrs": "1000", "blart": "XX", "belnr": "B002", "budat": "2023-01-02"},
        {"bukrs": "2000", "blart": "SA", "belnr": "B003", "budat": "2023-01-03"},
        {"bukrs": "1000", "blart": "SA", "belnr": "B004", "budat": "2023-01-04"}
    ]
    bkpf_df = spark.createDataFrame(data)
    
    result_df = transform_bkpf_df(bkpf_df)
    
    expected = [
        {"belnr": "B001", "budat": "2023-01-01"},
        {"belnr": "B004", "budat": "2023-01-04"}
    ]
    assert_df_equality(result_df, expected)

def test_no_bukrs(spark):
    \"\"\" 
    TC002: No Matching Bukrs
    Given a DataFrame that does not contain any record with bukrs equal to '1000'.
    Expected: The resulting DataFrame should be empty.
    \"\"\"
    data = [
        {"bukrs": "2000", "blart": "SA", "belnr": "B005", "budat": "2023-02-01"},
        {"bukrs": "3000", "blart": "SA", "belnr": "B006", "budat": "2023-02-02"}
    ]
    bkpf_df = spark.createDataFrame(data)
    
    result_df = transform_bkpf_df(bkpf_df)
    assert result_df.count() == 0

def test_no_blart(spark):
    \"\"\" 
    TC003: No Matching Blart
    Given a DataFrame where records have bukrs equal to '1000', 
    but none have blart equal to 'SA'.
    Expected: The resulting DataFrame should be empty.
    \"\"\"
    data = [
        {"bukrs": "1000", "blart": "XX", "belnr": "B007", "budat": "2023-03-01"},
        {"bukrs": "1000", "blart": "YY", "belnr": "B008", "budat": "2023-03-02"}
    ]
    bkpf_df = spark.createDataFrame(data)
    
    result_df = transform_bkpf_df(bkpf_df)
    assert result_df.count() == 0

def test_null_values(spark):
    \"\"\" 
    TC004: Null Values
    Given a DataFrame where some records have null values for key fields (bukrs or blart):
      - The record with both valid bukrs and blart should be returned.
    Expected: Only records fully matching bukrs = '1000' and blart = 'SA' are returned.
    \"\"\"
    data = [
        {"bukrs": None, "blart": "SA", "belnr": "B009", "budat": "2023-04-01"},
        {"bukrs": "1000", "blart": None, "belnr": "B010", "budat": "2023-04-02"},
        {"bukrs": "1000", "blart": "SA", "belnr": "B011", "budat": "2023-04-03"}
    ]
    bkpf_df = spark.createDataFrame(data)
    
    result_df = transform_bkpf_df(bkpf_df)
    
    expected = [
        {"belnr": "B011", "budat": "2023-04-03"}
    ]
    assert_df_equality(result_df, expected)

# API Cost Consumed for this call: $0.01