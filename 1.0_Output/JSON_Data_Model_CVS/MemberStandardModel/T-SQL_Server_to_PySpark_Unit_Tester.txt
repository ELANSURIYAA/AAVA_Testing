# Test Case List and Pytest Script for GetPersonInfo PySpark Code

## Test Case List

### Basic Functionality Tests
1. **TC001: Test Basic Retrieval - No Filters (SQL)**
   - **Description**: Verify that all person records are retrieved when no filters are applied using SQL method
   - **Expected Outcome**: All records returned with correct columns

2. **TC002: Test Basic Retrieval - No Filters (DataFrame)**
   - **Description**: Verify that all person records are retrieved when no filters are applied using DataFrame method
   - **Expected Outcome**: All records returned with correct columns

### Filter Tests
3. **TC003: Test Person ID Filter (SQL)**
   - **Description**: Verify filtering by PersonID using SQL method
   - **Expected Outcome**: Only the record with matching PersonID is returned

4. **TC004: Test Person ID Filter (DataFrame)**
   - **Description**: Verify filtering by PersonID using DataFrame method
   - **Expected Outcome**: Only the record with matching PersonID is returned

5. **TC005: Test Gender Filter (SQL)**
   - **Description**: Verify filtering by Gender using SQL method
   - **Expected Outcome**: Only records with matching Gender are returned

6. **TC006: Test Gender Filter (DataFrame)**
   - **Description**: Verify filtering by Gender using DataFrame method
   - **Expected Outcome**: Only records with matching Gender are returned

7. **TC007: Test Race Filter (SQL)**
   - **Description**: Verify filtering by Race using SQL method
   - **Expected Outcome**: Only records with matching Race are returned

8. **TC008: Test Race Filter (DataFrame)**
   - **Description**: Verify filtering by Race using DataFrame method
   - **Expected Outcome**: Only records with matching Race are returned

9. **TC009: Test Multiple Filters (SQL)**
   - **Description**: Verify applying multiple filters simultaneously using SQL method
   - **Expected Outcome**: Only records matching all filter criteria are returned

10. **TC010: Test Multiple Filters (DataFrame)**
    - **Description**: Verify applying multiple filters simultaneously using DataFrame method
    - **Expected Outcome**: Only records matching all filter criteria are returned

### Join Tests
11. **TC011: Test Include Contact Info (SQL)**
    - **Description**: Verify including contact information using SQL method
    - **Expected Outcome**: Contact columns are included in the result

12. **TC012: Test Include Contact Info (DataFrame)**
    - **Description**: Verify including contact information using DataFrame method
    - **Expected Outcome**: Contact columns are included in the result

13. **TC013: Test Include Language Info (SQL)**
    - **Description**: Verify including language information using SQL method
    - **Expected Outcome**: Language columns are included in the result

14. **TC014: Test Include Language Info (DataFrame)**
    - **Description**: Verify including language information using DataFrame method
    - **Expected Outcome**: Language columns are included in the result

15. **TC015: Test Include All Optional Data (SQL)**
    - **Description**: Verify including both contact and language information using SQL method
    - **Expected Outcome**: Both contact and language columns are included in the result

16. **TC016: Test Include All Optional Data (DataFrame)**
    - **Description**: Verify including both contact and language information using DataFrame method
    - **Expected Outcome**: Both contact and language columns are included in the result

### Edge Case Tests
17. **TC017: Test Empty Person DataFrame**
    - **Description**: Verify behavior with an empty Person DataFrame
    - **Expected Outcome**: Empty result set with correct schema

18. **TC018: Test Empty Contact DataFrame**
    - **Description**: Verify behavior with an empty ContactInfo DataFrame
    - **Expected Outcome**: Person records returned with null contact info

19. **TC019: Test Empty Language DataFrame**
    - **Description**: Verify behavior with an empty Language DataFrame
    - **Expected Outcome**: Person records returned with null language info

20. **TC020: Test NULL Values in Person**
    - **Description**: Verify handling of NULL values in Person table
    - **Expected Outcome**: NULL values are preserved in the result

21. **TC021: Test Special Characters in Data**
    - **Description**: Verify handling of special characters in data
    - **Expected Outcome**: Special characters are preserved in the result

22. **TC022: Test Special Characters in Filters**
    - **Description**: Verify filtering with values containing special characters
    - **Expected Outcome**: Correct filtering with special characters

23. **TC023: Test Extremely Long Values**
    - **Description**: Verify handling of extremely long string values
    - **Expected Outcome**: Long values are preserved in the result

24. **TC024: Test Multiple Contact Records**
    - **Description**: Verify behavior when a person has multiple contact records
    - **Expected Outcome**: Consistent handling of multiple records

25. **TC025: Test Multiple Language Records**
    - **Description**: Verify behavior when a person has multiple language records
    - **Expected Outcome**: Consistent handling of multiple records

26. **TC026: Test Whitespace Handling**
    - **Description**: Verify handling of whitespace in values and filters
    - **Expected Outcome**: Consistent handling of whitespace

27. **TC027: Test Case Sensitivity**
    - **Description**: Verify case sensitivity in filters
    - **Expected Outcome**: Consistent case handling

### Error Handling Tests
28. **TC028: Test No Results (SQL)**
    - **Description**: Verify behavior when no records match the filter criteria using SQL method
    - **Expected Outcome**: Empty result set with success status

29. **TC029: Test No Results (DataFrame)**
    - **Description**: Verify behavior when no records match the filter criteria using DataFrame method
    - **Expected Outcome**: Empty result set with success status

30. **TC030: Test Invalid Person DataFrame**
    - **Description**: Verify behavior with invalid person_df parameter
    - **Expected Outcome**: Appropriate error handling

31. **TC031: Test Invalid Parameter Types**
    - **Description**: Verify behavior with invalid parameter types
    - **Expected Outcome**: Appropriate error handling

32. **TC032: Test Missing Required Tables**
    - **Description**: Verify behavior when required tables are missing
    - **Expected Outcome**: Appropriate error handling

33. **TC033: Test Invalid Schema**
    - **Description**: Verify behavior with DataFrames having invalid schemas
    - **Expected Outcome**: Appropriate error handling

### Performance Tests
34. **TC034: Test SQL vs DataFrame Performance**
    - **Description**: Compare performance between SQL and DataFrame methods
    - **Expected Outcome**: Both methods return same results, performance metrics logged

## Pytest Script

```python
import pytest
from pyspark.sql import SparkSession
from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DateType, TimestampType
import datetime
from pyspark.sql.functions import col, lit, monotonically_increasing_id, concat
import time
from GetPersonInfo import GetPersonInfo

@pytest.fixture(scope="module")
def spark():
    """Create a SparkSession for all tests."""
    spark = (SparkSession.builder
             .master("local[2]")
             .appName("GetPersonInfoTest")
             .getOrCreate())
    yield spark
    spark.stop()

@pytest.fixture(scope="module")
def sample_data(spark):
    """Create sample test data for all tables."""
    # Person table schema
    person_schema = StructType([
        StructField("PersonID", StringType(), False),
        StructField("DOB", DateType(), True),
        StructField("Gender", IntegerType(), True),
        StructField("Race", StringType(), True),
        StructField("Ethnicity", StringType(), True),
        StructField("Insurance", StringType(), True),
        StructField("Provider", StringType(), True),
        StructField("SourceSystem", StringType(), True),
        StructField("IngestionTimestamp", TimestampType(), True)
    ])
    
    # ContactInfo table schema
    contact_schema = StructType([
        StructField("PersonID", StringType(), False),
        StructField("Address", StringType(), True),
        StructField("Phone", IntegerType(), True),
        StructField("Email", StringType(), True)
    ])
    
    # Language table schema
    language_schema = StructType([
        StructField("PersonID", StringType(), False),
        StructField("Spoken", StringType(), True),
        StructField("Written", StringType(), True)
    ])
    
    # Create sample data for Person table
    person_data = [
        ("P12345", datetime.date(1990, 5, 15), 1, "Caucasian", "Non-Hispanic", 
         "BlueCross", "Dr. Smith", "EMR System A", datetime.datetime(2024, 3, 24, 10, 15, 0)),
        ("P67890", datetime.date(1985, 8, 20), 0, "Asian", "Non-Hispanic", 
         "Aetna", "Dr. Johnson", "EMR System B", datetime.datetime(2024, 3, 25, 9, 30, 0)),
        ("P24680", datetime.date(1975, 3, 10), 1, "African American", "Hispanic", 
         "Cigna", "Dr. Brown", "EMR System A", datetime.datetime(2024, 3, 26, 14, 45, 0))
    ]
    
    # Create sample data for ContactInfo table
    contact_data = [
        ("P12345", "123 Main St, NY", 1234567890, "john@example.com"),
        ("P67890", "456 Oak St, CA", 9876543210, "mary@example.com"),
        ("P24680", "789 Pine St, TX", 5551234567, "robert@example.com")
    ]
    
    # Create sample data for Language table
    language_data = [
        ("P12345", "English", "English"),
        ("P67890", "Spanish", "Spanish"),
        ("P24680", "French", "French")
    ]
    
    # Create DataFrames
    person_df = spark.createDataFrame(person_data, person_schema)
    contact_df = spark.createDataFrame(contact_data, contact_schema)
    language_df = spark.createDataFrame(language_data, language_schema)
    
    # Create temporary views
    person_df.createOrReplaceTempView("Person")
    contact_df.createOrReplaceTempView("ContactInfo")
    language_df.createOrReplaceTempView("Language")
    
    return {
        "person_df": person_df,
        "contact_df": contact_df,
        "language_df": language_df
    }

@pytest.fixture(scope="module")
def edge_case_data(spark):
    """Create edge case test data."""
    # Person table schema
    person_schema = StructType([
        StructField("PersonID", StringType(), False),
        StructField("DOB", DateType(), True),
        StructField("Gender", IntegerType(), True),
        StructField("Race", StringType(), True),
        StructField("Ethnicity", StringType(), True),
        StructField("Insurance", StringType(), True),
        StructField("Provider", StringType(), True),
        StructField("SourceSystem", StringType(), True),
        StructField("IngestionTimestamp", TimestampType(), True)
    ])
    
    # Create edge case data for Person table
    person_data = [
        # Person with NULL values
        ("P99991", None, None, None, None, None, None, None, None),
        # Person with special characters
        ("P99992", datetime.date(1980, 1, 1), 1, "O'Reilly's Race", "Hispanic/Latino", 
         "Blue-Cross/Shield", "Dr. Smith-Jones", "EMR System C", datetime.datetime(2024, 3, 27, 8, 0, 0)),
        # Person with extremely long values
        ("P99993", datetime.date(1970, 12, 31), 0, "A" * 100, "B" * 100, 
         "C" * 100, "D" * 100, "E" * 100, datetime.datetime(2024, 3, 28, 9, 0, 0)),
        # Duplicate person with same attributes
        ("P99994", datetime.date(1990, 5, 15), 1, "Caucasian", "Non-Hispanic", 
         "BlueCross", "Dr. Smith", "EMR System A", datetime.datetime(2024, 3, 24, 10, 15, 0)),
        # Person with whitespace in values
        ("P99995", datetime.date(1985, 6, 15), 1, "  Caucasian  ", "  Non-Hispanic  ", 
         "  BlueCross  ", "  Dr. Smith  ", "  EMR System A  ", datetime.datetime(2024, 3, 29, 11, 0, 0))
    ]
    
    # Create edge case data for ContactInfo table
    contact_schema = StructType([
        StructField("PersonID", StringType(), False),
        StructField("Address", StringType(), True),
        StructField("Phone", IntegerType(), True),
        StructField("Email", StringType(), True)
    ])
    
    contact_data = [
        # NULL values
        ("P99991", None, None, None),
        # Special characters
        ("P99992", "123 Main St., Apt #4", 1234567890, "test+special@example.com"),
        # Extremely long values
        ("P99993", "A" * 100, 9999999999, "B" * 50 + "@example.com"),
        # Multiple contact records for same person
        ("P99994", "123 Home St", 1111111111, "home@example.com"),
        ("P99994", "456 Work Ave", 2222222222, "work@example.com"),
        #