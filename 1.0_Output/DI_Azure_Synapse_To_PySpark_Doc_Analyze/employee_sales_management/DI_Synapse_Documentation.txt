# ====================================================
**Author:**        Ascendion AAVA  
**Date:**          <!-- leave it blank -->  
**Description:**   Loads cleaned and validated sales transactions from staging into the sales fact table, with audit logging and data quality checks.
# ====================================================

## 1. Overview of Pipeline/Component

This stored procedure (`dw.sp_load_sales_fact`) is designed to load transactional sales data from a staging table (`stg.Sales_Transactions`) into the enterprise data warehouse fact table (`dw.Fact_Sales`). It performs data quality checks, applies business transformations, logs audit information, and manages error handling. The procedure ensures only valid and enriched sales records are loaded, supporting accurate reporting, analytics, and regulatory compliance.

## 2. Component Structure and Design

- **Component Type:** Azure Synapse SQL Stored Procedure
- **Key Modules:**
  - **Audit Logging:** Inserts start and end audit records in `dw.Audit_Log`.
  - **Data Quality Validation:** Identifies and removes invalid records (missing `Customer_ID`, non-positive `Quantity`).
  - **Transformation:** Enriches sales data with customer and date dimension lookups, computes `Total_Sales_Amount`, and adds metadata columns.
  - **Fact Table Load:** Inserts cleaned and transformed data into `dw.Fact_Sales`.
  - **Error Handling:** Catches and logs errors, updates audit log with failure status.
  - **Data Quality Failure Logging:** Invalid records are logged in `dw.DQ_Failures`.
  - **Cleanup:** Removes temporary tables and truncates staging data post-load.

- **Integration Points:**
  - **Source:** `stg.Sales_Transactions` (staging table)
  - **Reference/Lookup:** `dw.Dim_Customer`, `dw.Dim_Date`
  - **Target:** `dw.Fact_Sales` (fact table), `dw.DQ_Failures` (DQ log), `dw.Audit_Log` (audit log)
  - **Parameters/Variables:** Batch ID, timestamps, row counters, error message, procedure name

- **Flow:**  
  1. Start audit log  
  2. Validate and remove bad records  
  3. Transform and load valid records  
  4. Log DQ failures  
  5. End audit log  
  6. Error handling and cleanup

## 3. Data Flow and Processing Logic

- **Processed Datasets:**
  - `stg.Sales_Transactions`
  - `dw.Dim_Customer`
  - `dw.Dim_Date`
  - `dw.Fact_Sales`
  - `dw.Audit_Log`
  - `dw.DQ_Failures`

- **Data Flow:**
  1. **Ingestion:** Sales transactions are staged in `stg.Sales_Transactions`.
  2. **Validation:** Records with missing `Customer_ID` or invalid `Quantity` are identified and removed from staging.
  3. **Transformation:** Valid records are enriched by joining with customer and date dimensions, and `Total_Sales_Amount` is calculated.
  4. **Loading:** Transformed records are inserted into `dw.Fact_Sales`.
  5. **Audit Logging:** Start and end of the process, row counts, and status are logged in `dw.Audit_Log`.
  6. **DQ Logging:** Invalid records are logged in `dw.DQ_Failures`.
  7. **Cleanup:** Staging table is truncated, and temporary tables are dropped.

## 4. Data Mapping (Lineage)

| Target Table Name | Target Column Name   | Source Table Name      | Source Column Name   | Remarks                                                                 |
|-------------------|---------------------|------------------------|---------------------|-------------------------------------------------------------------------|
| dw.Fact_Sales     | Transaction_ID      | stg.Sales_Transactions | Transaction_ID      | 1:1 Mapping                                                            |
| dw.Fact_Sales     | Customer_ID         | stg.Sales_Transactions | Customer_ID         | 1:1 Mapping                                                            |
| dw.Fact_Sales     | Product_ID          | stg.Sales_Transactions | Product_ID          | 1:1 Mapping                                                            |
| dw.Fact_Sales     | Sales_Date          | stg.Sales_Transactions | Sales_Date          | 1:1 Mapping                                                            |
| dw.Fact_Sales     | Quantity            | stg.Sales_Transactions | Quantity            | 1:1 Mapping                                                            |
| dw.Fact_Sales     | Unit_Price          | stg.Sales_Transactions | Unit_Price          | 1:1 Mapping                                                            |
| dw.Fact_Sales     | Total_Sales_Amount  | stg.Sales_Transactions | Quantity, Unit_Price| Transformation: Quantity * Unit_Price                                  |
| dw.Fact_Sales     | Region_ID           | dw.Dim_Date            | Region_ID           | Lookup: Join on Sales_Date = Date_Value                                 |
| dw.Fact_Sales     | Customer_Segment    | dw.Dim_Customer        | Customer_Segment    | Lookup: Join on Customer_ID                                            |
| dw.Fact_Sales     | Load_Timestamp      | (system)               | (system)            | Transformation: SYSDATETIME()                                          |
| dw.Fact_Sales     | Batch_ID            | (procedure variable)   | @batch_id           | Transformation: Unique batch identifier per load                        |

## 5. Transformation Logic

- **Data Quality Checks:**
  - Reject records with `Customer_ID IS NULL`
  - Reject records with `Quantity <= 0`
- **Transformations:**
  - `Total_Sales_Amount = Quantity * Unit_Price`
  - `Region_ID` via join with `dw.Dim_Date` on `Sales_Date = Date_Value`
  - `Customer_Segment` via join with `dw.Dim_Customer` on `Customer_ID`
  - `Load_Timestamp = SYSDATETIME()`
  - `Batch_ID = NEWID()` (unique per load)
- **Audit Logging:**
  - Insert and update audit log with batch details, row counts, status, and messages
- **Error Handling:**
  - On error, update audit log with failure status and error message, rethrow error for pipeline monitoring

## 6. Complexity Analysis

| Metric                            | Value/Details                                                                 |
|------------------------------------|-------------------------------------------------------------------------------|
| Number of Pipeline Activities      | 1 (single stored procedure, can be invoked by a Synapse pipeline)             |
| Number of Dataflow Transformations | 3 (joins with customer/date, computed column, data quality filters)           |
| SQL Scripts or Stored Procedures   | 1                                                                             |
| Joins Used                        | 2 (INNER JOIN: Dim_Customer, Dim_Date)                                        |
| Lookup Tables or Reference Data    | 2 (Dim_Customer, Dim_Date)                                                    |
| Parameters/Variables/Triggers      | 7 (batch_id, start_time, end_time, rows_inserted, rows_rejected, error_message, proc_name) |
| Number of Output Datasets          | 3 (Fact_Sales, DQ_Failures, Audit_Log)                                        |
| Conditional Logic or if-else Flows | 2 (TRY...CATCH for error handling, DQ checks for row rejection)               |
| External Dependencies              | stg.Sales_Transactions, dw.Dim_Customer, dw.Dim_Date, dw.Audit_Log, dw.DQ_Failures |
| Overall Complexity Score           | 40                                                                            |

## 7. Key Outputs

- **Fact Table:** `dw.Fact_Sales`  
  - Contains validated, enriched, and transformed sales transactions for analytics and reporting.
- **Audit Log:** `dw.Audit_Log`  
  - Tracks batch execution, row counts, status, and error messages for operational monitoring.
- **DQ Failures:** `dw.DQ_Failures`  
  - Stores details of rejected records and reasons for data quality failures.
- **Format:** All outputs are in relational table format (SQL tables), suitable for downstream BI, reporting, or further ETL processing.

---

**API Cost:** apiCost: 0.0025 USD