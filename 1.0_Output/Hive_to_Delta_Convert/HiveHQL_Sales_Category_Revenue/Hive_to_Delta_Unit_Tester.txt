**Test Case List:**

1. **Test Case ID:** TC001  
   **Description:** Verify that the script correctly filters sales data for the last 12 months.  
   **Expected Outcome:** The `FilteredSales` CTE should only include rows where `order_date` is within the last 12 months.

2. **Test Case ID:** TC002  
   **Description:** Validate the join logic between `sales`, `products`, and `regions` tables.  
   **Expected Outcome:** The resulting dataset should have valid `category_id` and `region_id` for each `order_id`.

3. **Test Case ID:** TC003  
   **Description:** Check the calculation of `revenue` in the `FilteredSales` CTE.  
   **Expected Outcome:** The `revenue` column should correctly compute as `quantity * price` for each row.

4. **Test Case ID:** TC004  
   **Description:** Validate the aggregation logic in the `CategoryRevenue` CTE.  
   **Expected Outcome:** The `total_revenue` and `avg_order_value` columns should correctly compute as `SUM(revenue)` and `AVG(revenue)` grouped by `region_id` and `category_id`.

5. **Test Case ID:** TC005  
   **Description:** Verify the ranking logic in the `RankedCategories` CTE.  
   **Expected Outcome:** Categories within each region should be ranked correctly based on `total_revenue` in descending order.

6. **Test Case ID:** TC006  
   **Description:** Ensure that only the top 3 categories per region are selected in the final output.  
   **Expected Outcome:** The final result should only include rows where `category_rank <= 3`.

7. **Test Case ID:** TC007  
   **Description:** Test the script with an empty `sales` table.  
   **Expected Outcome:** The final result should be an empty dataset.

8. **Test Case ID:** TC008  
   **Description:** Test the script with NULL values in `quantity` or `price` columns.  
   **Expected Outcome:** Rows with NULL `quantity` or `price` should not contribute to the `revenue` calculation.

9. **Test Case ID:** TC009  
   **Description:** Test the script with boundary dates (e.g., exactly 12 months ago).  
   **Expected Outcome:** Rows with `order_date` exactly 12 months ago should be included in the `FilteredSales` CTE.

10. **Test Case ID:** TC010  
    **Description:** Validate the script's behavior with duplicate rows in the `sales` table.  
    **Expected Outcome:** The aggregations in `CategoryRevenue` should correctly account for duplicate rows.

---

**Pytest Script:**

```python
import pytest
from pyspark.sql import SparkSession
from pyspark.sql.functions import col
from datetime import datetime, timedelta

@pytest.fixture(scope="module")
def spark():
    return SparkSession.builder \
        .appName("DeltaUnitTests") \
        .master("local[*]") \
        .getOrCreate()

@pytest.fixture
def sales_data(spark):
    data = [
        (1, 101, 201, datetime.now() - timedelta(days=30), 2, 50.0),
        (2, 102, 202, datetime.now() - timedelta(days=400), 1, 100.0),
        (3, 103, 203, datetime.now() - timedelta(days=10), 5, 20.0),
    ]
    schema = ["order_id", "product_id", "region_id", "order_date", "quantity", "price"]
    return spark.createDataFrame(data, schema)

@pytest.fixture
def products_data(spark):
    data = [
        (101, 301),
        (102, 302),
        (103, 303),
    ]
    schema = ["product_id", "category_id"]
    return spark.createDataFrame(data, schema)

@pytest.fixture
def regions_data(spark):
    data = [
        (201, "North"),
        (202, "South"),
        (203, "East"),
    ]
    schema = ["region_id", "region_name"]
    return spark.createDataFrame(data, schema)

def test_filtered_sales(spark, sales_data, products_data, regions_data):
    sales_data.createOrReplaceTempView("sales")
    products_data.createOrReplaceTempView("products")
    regions_data.createOrReplaceTempView("regions")
    
    query = """
    WITH FilteredSales AS (
        SELECT 
            s.order_id,
            s.product_id,
            p.category_id,
            r.region_id,
            s.order_date,
            CAST(s.quantity * s.price AS DECIMAL(10,2)) AS revenue
        FROM sales s
        JOIN products p ON s.product_id = p.product_id
        JOIN regions r ON s.region_id = r.region_id
        WHERE s.order_date >= DATE_ADD(CURRENT_DATE(), -365)
    )
    SELECT * FROM FilteredSales
    """
    result = spark.sql(query)
    assert result.count() == 2  # Only 2 rows should be within the last 12 months

def test_category_revenue(spark, sales_data, products_data, regions_data):
    sales_data.createOrReplaceTempView("sales")
    products_data.createOrReplaceTempView("products")
    regions_data.createOrReplaceTempView("regions")
    
    query = """
    WITH FilteredSales AS (
        SELECT 
            s.order_id,
            s.product_id,
            p.category_id,
            r.region_id,
            s.order_date,
            CAST(s.quantity * s.price AS DECIMAL(10,2)) AS revenue
        FROM sales s
        JOIN products p ON s.product_id = p.product_id
        JOIN regions r ON s.region_id = r.region_id
        WHERE s.order_date >= DATE_ADD(CURRENT_DATE(), -365)
    ),
    CategoryRevenue AS (
        SELECT 
            f.region_id,
            f.category_id,
            SUM(f.revenue) AS total_revenue,
            AVG(f.revenue) AS avg_order_value
        FROM FilteredSales f
        GROUP BY f.region_id, f.category_id
    )
    SELECT * FROM CategoryRevenue
    """
    result = spark.sql(query)
    assert result.count() == 3  # 3 categories should be present
    assert result.filter(col("region_id") == 201).count() == 1  # Validate specific region

# Additional test cases can be implemented similarly for other scenarios.

```

**API Cost:** 0.0012 USD