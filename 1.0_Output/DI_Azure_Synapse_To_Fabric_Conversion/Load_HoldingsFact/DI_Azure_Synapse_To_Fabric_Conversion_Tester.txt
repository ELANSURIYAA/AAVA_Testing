===============================================================================================
Author: Ascendion AAVA
Created on: 
Description: Unit tests and Pytest automation for validating the Fabric SQL ETL logic that loads FACT_EXECUTIVE_SUMMARY from STG_HOLDING_METRICS, ensuring data quality, referential integrity, and business rule enforcement.
===============================================================================================

### Test Case List

| Test Case ID | Test Case                                      | Description                                                                                         | Expected Outcome                                                                                                    |
|--------------|------------------------------------------------|-----------------------------------------------------------------------------------------------------|---------------------------------------------------------------------------------------------------------------------|
| TC01         | Happy Path: Valid Data Insert                  | Insert valid records with all dimension keys present and positive income_amount                      | Records are inserted/updated correctly in FACT_EXECUTIVE_SUMMARY; income_amount as provided                         |
| TC02         | Edge: income_amount NULL                       | Record with income_amount as NULL                                                                   | income_amount is set to 0 in FACT_EXECUTIVE_SUMMARY                                                                 |
| TC03         | Edge: income_amount Negative                   | Record with income_amount < 0                                                                        | income_amount is set to 0 in FACT_EXECUTIVE_SUMMARY                                                                 |
| TC04         | Edge: Empty STG_HOLDING_METRICS                | No records in staging table                                                                         | No new records inserted; row count remains unchanged                                                                |
| TC05         | Error: Missing Dimension Key                   | Record with non-existent dimension key (e.g., institution_id not in DIM_INSTITUTION)                | Record is not inserted; referential integrity enforced                                                              |
| TC06         | Error: Missing Required Column                 | STG_HOLDING_METRICS missing a required column (e.g., a120_amount)                                   | SQL error or ETL fails with missing column error                                                                    |
| TC07         | Edge: Duplicate Source Keys                    | Multiple records in staging with same PK (date_value, institution_id, corporation_id, product_id)   | Only one record per PK in FACT_EXECUTIVE_SUMMARY; upsert/merge logic works as expected                              |
| TC08         | Edge: Boundary Values                          | Records with zero, very large, or very small numeric values                                         | Values are loaded as-is, except for income_amount logic; no overflow or truncation errors                           |
| TC09         | Error: Invalid Data Types                      | Record with wrong data type (e.g., string in numeric field)                                         | SQL error or ETL fails with type error                                                                              |
| TC10         | Audit Logging                                  | Validate row count logging after ETL                                                                | inserted_row_count matches number of records processed from staging table                                           |

---

### Pytest Script


import pytest
import pandas as pd
from sqlalchemy import create_engine, text
from sqlalchemy.exc import ProgrammingError, DataError

# Helper function to create test tables and insert mock data
def setup_dimension_tables(conn):
    conn.execute(text("DROP TABLE IF EXISTS dbo.DIM_DATE"))
    conn.execute(text("DROP TABLE IF EXISTS dbo.DIM_INSTITUTION"))
    conn.execute(text("DROP TABLE IF EXISTS dbo.DIM_CORPORATION"))
    conn.execute(text("DROP TABLE IF EXISTS dbo.DIM_PRODUCT"))
    conn.execute(text("DROP TABLE IF EXISTS dbo.FACT_EXECUTIVE_SUMMARY"))
    conn.execute(text("DROP TABLE IF EXISTS dbo.STG_HOLDING_METRICS"))

    conn.execute(text("""
        CREATE TABLE dbo.DIM_DATE (date_key INT PRIMARY KEY)
    """))
    conn.execute(text("""
        CREATE TABLE dbo.DIM_INSTITUTION (institution_id INT PRIMARY KEY)
    """))
    conn.execute(text("""
        CREATE TABLE dbo.DIM_CORPORATION (corporation_id INT PRIMARY KEY)
    """))
    conn.execute(text("""
        CREATE TABLE dbo.DIM_PRODUCT (product_id INT PRIMARY KEY)
    """))
    conn.execute(text("""
        CREATE TABLE dbo.FACT_EXECUTIVE_SUMMARY (
            date_key INT,
            institution_id INT,
            corporation_id INT,
            product_id INT,
            a120_amount FLOAT,
            a120_count INT,
            a30_to_59_amount FLOAT,
            a30_to_59_count INT,
            a60_to_89_amount FLOAT,
            a60_to_89_count INT,
            a90_to_119_amount FLOAT,
            a90_to_119_count INT,
            charge_off_amount FLOAT,
            charge_off_count INT,
            fraud_amount FLOAT,
            fraud_count INT,
            income_amount FLOAT,
            number_of_accounts INT,
            purchases_amount FLOAT,
            purchases_count INT,
            PRIMARY KEY (date_key, institution_id, corporation_id, product_id)
        )
    """))
    conn.execute(text("""
        CREATE TABLE dbo.STG_HOLDING_METRICS (
            date_value INT,
            institution_id INT,
            corporation_id INT,
            product_id INT,
            a120_amount FLOAT,
            a120_count INT,
            a30_to_59_amount FLOAT,
            a30_to_59_count INT,
            a60_to_89_amount FLOAT,
            a60_to_89_count INT,
            a90_to_119_amount FLOAT,
            a90_to_119_count INT,
            charge_off_amount FLOAT,
            charge_off_count INT,
            fraud_amount FLOAT,
            fraud_count INT,
            income_amount FLOAT,
            number_of_accounts INT,
            purchases_amount FLOAT,
            purchases_count INT
        )
    """))

def truncate_tables(conn):
    conn.execute(text("DELETE FROM dbo.FACT_EXECUTIVE_SUMMARY"))
    conn.execute(text("DELETE FROM dbo.STG_HOLDING_METRICS"))

def insert_dimension_data(conn):
    conn.execute(text("INSERT INTO dbo.DIM_DATE VALUES (20230101), (20230102)"))
    conn.execute(text("INSERT INTO dbo.DIM_INSTITUTION VALUES (1), (2)"))
    conn.execute(text("INSERT INTO dbo.DIM_CORPORATION VALUES (10), (20)"))
    conn.execute(text("INSERT INTO dbo.DIM_PRODUCT VALUES (100), (200)"))

# Simulate the Fabric SQL ETL logic in Python for testing
def run_fabric_etl(conn):
    # Step 1: staging_metrics CTE
    stg_df = pd.read_sql("SELECT * FROM dbo.STG_HOLDING_METRICS", conn)
    if stg_df.empty:
        return

    # Step 2: Join with dimensions, apply business rules
    dim_date = pd.read_sql("SELECT * FROM dbo.DIM_DATE", conn)
    dim_inst = pd.read_sql("SELECT * FROM dbo.DIM_INSTITUTION", conn)
    dim_corp = pd.read_sql("SELECT * FROM dbo.DIM_CORPORATION", conn)
    dim_prod = pd.read_sql("SELECT * FROM dbo.DIM_PRODUCT", conn)

    merged = stg_df.merge(dim_date, left_on='date_value', right_on='date_key') \
                   .merge(dim_inst, left_on='institution_id', right_on='institution_id') \
                   .merge(dim_corp, left_on='corporation_id', right_on='corporation_id') \
                   .merge(dim_prod, left_on='product_id', right_on='product_id')

    if merged.empty:
        return

    # Apply income_amount business rule
    merged['income_amount'] = merged['income_amount'].apply(
        lambda x: 0 if pd.isnull(x) or x < 0 else x
    )

    # Prepare final columns
    fact_cols = [
        'date_key', 'institution_id', 'corporation_id', 'product_id',
        'a120_amount', 'a120_count', 'a30_to_59_amount', 'a30_to_59_count',
        'a60_to_89_amount', 'a60_to_89_count', 'a90_to_119_amount', 'a90_to_119_count',
        'charge_off_amount', 'charge_off_count', 'fraud_amount', 'fraud_count',
        'income_amount', 'number_of_accounts', 'purchases_amount', 'purchases_count'
    ]
    fact_df = merged[fact_cols]

    # Upsert logic (simulate Delta Lake MERGE)
    for _, row in fact_df.iterrows():
        pk = (row['date_key'], row['institution_id'], row['corporation_id'], row['product_id'])
        exists = pd.read_sql(
            f"SELECT COUNT(*) as cnt FROM dbo.FACT_EXECUTIVE_SUMMARY WHERE date_key={pk[0]} AND institution_id={pk[1]} AND corporation_id={pk[2]} AND product_id={pk[3]}",
            conn
        )['cnt'][0]
        if exists:
            # Update
            set_clause = ", ".join([f"{col} = {repr(row[col])}" for col in fact_cols[4:]])
            conn.execute(text(f"""
                UPDATE dbo.FACT_EXECUTIVE_SUMMARY
                SET {set_clause}
                WHERE date_key={pk[0]} AND institution_id={pk[1]} AND corporation_id={pk[2]} AND product_id={pk[3]}
            """))
        else:
            # Insert
            values = ", ".join([repr(row[col]) for col in fact_cols])
            conn.execute(text(f"""
                INSERT INTO dbo.FACT_EXECUTIVE_SUMMARY ({', '.join(fact_cols)})
                VALUES ({values})
            """))

@pytest.fixture(scope="function")
def db_engine():
    # Use SQLite in-memory for demonstration; replace with actual SQL Server/Fabric connection in production
    engine = create_engine("sqlite:///:memory:", echo=False)
    with engine.connect() as conn:
        setup_dimension_tables(conn)
        insert_dimension_data(conn)
        yield conn
        truncate_tables(conn)

def test_TC01_happy_path_valid_data_insert(db_engine):
    conn = db_engine
    truncate_tables(conn)
    insert_dimension_data(conn)
    # Insert valid staging record
    conn.execute(text("""
        INSERT INTO dbo.STG_HOLDING_METRICS VALUES (
            20230101, 1, 10, 100, 1000.0, 5, 200.0, 2, 300.0, 3, 400.0, 4,
            500.0, 1, 600.0, 1, 700.0, 10, 800.0, 8
        )
    """))
    run_fabric_etl(conn)
    df = pd.read_sql("SELECT * FROM dbo.FACT_EXECUTIVE_SUMMARY", conn)
    assert len(df) == 1
    assert df.iloc[0]['income_amount'] == 700.0

def test_TC02_edge_income_amount_null(db_engine):
    conn = db_engine
    truncate_tables(conn)
    insert_dimension_data(conn)
    # Insert record with income_amount NULL
    conn.execute(text("""
        INSERT INTO dbo.STG_HOLDING_METRICS (
            date_value, institution_id, corporation_id, product_id,
            a120_amount, a120_count, a30_to_59_amount, a30_to_59_count,
            a60_to_89_amount, a60_to_89_count, a90_to_119_amount, a90_to_119_count,
            charge_off_amount, charge_off_count, fraud_amount, fraud_count,
            income_amount, number_of_accounts, purchases_amount, purchases_count
        ) VALUES (
            20230101, 1, 10, 100, 1000.0, 5, 200.0, 2, 300.0, 3, 400.0, 4,
            500.0, 1, 600.0, 1, NULL, 10, 800.0, 8
        )
    """))
    run_fabric_etl(conn)
    df = pd.read_sql("SELECT * FROM dbo.FACT_EXECUTIVE_SUMMARY", conn)
    assert len(df) == 1
    assert df.iloc[0]['income_amount'] == 0

def test_TC03_edge_income_amount_negative(db_engine):
    conn = db_engine
    truncate_tables(conn)
    insert_dimension_data(conn)
    # Insert record with income_amount negative
    conn.execute(text("""
        INSERT INTO dbo.STG_HOLDING_METRICS VALUES (
            20230101, 1, 10, 100, 1000.0, 5, 200.0, 2, 300.0, 3, 400.0, 4,
            500.0, 1, 600.0, 1, -50.0, 10, 800.0, 8
        )
    """))
    run_fabric_etl(conn)
    df = pd.read_sql("SELECT * FROM dbo.FACT_EXECUTIVE_SUMMARY", conn)
    assert len(df) == 1
    assert df.iloc[0]['income_amount'] == 0

def test_TC04_edge_empty_staging(db_engine):
    conn = db_engine
    truncate_tables(conn)
    insert_dimension_data(conn)
    # No records in staging
    run_fabric_etl(conn)
    df = pd.read_sql("SELECT * FROM dbo.FACT_EXECUTIVE_SUMMARY", conn)
    assert len(df) == 0

def test_TC05_error_missing_dimension_key(db_engine):
    conn = db_engine
    truncate_tables(conn)
    insert_dimension_data(conn)
    # Insert record with non-existent institution_id
    conn.execute(text("""
        INSERT INTO dbo.STG_HOLDING_METRICS VALUES (
            20230101, 999, 10, 100, 1000.0, 5, 200.0, 2, 300.0, 3, 400.0, 4,
            500.0, 1, 600.0, 1, 700.0, 10, 800.0, 8
        )
    """))
    run_fabric_etl(conn)
    df = pd.read_sql("SELECT * FROM dbo.FACT_EXECUTIVE_SUMMARY", conn)
    assert len(df) == 0

def test_TC06_error_missing_required_column(db_engine):
    conn = db_engine
    truncate_tables(conn)
    insert_dimension_data(conn)
    # Drop a required column
    conn.execute(text("ALTER TABLE dbo.STG_HOLDING_METRICS DROP COLUMN a120_amount"))
    with pytest.raises((ProgrammingError, KeyError)):
        run_fabric_etl(conn)

def test_TC07_edge_duplicate_source_keys(db_engine):
    conn = db_engine
    truncate_tables(conn)
    insert_dimension_data(conn)
    # Insert duplicate PK records in staging
    conn.execute(text("""
        INSERT INTO dbo.STG_HOLDING_METRICS VALUES (
            20230101, 1, 10, 100, 1000.0, 5, 200.0, 2, 300.0, 3, 400.0, 4,
            500.0, 1, 600.0, 1, 700.0, 10, 800.0, 8
        )
    """))
    conn.execute(text("""
        INSERT INTO dbo.STG_HOLDING_METRICS VALUES (
            20230101, 1, 10, 100, 9999.0, 9, 888.0, 8, 777.0, 7, 666.0, 6,
            555.0, 5, 444.0, 4, 333.0, 3, 222.0, 2
        )
    """))
    run_fabric_etl(conn)
    df = pd.read_sql("SELECT * FROM dbo.FACT_EXECUTIVE_SUMMARY", conn)
    # Only one record for the PK, with the last upserted values
    assert len(df) == 1
    assert df.iloc[0]['a120_amount'] in (1000.0, 9999.0)  # Upsert logic may take last or first, depending on implementation

def test_TC08_edge_boundary_values(db_engine):
    conn = db_engine
    truncate_tables(conn)
    insert_dimension_data(conn)
    # Insert record with boundary values
    conn.execute(text("""
        INSERT INTO dbo.STG_HOLDING_METRICS VALUES (
            20230101, 1, 10, 100, 0.0, 0, 1e10, 1, -1e10, 2, 999999999, 3,
            0.0, 0, 0.0, 0, 0.0, 0, 0.0, 0
        )
    """))
    run_fabric_etl(conn)
    df = pd.read_sql("SELECT * FROM dbo.FACT_EXECUTIVE_SUMMARY", conn)
    assert len(df) == 1
    assert df.iloc[0]['a120_amount'] == 0.0
    assert df.iloc[0]['a60_to_89_amount'] == -1e10

def test_TC09_error_invalid_data_types(db_engine):
    conn = db_engine
    truncate_tables(conn)
    insert_dimension_data(conn)
    # Insert record with string in numeric field
    with pytest.raises((ProgrammingError, DataError, ValueError)):
        conn.execute(text("""
            INSERT INTO dbo.STG_HOLDING_METRICS VALUES (
                20230101, 1, 10, 100, 'bad_data', 5, 200.0, 2, 300.0, 3, 400.0, 4,
                500.0, 1, 600.0, 1, 700.0, 10, 800.0, 8
            )
        """))
        run_fabric_etl(conn)

def test_TC10_audit_logging_row_count(db_engine):
    conn = db_engine
    truncate_tables(conn)
    insert_dimension_data(conn)
    # Insert two records
    conn.execute(text("""
        INSERT INTO dbo.STG_HOLDING_METRICS VALUES (
            20230101, 1, 10, 100, 1000.0, 5, 200.0, 2, 300.0, 3, 400.0, 4,
            500.0, 1, 600.0, 1, 700.0, 10, 800.0, 8
        )
    """))
    conn.execute(text("""
        INSERT INTO dbo.STG_HOLDING_METRICS VALUES (
            20230102, 2, 20, 200, 2000.0, 10, 400.0, 4, 600.0, 6, 800.0, 8,
            1000.0, 2, 1200.0, 2, 1400.0, 20, 1600.0, 16
        )
    """))
    run_fabric_etl(conn)
    # Simulate audit logging
    stg_dates = pd.read_sql("SELECT DISTINCT date_value FROM dbo.STG_HOLDING_METRICS", conn)['date_value'].tolist()
    placeholders = ",".join(str(d) for d in stg_dates)
    df = pd.read_sql(f"SELECT COUNT(*) as cnt FROM dbo.FACT_EXECUTIVE_SUMMARY WHERE date_key IN ({placeholders})", conn)
    assert df['cnt'][0] == 2


---

### API Cost Estimation


apiCost: 0.0047 USD