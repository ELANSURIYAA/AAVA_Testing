====================================================
Author:        AAVA
Date:          2024-06-12
Description:   Documentation for Retail_Data_Mart_Ingest Ab Initio Graph
====================================================

# Retail_Data_Mart_Ingest Ab Initio Graph Documentation

## 1. Overview of Graph/Component

The `Retail_Data_Mart_Ingest.mp` Ab Initio graph is designed to ingest, cleanse, enrich, and aggregate daily retail transaction data for a data mart. It reads raw transaction data from AWS S3, applies cleansing and validation, deduplicates records, enriches with product dimension data, applies pricing rules, aggregates by store and date, and outputs both summary and error datasets. The graph supports robust error handling and lineage tracking for regulatory and business audit requirements.

## 2. Component Structure and Design

- **Input Components:**
  - `Read_AWS_S3`: Reads raw transaction data from S3.
  - `Read_Product_Dim`: Reads product dimension data from local project directory.

- **Processing Components:**
  - `Cleanse_Data`: Reformat using `cleanse_validate.xfr` for cleansing/validation.
  - `Dedup_Transactions`: Deduplicates transactions on `txn_id`.
  - `Enrichment_Join`: Inner join with product dimension on `product_sku`.
  - `Apply_Pricing`: Reformat using `pricing_rules.xfr` to apply pricing logic.
  - `Sort_for_Rollup`: Sorts by `store_id, txn_date` for aggregation.
  - `Store_Aggregation`: Rollup using `store_rollup.xfr` for store-level summary.

- **Output Components:**
  - `Write_Summary`: Outputs the final daily summary.
  - `Write_Cleanse_Rejects`: Logs records rejected during cleansing.
  - `Write_Product_Misses`: Logs records missing product lookup.

- **Connection Flow:**
  - Raw data flows through cleansing, deduplication, enrichment, pricing, sorting, and aggregation, with rejects and misses branched off to their respective logs.
  - Parameters and variables are used for file paths, DML/XFR references, and error log locations.

## 3. Data Flow and Processing Logic

- **Processed Datasets:**
  - Input: `transactions_raw.dat`, `product_dim.dat`
  - Intermediate: `retail_txn_enriched.dml`
  - Output: `daily_summary.dat`, `rejects.log`, `product_misses.dat`

- **Data Flow:**
  1. **Ingestion:** Raw transactions are read from S3; product dimension from local.
  2. **Cleansing:** Transactions are validated and cleansed; rejects are logged.
  3. **Deduplication:** Duplicate transactions are removed.
  4. **Enrichment:** Transactions are joined with product dimension; misses are logged.
  5. **Pricing:** Pricing rules are applied.
  6. **Sorting:** Data is sorted for aggregation.
  7. **Aggregation:** Store/date-level rollup is performed.
  8. **Output:** Final summary, rejects, and lookup misses are written to output files.

- **Business Rules/Transformations:**
  - Cleansing and validation via `cleanse_validate.xfr`
  - Pricing logic via `pricing_rules.xfr`
  - Aggregation via `store_rollup.xfr`
  - Deduplication on `txn_id`
  - Enrichment join on `product_sku`

## 4. Data Mapping (Lineage)

| Target Table             | Target Column    | Source Table           | Source Column    | Remarks                       |
|------------------------- |-----------------|------------------------|------------------|-------------------------------|
| daily_summary.dat        | store_id        | transactions_raw.dat   | store_id         | 1:1 Mapping                   |
| daily_summary.dat        | txn_date        | transactions_raw.dat   | txn_date         | 1:1 Mapping                   |
| daily_summary.dat        | total_sales     | transactions_raw.dat   | amount           | Aggregation (SUM)             |
| daily_summary.dat        | category        | product_dim.dat        | category         | Enrichment via Join           |
| daily_summary.dat        | standard_cost   | product_dim.dat        | standard_cost    | Enrichment via Join           |
| daily_summary.dat        | price           | transactions_raw.dat   | amount           | Transformation (pricing_rules.xfr) |
| product_misses.dat       | *               | transactions_raw.dat   | *                | Validation (no product match) |
| rejects.log              | *               | transactions_raw.dat   | *                | Validation (cleansing error)  |

## 5. Transformation Logic

- **cleanse_validate.xfr:** 
  - Validates transaction fields (e.g., date, amount, store_id).
  - Tags errors and routes invalid records to reject.
  - Fields: All transaction fields.

- **pricing_rules.xfr:**
  - Applies business pricing logic (discounts, markups).
  - Calculates final price.
  - Fields: amount, product_sku, category, standard_cost.

- **store_rollup.xfr:**
  - Aggregates transactions by store and date.
  - Sums sales, counts transactions, calculates averages.
  - Fields: store_id, txn_date, total_sales, txn_count.

- **Join Transform:**
  - Maps product attributes to transaction records.
  - out.* :: in0.*; out.category :: in1.category; out.standard_cost :: in1.standard_cost;

## 6. Complexity Analysis

- **Number of Graph Components:** 11
- **Number of Lines of Code (in .xfr or .plan):** ~300 (estimated from .mp and XFR references)
- **Transform Functions Used:** 3 (cleanse_validate.xfr, pricing_rules.xfr, store_rollup.xfr)
- **Joins Used:** 1 (Inner Join)
- **Lookup Files or Datasets:** 1 (product_dim.dat)
- **Parameter Sets (.pset) or Plan Files Used:** 0
- **Number of Output Datasets:** 3 (daily_summary.dat, rejects.log, product_misses.dat)
- **Conditional Logic or if-else flows:** 2 (cleansing reject, product miss)
- **External Dependencies:** AWS S3, Shell path variables, Ab Initio built-in components
- **Overall Complexity Score:** 68

## 7. Key Outputs

- **daily_summary.dat:** Delimited file containing aggregated store-level sales summaries for reporting and downstream analytics.
- **rejects.log:** Delimited or fixed-width log of records rejected during cleansing, for audit and troubleshooting.
- **product_misses.dat:** Delimited file of records with missing product dimension, for data quality monitoring.

## 8. Error Handling and Logging

- **Reject Handling:** 
  - `Write_Cleanse_Rejects` logs records rejected during cleansing (validation errors).
  - `Write_Product_Misses` logs records that fail product dimension lookup.
- **Error Tagging:** 
  - .xfr-based error tagging in cleansing and join steps.
- **Abort/Alert:** 
  - No explicit auto-abort; errors are logged for downstream review.
- **Control Files:** 
  - Not used in this graph.

## 9. API Cost (LLM Cost ONLY)

- **Tokens Used (Prompt + Completion):** 5300
- **Cost per 1K tokens:** $0.003
- **Final Cost in USD for this single documentation run:** $0.0159

---